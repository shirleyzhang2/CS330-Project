{"run_name": "output/textual_entailment_first10/tk-instruct-base-def-pos/", "predict_loss": 0.5684033036231995, "predict_exact_match": 31.1, "predict_rouge1": 36.2667, "predict_rougeL": 36.2667, "predict_exact_match_for_task937_defeasible_nli_social_classification": 45.0, "predict_rouge1_for_task937_defeasible_nli_social_classification": 45.0, "predict_rougeL_for_task937_defeasible_nli_social_classification": 45.0, "predict_exact_match_for_task202_mnli_contradiction_classification": 32.0, "predict_rouge1_for_task202_mnli_contradiction_classification": 32.0, "predict_rougeL_for_task202_mnli_contradiction_classification": 32.0, "predict_exact_match_for_task936_defeasible_nli_snli_classification": 29.0, "predict_rouge1_for_task936_defeasible_nli_snli_classification": 29.0, "predict_rougeL_for_task936_defeasible_nli_snli_classification": 29.0, "predict_exact_match_for_task641_esnli_classification": 33.0, "predict_rouge1_for_task641_esnli_classification": 33.0, "predict_rougeL_for_task641_esnli_classification": 33.0, "predict_exact_match_for_task1344_glue_entailment_classification": 50.0, "predict_rouge1_for_task1344_glue_entailment_classification": 50.0, "predict_rougeL_for_task1344_glue_entailment_classification": 50.0, "predict_exact_match_for_task1615_sick_tclassify_b_relation_a": 42.0, "predict_rouge1_for_task1615_sick_tclassify_b_relation_a": 80.6667, "predict_rougeL_for_task1615_sick_tclassify_b_relation_a": 80.6667, "predict_exact_match_for_task1385_anli_r1_entailment": 21.0, "predict_rouge1_for_task1385_anli_r1_entailment": 31.0, "predict_rougeL_for_task1385_anli_r1_entailment": 31.0, "predict_exact_match_for_task935_defeasible_nli_atomic_classification": 5.0, "predict_rouge1_for_task935_defeasible_nli_atomic_classification": 5.0, "predict_rougeL_for_task935_defeasible_nli_atomic_classification": 5.0, "predict_exact_match_for_task199_mnli_classification": 32.0, "predict_rouge1_for_task199_mnli_classification": 32.0, "predict_rougeL_for_task199_mnli_classification": 32.0, "predict_exact_match_for_task1388_cb_entailment": 22.0, "predict_rouge1_for_task1388_cb_entailment": 25.0, "predict_rougeL_for_task1388_cb_entailment": 25.0, "predict_exact_match_for_textual_entailment": 31.1, "predict_rouge1_for_textual_entailment": 36.2667, "predict_rougeL_for_textual_entailment": 36.2667, "predict_gen_len": 3.374, "predict_global_step": 0, "predict_runtime": 101.9872, "predict_samples_per_second": 9.805, "predict_steps_per_second": 2.451, "predict_samples": 1000}