{
    "predict_exact_match": 40.125,
    "predict_exact_match_for_task1344_glue_entailment_classification_gpt3_0": 50.0,
    "predict_exact_match_for_task1385_anli_r1_entailment_gpt3_0": 34.0,
    "predict_exact_match_for_task1386_anli_r2_entailment_gpt3_0": 36.0,
    "predict_exact_match_for_task1387_anli_r3_entailment_gpt3_0": 34.0,
    "predict_exact_match_for_task1388_cb_entailment_gpt3_0": 23.0,
    "predict_exact_match_for_task1516_imppres_naturallanguageinference_gpt3_0": 9.0,
    "predict_exact_match_for_task1529_scitail1.1_classification_gpt3_0": 50.0,
    "predict_exact_match_for_task1554_scitail_classification_gpt3_0": 50.0,
    "predict_exact_match_for_task1612_sick_label_classification_gpt3_0": 33.0,
    "predict_exact_match_for_task1615_sick_tclassify_b_relation_a_gpt3_0": 36.0,
    "predict_exact_match_for_task190_snli_classification_gpt3_0": 50.0,
    "predict_exact_match_for_task199_mnli_classification_gpt3_0": 50.0,
    "predict_exact_match_for_task200_mnli_entailment_classification_gpt3_0": 33.0,
    "predict_exact_match_for_task201_mnli_neutral_classification_gpt3_0": 32.0,
    "predict_exact_match_for_task202_mnli_contradiction_classification_gpt3_0": 31.0,
    "predict_exact_match_for_task640_esnli_classification_gpt3_0": 31.0,
    "predict_exact_match_for_task641_esnli_classification_gpt3_0": 35.0,
    "predict_exact_match_for_task642_esnli_classification_gpt3_0": 50.0,
    "predict_exact_match_for_task738_perspectrum_classification_gpt3_0": 57.0,
    "predict_exact_match_for_task890_gcwd_classification_gpt3_0": 35.0,
    "predict_exact_match_for_task935_defeasible_nli_atomic_classification_gpt3_0": 51.0,
    "predict_exact_match_for_task936_defeasible_nli_snli_classification_gpt3_0": 50.0,
    "predict_exact_match_for_task937_defeasible_nli_social_classification_gpt3_0": 51.0,
    "predict_exact_match_for_task970_sherliic_causal_relationship_gpt3_0": 52.0,
    "predict_exact_match_for_textual_entailment": 40.125,
    "predict_gen_len": 3.1371,
    "predict_global_step": 0,
    "predict_loss": 0.8635068535804749,
    "predict_rouge1": 41.9179,
    "predict_rouge1_for_task1344_glue_entailment_classification_gpt3_0": 50.0,
    "predict_rouge1_for_task1385_anli_r1_entailment_gpt3_0": 34.0,
    "predict_rouge1_for_task1386_anli_r2_entailment_gpt3_0": 36.0,
    "predict_rouge1_for_task1387_anli_r3_entailment_gpt3_0": 34.0,
    "predict_rouge1_for_task1388_cb_entailment_gpt3_0": 23.0,
    "predict_rouge1_for_task1516_imppres_naturallanguageinference_gpt3_0": 9.0,
    "predict_rouge1_for_task1529_scitail1.1_classification_gpt3_0": 50.0,
    "predict_rouge1_for_task1554_scitail_classification_gpt3_0": 50.0,
    "predict_rouge1_for_task1612_sick_label_classification_gpt3_0": 33.0,
    "predict_rouge1_for_task1615_sick_tclassify_b_relation_a_gpt3_0": 78.6667,
    "predict_rouge1_for_task190_snli_classification_gpt3_0": 50.0,
    "predict_rouge1_for_task199_mnli_classification_gpt3_0": 50.0,
    "predict_rouge1_for_task200_mnli_entailment_classification_gpt3_0": 33.0,
    "predict_rouge1_for_task201_mnli_neutral_classification_gpt3_0": 32.3624,
    "predict_rouge1_for_task202_mnli_contradiction_classification_gpt3_0": 31.0,
    "predict_rouge1_for_task640_esnli_classification_gpt3_0": 31.0,
    "predict_rouge1_for_task641_esnli_classification_gpt3_0": 35.0,
    "predict_rouge1_for_task642_esnli_classification_gpt3_0": 50.0,
    "predict_rouge1_for_task738_perspectrum_classification_gpt3_0": 57.0,
    "predict_rouge1_for_task890_gcwd_classification_gpt3_0": 35.0,
    "predict_rouge1_for_task935_defeasible_nli_atomic_classification_gpt3_0": 51.0,
    "predict_rouge1_for_task936_defeasible_nli_snli_classification_gpt3_0": 50.0,
    "predict_rouge1_for_task937_defeasible_nli_social_classification_gpt3_0": 51.0,
    "predict_rouge1_for_task970_sherliic_causal_relationship_gpt3_0": 52.0,
    "predict_rouge1_for_textual_entailment": 41.9179,
    "predict_rougeL": 41.9179,
    "predict_rougeL_for_task1344_glue_entailment_classification_gpt3_0": 50.0,
    "predict_rougeL_for_task1385_anli_r1_entailment_gpt3_0": 34.0,
    "predict_rougeL_for_task1386_anli_r2_entailment_gpt3_0": 36.0,
    "predict_rougeL_for_task1387_anli_r3_entailment_gpt3_0": 34.0,
    "predict_rougeL_for_task1388_cb_entailment_gpt3_0": 23.0,
    "predict_rougeL_for_task1516_imppres_naturallanguageinference_gpt3_0": 9.0,
    "predict_rougeL_for_task1529_scitail1.1_classification_gpt3_0": 50.0,
    "predict_rougeL_for_task1554_scitail_classification_gpt3_0": 50.0,
    "predict_rougeL_for_task1612_sick_label_classification_gpt3_0": 33.0,
    "predict_rougeL_for_task1615_sick_tclassify_b_relation_a_gpt3_0": 78.6667,
    "predict_rougeL_for_task190_snli_classification_gpt3_0": 50.0,
    "predict_rougeL_for_task199_mnli_classification_gpt3_0": 50.0,
    "predict_rougeL_for_task200_mnli_entailment_classification_gpt3_0": 33.0,
    "predict_rougeL_for_task201_mnli_neutral_classification_gpt3_0": 32.3624,
    "predict_rougeL_for_task202_mnli_contradiction_classification_gpt3_0": 31.0,
    "predict_rougeL_for_task640_esnli_classification_gpt3_0": 31.0,
    "predict_rougeL_for_task641_esnli_classification_gpt3_0": 35.0,
    "predict_rougeL_for_task642_esnli_classification_gpt3_0": 50.0,
    "predict_rougeL_for_task738_perspectrum_classification_gpt3_0": 57.0,
    "predict_rougeL_for_task890_gcwd_classification_gpt3_0": 35.0,
    "predict_rougeL_for_task935_defeasible_nli_atomic_classification_gpt3_0": 51.0,
    "predict_rougeL_for_task936_defeasible_nli_snli_classification_gpt3_0": 50.0,
    "predict_rougeL_for_task937_defeasible_nli_social_classification_gpt3_0": 51.0,
    "predict_rougeL_for_task970_sherliic_causal_relationship_gpt3_0": 52.0,
    "predict_rougeL_for_textual_entailment": 41.9179,
    "predict_runtime": 110.4896,
    "predict_samples": 2400,
    "predict_samples_per_second": 21.722,
    "predict_steps_per_second": 5.43
}