{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-12e56ee29fdb4fb5a322cf03b0fcc16b", "input": "\u0646\u0628\u0631\u062f \u0633\u0627\u0644\u0627\u0645\u06cc\u0633 \u0646\u0627\u0645 \u0633\u0648\u0645\u06cc\u0646 \u0646\u0628\u0631\u062f\u060c \u0627\u0632 \u0633\u0631\u06cc \u062f\u0648\u0645\u06cc\u0646 \u062f\u0648\u0631\u0647 \u062c\u0646\u06af\u200c\u0647\u0627\u06cc \u0627\u06cc\u0631\u0627\u0646 \u0648 \u06cc\u0648\u0646\u0627\u0646 \u0627\u0633\u062a. \u06a9\u0647 \u0627\u0632 \u0633\u0627\u0644 \u06f4\u06f7\u06f9 \u062a\u0627 \u06f4\u06f8\u06f0 \u067e\u06cc\u0634 \u0627\u0632 \u0645\u06cc\u0644\u0627\u062f\u060c \u0628\u06cc\u0646 \u062e\u0634\u0627\u06cc\u0627\u0631\u0634\u0627\u0647 \u0648 \u062f\u0648\u0644\u062a \u06cc\u0648\u0646\u0627\u0646\u06cc \u0631\u062e \u062f\u0627\u062f. \n\u0646\u0628\u0631\u062f \u0633\u0627\u0644\u0627\u0645\u06cc\u0633 \u062f\u0631 \u0639\u0647\u062f \u062e\u0634\u0627\u06cc\u0627\u0631\u0634\u0627\u0647 \u0631\u062e \u062f\u0627\u062f.", "output": ["E"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-fe24dccec5eb41d4b06be2087c543210", "input": "\u062f\u0627\u0633\u062a\u0627\u0646 \u0628\u06cc\u0698\u0646 \u0648 \u0645\u0646\u06cc\u0698\u0647 \u06cc\u06a9\u06cc \u0627\u0632 \u062f\u0627\u0633\u062a\u0627\u0646\u200c\u0647\u0627\u06cc \u0645\u0639\u0631\u0648\u0641 \u06a9\u062a\u0627\u0628 \u0634\u0627\u0647\u0646\u0627\u0645\u0647\u060c \u06a9\u062a\u0627\u0628 \u062d\u0645\u0627\u0633\u06cc \u0627\u06cc\u0631\u0627\u0646\u06cc\u0627\u0646 \u0627\u0633\u062a. \u0627\u06cc\u0646 \u062f\u0627\u0633\u062a\u0627\u0646 \u0631\u0648\u0627\u06cc\u062a \u0639\u0634\u0642 \u0628\u06cc\u0698\u0646 \u067e\u0633\u0631 \u06af\u06cc\u0648 \u0648 \u0645\u0646\u06cc\u0698\u0647 \u062f\u062e\u062a\u0631 \u0627\u0641\u0631\u0627\u0633\u06cc\u0627\u0628 \u0627\u0633\u062a.\n\u062c\u0645\u0634\u06cc\u062f \u0635\u062f\u0627\u0642\u062a \u0646\u0698\u0627\u062f \u060c\u062f\u0627\u0633\u062a\u0627\u0646\"\u0628\u06cc\u0698\u0646 \u0648 \u0645\u0646\u06cc\u0698\u0647\" \u0631\u0627 \u0628\u0647 \u0646\u062b\u0631 \u0628\u0631\u06af\u0631\u062f\u0627\u0646\u062f\u0647 \u0627\u0633\u062a.", "output": ["N"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-ae59a5e6f20348e2b6ede2969b796315", "input": " \u062f\u0631 \u0627\u0631\u062f\u06cc\u0628\u0647\u0634\u062a \u0645\u0627\u0647 \u06f1\u06f3\u06f2\u06f8\u060c \u0645\u062c\u0644\u0633 \u0645\u0624\u0633\u0633\u0627\u0646 \u0628\u0647 \u0645\u0646\u0638\u0648\u0631 \u062a\u0642\u0648\u06cc\u062a \u0633\u0644\u0637\u0646\u062a \u0648 \u0627\u0633\u062a\u0642\u0631\u0627\u0631 \u062d\u0627\u06a9\u0645\u06cc\u062a \u0634\u0627\u0647 \u0648 \u0628\u0627\u0632\u06af\u0634\u062a \u0628\u0647 \u062f\u0648\u0631\u0627\u0646 \u062f\u06cc\u06a9\u062a\u0627\u062a\u0648\u0631\u06cc \u0642\u0628\u0644 \u0627\u0632 \u0633\u0627\u0644 \u06f1\u06f3\u06f2\u06f0 \u0648 \u062a\u0636\u0639\u06cc\u0641 \u062d\u0642\u0648\u0642 \u0645\u0644\u062a \u0628\u0647 \u062f\u0633\u062a\u0648\u0631 \u0634\u0627\u0647 \u062a\u0634\u06a9\u06cc\u0644 \u0634\u062f.\n\u0628\u0631\u0627\u06cc \u062a\u0642\u0648\u06cc\u062a \u0648 \u0627\u0633\u062a\u0642\u0631\u0627\u0631 \u0633\u0644\u0637\u0646\u062a \u0648 \u062d\u0627\u06a9\u0645\u06cc\u062a \u0645\u062c\u0644\u0633 \u0633\u0646\u0627 \u0628\u0647 \u062f\u0633\u062a\u0648\u0631 \u0645\u062d\u0645\u062f\u0631\u0636\u0627 \u0634\u0627\u0647 \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f3\u06f2\u06f8 \u0634\u06a9\u0644 \u06af\u0631\u0641\u062a.", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-ac750cd9883245a483a481e2dda8a4ef", "input": "\u0628\u0627 \u0641\u0631\u0648\u067e\u0627\u0634\u06cc \u0634\u0648\u0631\u0648\u06cc \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f9\u06f9\u06f1 \u0645\u06cc\u0644\u0627\u062f\u06cc \u0648 \u067e\u0627\u06cc\u0627\u0646 \u062c\u0646\u06af \u0633\u0631\u062f \u06a9\u0627\u0631\u0634\u0646\u0627\u0633\u0627\u0646 \u0628\u062e\u0634 \u062c\u0646\u06af \u062f\u0631 \u0627\u06cc\u0627\u0644\u0627\u062a \u0645\u062a\u062d\u062f\u0647 \u0628\u0627 \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u0627\u0632 \u062a\u062c\u0627\u0631\u0628 \u062f\u0648 \u062c\u0646\u06af \u062c\u0647\u0627\u0646\u06cc \u0648 \u062f\u0648\u0631\u0627\u0646 \u062c\u0646\u06af \u0633\u0631\u062f \u0628\u0627 \u0634\u0648\u0631\u0648\u06cc \u062f\u0631\u06cc\u0627\u0641\u062a\u0646\u062f \u06a9\u0647 \u0645\u06cc \u0634\u0648\u062f \u0628\u0627 \u0647\u0632\u06cc\u0646\u0647 \u06a9\u0645\u062a\u0631 \u0648 \u0628\u062f\u0648\u0646 \u062f\u062e\u0627\u0644\u062a \u0645\u0633\u062a\u0642\u06cc\u0645 \u062f\u0631 \u0633\u0627\u06cc\u0631 \u06a9\u0634\u0648\u0631\u0647\u0627 \u0628\u0647 \u0627\u0647\u062f\u0627\u0641 \u0633\u06cc\u0627\u0633\u06cc\u060c \u0627\u0642\u062a\u0635\u0627\u062f\u06cc \u0648... \u062f\u0633\u062a \u06cc\u0627\u0641\u062a \u06a9\u0647 \u062f\u0631 \u0627\u062f\u0628\u06cc\u0627\u062a \u0633\u06cc\u0627\u0633\u06cc \u062c\u0647\u0627\u0646 \u0628\u0647 \u062c\u0646\u06af \u0646\u0631\u0645 \u0634\u0647\u0631\u062a \u06cc\u0627\u0641\u062a.\n\u0628\u0631\u0631\u0633\u06cc \u062c\u0646\u06af \u0646\u0631\u0645 \u0627\u0632 \u0632\u0645\u0627\u0646 \u0641\u0631\u0648\u067e\u0627\u0634\u06cc \u0634\u0648\u0631\u0648\u06cc \u0622\u063a\u0627\u0632 \u0634\u062f.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-6b1dd8a9a9f94fc7bd741b54128da5f0", "input": "\u067e\u06cc\u0645\u0627\u0646 \u0622\u0645\u0627\u0633\u06cc\u0647 \u0646\u0627\u0645 \u067e\u06cc\u0645\u0627\u0646\u06cc \u0627\u0633\u062a \u06a9\u0647 \u0628\u06cc\u0646 \u0634\u0627\u0647 \u0637\u0647\u0645\u0627\u0633\u0628 \u0635\u0641\u0648\u06cc \u0648 \u0633\u0644\u0637\u0627\u0646 \u0633\u0644\u06cc\u0645\u0627\u0646 \u0639\u062b\u0645\u0627\u0646\u06cc \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f5\u06f5\u06f5 \u0645\u06cc\u0644\u0627\u062f\u06cc \u0648 \u062f\u0631 \u0634\u0647\u0631 \u0622\u0645\u0627\u0633\u06cc\u0647 \u0628\u0633\u062a\u0647 \u0634\u062f. \u0627\u06cc\u0646 \u067e\u06cc\u0645\u0627\u0646 \u0628\u0627 \u0645\u0634\u062e\u0635\u200c\u06a9\u0631\u062f\u0646 \u0645\u0631\u0632 \u0627\u06cc\u0631\u0627\u0646 \u0648 \u0639\u062b\u0645\u0627\u0646\u06cc\u060c \u067e\u0627\u06cc\u0627\u0646\u06cc \u0628\u0631 \u062c\u0646\u06af\u200c\u0647\u0627\u06cc \u062f\u0631\u0627\u0632 \u0645\u062f\u062a \u062f\u0648 \u06a9\u0634\u0648\u0631 \u0628\u0648\u062f.\n\u0642\u0631\u0627\u0631\u062f\u0627\u062f \u0622\u0645\u0627\u0633\u06cc\u0647 \u0627\u0648\u0644\u06cc\u0646 \u067e\u06cc\u0645\u0627\u0646 \u0635\u0644\u062d\u06cc \u0627\u0633\u062a \u06a9\u0647 \u0628\u06cc\u0646 \u062f\u0648\u0644\u062a \u0627\u06cc\u0631\u0627\u0646 \u0648 \u0639\u062b\u0645\u0627\u0646\u06cc \u067e\u0633 \u0627\u0632 \u062c\u0646\u06af\u200c\u0647\u0627\u06cc \u0628\u06cc\u0633\u062a\u200c\u0633\u0627\u0644\u0647 \u0628\u0647 \u0627\u0645\u0636\u0627 \u0631\u0633\u06cc\u062f.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-0ebf9d5ec82343a88cc97350102b140c", "input": "\u0642\u062f\u06cc\u0645\u06cc\u062a\u0631\u06cc\u0646 \u0633\u0646\u062f \u0627\u0632 \u0645\u0646\u0627\u0628\u0639 \u0645\u06a9\u062a\u0648\u0628 \u06a9\u0647 \u0628\u0647 \u0646\u0627\u0645 \u0627\u0631\u06cc\u0627\u0631\u0645\u0646\u0647 \u0627\u0634\u0627\u0631\u0647 \u0645\u06cc\u200c\u06a9\u0646\u062f\u060c \u0627\u062b\u0631 \u0647\u0631\u0648\u062f\u062a \u0627\u0633\u062a \u06a9\u0647 \u0646\u0648\u0634\u062a\u0647 \u0634\u062f\u0647 \u062f\u0627\u0631\u06cc\u0648\u0634 \u0628\u0632\u0631\u06af \u0628\u0627 \u0628\u0647 \u062f\u0633\u062a \u06af\u0631\u0641\u062a\u0646 \u0642\u062f\u0631\u062a \u062f\u0631 \u200c\u0633\u0646\u06af \u0646\u0628\u0634\u062a\u0647 \u0628\u06cc\u0633\u062a\u0648\u0646 \u067e\u062f\u0631 \u062e\u0648\u062f \u0631\u0627 \u0648\u06cc\u0634\u062a\u0627\u0633\u067e \u0648 \u067e\u062f\u0631 \u0648\u06cc\u0634\u062a\u0627\u0633\u067e \u0631\u0627 \u0627\u0631\u0634\u0627\u0645 \u0648 \u067e\u062f\u0631 \u0622\u0631\u0634\u0627\u0645 \u0631\u0627 \u0627\u0631\u06cc\u0627\u0631\u0645\u0646\u0647 \u0645\u06cc\u200c\u062e\u0648\u0627\u0646\u062f.\n\u0627\u0631\u06cc\u0627\u0631\u0645\u0646\u0647 \u0627\u0632 \u062f\u0648 \u062c\u0632\u0621 \"\u0627\u0631\u06cc\u0627\" \u0648 \"\u0631\u0627\u0645\u064e\u0646\" \u0628\u0627\u0633\u062a\u0627\u0646 \u0628\u0647 \u0645\u0639\u0646\u06cc \"\u0631\u0627\u0645\u0634 \u0622\u0631\u06cc\u0627\u06cc\u06cc\u060c \u0622\u0631\u0627\u0645\u0634 \u0627\u06cc\u0631\u0627\u0646\u06cc\u0627\u0646\" \u062f\u0631\u0633\u062a \u0634\u062f\u0647 \u0627\u0633\u062a.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-78727d4b6531440794be21139bdaa9dc", "input": "\u0627\u0639\u0636\u0627\u0649 \u0634\u0648\u0631\u0627\u0649 \u0646\u06af\u0647\u0628\u0627\u0646 \u062d\u0642 \u062d\u0636\u0648\u0631 \u062f\u0631 \u06a9\u0644\u06cc\u0647 \u062c\u0644\u0633\u0627\u062a \u0631\u0633\u0645\u0649 \u0645\u062c\u0644\u0633 \u0631\u0627 \u062f\u0627\u0631\u0646\u062f \u0648 \u0686\u0646\u0627\u0646\u0686\u0647 \u0637\u0631\u062d \u06cc\u0627 \u0644\u0627\u06cc\u062d\u0647\u200c\u200f\u0627\u0649 \u0628\u0627 \u0642\u06cc\u062f \u062f\u0648 \u06cc\u0627 \u0633\u0647 \u0641\u0648\u0631\u06cc\u062a \u062f\u0631 \u062f\u0633\u062a\u0648\u0631 \u0645\u062c\u0644\u0633 \u0642\u0631\u0627\u0631 \u06af\u06cc\u0631\u062f\u060c \u0627\u0639\u0636\u0627\u06cc \u0634\u0648\u0631\u0627\u0649 \u0646\u06af\u0647\u0628\u0627\u0646 \u0628\u0627\u06cc\u062f \u062f\u0631 \u0622\u0646 \u062c\u0644\u0633\u0647 \u0634\u0631\u06a9\u062a \u0646\u0645\u0627\u06cc\u0646\u062f.\n\u062d\u0636\u0648\u0631 \u0627\u0639\u0636\u0627\u06cc \u0634\u0648\u0631\u0627\u06cc \u0646\u06af\u0647\u0628\u0627\u0646 \u062f\u0631 \u06a9\u0644\u06cc\u0647 \u062c\u0644\u0633\u0627\u062a \u0645\u062c\u0644\u0633 \u0634\u0648\u0631\u0627\u06cc \u0627\u0633\u0644\u0627\u0645\u06cc \u0627\u062e\u062a\u06cc\u0627\u0631\u06cc \u0627\u0633\u062a.", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-856ffd0542634dd1849c104d9418ec4b", "input": "\u0646\u0627\u0645\u0647 \u0645\u0639\u0631\u0648\u0641 \u0648 \u062a\u0627\u0631\u06cc\u062e\u06cc \u0627\u0645\u0627\u0645 \u062e\u0645\u06cc\u0646\u06cc (\u0631\u0647) \u062e\u0637\u0627\u0628 \u0628\u0647 \u06af\u0648\u0631\u0628\u0627\u0686\u0641 \u0622\u062e\u0631\u06cc\u0646 \u0631\u0626\u06cc\u0633 \u062c\u0645\u0647\u0648\u0631 \u0634\u0648\u0631\u0648\u06cc \u062a\u0648\u0633\u0637 \u0647\u06cc\u0626\u062a\u06cc \u0639\u0627\u0644\u06cc \u0631\u062a\u0628\u0647 \u06a9\u0647 \u062f\u0631 \u0631\u0623\u0633 \u0622\u0646\u060c \u06cc\u06a9 \u0639\u0627\u0644\u0645 \u062f\u06cc\u0646\u06cc \u0622\u06af\u0627\u0647 \u0628\u0647 \u0645\u0633\u0627\u0626\u0644 \u0633\u06cc\u0627\u0633\u06cc \u0648 \u0645\u0630\u0647\u0628\u06cc \u06cc\u0639\u0646\u06cc \u0622\u06cc\u062a \u0627\u0644\u0644\u0647 \u062c\u0648\u0627\u062f\u06cc \u0622\u0645\u0644\u06cc \u0642\u0631\u0627\u0631 \u062f\u0627\u0634\u062a\u060c \u0628\u0647 \u06af\u0648\u0631\u0628\u0627\u0686\u0641 \u0627\u0628\u0644\u0627\u063a \u0648 \u0628\u0631\u0627\u06cc \u0648\u06cc \u062a\u0628\u06cc\u06cc\u0646 \u0648 \u062a\u0634\u0631\u06cc\u062d \u06af\u0631\u062f\u06cc\u062f. \n\u0645\u0633\u0626\u0648\u0644\u06cc\u062a \u0627\u0628\u0644\u0627\u063a \u0646\u0627\u0645\u0647 \u0627\u0645\u0627\u0645 \u062e\u0645\u06cc\u0646\u06cc \u0628\u0647 \u06af\u0648\u0631\u0628\u0627\u0686\u0641 \u0628\u0631 \u0639\u0647\u062f\u0647 \u0634\u0647\u06cc\u062f \u0628\u0647\u0634\u062a\u06cc \u0628\u0648\u062f.", "output": ["C"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-6e0b250d5ba6490fbfb7b00b53528ac5", "input": "\u062d\u0642\u0648\u0642 \u0639\u0645\u0648\u0645\u06cc \u0628\u0647 \u0686\u0646\u062f \u0634\u0627\u062e\u0647 \u062a\u0642\u0633\u06cc\u0645 \u0645\u06cc\u200c\u0634\u0648\u062f \u06a9\u0647 \u062d\u0642\u0648\u0642 \u0627\u0633\u0627\u0633\u06cc\u060c \u062d\u0642\u0648\u0642 \u0627\u062f\u0627\u0631\u06cc\u060c \u062d\u0642\u0648\u0642 \u062c\u0632\u0627 \u0648 \u062d\u0642\u0648\u0642 \u0628\u06cc\u0646\u200c\u0627\u0644\u0645\u0644\u0644 \u0639\u0645\u0648\u0645\u06cc \u0627\u0632 \u0645\u0647\u0645\u062a\u0631\u06cc\u0646 \u0622\u0646 \u0647\u0627\u0633\u062a.\n\u062d\u0642\u0648\u0642 \u0627\u0633\u0627\u0633\u06cc \u062c\u0632\u0621 \u06cc\u06a9\u06cc \u0627\u0632 \u0634\u0627\u062e\u0647 \u0647\u0627\u06cc \u062d\u0642\u0648\u0642 \u0628\u0647 \u0646\u0627\u0645 \u062d\u0642\u0648\u0642 \u0639\u0645\u0648\u0645\u06cc \u0627\u0633\u062a.", "output": ["E"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-076a994d440543d2a1297fb2e3f68365", "input": "\u0627\u0645\u06cc\u0631 \u062a\u06cc\u0645\u0648\u0631 \u06af\u0648\u0631\u06a9\u0627\u0646 \u062f\u0631 \u0628\u0627\u0632\u06af\u0634\u062a \u0627\u0632 \u0644\u0634\u06a9\u0631\u06a9\u0634\u0649 \u0628\u0647 \u0631\u0648\u0645 \u0648 \u062c\u0646\u06af \u0628\u0627 \u0628\u0627\u06cc\u0632\u06cc\u062f \u0639\u062b\u0645\u0627\u0646\u0649\u060c \u0627\u0633\u06cc\u0631\u0627\u0646\u06cc \u0628\u0647 \u0647\u0645\u0631\u0627\u0647 \u062e\u0648\u062f \u0628\u0647 \u0627\u06cc\u0631\u0627\u0646 \u0622\u0648\u0631\u062f\u0647 \u0628\u0648\u062f. \u062a\u06cc\u0645\u0648\u0631 \u062f\u0631 \u0627\u06cc\u0631\u0627\u0646 \u0628\u0627 \u062e\u0648\u0627\u062c\u0647 \u0639\u0644\u0649 \u0645\u0644\u0627\u0642\u0627\u062a \u06a9\u0631\u062f. \u062e\u0648\u0627\u062c\u0647 \u0627\u0632 \u0627\u0645\u06cc\u0631 \u062a\u06cc\u0645\u0648\u0631 \u062e\u0648\u0627\u0633\u062a \u06a9\u0647 \u0627\u0633\u06cc\u0631\u0627\u0646 \u0631\u0648\u0645\u06cc \u0631\u0627 \u0622\u0632\u0627\u062f \u06a9\u0646\u062f. \u0627\u0632 \u0622\u0646 \u062a\u0627\u0631\u06cc\u062e\u060c \u0627\u06cc\u0646 \u0627\u0633\u06cc\u0631\u0627\u0646 \u062f\u0631 \u0632\u0645\u0631\u0647 \u0645\u0631\u06cc\u062f\u0627\u0646 \u062c\u0627\u0646 \u0646\u062b\u0627\u0631 \u0648 \u062d\u0627\u0645\u06cc\u0627\u0646 \u062e\u0627\u0646\u062f\u0627\u0646 \u0635\u0641\u0648\u0649 \u062f\u0631\u0622\u0645\u062f\u0646\u062f \u0648 \u0628\u0647 \u0635\u0648\u0641\u06cc\u0627\u0646 \u0631\u0648\u0645\u0644\u0648 \u0645\u0639\u0631\u0648\u0641 \u06af\u0634\u062a\u0646\u062f.\n\u0627\u0633\u0631\u0627\u06cc \u0631\u0648\u0645\u06cc \u0647\u0645\u0631\u0627\u0647 \u062a\u06cc\u0645\u0648\u0631 \u06a9\u0647 \u0628\u0647 \u062f\u0631\u062e\u0648\u0627\u0633\u062a \u062e\u0648\u0627\u062c\u0647 \u0639\u0644\u06cc \u0622\u0632\u0627\u062f \u0634\u062f\u0646\u062f\u060c \u0628\u0647 \u0635\u0648\u0641\u06cc\u0627\u0646 \u0631\u0648\u0645\u0644\u0648 \u0645\u0634\u0647\u0648\u0631 \u0634\u062f\u0646\u062f.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-da1b2fe7e9144c3fbdadee4f0da82e33", "input": "\u0627\u06cc\u0631\u0627\u0646 \u062f\u0627\u0631\u0627\u06cc \u06f3 \u0627\u0645\u062a\u06cc\u0627\u0632 \u0627\u0633\u062a: \u06f1. \u0645\u062a\u0635\u0644 \u0628\u0647 \u0645\u0648\u0642\u0639\u06cc\u062a \u0628\u0631\u06cc \u0627\u0648\u0631\u0627\u0633\u06cc\u0627\u0633\u062a. \u06f2. \u0628\u0647 \u0644\u062d\u0627\u0638 \u062f\u0631 \u0627\u062e\u062a\u06cc\u0627\u0631 \u062f\u0627\u0634\u062a\u0646 \u062a\u0646\u06af\u0647 \u0627\u0633\u062a\u0631\u0627\u062a\u0698\u06cc\u06a9 \u0647\u0631\u0645\u0632\u060c\u062f\u0627\u0631\u0627\u06cc \u0645\u0648\u0642\u0639\u06cc\u062a \u06af\u0630\u0631\u06af\u0627\u0647\u06cc \u0627\u0633\u062a \u0648 \u0631\u0648\u0632\u0627\u0646\u0647 \u0628\u06cc\u0634 \u0627\u0632 \u06f1\u06f8\u0645\u06cc\u0644\u06cc\u0648\u0646 \u0628\u0634\u06a9\u0647 \u0646\u0641\u062a \u0627\u0632 \u0627\u06cc\u0646 \u062a\u0646\u06af\u0647 \u0635\u0627\u062f\u0631 \u0645\u06cc \u0634\u0648\u062f .\u06f3. ...\n\u0645\u062a\u0635\u0644 \u0628\u0648\u062f\u0646 \u0628\u0647 \u0645\u0648\u0642\u0639\u06cc\u062a \u0628\u0631\u06cc \u0627\u0648\u0631\u0627\u0633\u06cc\u0627\u0633\u062a\u060c \u0628\u0631\u0627\u06cc \u0627\u06cc\u0631\u0627\u0646 \u0645\u0648\u0642\u0639\u06cc\u062a \u06af\u0630\u0631\u06af\u0627\u0647\u06cc \u0645\u062d\u0633\u0648\u0628 \u0645\u06cc\u200c\u0634\u0648\u062f. ", "output": ["C"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-e0e5bd0713fa4a9fbd24d49b7a1616c7", "input": "\u062f\u0627\u0631\u06cc\u0648\u0634 \u06a9\u0628\u06cc\u0631 \u06a9\u0647 \u0645\u06cc \u062e\u0648\u0627\u0633\u062a \u0628\u062f\u0627\u0646\u062f \u0633\u0646\u062f \u0627\u0632 \u06a9\u062c\u0627 \u0633\u0631\u0686\u0634\u0645\u0647 \u0645\u06cc \u06af\u06cc\u0631\u062f \u0648 \u062f\u0631 \u06a9\u062c\u0627 \u0628\u0647 \u062f\u0631\u06cc\u0627 \u0645\u06cc \u0631\u06cc\u0632\u062f\u060c \u06a9\u0634\u062a\u06cc \u0647\u0627\u06cc\u06cc \u0631\u0627 \u0628\u0647 \u0633\u0631\u067e\u0631\u0633\u062a\u06cc \u0627\u0633\u06a9\u06cc\u0644\u0627\u06a9\u0633 \u062f\u0631\u06cc\u0627\u0646\u0648\u0631\u062f \u0647\u062e\u0627\u0645\u0646\u0634\u06cc \u0648 \u0645\u0631\u062f\u0627\u0646 \u062f\u06cc\u06af\u0631\u06cc \u0631\u0627 \u06a9\u0647 \u0628\u0647 \u0631\u0627\u0633\u062a\u06af\u0648\u06cc\u06cc \u0622\u0646\u0627\u0646 \u0627\u0639\u062a\u0645\u0627\u062f \u062f\u0627\u0634\u062a\u060c \u062f\u0631 \u067e\u06cc \u0634\u0646\u0627\u0633\u0627\u06cc\u06cc \u062f\u0631\u06cc\u0627\u0647\u0627 \u0641\u0631\u0633\u062a\u0627\u062f. \n\u0633\u06cc\u0644\u0633\u06cc\u0648\u0646 \u0627\u0632 \u0637\u0631\u0641 \u062f\u0627\u0631\u06cc\u0648\u0634 \u06a9\u0628\u06cc\u0631 \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u0633\u0631\u067e\u0631\u0633\u062a \u06af\u0631\u0648\u0647 \u062f\u0631\u06cc\u0627\u0646\u0648\u0631\u062f\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0634\u0641 \u062f\u0631\u06cc\u0627\u0647\u0627 \u0627\u0646\u062a\u062e\u0627\u0628 \u0634\u062f.", "output": ["C"]}, "Prediction": "E."}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-d38bacfc80b84d648f433c5be31ec045", "input": " \u0645\u0648\u0627\u0636\u0639 \u0698\u0627\u067e\u0646 \u0648 \u0622\u0644\u0645\u0627\u0646 \u062f\u0631 \u062c\u0627\u0646\u0628\u062f\u0627\u0631\u06cc \u0627\u0632 \u0639\u0631\u0627\u0642 \u0628\u06cc\u0634\u062a\u0631 \u0627\u0642\u062a\u0635\u0627\u062f\u06cc \u0628\u0648\u062f\u0647 \u0648 \u0646\u0633\u0628\u062a \u0628\u0647 \u0622\u0645\u0631\u06cc\u06a9\u0627 \u0648 \u0641\u0631\u0627\u0646\u0633\u0647 \u0648 \u0633\u067e\u0633 \u0627\u0646\u06af\u0644\u0633\u062a\u0627\u0646 \u0627\u0632 \u0627\u0639\u062a\u062f\u0627\u0644 \u0628\u06cc\u0634\u062a\u0631\u06cc \u0628\u0631\u062e\u0648\u0631\u062f\u0627\u0631 \u0628\u0648\u062f\u0647 \u0627\u0633\u062a. \n\u06a9\u0634\u0648\u0631\u0647\u0627\u06cc \u0622\u0645\u0631\u06cc\u06a9\u0627 \u0648 \u0641\u0631\u0627\u0646\u0633\u0647 \u062f\u0631 \u062c\u0627\u0646\u0628\u062f\u0627\u0631\u06cc \u0627\u0632 \u0639\u0631\u0627\u0642 \u0628\u06cc\u0634\u062a\u0631 \u0645\u0648\u0627\u0636\u0639 \u0627\u0642\u062a\u0635\u0627\u062f\u06cc \u062f\u0627\u0634\u062a\u0646\u062f \u0648 \u0627\u0632 \u0627\u0639\u062a\u062f\u0627\u0644 \u0628\u06cc\u0634\u062a\u0631\u06cc \u0628\u0631\u062e\u0648\u0631\u062f\u0627\u0631 \u0628\u0648\u062f\u0646\u062f. ", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-20e02f31cab6426f821e174f596a0a35", "input": "\u062f\u0648\u0644\u062a \u0639\u0644\u0645 \u062f\u0631 \u06f1\u06f6 \u0645\u0647\u0631 \u06f1\u06f3\u06f4\u06f1\u062e\u0648\u0631\u0634\u06cc\u062f\u06cc\u060c \u0646\u0638\u0627\u0645\u0646\u0627\u0645\u06c0 \u0627\u0646\u062c\u0645\u0646\u200c\u0647\u0627\u06cc \u0627\u06cc\u0627\u0644\u062a\u06cc \u0648 \u0648\u0644\u0627\u06cc\u062a\u06cc \u0631\u0627 \u062a\u063a\u06cc\u06cc\u0631 \u062f\u0627\u062f \u06a9\u0647 \u0628\u0631\u067e\u0627\u06cc\u0647 \u0622\u0646 \u0642\u06cc\u062f \u0627\u0633\u0644\u0627\u0645 \u0627\u0632 \u0634\u0631\u0627\u06cc\u0637 \u0627\u0646\u062a\u062e\u0627\u0628 \u06a9\u0646\u0646\u062f\u06af\u0627\u0646 \u0648 \u0627\u0646\u062a\u062e\u0627\u0628 \u0634\u0648\u0646\u062f\u06af\u0627\u0646 \u062d\u0630\u0641 \u0648 \u0633\u0648\u06af\u0646\u062f \u0628\u0647 \u0647\u0631 \u06a9\u062a\u0627\u0628 \u0622\u0633\u0645\u0627\u0646\u06cc \u0645\u062c\u0627\u0632 \u0634\u062f.\n\u062a\u063a\u06cc\u06cc\u0631\u0627\u062a \u067e\u06cc\u0634 \u0622\u0645\u062f\u0647 \u0644\u0627\u06cc\u062d\u0647 \u0627\u0646\u062c\u0645\u0646 \u0627\u06cc\u0627\u0644\u062a\u06cc \u0648 \u0648\u0644\u0627\u06cc\u062a\u06cc \u0632\u0645\u06cc\u0646\u0647\u200c\u0627\u06cc \u0628\u0631\u0627\u06cc \u062a\u0633\u0644\u0637 \u063a\u06cc\u0631\u0645\u0633\u0644\u0645\u06cc\u0646\u060c \u0628\u0647\u200c\u0648\u06cc\u0698\u0647 \u0628\u0647\u0627\u0626\u06cc\u0627\u0646 \u0648 \u0644\u0637\u0645\u0647 \u0628\u0647 \u0627\u0633\u062a\u0642\u0644\u0627\u0644 \u062c\u0627\u0645\u0639\u0647 \u0627\u0633\u0644\u0627\u0645\u06cc \u0627\u0633\u062a.", "output": ["N"]}, "Prediction": "E."}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-937e4198d5344f7b83cb52c5ad1124f3", "input": "\u0647\u062f\u0627\u06cc\u062a \u062a\u0634\u0631\u06cc\u0639\u06cc \u0645\u062e\u062a\u0635\u0651 \u0645\u0648\u062c\u0648\u062f\u0627\u062a \u0645\u062e\u062a\u0627\u0631 \u0648 \u0628\u0627 \u0627\u0631\u0627\u062f\u0647\u200f\u200c\u0627\u06cc \u0627\u0633\u062a \u06a9\u0647 \u0642\u062f\u0631\u062a \u06af\u0632\u06cc\u0646\u0634 \u062f\u0627\u0634\u062a\u0647 \u0628\u0627\u0634\u0646\u062f. \u0627\u06af\u0631 \u0641\u0637\u0631\u062a \u0648 \u0639\u0642\u0644 \u0645\u06cc\u200f\u200c\u062a\u0648\u0627\u0646\u0633\u062a\u0646\u062f \u0631\u0627\u0647 \u062a\u06a9\u0627\u0645\u0644 \u0631\u0627 \u0627\u0631\u0627\u0626\u0647 \u06a9\u0646\u0646\u062f\u060c \u0646\u06cc\u0627\u0632\u06cc \u0628\u0647 \u0647\u062f\u0627\u06cc\u062a \u062a\u0634\u0631\u06cc\u0639\u06cc \u0646\u0628\u0648\u062f\u061b \u0648\u0644\u06cc \u0627\u0632 \u0622\u0646\u062c\u0627 \u06a9\u0647 \u0627\u062f\u0631\u0627\u06a9\u0627\u062a \u0641\u0637\u0631\u06cc \u0648 \u0639\u0642\u0644\u06cc\u060c \u0627\u062c\u0645\u0627\u0644\u06cc \u0648 \u06a9\u0644\u0651\u06cc \u0627\u0633\u062a\u060c \u0628\u0631\u0627\u06cc \u062f\u0633\u062a\u200f\u06cc\u0627\u0628\u06cc \u0628\u0647 \u06a9\u0645\u0627\u0644 \u0646\u06cc\u0627\u0632 \u0628\u0647 \u0647\u062f\u0627\u06cc\u062a \u062a\u0634\u0631\u06cc\u0639\u06cc \u0627\u0633\u062a.\n\u0647\u062f\u0627\u06cc\u062a \u062a\u0634\u0631\u06cc\u0639\u06cc \u0628\u0631\u0627\u06cc \u0645\u0648\u062c\u0648\u062f\u06cc \u06a9\u0647 \u0627\u0632 \u0645\u0648\u0647\u0628\u062a \u0639\u0642\u0644 \u0648\u0627\u062e\u062a\u06cc\u0627\u0631 \u0628\u0631\u062e\u0648\u0631\u062f\u0627\u0631 \u0628\u0627\u0634\u062f \u0648 \u0628\u0647 \u062a\u0646\u0647\u0627\u06cc\u06cc \u0642\u0627\u062f\u0631 \u0628\u0647 \u062a\u062d\u0635\u06cc\u0644 \u06a9\u0645\u0627\u0644\u0627\u062a \u062e\u0648\u062f \u0646\u0628\u0627\u0634\u062f\u060c \u0636\u0631\u0648\u0631\u06cc \u0627\u0633\u062a.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-e0ae5879a720434f976ef118aa40af0e", "input": "\u0628\u0632\u0631\u06af \u0639\u0644\u0648\u06cc \u0686\u0647\u0627\u0631\u0633\u0627\u0644 \u062f\u0631 \u0632\u0646\u062f\u0627\u0646 \u0642\u0635\u0631 \u0645\u062d\u0628\u0648\u0633 \u0628\u0648\u062f\u061b \u0627\u06cc\u0646 \u062f\u0648\u0631\u0627\u0646 \u062a\u0623\u062b\u06cc\u0631\u06cc \u0622\u0634\u06a9\u0627\u0631 \u0628\u0631 \u0628\u062e\u0634\u06cc \u0627\u0632 \u0622\u062b\u0627\u0631\u0634 \u0628\u0647\u200c\u062c\u0627\u06cc \u06af\u0630\u0627\u0634\u062a \u0648 \u0627\u0648 \u0631\u0627 \u0645\u0628\u062f\u0639 \u0627\u062f\u0628\u06cc\u0627\u062a \u062f\u0627\u0633\u062a\u0627\u0646\u06cc \u0632\u0646\u062f\u0627\u0646 \u062f\u0631 \u0627\u06cc\u0631\u0627\u0646 \u0645\u06cc\u200c\u062f\u0627\u0646\u0646\u062f.\n\u0628\u0632\u0631\u06af \u0639\u0644\u0648\u06cc\u060c \u0628\u0646\u06cc\u0627\u0646\u06af\u0630\u0627\u0631 \"\u0627\u062f\u0628\u06cc\u0627\u062a \u062f\u0627\u0633\u062a\u0627\u0646\u06cc \u0632\u0646\u062f\u0627\u0646\" \u062f\u0631 \u0627\u06cc\u0631\u0627\u0646 \u0645\u06cc \u0628\u0627\u0634\u062f.", "output": ["E"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-f52166a1e8f941209fcb2f598dfadda1", "input": "\u062d\u0648\u0632\u0647\u0654 \u0642\u0645 \u06cc\u06a9\u06cc \u0627\u0632 \u0633\u0647 \u062d\u0648\u0632\u0647\u0654 \u062d\u062f\u06cc\u062b\u06cc \u06a9\u0647\u0646 \u062f\u0631 \u062a\u0627\u0631\u06cc\u062e \u0639\u0644\u0645\u06cc \u062c\u0647\u0627\u0646 \u062a\u0634\u06cc\u0639 \u0628\u0648\u062f \u0648 \u062f\u0631 \u0642\u0631\u0646 \u0627\u062e\u06cc\u0631 \u062a\u0648\u0633\u0637 \u0639\u0628\u062f\u0627\u0644\u06a9\u0631\u06cc\u0645 \u062d\u0627\u0626\u0631\u06cc \u06cc\u0632\u062f\u06cc \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f3\u06f0\u06f1 \u062e\u0648\u0631\u0634\u06cc\u062f\u06cc \u062a\u062c\u062f\u06cc\u062f \u062d\u06cc\u0627\u062a \u0634\u062f \u0628\u0647 \u06af\u0648\u0646\u0647 \u0627\u06cc \u0648\u06cc \u0631\u0627 \u0645\u0624\u0633\u0633 \u062d\u0648\u0632\u0647 \u0639\u0644\u0645\u06cc\u0647 \u0642\u0645 \u0646\u0627\u0645\u06cc\u062f\u0647\u200c\u0627\u0646\u062f.\n\u062d\u0648\u0632\u0647 \u0639\u0644\u0645\u06cc\u0647 \u0642\u0645 \u0628\u0647 \u06a9\u0648\u0634\u0634 \u0622\u06cc\u062a \u0627\u0644\u0644\u0647 \u0634\u06cc\u062e \u0639\u0628\u062f\u0627\u0644\u06a9\u0631\u06cc\u0645 \u062d\u0627\u0626\u0631\u06cc \u06cc\u0632\u062f\u06cc \u0627\u062d\u06cc\u0627 \u0634\u062f.", "output": ["E"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-d1d4640033974d5cbca8bcd57b4b270f", "input": "\u062f\u0631 \u062f\u0648\u0631\u0647 \u0635\u0641\u0648\u06cc\u0647 \u0645\u0645\u0646\u0648\u0639\u06cc\u062a \u062a\u062c\u0627\u0631\u062a \u0627\u0628\u0631\u06cc\u0634\u0645 \u0627\u06cc\u0631\u0627\u0646\u060c \u062a\u0648\u0633\u0637 \u0639\u062b\u0645\u0627\u0646\u06cc\u0627\u0646 \u0627\u062b\u0631 \u0632\u06cc\u0627\u062f\u06cc \u0628\u0631 \u0628\u0627\u0632\u0631\u06af\u0627\u0646\u0627\u0646 \u0627\u0628\u0631\u06cc\u0634\u0645 \u062f\u0627\u0634\u062a. \u0628\u06cc\u0634\u062a\u0631 \u0628\u0627\u0632\u0631\u06af\u0627\u0646\u0627\u0646 \u0648 \u0628\u0627\u0641\u0646\u062f\u06af\u0627\u0646 \u0627\u0628\u0631\u06cc\u0634\u0645 \u062f\u0631 \u0627\u062b\u0631 \u0627\u06cc\u0646 \u0645\u0645\u0646\u0648\u0639\u06cc\u062a \u062f\u0633\u062a \u0627\u0632 \u06a9\u0627\u0631 \u06a9\u0634\u06cc\u062f\u0646\u062f \u0648 \u0628\u0647 \u062c\u0627\u06cc \u0628\u0627\u0632\u0631\u06af\u0627\u0646\u0627\u0646 \u0627\u06cc\u0631\u0627\u0646\u06cc \u0648 \u062a\u0631\u06a9\u060c \u0627\u0631\u0645\u0646\u06cc\u0627\u0646 \u0627\u06cc\u0646 \u062a\u062c\u0627\u0631\u062a \u0631\u0627 \u0628\u0647 \u062f\u0633\u062a \u06af\u0631\u0641\u062a\u0646\u062f.\n\u0634\u0627\u0647\u200c\u0639\u0628\u0627\u0633 \u0628\u0631\u0627\u06cc \u062a\u0642\u0648\u06cc\u062a \u062a\u062c\u0627\u0631\u062a\u060c \u0631\u0627\u0647\u200c\u0647\u0627\u06cc \u0634\u0645\u0627\u0644\u200c\u063a\u0631\u0628 \u0631\u0627 \u0627\u0632 \u062f\u0633\u062a \u0639\u062b\u0645\u0627\u0646\u06cc\u200c\u0647\u0627 \u0622\u0632\u0627\u062f \u06a9\u0631\u062f \u0648 \u062a\u0645\u0627\u0645\u06cc \u0645\u0631\u0627\u06a9\u0632 \u062a\u0648\u0644\u06cc\u062f \u0627\u0628\u0631\u06cc\u0634\u0645 \u0631\u0627 \u067e\u0633 \u06af\u0631\u0641\u062a.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-886557c0e6fb4a71930c64a5dd88e888", "input": "\u0642\u0631\u0622\u0646 \u0628\u0647 \u06f3\u06f0 \u0628\u062e\u0634 \u062a\u0642\u0631\u06cc\u0628\u0627\u064b \u0645\u0633\u0627\u0648\u06cc \u0628\u0647 \u0646\u0627\u0645 \u062c\u0632\u0621 \u062a\u0642\u0633\u06cc\u0645 \u0634\u062f\u0647\u200c\u0627\u0633\u062a. \u0647\u0631 \u062c\u0632\u0621 \u0627\u0632 \u0686\u0647\u0627\u0631 \u0642\u0633\u0645\u062a \u0645\u0633\u0627\u0648\u06cc \u0628\u0647 \u0646\u0627\u0645 \u062d\u0632\u0628 \u062a\u0634\u06a9\u06cc\u0644 \u0634\u062f\u0647\u200c\u0627\u0633\u062a \u0648 \u062f\u0631 \u0627\u06cc\u0646 \u0635\u0648\u0631\u062a \u06f1\u06f2\u06f0 \u062d\u0632\u0628 \u062f\u0627\u0631\u06cc\u0645.\n\u0642\u0631\u0622\u0646 \u06a9\u0631\u06cc\u0645 \u0645\u062c\u0645\u0648\u0639\u0627 \u0634\u0627\u0645\u0644 \u06f1\u06f5\u06f0 \u062d\u0632\u0628 \u0645\u06cc \u0628\u0627\u0634\u062f.", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-9c6dd00201374b4bb6608f4faf9f9d88", "input": "\u0646\u0628\u0631\u062f \u062a\u06cc\u0631\u067e\u0644\u060c \u0622\u0648\u0631\u062f\u06cc \u0628\u0648\u062f \u06a9\u0647 \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f5\u06f8\u06f3 \u0645\u06cc\u0644\u0627\u062f\u06cc \u0648 \u0645\u0627\u0628\u06cc\u0646 \u062f\u0648 \u0633\u067e\u0627\u0647 \u06cc\u06a9\u06cc \u062d\u06a9\u0648\u0645\u062a \u0645\u0631\u06a9\u0632\u06cc \u0635\u0641\u0648\u06cc\u0647 (\u0634\u0627\u0647 \u0645\u062d\u0645\u062f \u062e\u062f\u0627\u0628\u0646\u062f\u0647) \u0628\u0647 \u0641\u0631\u0645\u0627\u0646\u062f\u0647\u06cc \u0645\u0631\u062a\u0636\u06cc \u0642\u0644\u06cc\u200c\u062e\u0627\u0646 \u067e\u0631\u0646\u0627\u06a9 \u0648 \u062f\u06cc\u06af\u0631\u06cc \u0628\u0647 \u0641\u0631\u0645\u0627\u0646\u062f\u0647\u06cc \u0639\u0644\u06cc\u200c\u0642\u0644\u06cc\u200c\u062e\u0627\u0646 \u06af\u0648\u0631\u06a9\u0627\u0646 \u0648 \u0628\u0647 \u062d\u0645\u0627\u06cc\u062a \u0639\u0628\u0627\u0633 \u0645\u06cc\u0631\u0632\u0627 \u0631\u0648\u06cc \u062f\u0627\u062f. \n\u0646\u0628\u0631\u062f \u062a\u06cc\u0631\u067e\u0644 \u0645\u06cc\u0627\u0646 \u0639\u0644\u06cc\u0642\u0644\u06cc \u062e\u0627\u0646 \u0648 \u0645\u0631\u062a\u0636\u06cc \u0642\u0644\u06cc \u062e\u0627\u0646 \u062f\u0631 \u0632\u0645\u0627\u0646 \u0634\u0627\u0647 \u0627\u0633\u0645\u0627\u0639\u06cc\u0644 \u062f\u0648\u0645 \u0631\u0648\u06cc \u062f\u0627\u062f. ", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-539ecbc2efac45f5af8d617ef365be39", "input": "\u062f\u0631 \u062d\u062f\u06cc\u062b \u0627\u0633\u062a \u0627\u0632 \u067e\u06cc\u0627\u0645\u0628\u0631 \u0627\u06a9\u0631\u0645 (\u0635): \u0634\u0631\u06a9 (\u0631\u0627\u0647 \u06cc\u0627\u0641\u062a\u0646 \u0634\u0631\u06a9) \u0645\u062e\u0641\u06cc \u062a\u0631 \u0627\u0633\u062a \u0627\u0632 \u0631\u0641\u062a\u0646 \u0645\u0648\u0631\u0686\u0647 \u0628\u0631 \u0633\u0646\u06af \u0635\u0627\u0641 \u062f\u0631 \u0634\u0628 \u062a\u0627\u0631\u06cc\u06a9.\n\u062d\u062f\u06cc\u062b \u00ab \u0631\u0627\u0647 \u06cc\u0627\u0641\u062a\u0646 \u0634\u0631\u06a9 \u0627\u0632 \u0631\u0627\u0647 \u0631\u0641\u062a\u0646 \u0645\u0648\u0631\u0686\u0647\u200c\u06cc \u06a9\u0648\u0686\u06a9\u06cc \u06a9\u0647 \u062f\u0631 \u0634\u0628\u06cc \u062a\u0627\u0631\u06cc\u06a9 \u0628\u0631 \u0633\u0646\u06af\u06cc \u0635\u0627\u0641 \u0628\u06af\u0630\u0631\u062f\u060c \u0645\u062e\u0641\u06cc \u062a\u0631 \u0627\u0633\u062a.\u00bb \u0627\u0632 \u067e\u06cc\u0627\u0645\u0628\u0631 \u0627\u06a9\u0631\u0645 (\u0635) \u0627\u0633\u062a.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-a1887dabeccb41619aea253fa22f7066", "input": "\u0627\u0648\u0644\u06cc\u0646 \u0646\u0645\u0627\u0632 \u062c\u0645\u0639\u0647\u200c\u0627\u0649 \u06a9\u0647 \u0631\u0633\u0648\u0644 \u062e\u062f\u0627 (\u0635\u0644\u0649 \u0627\u0644\u0644\u0647 \u0639\u0644\u06cc\u0647 \u0648 \u0622\u0644\u0647) \u0628\u0627 \u0627\u0635\u062d\u0627\u0628\u0634 \u062f\u0631 \u0627\u0633\u0644\u0627\u0645 \u0628\u0647 \u062c\u0627 \u0622\u0648\u0631\u062f\u060c \u0647\u0646\u06af\u0627\u0645\u0649 \u0628\u0648\u062f \u06a9\u0647 \u0628\u0647 \u0645\u062f\u06cc\u0646\u0647 \u0647\u062c\u0631\u062a \u06a9\u0631\u062f. \u067e\u06cc\u0627\u0645\u0628\u0631 \u062f\u0631 \u0631\u0648\u0632 \u062f\u0648\u0634\u0646\u0628\u0647 \u062f\u0648\u0627\u0632\u062f\u0647\u0645 \u0631\u0628\u06cc\u0639 \u0627\u0644\u0627\u0648\u0644 \u0647\u0646\u06af\u0627\u0645 \u0638\u0647\u0631 \u0648\u0627\u0631\u062f \u0645\u062f\u06cc\u0646\u0647 \u0634\u062f.\n\u0627\u0648\u0644\u06cc\u0646 \u0646\u0645\u0627\u0632 \u062c\u0645\u0639\u0647 \u0627\u0633\u0644\u0627\u0645 \u062f\u0631 \u062c\u0631\u06cc\u0627\u0646 \u0647\u062c\u0631\u062a \u0628\u0647 \u0645\u062f\u06cc\u0646\u0647 \u0627\u0642\u0627\u0645\u0647 \u0634\u062f.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-7210a8e4a0154293b16233651990c20a", "input": "\u0635\u0631\u0641 \u0646\u0638\u0631 \u0627\u0632 \u0627\u0635\u062d\u0627\u0628 \u0639\u0627\u0645 \u0627\u0645\u0627\u0645 \u0633\u062c\u0627\u062f (\u0639) \u06a9\u0647 \u0627\u0632 \u062c\u0644\u0633\u0627\u062a \u062f\u0631\u0633 \u0648 \u0641\u0631\u0645\u0627\u06cc\u0634\u0627\u062a \u0627\u0648 \u0628\u0647\u0631\u0647 \u0645\u06cc\u200c\u0628\u0631\u062f\u0646\u062f\u060c \u0633\u0631\u0622\u0645\u062f \u0627\u0635\u062d\u0627\u0628\u0634 \u0639\u0628\u0627\u0631\u062a \u0628\u0648\u062f\u0646\u062f \u0627\u0632: \u0627\u0628\u0648\u062e\u0627\u0644\u062f \u06a9\u0627\u0628\u0644\u06cc\u060c \u06cc\u062d\u06cc\u06cc \u0627\u0628\u0646 \u0627\u0645 \u0637\u0648\u06cc\u0644\u060c \u0645\u062d\u0645\u062f \u0628\u0646 \u062c\u0628\u06cc\u0631 \u0628\u0646 \u0645\u0637\u0639\u0645\u060c \u0633\u0639\u06cc\u062f \u0628\u0646 \u0627\u0644\u0645\u0633\u06cc\u0628 \u0627\u0644\u0645\u062e\u0632\u0648\u0645\u06cc\u060c \u062c\u0627\u0628\u0631 \u0628\u0646 \u0639\u0628\u062f\u0627\u0644\u0644\u0647 \u0627\u0646\u0635\u0627\u0631\u06cc\u060c \u0639\u0627\u0645\u0631 \u0628\u0646 \u0648\u0627\u0626\u0644\u0647 \u0627\u0644\u06a9\u0646\u0627\u0646\u06cc\u060c \u0633\u0639\u06cc\u062f \u0628\u0646 \u062c\u0628\u06cc\u0631 \u0627\u0644\u06a9\u0648\u0641\u06cc\u060c \u062c\u0628\u06cc\u0631 \u0628\u0646 \u0645\u0637\u0639\u0645. \u0647\u0645\u0686\u0646\u06cc\u0646 \u0627\u0628\u0648\u062d\u0645\u0632\u0647 \u062b\u0645\u0627\u0644\u06cc \u0631\u0627 \u0646\u06cc\u0632 \u0634\u0627\u06af\u0631\u062f \u0627\u0645\u0627\u0645 \u0633\u062c\u0627\u062f(\u0639) \u0646\u0627\u0645 \u0628\u0631\u062f\u0647 \u0627\u0646\u062f.\n\u0628\u0639\u062f \u0627\u0632 \u0627\u0645\u0627\u0645 \u062d\u0633\u06cc\u0646 \u0639\u0644\u06cc\u0647 \u0627\u0644\u0633\u0644\u0627\u0645 \u0686\u0647\u0627\u0631 \u0646\u0641\u0631 \u0627\u0632 \u0627\u0635\u062d\u0627\u0628 \u0627\u0645\u0627\u0645 \u0633\u062c\u0627\u062f \u0628\u0648\u062f\u0646\u062f \u06a9\u0647 \u0645\u0631\u062a\u062f \u0646\u0634\u062f\u0646\u062f.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-633fb12dd4a349ceb425841ecbdf9fa3", "input": "\u0622\u062a\u0646 \u0637\u0628\u0642 \u067e\u06cc\u0645\u0627\u0646 \u0622\u0646\u062a\u0627\u0644\u06a9\u06cc\u062f\u0627\u0633 \u0645\u0646\u0639\u0642\u062f\u0647 \u062f\u0631 \u0633\u0627\u0644 \u06f3\u06f8\u06f6 \u067e\u06cc\u0634 \u0627\u0632 \u0645\u06cc\u0644\u0627\u062f \u062d\u06a9\u0648\u0645\u062a \u0627\u06cc\u0631\u0627\u0646 \u0628\u0631 \u0642\u0628\u0631\u0633 \u0631\u0627 \u0628\u0647 \u0631\u0633\u0645\u06cc\u062a \u0634\u0646\u0627\u062e\u062a \u0648 \u0645\u062a\u0639\u0647\u062f \u0634\u062f \u06a9\u0647 \u062f\u0631 \u0647\u06cc\u0686 \u0645\u0646\u0637\u0642\u0647 \u0627\u06cc \u0627\u0642\u062f\u0627\u0645\u06cc \u0628\u0631\u0636\u062f \u0645\u0646\u0627\u0641\u0639 \u0627\u06cc\u0631\u0627\u0646 \u0628\u0639\u0645\u0644 \u0646\u06cc\u0627\u0648\u0631\u062f.\n\u0637\u0628\u0642 \u067e\u06cc\u0645\u0627\u0646 \u0622\u0646\u062a\u0627\u0644\u06a9\u06cc\u062f\u0627\u0633 \u062d\u06a9\u0648\u0645\u062a \u0628\u0631 \u0642\u0628\u0631\u0633 \u0628\u0647 \u0627\u06cc\u0631\u0627\u0646 \u062a\u0639\u0644\u0642 \u06af\u0631\u0641\u062a.", "output": ["E"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-74c0e2110030493f92b7f355c5ff2f29", "input": " \u0627\u0631\u062f\u0646 \u0628\u0646\u062f\u0631 \u0639\u0642\u0628\u0647 \u0631\u0627 \u0628\u0647 \u0645\u0646\u0638\u0648\u0631 \u062a\u062f\u0627\u0631\u06a9 \u0627\u0631\u062a\u0634 \u0628\u0639\u062b\u06cc \u0639\u0631\u0627\u0642 \u062f\u0631 \u0627\u062e\u062a\u06cc\u0627\u0631 \u0622\u0646 \u06a9\u0634\u0648\u0631 \u0642\u0631\u0627\u0631 \u062f\u0627\u062f \u0648 \u062c\u0627\u062f\u0647 \u0627\u0631\u062a\u0628\u0627\u0637\u06cc \u0627\u0631\u062f\u0646 \u0628\u0647 \u0639\u0631\u0627\u0642\u060c \u0645\u0647\u0645 \u062a\u0631\u06cc\u0646 \u0645\u0633\u06cc\u0631 \u062a\u062f\u0627\u0631\u06a9\u0627\u062a\u06cc \u0627\u0631\u062a\u0634 \u0639\u0631\u0627\u0642 \u0648 \u0646\u06cc\u0632 \u0635\u0627\u062f\u0631\u0627\u062a \u0646\u0641\u062a \u0639\u0631\u0627\u0642 \u0627\u0632 \u0637\u0631\u06cc\u0642 \u062a\u0627\u0646\u06a9\u0631\u0647\u0627\u06cc \u0646\u0641\u062a\u06a9\u0634 \u0634\u062f.\n\u0628\u0646\u062f\u0631 \u0639\u0642\u0628\u0647 \u062f\u0631 \u062f\u0631\u06cc\u0627\u06cc \u0633\u0631\u062e \u062f\u0631 \u0627\u062e\u062a\u06cc\u0627\u0631 \u0639\u0631\u0627\u0642 \u0628\u0648\u062f.", "output": ["N"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-6d50c9c83df04784bf144b312491b14e", "input": "\u062e\u06cc\u0627\u0645 \u062f\u0631 \u0646\u0632\u062f\u06cc\u06a9 \u0633\u0627\u0644 \u06f4\u06f4\u06f9 (\u0647\u062c\u0631\u06cc \u0642\u0645\u0631\u06cc) \u0632\u06cc\u0631 \u067e\u0648\u0634\u0634 \u0648 \u0633\u0631\u067e\u0631\u0633\u062a\u06cc \u0627\u0628\u0648\u0637\u0627\u0647\u0631\u060c \u0642\u0627\u0636\u06cc\u200c\u0627\u0644\u0642\u0636\u0627\u062a \u0633\u0645\u0631\u0642\u0646\u062f\u060c \u06a9\u062a\u0627\u0628\u06cc \u062f\u0631\u0628\u0627\u0631\u0647\u0654 \u0645\u0639\u0627\u062f\u0644\u0647\u200c\u0647\u0627\u06cc \u062f\u0631\u062c\u0647\u0654 \u0633\u0648\u0645 \u0628\u0647 \u0632\u0628\u0627\u0646 \u0639\u0631\u0628\u06cc \u0646\u0648\u0634\u062a \u062a\u062d\u062a \u0646\u0627\u0645 \"\u0631\u0633\u0627\u0644\u0647 \u0641\u06cc \u0627\u0644\u0628\u0631\u0627\u0647\u06cc\u0646 \u0639\u0644\u06cc \u0645\u0633\u0627\u0626\u0644 \u0627\u0644\u062c\u0628\u0631 \u0648 \u0627\u0644\u0645\u0642\u0627\u0628\u0644\u0647\".\n\u062e\u0637\u0648\u0637 \u0645\u0648\u0627\u0632\u06cc\u060c \u0645\u0648\u0636\u0648\u0639 \u06a9\u062a\u0627\u0628 \"\u0631\u0633\u0627\u0644\u0647 \u0641\u06cc \u0627\u0644\u0628\u0631\u0627\u0647\u06cc\u0646 \u0639\u0644\u06cc \u0645\u0633\u0627\u0626\u0644 \u0627\u0644\u062c\u0628\u0631 \u0648 \u0627\u0644\u0645\u0642\u0627\u0628\u0644\u0647\" \u0645\u06cc \u0628\u0627\u0634\u062f.", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-a813d07b175544cca1fb028b73106a7c", "input": "\u062e\u0644\u0627\u0635\u0647 \u06a9\u0644\u0627\u0645 \u0622\u0646\u06a9\u0647\u060c \u062d\u0642 \u062d\u06cc\u0627\u062a \u062f\u0631 \u062a\u0641\u06a9\u0631 \u0647\u0648\u0627\u062f\u0627\u0631\u0627\u0646 \u062d\u0642\u0648\u0642 \u0628\u0634\u0631 \u0645\u062f\u0631\u0646\u060c \u062d\u0642\u06cc \u0645\u0637\u0644\u0642\u060c \u0628\u0646\u06cc\u0627\u062f\u06cc \u0648 \u067e\u0627\u06cc\u0647 \u0648 \u0627\u0633\u0627\u0633 \u0633\u0627\u06cc\u0631 \u062d\u0642\u0648\u0642 \u062a\u0644\u0642\u06cc \u0645\u06cc \u0634\u0648\u062f \u0648 \u0645\u062d\u062f\u0648\u062f\u06cc\u062a \u0628\u0631\u062f\u0627\u0631 \u0648 \u0633\u0644\u0628 \u067e\u0630\u06cc\u0631 \u0646\u06cc\u0633\u062a. \n\u062d\u0642 \u062d\u06cc\u0627\u062a \u0627\u0632 \u062f\u06cc\u062f\u06af\u0627\u0647 \u0647\u0648\u0627\u062f\u0627\u0631\u0627\u0646 \u062d\u0642\u0648\u0642 \u0628\u0634\u0631 \u0645\u062f\u0631\u0646 \u0641\u0642\u0637 \u0632\u0646\u062f\u06af\u06cc \u0645\u0627\u062f\u06cc \u0648 \u062c\u0633\u0645\u06cc \u0631\u0627 \u0634\u0627\u0645\u0644 \u0645\u06cc \u0634\u0648\u062f. ", "output": ["N"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-ce9f57b57f344b3a88072ac45cd4f5de", "input": "\u0645\u062f\u06cc\u0631\u06cc\u062a \u0627\u0646\u0642\u0644\u0627\u0628 \u0627\u0633\u0644\u0627\u0645\u06cc \u0628\u0627 \u062a\u06a9\u06cc\u0647 \u0628\u0631 \u0645\u0639\u0646\u0648\u06cc\u062a \u0627\u0646\u0642\u0644\u0627\u0628\u060c \u0645\u06cc \u062a\u0648\u0627\u0646\u0633\u062a \u0632\u0645\u06cc\u0646\u0647 \u06cc \u0645\u0633\u0627\u0639\u062f\u06cc \u0628\u0631\u0627\u06cc \u062d\u0631\u06a9\u062a \u0647\u0627\u06cc \u0628\u0646\u06cc\u0627\u062f\u06cc \u062f\u0631 \u0627\u0628\u0639\u0627\u062f \u0645\u062e\u062a\u0644\u0641 \u0645\u0648\u0631\u062f \u0646\u06cc\u0627\u0632 \u062e\u0648\u062f \u0628\u0647 \u062f\u0633\u062a \u0622\u0648\u0631\u062f. \u0628\u0631\u0627\u06cc \u0645\u062b\u0627\u0644\u060c \u06cc\u06a9\u06cc \u0627\u0632 \u0633\u0646\u062a \u0647\u0627\u06cc \u0645\u0631\u062f\u0645 \u0627\u06cc\u0631\u0627\u0646 \u0628\u0647 \u062f\u0644\u06cc\u0644 \u062a\u0647\u0627\u062c\u0645\u0627\u062a \u0645\u06a9\u0631\u0631 \u0628\u06cc\u06af\u0627\u0646\u06af\u0627\u0646 \u0648 \u0627\u06cc\u062c\u0627\u062f \u0642\u062d\u0637\u06cc \u062f\u0631 \u0645\u0631\u0627\u062d\u0644 \u062e\u0627\u0635 \u062a\u0627\u0631\u06cc\u062e\u06cc\u060c \u0633\u0646\u062a \u0630\u062e\u06cc\u0631\u0647 \u0633\u0627\u0632\u06cc \u0645\u0648\u0627\u062f \u063a\u0630\u0627\u06cc\u06cc \u0628\u0648\u062f. \u0627\u06cc\u0646 \u0633\u0646\u062a \u062f\u0631 \u0634\u0631\u0627\u06cc\u0637 \u062c\u0646\u06af\u06cc \u0645\u06cc \u062a\u0648\u0627\u0646\u0633\u062a \u0636\u0631\u0628\u0647 \u06cc \u06a9\u0627\u0631\u06cc \u0628\u0631 \u0627\u0642\u062a\u0635\u0627\u062f \u0627\u0646\u0642\u0644\u0627\u0628 \u062f\u0631 \u0634\u0631\u0627\u06cc\u0637 \u062c\u0646\u06af \u0628\u0632\u0646\u062f.\n \u0628\u0627 \u062a\u0648\u0632\u06cc\u0639 \u0639\u0627\u062f\u0644\u0627\u0646\u0647 \u06a9\u0627\u0644\u0627 \u062f\u0631 \u0637\u0648\u0644 \u062c\u0646\u06af\u060c \u0633\u0646\u062a \u0630\u062e\u06cc\u0631\u0647 \u0633\u0627\u0632\u06cc \u0645\u0648\u0627\u062f \u063a\u0630\u0627\u06cc\u06cc \u062f\u0631 \u0634\u0631\u0627\u06cc\u0637 \u062e\u0637\u0631\u0646\u0627\u06a9 \u0648 \u0645\u0647\u06cc\u062c\u060c \u06a9\u0646\u062a\u0631\u0644 \u0634\u062f.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-e61895bb40084ec8ab323e117861ca8e", "input": "\u0627\u0645\u0627\u0645 \u062e\u0645\u06cc\u0646\u06cc \u0641\u0631\u0645\u0648\u062f\u0646\u062f: \u067e\u0633 \u0627\u0632 \u0631\u0623\u06cc \u0627\u06a9\u062b\u0631\u06cc\u062a \u0642\u0627\u0637\u0639 \u0646\u0645\u0627\u06cc\u0646\u062f\u06af\u0627\u0646 \u0645\u062d\u062a\u0631\u0645 \u0645\u062c\u0644\u0633 \u0634\u0648\u0631\u0627\u06cc \u0627\u0633\u0644\u0627\u0645\u06cc \u0645\u0628\u0646\u06cc \u0628\u0631 \u0627\u06cc\u0646\u06a9\u0647 \u0622\u0642\u0627\u06cc \u0627\u0628\u0648\u0627\u0644\u062d\u0633\u0646 \u0628\u0646\u06cc \u0635\u062f\u0631 \u0628\u0631\u0627\u06cc \u0631\u06cc\u0627\u0633\u062a \u062c\u0645\u0647\u0648\u0631\u06cc \u0627\u0633\u0644\u0627\u0645\u06cc \u0627\u06cc\u0631\u0627\u0646 \u06a9\u0641\u0627\u06cc\u062a \u0633\u06cc\u0627\u0633\u06cc \u0646\u062f\u0627\u0631\u062f\u060c \u0627\u06cc\u0634\u0627\u0646 \u0631\u0627 \u0627\u0632 \u0631\u06cc\u0627\u0633\u062a \u062c\u0645\u0647\u0648\u0631\u06cc \u0627\u0633\u0644\u0627\u0645\u06cc \u0627\u06cc\u0631\u0627\u0646 \u0639\u0632\u0644 \u0646\u0645\u0648\u062f\u0645. \n\u0627\u0645\u0627\u0645 \u062e\u0645\u06cc\u0646\u06cc \u0628\u0646\u06cc\u200c\u0635\u062f\u0631 \u0631\u0627 \u0627\u0632 \u0631\u06cc\u0627\u0633\u062a \u062c\u0645\u0647\u0648\u0631\u06cc \u0627\u0633\u0644\u0627\u0645\u06cc \u0627\u06cc\u0631\u0627\u0646 \u0639\u0632\u0644 \u06a9\u0631\u062f", "output": ["E"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-28914211435f4d3c9d71fb3a1d413380", "input": "\u06a9\u0645\u067e\u0627\u0646\u06cc \u0647\u0646\u062f \u0634\u0631\u0642\u06cc \u0641\u0631\u0627\u0646\u0633\u0647 \u062f\u0631 \u0632\u0645\u0627\u0646 \u0633\u0644\u0637\u0646\u062a \u0644\u0648\u06cc\u0649 \u0686\u0647\u0627\u0631\u062f\u0647\u0645\u060c \u0628\u0631\u0627\u06cc \u0631\u0642\u0627\u0628\u062a \u0633\u06cc\u0627\u0633\u06cc\u060c \u0627\u0642\u062a\u0635\u0627\u062f\u06cc \u0648 \u0627\u0633\u062a\u0639\u0645\u0627\u0631\u06cc \u0628\u0627 \u062f\u0648\u0644\u062a \u0628\u0631\u06cc\u062a\u0627\u0646\u06cc\u0627 \u062f\u0631 \u0647\u0646\u062f\u0648\u0633\u062a\u0627\u0646 \u062a\u0623\u0633\u06cc\u0633 \u0634\u062f.\n\u06a9\u0645\u067e\u0627\u0646\u06cc \u0647\u0646\u062f \u0634\u0631\u0642\u06cc \u0641\u0631\u0627\u0646\u0633\u0647 \u062f\u0631 \u062f\u0648\u0631\u0647 \u067e\u0627\u062f\u0634\u0627\u0647\u06cc \u0644\u0648\u0626\u06cc \u0686\u0647\u0627\u0631\u062f\u0647\u0645 \u062a\u0627\u0633\u06cc\u0633 \u0634\u062f.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-1bcf063aa3bb4d77a2465b55e494f6e8", "input": "\u062f\u0631 \u0634\u0645\u0627\u0631 \u0622\u06cc\u0627\u062a \u0642\u0631\u0622\u0646 \u0627\u062e\u062a\u0644\u0627\u0641 \u0627\u0633\u062a. \u062e\u0627\u0644\u0649 \u0628\u0648\u062f\u0646 \u0642\u0631\u0622\u0646 \u0647\u0627\u0649 \u0627\u0648\u0644\u06cc\u0647 \u0627\u0632 \u0639\u0644\u0627\u0645\u062a \u062c\u062f\u0627\u06a9\u0646\u0646\u062f\u0647 \u0622\u06cc\u0627\u062a \u0627\u0632 \u06cc\u06a9\u062f\u06cc\u06af\u0631 \u0628\u0627\u0639\u062b \u0645\u0649 \u0634\u062f\u0647 \u062a\u0627 \u0648\u0642\u0641 \u0628\u0631 \u0628\u0639\u0636\u0649 \u0622\u06cc\u0627\u062a \u0635\u0648\u0631\u062a \u0646\u06af\u06cc\u0631\u062f \u0648 \u06cc\u06a9 \u0622\u06cc\u0647 \u0634\u0645\u0631\u062f\u0647 \u0634\u0648\u062f \u06cc\u0627 \u0628\u0627\u0644\u0639\u06a9\u0633 \u0648 \u0627\u06cc\u0646 \u0628\u0627\u0639\u062b \u0627\u062e\u062a\u0644\u0627\u0641 \u0646\u0638\u0631 \u062f\u0631 \u062a\u0639\u062f\u0627\u062f \u0622\u06cc\u0627\u062a \u0627\u0633\u062a. \u0637\u0628\u0642 \u0645\u0634\u0647\u0648\u0631\u062a\u0631\u06cc\u0646 \u0631\u0648\u0627\u06cc\u0627\u062a \u0642\u0631\u0622\u0646 \u062f\u0627\u0631\u0627\u0649 \u06f1\u06f1\u06f4 \u0633\u0648\u0631\u0647 \u0648 \u06f6\u06f2\u06f3\u06f6 \u0622\u06cc\u0647 \u0627\u0633\u062a.\n\u062a\u0639\u062f\u0627\u062f \u06a9\u0644\u0645\u0627\u062a \u0642\u0631\u0622\u0646 \u0645\u0637\u0627\u0628\u0642 \u0631\u0648\u0627\u06cc\u0627\u062a \u0645\u0634\u0647\u0648\u0631 \u06f7\u06f7\u06f8\u06f0\u06f7 \u0627\u0633\u062a.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-07d9bf6ab2be4b04ad3bcf94642237e6", "input": "\u062c\u0647\u0627\u062f \u062f\u0641\u0627\u0639\u06cc : \u062f\u0631 \u0627\u06cc\u0646 \u0646\u0648\u0639 \u062c\u0647\u0627\u062f\u060c \u06a9\u0641\u0627\u0631\u060c \u0645\u0634\u0631\u06a9\u06cc\u0646 \u0648 \u0645\u0646\u0627\u0641\u0642\u06cc\u0646 \u0628\u0647 \u0633\u0631\u0632\u0645\u06cc\u0646 \u0645\u0633\u0644\u0645\u06cc\u0646\u060c \u062a\u0647\u0627\u062c\u0645 \u0645\u06cc\u06a9\u0646\u0646\u062f \u06a9\u0647 \u0628\u0631 \u0647\u0645\u0647 \u0627\u0639\u0645 \u0627\u0632 \u0645\u0631\u062f \u0648 \u0632\u0646\u060c \u06a9\u0648\u0686\u06a9 \u0648 \u0628\u0632\u0631\u06af\u060c \u0636\u0639\u06cc\u0641 \u0648 \u0642\u0648\u06cc\u060c \u0633\u0627\u0644\u0645 \u0648 \u0645\u0631\u06cc\u0636 \u0648\u0627\u062c\u0628 \u0627\u0633\u062a \u0628\u0627 \u062f\u0634\u0645\u0646 \u0645\u0642\u0627\u0628\u0644\u0647 \u0648 \u0627\u0648 \u0631\u0627 \u0627\u0632 \u0633\u0631\u0632\u0645\u06cc\u0646 \u062e\u0648\u062f \u0628\u06cc\u0631\u0648\u0646 \u06a9\u0646\u0646\u062f.\n\u0627\u0646\u0648\u0627\u0639 \u062c\u0646\u06af \u0639\u0628\u0627\u0631\u062a\u0646\u062f \u0627\u0632 : \u0627\u0628\u062a\u062f\u0627\u0639\u06cc \u0648 \u062f\u0641\u0627\u0639\u06cc . ", "output": ["N"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-c22e4e2571c9427db000187d72a63a5a", "input": "\u06a9\u062a\u06cc\u0628\u0647 \u0634\u0627\u067e\u0648\u0631 \u06cc\u06a9\u0645 \u062f\u0631 \u06a9\u0639\u0628\u0647 \u0632\u0631\u062a\u0634\u062a \u0645\u0647\u0645\u200c\u062a\u0631\u06cc\u0646 \u06a9\u062a\u06cc\u0628\u0647\u200c\u06cc \u0633\u0627\u0633\u0627\u0646\u06cc \u0627\u0633\u062a. \u0628\u0627 \u0645\u0637\u0627\u0644\u0639\u0647 \u0627\u06cc\u0646 \u06a9\u062a\u06cc\u0628\u0647 \u0645\u06cc\u062a\u0648\u0627\u0646 \u0628\u0647 \u062d\u0648\u0627\u062f\u062b \u0645\u0647\u0645 \u0622\u0646 \u0632\u0645\u0627\u0646 \u0648 \u062a\u0627 \u062d\u062f\u06cc \u0628\u0647 \u062a\u0634\u06a9\u06cc\u0644\u0627\u062a \u0627\u062f\u0627\u0631\u06cc \u0648 \u0645\u0646\u0627\u0635\u0628 \u0645\u0647\u0645 \u0627\u06cc\u0646 \u062f\u0648\u0631\u0647 \u067e\u06cc \u0628\u0631\u062f. \u0647\u0645\u0686\u0646\u06cc\u0646 \u0630\u06a9\u0631 \u062a\u0639\u062f\u0627\u062f \u0628\u0633\u06cc\u0627\u0631\u06cc \u0627\u0632 \u0646\u0627\u0645\u200c\u0647\u0627\u06cc \u062e\u0627\u0635 \u0633\u0627\u0633\u0627\u0646\u06cc \u062f\u0631 \u0627\u06cc\u0646 \u06a9\u062a\u06cc\u0628\u0647 \u0628\u0631 \u06af\u0646\u062c\u06cc\u0646\u0647 \u0646\u0627\u0645\u200c\u0647\u0627\u06cc \u062e\u0627\u0635 \u0627\u06cc\u0631\u0627\u0646\u06cc \u0645\u06cc\u200c\u0627\u0641\u0632\u0627\u06cc\u062f.\n\u06a9\u062a\u06cc\u0628\u0647 \u0634\u0627\u067e\u0648\u0631 \u06cc\u06a9\u0645 \u062f\u0631 \u06a9\u0639\u0628\u0647 \u0632\u0631\u062a\u0634\u062a \u062f\u0631 \u0646\u0642\u0634 \u0631\u0633\u062a\u0645 \u062f\u0631 \u0627\u0633\u062a\u0627\u0646 \u0641\u0627\u0631\u0633 \u06a9\u0646\u062f\u0647 \u0634\u062f\u0647 \u200c\u0627\u0633\u062a.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-80750f214d084687b93fe6f2ba34eaee", "input": "\u0627\u0633\u06a9\u0627\u0631 \u0641\u06cc\u0646\u06af\u0644 \u0627\u064f. \u0641\u0650\u0644\u0627\u0647\u0631\u062a\u06cc \u0648\u06cc\u0644\u0632 \u0648\u0627\u06cc\u0644\u062f \u06a9\u0647 \u0628\u0647 \u0646\u0627\u0645 \u0647\u0646\u0631\u06cc \u0627\u0633\u06a9\u0627\u0631 \u0648\u0627\u06cc\u0644\u062f \u0634\u0646\u0627\u062e\u062a\u0647 \u0645\u06cc\u200c\u0634\u0648\u062f \u0634\u0627\u0639\u0631\u060c \u062f\u0627\u0633\u062a\u0627\u0646\u200c\u0646\u0648\u06cc\u0633\u060c \u0646\u0645\u0627\u06cc\u0634\u200c\u0646\u0627\u0645\u0647\u200c\u0646\u0648\u06cc\u0633 \u0648 \u0646\u0648\u06cc\u0633\u0646\u062f\u0647 \u062f\u0627\u0633\u062a\u0627\u0646\u200c\u0647\u0627\u06cc \u06a9\u0648\u062a\u0627\u0647 \u0627\u06cc\u0631\u0644\u0646\u062f\u06cc \u0628\u0648\u062f \u062f\u0631 \u062d\u0627\u0644\u06cc\u06a9\u0647 \u0648\u06cc\u06a9\u062a\u0648\u0631 \u0647\u0648\u06af\u0648 \u0634\u0627\u0639\u0631\u060c \u062f\u0627\u0633\u062a\u0627\u0646\u200c\u0646\u0648\u06cc\u0633 \u0648 \u0646\u0645\u0627\u06cc\u0634\u0646\u0627\u0645\u0647\u200c\u0646\u0648\u06cc\u0633 \u067e\u06cc\u0631\u0648 \u0633\u0628\u06a9 \u0631\u0648\u0645\u0627\u0646\u062a\u06cc\u0633\u0645\u060c \u0641\u0631\u0627\u0646\u0633\u0648\u06cc \u0628\u0648\u062f.\n\u0627\u0633\u06a9\u0627\u0631 \u0648\u0627\u06cc\u0644\u062f \u0646\u0648\u06cc\u0633\u0646\u062f\u0647 \u0627\u0647\u0644 \u0627\u06cc\u0631\u0644\u0646\u062f \u0645\u06cc \u0628\u0627\u0634\u062f. ", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-adbe93e0ce664405a3a1c02b6b3ade32", "input": "\"\u06a9\u0650\u0644\u06cc\u062f\u064e\u0631\" \u0628\u0644\u0646\u062f\u062a\u0631\u06cc\u0646 \u0627\u062b\u0631 \u0645\u062d\u0645\u0648\u062f \u062f\u0648\u0644\u062a\u200c\u0622\u0628\u0627\u062f\u06cc \u0627\u0633\u062a \u06a9\u0647 \u062f\u0631 \u0633\u0647 \u0647\u0632\u0627\u0631 \u0635\u0641\u062d\u0647 \u0648 \u062f\u0647 \u062c\u0644\u062f \u0628\u0647 \u0686\u0627\u067e \u0631\u0633\u06cc\u062f\u0647 \u0627\u0633\u062a.\n\"\u06a9\u0644\u06cc\u062f\u0631\" \u0628\u0647 \u0633\u0628\u06a9 \u0648\u0627\u0642\u0639\u200c\u06af\u0631\u0627\u06cc\u06cc \u0646\u0648\u0634\u062a\u0647 \u0634\u062f\u0647\u200c\u0627\u0633\u062a.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-e47cddf4839f45f0a29d419f0aaa633d", "input": "\u0627\u0628\u0631\u0627\u0647\u06cc\u0645 \u06af\u0644\u0633\u062a\u0627\u0646 \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f3\u06f4\u06f0 \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u062f\u0627\u0646\u06cc \u0641\u06cc\u0644\u0645 \"\u06cc\u06a9 \u0622\u062a\u0634\" \u0645\u0648\u0641\u0642 \u0628\u0647 \u062f\u0631\u06cc\u0627\u0641\u062a \u0645\u062f\u0627\u0644 \u0628\u0631\u0646\u0632 \u062c\u0634\u0646\u0648\u0627\u0631\u0647\u0654 \u0641\u06cc\u0644\u0645 \u06a9\u0648\u062a\u0627\u0647 \u0648\u0646\u06cc\u0632 \u0634\u062f. \u0627\u06cc\u0646 \u062c\u0627\u06cc\u0632\u0647\u060c \u0627\u0648\u0644\u06cc\u0646 \u062c\u0627\u06cc\u0632\u0647\u0654 \u0628\u06cc\u0646\u200c\u0627\u0644\u0645\u0644\u0644\u06cc \u0628\u0631\u0627\u06cc \u06cc\u06a9 \u06a9\u0627\u0631\u06af\u0631\u062f\u0627\u0646 \u0627\u06cc\u0631\u0627\u0646\u06cc \u0628\u0647\u200c\u0634\u0645\u0627\u0631 \u0645\u06cc\u200c\u0631\u0648\u062f.\n\u0633\u06cc\u062f\u0627\u0628\u0631\u0627\u0647\u06cc\u0645 \u06af\u0644\u0633\u062a\u0627\u0646 \u06a9\u0627\u0631\u06af\u0631\u062f\u0627\u0646\u060c \u062f\u0627\u0633\u062a\u0627\u0646\u200c\u0646\u0648\u06cc\u0633\u060c \u0645\u062a\u0631\u062c\u0645 \u0648 \u0631\u0648\u0632\u0646\u0627\u0645\u0647\u200c\u0646\u06af\u0627\u0631 \u0627\u06cc\u0631\u0627\u0646\u06cc \u0627\u0633\u062a.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-b08de9d5f47443edac8126b7cdd67ace", "input": "\u062f\u0631 \u062a\u0641\u06a9\u0631 \u0646\u0648\u06cc\u0646 \u0627\u0646\u0642\u0644\u0627\u0628\u06cc \u0634\u06cc\u0639\u0647\u060c \u062a\u0641\u0633\u06cc\u0631 \u0647\u0627\u06cc \u00ab\u062f\u0639\u0648\u062a \u06a9\u0646\u0646\u062f\u0647 \u0628\u0647 \u0622\u0631\u0627\u0645\u0634\u00bb \u0648 \u00ab\u0627\u0646\u0641\u0639\u0627\u0644\u00bb \u0648 \u00ab\u062a\u0633\u0644\u06cc\u0645\u00bb \u06a9\u0646\u0627\u0631 \u0646\u0647\u0627\u062f\u0647 \u0634\u062f \u0648 \u0631\u0648\u062d\u06cc\u0629 \u0645\u0628\u0627\u0631\u0632\u0647\u060c \u0633\u062a\u06cc\u0632 \u0648 \u0627\u0646\u0642\u0644\u0627\u0628\u06cc \u06af\u0631\u06cc \u062c\u0627\u06cc \u0622\u0646 \u0631\u0627 \u06af\u0631\u0641\u062a.\n\u062f\u0631 \u062f\u0627\u0646\u0634\u06af\u0627\u0647 \u062a\u0641\u06a9\u0631 \u062f\u0641\u0627\u0639 \u0627\u0632 \u0627\u0633\u0644\u0627\u0645 \u0648 \u0647\u0648\u06cc\u062a \u062f\u06cc\u0646\u06cc \u0628\u0647 \u062a\u062f\u0631\u06cc\u062c \u0631\u0634\u062f \u06a9\u0631\u062f.", "output": ["N"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-d5da72f5986044f496d1056c2f87d0fe", "input": "\u0645\u0648\u0631\u062e\u06cc\u0646 \u0645\u0639\u062a\u0642\u062f\u0646\u062f \u0645\u062c\u0645\u0648\u0639\u0647 \u06a9\u0627\u062e \u0633\u0627\u0633\u0627\u0646\u06cc \u06af\u0646\u0628\u062f\u06cc \u0633\u0631\u0648\u0633\u062a\u0627\u0646 \u062f\u0631 \u0632\u0645\u0627\u0646 \u0628\u0647\u0631\u0627\u0645 \u06af\u0648\u0631 \u0633\u0627\u0633\u0627\u0646\u06cc \u0633\u0627\u062e\u062a\u0647 \u0634\u062f\u0647 \u06a9\u0647 \u0628\u0648\u0633\u06cc\u0644\u0647 \u0645\u0647\u0631 \u0646\u0631\u0633\u06cc \u0648\u0632\u06cc\u0631 \u0645\u0639\u0631\u0648\u0641 \u0627\u0648 \u06a9\u0647 \u0635\u062f\u0627\u0631\u062a \u06cc\u0632\u062f\u06af\u0631\u062f \u0627\u0648\u0644 \u0648 \u06cc\u0632\u062f\u06af\u0631\u062f \u062f\u0648\u0645 \u0631\u0627 \u0646\u06cc\u0632 \u0639\u0647\u062f\u0647\u200c\u062f\u0627\u0631 \u0628\u0648\u062f\u0647 \u0633\u0627\u062e\u062a\u0647 \u0634\u062f\u0647\u200c\u0627\u0633\u062a.\n\u0645\u0648\u0631\u062e\u06cc\u0646 \u0633\u0627\u062e\u062a \u06a9\u0627\u062e \u06af\u0646\u0628\u062f\u06cc \u0633\u0631\u0648\u0633\u062a\u0627\u0646 \u0631\u0627 \u0645\u0631\u0628\u0648\u0637 \u0628\u0647 \u062f\u0648\u0631\u0647 \u0633\u0644\u0637\u0646\u062a \u062e\u0633\u0631\u0648 \u067e\u0631\u0648\u06cc\u0632 \u062f\u0627\u0646\u0633\u062a\u0647 \u0627\u0646\u062f.", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-04f621839a184337b5a5470caee9b2d6", "input": "\u0627\u0628\u0648\u0627\u0644\u0642\u0627\u0633\u0645 \u062d\u0627\u0644\u062a \u0627\u0632 \u0633\u0627\u0644 \u06f1\u06f3\u06f1\u06f7 \u0647\u0645\u06a9\u0627\u0631\u06cc \u062e\u0648\u062f \u0631\u0627 \u0628\u0627 \u0645\u062c\u0644\u0647 \u0645\u0639\u0631\u0648\u0641 \u0641\u06a9\u0627\u0647\u06cc \u062a\u0648\u0641\u06cc\u0642 \u0622\u063a\u0627\u0632 \u06a9\u0631\u062f \u0648 \u0628\u062d\u0631 \u0637\u0648\u06cc\u0644\u0647\u0627\u06cc \u062e\u0648\u062f \u0631\u0627 \u0628\u0627 \u0627\u0645\u0636\u0627\u06cc \u0647\u062f\u0647\u062f \u0645\u06cc\u0631\u0632\u0627 \u0648 \u0627\u0634\u0639\u0627\u0631\u0634 \u0631\u0627 \u0628\u0627 \u0627\u0633\u0627\u0645\u06cc \u0645\u0633\u062a\u0639\u0627\u0631 \u062e\u0631\u0648\u0633 \u0644\u0627\u0631\u06cc\u060c \u0634\u0648\u062e\u060c \u0641\u0627\u0636\u0644 \u0645\u0627\u0628 \u0648 \u0627\u0628\u0648\u0627\u0644\u0639\u06cc\u0646\u06a9 \u0628\u0647 \u0686\u0627\u067e \u0645\u06cc\u200c\u0631\u0633\u0627\u0646\u062f.\n\u062f\u0631 \u0645\u062c\u0644\u0647 \u062a\u0648\u0641\u06cc\u0642\u060c \u0627\u0645\u0636\u0627\u06cc \u0639\u0644\u06cc \u0627\u06a9\u0628\u0631 \u062f\u0647\u062e\u062f\u0627 \"\u0647\u062f\u0647\u062f \u0645\u06cc\u0631\u0632\u0627\" \u0628\u0648\u062f.", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-8e804c078ea4419bb3e9653ae8a14ec1", "input": "\u0648\u0627\u0698\u0647 \u0645\u062f\u0631\u0646\u06cc\u062a\u0647 \u0631\u0627 \u0645\u0639\u0645\u0648\u0644\u0627 \u0628\u0627 \u0645\u0641\u0647\u0648\u0645 \u062a\u062c\u062f\u062f \u0648 \u0648\u0627\u0698\u0647 \u0645\u062f\u0631\u0646\u06cc\u0633\u0645 \u0631\u0627 \u0628\u0627 \u062a\u062c\u062f\u062f \u06af\u0631\u0627\u06cc\u06cc \u0648 \u0646\u0648 \u06af\u0631\u0627\u06cc\u06cc \u0628\u0631\u0627\u0628\u0631 \u0645\u06cc \u062f\u0627\u0646\u0646\u062f.\n\u06af\u0627\u0647 \u062a\u062c\u062f\u062f \u0631\u0627 \u0628\u0627 \u0648\u0627\u0698\u0647 \u0645\u062f\u0631\u0646\u06cc\u062a\u0647 \u0647\u0645 \u0645\u0639\u0646\u0627 \u062f\u0627\u0646\u0633\u062a\u0647\u200c\u0627\u0646\u062f.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-1aada7e005f749a48d8cd2c864643143", "input": "\u062f\u0631 \u062c\u0646\u0627\u062d \u0634\u0645\u0627\u0644\u06cc \u0627\u06cc\u0646 \u062c\u0628\u0647\u0647 \u0627\u0631\u062a\u0634 \u0639\u0631\u0627\u0642 \u0628\u0631\u0627\u0628\u0631 \u067e\u0627\u06cc\u062f\u0627\u0631\u06cc \u0633\u0631\u0633\u062e\u062a\u0627\u0646\u0647\u200c\u06cc \u0646\u06cc\u0631\u0648\u0647\u0627\u06cc \u0645\u0633\u0644\u062d \u0648 \u0645\u0631\u062f\u0645 \u0627\u06cc\u0631\u0627\u0646 \u0627\u0632 \u062d\u0631\u06a9\u062a \u0628\u0627\u0632 \u0627\u06cc\u0633\u062a\u0627\u062f. \u0627\u0645\u0627 \u062f\u0631 \u062c\u0628\u0647\u0647\u200c \u0634\u0645\u0627\u0644\u06cc \u0633\u067e\u0627\u0647 \u0633\u0648\u0645 \u0627\u0631\u062a\u0634 \u0645\u062a\u062c\u0627\u0648\u0632 \u0628\u0627 \u0645\u0648\u0641\u0642\u06cc\u062a \u0631\u0648\u0628\u0631\u0648 \u0634\u062f \u0648 \u062a\u0648\u0627\u0646\u0633\u062a \u0628\u0647 \u0628\u06cc\u0634\u062a\u0631 \u0627\u0647\u062f\u0627\u0641 \u062e\u0648\u062f \u062f\u0633\u062a \u06cc\u0627\u0628\u062f \u0648 \u062f\u0631 \u0627\u0633\u062a\u0627\u0646\u200c\u0647\u0627\u06cc \u06a9\u0631\u0645\u0627\u0646\u0634\u0627\u0647 \u0648 \u0627\u06cc\u0644\u0627\u0645 \u0634\u0647\u0631\u200c\u0647\u0627\u06cc \u0646\u0641\u062a \u0634\u0647\u0631\u060c \u0642\u0635\u0631\u0634\u06cc\u0631\u06cc\u0646\u060c \u0633\u0648\u0645\u0627\u0631\u060c \u0645\u0647\u0631\u0627\u0646 \u0631\u0627 \u0627\u0634\u063a\u0627\u0644 \u0648 \u06cc\u0627 \u0645\u0648\u0631\u062f \u062a\u0639\u0631\u0636 \u062c\u062f\u06cc \u0642\u0631\u0627\u0631 \u062f\u0647\u062f.\n\u0627\u0631\u062a\u0634 \u0639\u0631\u0627\u0642 \u062f\u0631 \u0645\u0646\u0637\u0642\u0647 \u0627\u0633\u062a\u0627\u0646 \u06a9\u0631\u0645\u0627\u0646\u0634\u0627\u0647 \u0648 \u0627\u06cc\u0644\u0627\u0645 \u062a\u0648\u0627\u0646\u0633\u062a \u0634\u0647\u0631\u0647\u0627\u06cc \u0646\u0641\u062a \u0634\u0647\u0631\u060c \u0642\u0635\u0631 \u0634\u06cc\u0631\u06cc\u0646\u060c \u0645\u0647\u0631\u0627\u0646\u060c \u0633\u0648\u0645\u0627\u0631 \u0631\u0627 \u062f\u0631 \u0645\u0631\u0632 \u0627\u0634\u063a\u0627\u0644 \u06a9\u0646\u062f.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-158aed5aa190470da258c1637e0cc741", "input": "\u0628\u0632\u0631\u06af\u062a\u0631\u06cc\u0646 \u0639\u0627\u0645\u0644 \u0627\u0646\u062d\u0637\u0627\u0637 \u062a\u0645\u062f\u0646 \u0647\u0627 \u062d\u0631\u0635 \u0648 \u0622\u0632\u0645\u0646\u062f\u06cc \u0627\u0633\u062a. \u062f\u0631 \u0627\u06cc\u0646 \u0645\u0633\u06cc\u0631 \u0639\u06cc\u0634 \u0637\u0644\u0628\u06cc \u0648 \u0634\u0647\u0648\u062a \u0631\u0627\u0646\u06cc \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u0645\u0638\u0627\u0647\u0631 \u0639\u0645\u062f\u0647 \u0632\u0648\u0627\u0644 \u0627\u062c\u062a\u0645\u0627\u0639\u06cc\u060c \u062c\u0627\u0645\u0639\u0647 \u0631\u0627 \u0628\u0647 \u0646\u0627\u0627\u0645\u0646\u06cc \u0648 \u0628\u06cc\u200c\u0639\u0641\u062a\u06cc \u0633\u0648\u0642 \u0645\u06cc \u062f\u0647\u062f.\n\u0639\u0648\u0627\u0645\u0644 \u0627\u0646\u062d\u0637\u0627\u0637 \u062a\u0645\u062f\u0646\u200c\u0647\u0627 \u0627\u0632 \u0634\u0634 \u0645\u0648\u0631\u062f \u062a\u0634\u06a9\u06cc\u0644 \u0634\u062f\u0647 \u0627\u0633\u062a \u06a9\u0647 \u062d\u0631\u0635 \u0648 \u0622\u0632\u0645\u0646\u062f\u06cc \u06cc\u06a9\u06cc \u0627\u0632 \u0645\u0647\u0645\u062a\u0631\u06cc\u0646 \u0622\u0646\u0647\u0627 \u0627\u0633\u062a \u0648 \u062c\u0627\u0645\u0639\u0647 \u0631\u0627 \u0628\u0647 \u0646\u06cc\u0633\u062a\u06cc \u0645\u06cc \u06a9\u0634\u0627\u0646\u062f.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-03b50500e4634127b5690c7227d50e98", "input": "\u0622\u06cc\u062a \u0627\u0644\u0644\u0647 \u062d\u0627\u0626\u0631\u06cc \u0634\u06a9\u0644 \u062f\u06cc\u06af\u0631\u06cc \u0627\u0632 \u0645\u0628\u0627\u0631\u0632\u0647 \u0646\u0647\u0627\u062f \u062f\u06cc\u0646\u06cc \u0631\u0627 \u067e\u062f\u06cc\u062f \u0622\u0648\u0631\u062f \u06a9\u0647 \u067e\u06cc \u0631\u06cc\u0632\u06cc \u062d\u0631\u06a9\u062a \u0641\u0631\u0647\u0646\u06af\u06cc \u062d\u0648\u0632\u0648\u06cc \u0648 \u0627\u0635\u06cc\u0644 \u0634\u06cc\u0639\u06cc \u062f\u0631 \u0628\u0631\u0627\u0628\u0631 \u0627\u0645\u0648\u0627\u062c \u0641\u0632\u0627\u06cc\u0646\u062f\u0647 \u0648 \u0645\u062e\u0631\u0628 \u063a\u0631\u0628 \u06af\u0631\u0627\u06cc\u06cc \u0628\u0648\u062f.\u0627\u06af\u0631 \u0639\u0644\u0645\u0627\u06cc \u067e\u06cc\u0634 \u0627\u0632 \u0648\u06cc \u062f\u0631 \u0628\u0639\u062f \u0633\u06cc\u0627\u0633\u06cc \u0648 \u0627\u0646\u0642\u0644\u0627\u0628\u06cc \u0628\u0627 \u062f\u0648 \u0636\u0644\u0639 \u0627\u0633\u062a\u0639\u0645\u0627\u0631 \u0648 \u0627\u0633\u062a\u0628\u062f\u0627\u062f \u062f\u0631\u06af\u06cc\u0631 \u0628\u0648\u062f\u0646\u062f\u060c \u0627\u0648 \u0628\u0647 \u0636\u0644\u0639 \u0633\u0648\u0645 \u06cc\u0639\u0646\u06cc \u0644\u0627\u0626\u06cc\u062a\u06cc\u0633\u0645 \u062f\u0631 \u062d\u0627\u0644 \u067e\u06cc\u0634\u0631\u0648\u06cc \u062a\u0648\u062c\u0647 \u06a9\u0631\u062f \u0648 \u0628\u0647 \u0645\u0642\u0627\u0628\u0644\u0647 \u0628\u0627 \u0622\u0646 \u067e\u0631\u062f\u0627\u062e\u062a.\n\u0622\u06cc\u062a \u0627\u0644\u0644\u0647 \u062d\u0627\u0626\u0631\u06cc \u0628\u0631\u0627\u06cc \u0627\u0648\u0644\u06cc\u0646 \u0628\u0627\u0631 \u0645\u0628\u0627\u0631\u0632\u0647 \u0628\u0627 \u0644\u0627\u0626\u06cc\u062a\u06cc\u0633\u0645 \u0631\u0627 \u0622\u063a\u0627\u0632 \u06a9\u0631\u062f.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-91725534be7e4b45a31879fe59e55e71", "input": "\u0627\u0632 \u0622\u0646\u200f\u062c\u0627 \u06a9\u0647 \u062a\u062c\u0647\u06cc\u0632 \u06a9\u062a\u0627\u0628\u062e\u0627\u0646\u0647 \u0628\u06cc\u062a \u0627\u0644\u062d\u06a9\u0645\u0647 \u0648 \u062f\u0633\u062a\u200f\u06cc\u0627\u0628\u0649 \u0628\u0647 \u06a9\u062a\u0627\u0628\u200f\u0647\u0627\u0649 \u0627\u0631\u0632\u0634\u0645\u0646\u062f \u0639\u0644\u0645\u0649 \u0633\u0627\u06cc\u0631 \u0633\u0631\u0632\u0645\u06cc\u0646\u200f\u0647\u0627 \u062f\u0631 \u0633\u0631\u0644\u0648\u062d\u0647 \u0633\u06cc\u0627\u0633\u062a \u0645\u0627\u0645\u0648\u0646 \u0642\u0631\u0627\u0631 \u062f\u0627\u0634\u062a\u060c \u06a9\u062a\u0627\u0628\u200c\u200f\u0647\u0627\u0649 \u0632\u06cc\u0627\u062f\u0649 \u0628\u0647 \u062f\u0631\u0628\u0627\u0631 \u062e\u0644\u0627\u0641\u062a \u0628\u063a\u062f\u0627\u062f \u06af\u0633\u06cc\u0644 \u0634\u062f\u061b \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u0645\u062b\u0627\u0644\u060c \u0627\u0632 \u0631\u0648\u0645 \u062d\u062f\u0648\u062f \u067e\u0646\u062c \u0628\u0627\u0631 \u0634\u062a\u0631 \u06a9\u062a\u0627\u0628 \u0648 \u0627\u0632 \u062e\u0631\u0627\u0633\u0627\u0646 \u0635\u062f \u0628\u0627\u0631 \u0634\u062a\u0631 \u06a9\u062a\u0627\u0628 \u0628\u0647 \u0628\u063a\u062f\u0627\u062f \u0631\u0633\u06cc\u062f.\n\u0633\u0631\u0644\u0648\u062d\u0647 \u0633\u06cc\u0627\u0633\u062a \u0647\u0627\u0631\u0648\u0646 \u0627\u06cc\u0646 \u0628\u0648\u062f \u06a9\u0647 \u062f\u0631 \u0632\u0645\u0627\u0646 \u062e\u0644\u0627\u0641\u062a\u0634 \u062a\u0639\u062f\u0627\u062f \u0632\u06cc\u0627\u062f\u06cc \u06a9\u062a\u0627\u0628 \u0627\u0632 \u0633\u0631\u0632\u0645\u06cc\u0646\u200c\u0647\u0627\u06cc\u06cc \u0686\u0648\u0646 \u062e\u0631\u0627\u0633\u0627\u0646 \u0648 \u0631\u0648\u0645 \u0628\u0631\u0627\u06cc \u0645\u062c\u0647\u0632 \u06a9\u0631\u062f\u0646 \u06a9\u062a\u0627\u0628\u062e\u0627\u0646\u0647 \u0628\u06cc\u062a \u0627\u0644\u062d\u06a9\u0645\u0647 \u0628\u063a\u062f\u0627\u062f \u0641\u0631\u0633\u062a\u0627\u062f\u0647 \u0634\u062f.", "output": ["C"]}, "Prediction": "E."}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-e384d092a3004af69d313fa0e2d213e1", "input": "\u0647\u062f\u0627\u06cc\u062a \u062a\u0634\u0631\u06cc\u0639\u06cc \u0622\u0646 \u0627\u0633\u062a \u06a9\u0647 \u062e\u062f\u0627\u0648\u0646\u062f \u0628\u0647 \u0648\u0633\u06cc\u0644\u0647 \u067e\u06cc\u0627\u0645\u0628\u0631\u0627\u0646 \u0648 \u06a9\u062a\u0627\u0628\u200c\u0647\u0627\u06cc \u0622\u0633\u0645\u0627\u0646\u06cc\u060c \u0628\u0634\u0631 \u0631\u0627 \u062a\u0639\u0644\u06cc\u0645 \u0648 \u062a\u0631\u0628\u06cc\u062a \u0645\u06cc\u200c\u06a9\u0646\u062f \u0648 \u0645\u0633\u06cc\u0631\u062a\u06a9\u0627\u0645\u0644 \u0622\u0646\u0627\u0646 \u0631\u0627 \u0641\u0631\u0627\u0647\u0645 \u0646\u0645\u0648\u062f\u0647 \u0627\u0633\u062a\u060c \u0632\u06cc\u0631\u0627 \u0647\u062f\u0627\u06cc\u062a \u062a\u06a9\u0648\u06cc\u0646\u06cc \u0628\u0647 \u062a\u0646\u0647\u0627\u06cc\u06cc \u0646\u0645\u06cc\u200c\u200f\u062a\u0648\u0627\u0646\u062f \u0627\u0646\u0633\u0627\u0646 \u0631\u0627 \u0628\u0647 \u062a\u06a9\u0627\u0645\u0644 \u0628\u0631\u0633\u0627\u0646\u062f.\n\u0647\u062f\u0627\u06cc\u062a \u062a\u0634\u0631\u06cc\u0639\u06cc \u0628\u0647 \u0645\u0639\u0646\u0627\u06cc \u0647\u062f\u0627\u06cc\u062a \u0627\u0646\u0633\u0627\u0646 \u0627\u0632 \u0637\u0631\u06cc\u0642 \u0627\u0631\u0633\u0627\u0644 \u067e\u06cc\u0627\u0645\u0628\u0631\u0627\u0646 \u0648 \u0627\u0646\u0632\u0627\u0644 \u06a9\u062a\u0628 \u0622\u0633\u0645\u0627\u0646\u06cc \u0627\u0633\u062a.", "output": ["E"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-9b618b091aa54e1eb089f81377c7b903", "input": "\u0639\u0631\u0627\u0642 \u0628\u0627 \u062f\u0627\u0634\u062a\u0646 \u0628\u0646\u0627\u062f\u0631 \u0639\u0645\u062f\u0647 \u0628\u0635\u0631\u0647\u060c \u0627\u0645 \u0627\u0644\u0642\u0635\u0631 \u0648 \u0641\u0627\u0648 \u0648 \u0633\u06a9\u0648\u0647\u0627\u06cc \u0646\u0641\u062a\u06cc \u0627\u0644\u0627\u0645\u06cc\u0647 \u0648 \u0627\u0644\u0628\u06a9\u0631 \u0628\u062e\u0634 \u0639\u0645\u062f\u0647\u0627\u06cc \u0627\u0632 \u06a9\u0627\u0644\u0627 \u0647\u0627\u06cc \u062e\u0648\u062f \u0631\u0627 \u0627\u0632 \u0637\u0631\u06cc\u0642 \u062f\u0631\u06cc\u0627\u06cc\u06cc \u062c\u0627\u0628\u0647 \u062c\u0627 \u0645\u06cc \u06a9\u0646\u062f. \u0633\u0648\u0627\u062d\u0644 \u0639\u0631\u0627\u0642 \u062f\u0631 \u062e\u0644\u06cc\u062c \u0641\u0627\u0631\u0633 \u0627\u0632 \u062f\u0647\u0627\u0646\u0647 \u0641\u0627\u0648 (\u0631\u0627\u0633\u200c\u0627\u0644\u0628\u06cc\u0634\u0647) \u0634\u0631\u0648\u0639 \u0645\u06cc \u0634\u0648\u062f \u0648 \u062a\u0627 \u0628\u0646\u062f\u0631 \u0627\u0645 \u0627\u0644\u0642\u0635\u0631 \u0628\u0647 \u0637\u0648\u0644 \u06f4\u06f8 \u06a9\u06cc\u0644\u0648\u0645\u062a\u0631 \u0627\u062f\u0627\u0645\u0647 \u062f\u0627\u0631\u062f.\n\u0633\u0648\u0627\u062d\u0644 \u0639\u0631\u0627\u0642 \u062f\u0631 \u062e\u0644\u06cc\u062c \u0641\u0627\u0631\u0633 \u0627\u0632 \u062f\u0647\u0627\u0646\u0647 \u0641\u0627\u0648 \u062a\u0627 \u0627\u0645\u200c\u0627\u0644\u0642\u0635\u0631 \u0628\u0647 \u0637\u0648\u0644 \u06f4\u06f8 \u06a9\u06cc\u0644\u0648\u0645\u062a\u0631 \u0627\u062f\u0627\u0645\u0647 \u062f\u0627\u0631\u062f.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-589366b1baf749339b27045cb0bf8b45", "input": "\u062f\u0631 \u0628\u06cc\u0646 \u0627\u06cc\u0631\u0627\u0646\u06cc\u0627\u0646 \u0628\u0627\u0633\u062a\u0627\u0646 \u0628\u0631\u0627\u06cc \u0646\u0648\u0634\u06cc\u062f\u0646 \u0627\u0628\u0632\u0627\u0631\u06af\u0648\u0646\u0627\u06af\u0648\u0646\u06cc \u0644\u0627\u0632\u0645 \u0628\u0648\u062f \u06a9\u0647 \u0627\u0632 \u0627\u0628\u062f\u0627\u0639\u0627\u062a \u06a9\u0647\u0646 \u0627\u06cc\u0631\u0627\u0646\u06cc\u0627\u0646 \u062f\u0631\u0639\u0647\u062f \u06a9\u0647\u0646 \u0633\u0627\u062e\u062a \u062c\u0627\u0645 \u0647\u0627\u06cc\u06cc \u0628\u0647 \u0634\u06a9\u0644 \u06a9\u0644\u0647 \u062c\u0627\u0646\u0648\u0631\u0627\u0646 \u0642\u0648\u06cc \u0628\u0646\u06cc\u0647 \u0628\u0648\u062f \u06a9\u0647 \u0628\u0647 \u0622\u0646\u200c\u0647\u0627 \u0631\u06cc\u062a\u0648\u0646 \u06af\u0641\u062a\u0647 \u0645\u06cc\u0634\u062f \u0648 \u0628\u0631\u0627\u06cc\u0646 \u0628\u0627\u0648\u0631 \u0628\u0648\u062f\u0646\u062f \u0636\u0645\u0646 \u0646\u0648\u0634\u06cc\u062f\u0646 \u0627\u0632 \u0627\u06cc\u0646 \u062c\u0627\u0645 \u0647\u0627 \u0632\u0648\u0631 \u0648 \u0642\u0648\u0647 \u062c\u0627\u0646\u0648\u0631 \u0628\u0647 \u0622\u0646\u0647\u0627 \u0645\u0646\u062a\u0642\u0644 \u0645\u06cc\u0634\u0648\u062f. \n\u0631\u06cc\u062a\u0648\u0646 \u0633\u0627\u062e\u062a\u0647 \u062f\u0633\u062a \u0647\u0646\u0631\u0645\u0646\u062f\u0627\u0646 \u0627\u06cc\u0631\u0627\u0646\u06cc \u0628\u0648\u062f \u06a9\u0647 \u0628\u0647 \u0627\u0634\u06a9\u0627\u0644 \u0647\u0646\u062f\u0633\u06cc \u0633\u0627\u062e\u062a\u0647 \u0645\u06cc\u0634\u062f.", "output": ["C"]}, "Prediction": "E."}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-9349ff334f3e4904b4af1f01e344f364", "input": "\u062f\u0631 \u0622\u0633\u062a\u0627\u0646\u0647 \u062c\u0646\u06af \u062a\u062d\u0645\u06cc\u0644\u06cc\u060c \u0635\u062f\u0627\u0645 \u06af\u0641\u062a: \u0645\u0627 \u0627\u0632 \u062a\u0631\u0648\u0631\u06cc\u0633\u0645 \u0648\u062d\u0634\u062a\u06cc \u0646\u062f\u0627\u0631\u06cc\u0645\u060c \u062f\u0648\u0644\u062a \u0633\u0648\u0633\u06cc\u0627\u0644\u06cc\u0633\u062a \u0639\u0631\u0627\u0642 \u0628\u06cc\u0634 \u0627\u0632 \u0647\u0631 \u06a9\u0634\u0648\u0631 \u062f\u06cc\u06af\u0631 \u062f\u0631 \u062e\u0627\u0648\u0631\u0645\u06cc\u0627\u0646\u0647 \u0645\u0648\u0631\u062f \u062a\u0647\u062f\u06cc\u062f \u0641\u0631\u0645\u0627\u0646 \u0622\u06cc\u062a\u200c\u0644\u0644\u0647 \u062e\u0645\u06cc\u0646\u06cc \u0628\u0631\u0627\u06cc \u0635\u062f\u0648\u0631 \u0627\u0646\u0642\u0644\u0627\u0628 \u0627\u06cc\u0631\u0627\u0646 \u0642\u0631\u0627\u0631 \u062f\u0627\u0631\u062f\u060c \u0627\u06cc\u0631\u0627\u0646 \u06cc\u06a9 \u06a9\u0634\u0648\u0631 \u0634\u06cc\u0639\u0647 \u0628\u0648\u062f\u0647 \u0648 \u0646\u06cc\u0645\u06cc \u0627\u0632 \u062c\u0645\u0639\u06cc\u062a \u0661\u0663 \u0645\u06cc\u0644\u06cc\u0648\u0646\u06cc \u0639\u0631\u0627\u0642 \u0631\u0627 \u0646\u06cc\u0632 \u0634\u06cc\u0639\u06cc\u0627\u0646 \u062a\u0634\u06a9\u06cc\u0644 \u0645\u06cc\u200c\u062f\u0647\u0646\u062f. \n\u062f\u0631 \u0622\u0633\u062a\u0627\u0646\u0647 \u062c\u0646\u06af \u062a\u062d\u0645\u06cc\u0644\u06cc\u060c \u0646\u06cc\u0645\u06cc \u0627\u0632 \u062c\u0645\u0639\u06cc\u062a \u06f1\u06f3 \u0645\u06cc\u0644\u06cc\u0648\u0646 \u0639\u0631\u0627\u0642 \u0631\u0627 \u0634\u06cc\u0639\u06cc\u0627\u0646 \u062a\u0634\u06a9\u06cc\u0644 \u062f\u0627\u062f\u0646\u062f", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-0917d02d87644c83be34615df1399805", "input": "\u0633\u0627\u0644 \u0647\u0627 \u0628\u0639\u062f \u0627\u0632 \u062c\u0646\u06af \u0628\u0632\u0631\u06af \u0645\u0631\u0648\u060c \u0627\u0648\u0632\u0628\u06a9\u0627\u0646 \u067e\u0633 \u0627\u0632 \u0627\u0637\u0644\u0627\u0639 \u06cc\u0627\u0641\u062a\u0646 \u0627\u0632 \u0641\u0648\u062a \u0634\u0627\u0647 \u0627\u0633\u0645\u0627\u0639\u06cc\u0644 \u0648 \u0627\u062e\u062a\u0644\u0627\u0641 \u0645\u06cc\u0627\u0646 \u0633\u0631\u0627\u0646 \u0642\u0632\u0644\u0628\u0627\u0634 \u060c \u0641\u0631\u0635\u062a \u0631\u0627 \u0645\u063a\u062a\u0646\u0645 \u0634\u0645\u0631\u062f\u0647\u060c \u0627\u0632 \u062c\u06cc\u062d\u0648\u0646 \u06af\u0630\u0634\u062a\u0646\u062f \u0648 \u0645\u062a\u0648\u062c\u0647 \u062e\u0631\u0627\u0633\u0627\u0646 \u0634\u062f\u0646\u062f. \u0645\u062c\u0645\u0648\u0639\u0647 \u0627\u06cc\u0646 \u0627\u062a\u0641\u0627\u0642\u0627\u062a \u0648 \u062f\u0631\u06af\u06cc\u0631\u06cc \u0647\u0627 \u060c \u0639\u0627\u0642\u0628\u062a \u0628\u0647 \u062c\u0646\u06af \u062c\u0627\u0645 (\u062f\u0648\u0645\u06cc\u0646 \u062c\u0646\u06af \u0628\u0632\u0631\u06af \u0627\u0648\u0632\u0628\u06a9\u0627\u0646 \u0648 \u0635\u0641\u0648\u06cc\u0627\u0646) \u0648 \u067e\u06cc\u0631\u0648\u0632\u06cc \u0627\u06cc\u0631\u0627\u0646\u06cc\u0627\u0646 \u0627\u0646\u062c\u0627\u0645\u06cc\u062f.\n\u062c\u0646\u06af \u0647\u0631\u0627\u062a \u062f\u0648\u0645\u06cc\u0646 \u062c\u0646\u06af \u0628\u0632\u0631\u06af \u0645\u06cc\u0627\u0646 \u0635\u0641\u0648\u06cc\u0627\u0646 \u0648 \u0627\u0648\u0632\u0628\u06a9\u0627\u0646 \u0628\u0639\u062f \u0627\u0632 \u062c\u0646\u06af \u0645\u0631\u0648 \u0628\u0648\u062f.", "output": ["C"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-6ef00843057a4b8cbf6ce048e6294abe", "input": "\u0647\u062f\u0627\u06cc\u062a \u062a\u0634\u0631\u06cc\u0639\u06cc \u0639\u0628\u0627\u0631\u062a \u0627\u0633\u062a \u0627\u0632 \u0647\u062f\u0627\u06cc\u062a \u0627\u0646\u0633\u0627\u0646 \u0628\u0648\u0633\u06cc\u0644\u0647 \u067e\u06cc\u0627\u0645\u0628\u0631\u0627\u0646 \u0627\u0644\u0647\u06cc. \u0627\u0646\u0633\u0627\u0646 \u0647\u0645\u0627\u0646\u0646\u062f \u0633\u0627\u06cc\u0631 \u0645\u062e\u0644\u0648\u0642\u0627\u062a \u0645\u0634\u0645\u0648\u0644 \u0647\u062f\u0627\u06cc\u062a \u062a\u06a9\u0648\u06cc\u0646\u06cc \u0646\u06cc\u0632 \u0647\u0633\u062a. \u0648\u0644\u06cc \u0627\u0632 \u0622\u0646\u062c\u0627 \u06a9\u0647 \u0627\u0646\u0633\u0627\u0646 \u0645\u0648\u062c\u0648\u062f\u06cc \u0627\u0633\u062a \u062f\u0627\u0631\u0627\u06cc \u0639\u0642\u0644 \u0648 \u0627\u062e\u062a\u06cc\u0627\u0631 \u062e\u062f\u0627\u0648\u0646\u062f \u0647\u062f\u0627\u06cc\u062a \u062a\u0634\u0631\u06cc\u0639\u06cc \u0627\u0648 \u062f\u0631 \u06a9\u0646\u0627\u0631 \u0647\u062f\u0627\u06cc\u062a \u0641\u0637\u0631\u06cc \u0648 \u063a\u0631\u06cc\u0632\u06cc \u0627\u0634 \u0644\u0627\u0632\u0645 \u0648 \u0636\u0631\u0648\u0631\u06cc \u0627\u0633\u062a.\n\u0628\u0627 \u0648\u062c\u0648\u062f \u0639\u0646\u0635\u0631 \u0639\u0642\u0644 \u0648 \u0627\u062e\u062a\u06cc\u0627\u0631 \u062f\u0631 \u0622\u062f\u0645\u06cc\u060c \u0647\u062f\u0627\u06cc\u062a \u063a\u0631\u06cc\u0632\u06cc \u0628\u0631\u0627\u06cc\u0634 \u06a9\u0627\u0641\u06cc \u0645\u06cc \u0628\u0627\u0634\u062f.", "output": ["C"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-9118c3c10f5048eb8544e3fdadf196b8", "input": "\u0648\u06cc\u0646\u0633\u062a\u0648\u0646 \u0686\u0631\u0686\u06cc\u0644\u060c \u0646\u062e\u0633\u062a \u0648\u0632\u06cc\u0631 \u0628\u0631\u06cc\u062a\u0627\u0646\u06cc\u0627 \u062f\u0631 \u0633\u062e\u0646\u0631\u0627\u0646\u06cc \u062a\u0627\u0631\u06cc\u062e\u06cc \u062e\u0648\u062f \u0628\u0631\u0627\u06cc \u0646\u062e\u0633\u062a\u06cc\u0646 \u0628\u0627\u0631 \u0639\u0628\u0627\u0631\u062a \u00ab\u067e\u0631\u062f\u0647 \u0622\u0647\u0646\u06cc\u0646\u00bb \u0631\u0627 \u062f\u0631 \u062a\u0648\u0635\u06cc\u0641 \u0627\u0642\u062f\u0627\u0645\u0627\u062a \u062d\u06a9\u0648\u0645\u062a \u06a9\u0645\u0648\u0646\u06cc\u0633\u062a\u06cc \u0634\u0648\u0631\u0648\u06cc \u0628\u0647 \u06a9\u0627\u0631 \u0628\u0631\u062f. \u067e\u0631\u062f\u0647 \u0622\u0647\u0646\u06cc\u0646 \u0646\u0627\u0645 \u0628\u062e\u0634 \u0628\u0646\u062f\u06cc \u0645\u0631\u0632\u06cc \u0627\u0631\u0648\u067e\u0627 \u067e\u0633 \u0627\u0632 \u062c\u0646\u06af \u062c\u0647\u0627\u0646\u06cc \u062f\u0648\u0645 \u0648 \u062f\u0631 \u062f\u0648\u0631\u0627\u0646 \u062c\u0646\u06af \u0633\u0631\u062f \u0628\u0647 \u062f\u0648 \u0628\u062e\u0634 \u0627\u0631\u0648\u067e\u0627\u06cc \u063a\u0631\u0628\u06cc \u0648 \u06a9\u0634\u0648\u0631\u0647\u0627\u06cc \u0639\u0636\u0648 \u067e\u06cc\u0645\u0627\u0646 \u0648\u0631\u0634\u0648(\u0627\u0631\u0648\u067e\u0627\u06cc \u0634\u0631\u0642\u06cc) \u062a\u0648\u0633\u0637 \u0634\u0648\u0631\u0648\u06cc \u0628\u0648\u062f.\n\u0634\u0648\u0631\u0648\u06cc \u067e\u0633 \u0627\u0632 \u062c\u0646\u06af \u062c\u0647\u0627\u0646\u06cc \u062f\u0648\u0645 \u067e\u0631\u062f\u0647 \u0622\u0647\u0646\u06cc\u0646\u06cc \u0645\u06cc\u0627\u0646 \u063a\u0631\u0628 \u0648 \u0634\u0631\u0642 \u0627\u0631\u0648\u067e\u0627 \u0627\u06cc\u062c\u0627\u062f \u06a9\u0631\u062f.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-e4ef59c6adce4c4c919236aad31a2eba", "input": "\u062f\u0631\u062e\u0634\u0634 \u0631\u0648\u0634\u0646\u0641\u06a9\u0631\u06cc \u062f\u0631 \u0627\u0631\u0648\u067e\u0627 \u0628\u0627 \u0627\u0638\u0647\u0627\u0631\u0627\u062a \u062c\u0646\u062c\u0627\u0644 \u0628\u0631\u0627\u0646\u06af\u06cc\u0632 \u00ab\u067e\u062a\u0631 \u0622\u0628\u0644\u0627\u0631\u062f\u00bb \u0641\u0631\u0627\u0646\u0633\u0648\u06cc \u0639\u0644\u06cc\u0647 \u067e\u0627\u067e \u0634\u0631\u0648\u0639 \u0634\u062f. \u0622\u0628\u0644\u0627\u0631\u062f \u0646\u062e\u0633\u062a\u06cc\u0646 \u0641\u06cc\u0644\u0633\u0648\u0641\u06cc \u0628\u0648\u062f \u06a9\u0647 \u0628\u062d\u062b \u062c\u062f\u0627\u0644 \u0645\u06cc\u0627\u0646 \u0639\u0642\u0644 \u0648 \u0627\u06cc\u0645\u0627\u0646 \u0631\u0627 \u0645\u0637\u0631\u062d \u06a9\u0631\u062f. \n\u0641\u06cc\u0644\u06cc\u067e \u0648\u0644\u0641 \u0627\u0648\u0644\u06cc\u0646 \u0641\u06cc\u0644\u0633\u0648\u0641 \u0641\u0631\u0627\u0646\u0633\u0648\u06cc \u0628\u0648\u062f \u06a9\u0647 \u0645\u0628\u062d\u062b \u062c\u062f\u0627\u0644 \u0639\u0642\u0644 \u0648 \u0627\u06cc\u0645\u0627\u0646 \u0631\u0627 \u067e\u06cc\u0631\u0648 \u062c\u0631\u06cc\u0627\u0646 \u0647\u0627\u06cc \u0631\u0648\u0634\u0646\u0641\u06a9\u0631\u06cc \u062f\u0631 \u0627\u0631\u0648\u067e\u0627 \u0628\u0647 \u0645\u06cc\u0627\u0646 \u06a9\u0634\u06cc\u062f.", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-241f421117f64fe7aa95335700a00207", "input": "\u062f\u0631 \u0633\u0627\u0644 \u06f3\u06f8\u06f5 \u0642\u0645\u0631\u06cc / \u06f9\u06f9\u06f3 \u0645\u06cc\u0644\u0627\u062f\u06cc \u0627\u0645\u06cc\u0631 \u0627\u0628\u0648 \u0627\u0644\u0639\u0628\u0627\u0633 \u0645\u0623\u0645\u0648\u0646 \u0628\u0646 \u0645\u062d\u0645\u062f \u0628\u0627 \u06a9\u0634\u062a\u0646 \u0627\u0628\u0648\u0639\u0628\u062f\u0627\u0644\u0644\u0647 \u0628\u0646 \u0627\u062d\u0645\u062f \u062d\u06a9\u0648\u0645\u062a \u0622\u0646\u0627\u0646 \u0631\u0627 \u0645\u0646\u0642\u0631\u0636 \u06a9\u0631\u062f \u0648 \u062d\u06a9\u0648\u0645\u062a \u0645\u0627\u0645\u0648\u0646\u06cc\u0627\u0646 \u0628\u0631 \u0633\u0631 \u06a9\u0627\u0631 \u0622\u0645\u062f. \u0645\u0623\u0645\u0648\u0646 \u067e\u0633 \u0627\u0632 \u0642\u062f\u0631\u062a \u06af\u0631\u0641\u062a\u0646 \u062f\u0631 \u062e\u0648\u0627\u0631\u0632\u0645 \u0644\u0642\u0628 \u062e\u0648\u0627\u0631\u0632\u0645\u0634\u0627\u0647 \u0631\u0627 \u0628\u0631\u0627\u06cc \u062e\u0648\u062f \u0627\u0646\u062a\u062e\u0627\u0628 \u06a9\u0631\u062f \u0648 \u0628\u062f\u06cc\u0646 \u06af\u0648\u0646\u0647 \u062f\u0648\u0645\u06cc\u0646 \u0633\u0644\u0633\u0644\u0647 \u062e\u0648\u0627\u0631\u0632\u0645\u0634\u0627\u0647\u06cc \u062a\u0623\u0633\u06cc\u0633 \u0634\u062f.\n\u0645\u0623\u0645\u0648\u0646 \u062e\u0648\u0627\u0631\u0632\u0645\u0634\u0627\u0647 \u0628\u0631 \u0627\u062b\u0631 \u0627\u062e\u062a\u0644\u0627\u0641\u0627\u062a\u06cc \u06a9\u0647 \u0628\u0627 \u0633\u067e\u0647 \u0633\u0627\u0644\u0627\u0631\u0627\u0646\u0634 \u062f\u0627\u0634\u062a \u0628\u0647 \u0642\u062a\u0644 \u0631\u0633\u06cc\u062f \u0648 \u067e\u0633\u0631\u0634 \u0627\u0628\u0648\u0627\u0644\u062d\u0633\u0646 \u062c\u0627\u06cc\u06af\u0632\u06cc\u0646 \u0627\u0648 \u0634\u062f.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-72778de10bca430eb5ef3d398ab3a3a2", "input": "\u0634\u0627\u06cc\u0639\u0647 \u06cc\u06a9\u06cc \u0627\u0632 \u062a\u0631\u0641\u0646\u062f \u0647\u0627\u06cc \u0631\u0633\u0627\u0646\u0647 \u0627\u06cc \u0648 \u0639\u0645\u0644\u06cc\u0627\u062a \u0631\u0648\u0627\u0646\u06cc \u062f\u0631 \u062c\u0646\u06af \u0646\u0631\u0645 \u0627\u0633\u062a.\u0628\u0627 \u062a\u0648\u062c\u0647 \u0628\u0647 \u0645\u0648\u0636\u0648\u0639 \u0648 \u062c\u0627\u0645\u0639\u0647 \u0647\u062f\u0641\u060c \u0634\u0627\u06cc\u0639\u0627\u062a \u06af\u0648\u0646\u0627\u06af\u0648\u0646\u06cc \u062a\u0648\u0644\u06cc\u062f \u0645\u06cc \u0634\u0648\u0646\u062f \u06a9\u0647 \u0639\u0628\u0627\u0631\u062a\u0646\u062f \u0627\u0632 \u0634\u0627\u06cc\u0639\u0627\u062a \u062a\u0641\u0631\u0642\u0647 \u0627\u0641\u06a9\u0646\u060c \u0647\u0631\u0627\u0633 \u0622\u0648\u0631\u060c \u0627\u0645\u06cc\u062f \u0628\u062e\u0634\u060c \u0622\u062a\u0634\u06cc\u0646\u060c \u062e\u0632\u0646\u062f\u0647\u060c \u062f\u0644\u0641\u06cc\u0646\u06cc \u06cc\u0627 \u063a\u0648\u0627\u0635\u06cc\n\u0622\u062a\u0634\u06cc\u0646\u060c \u0627\u0645\u06cc\u062f \u0628\u062e\u0634\u060c \u062a\u0641\u0631\u0642\u0647 \u0627\u0641\u06a9\u0646 \u0648 \u0647\u0631\u0627\u0633 \u0622\u0648\u0631 \u0627\u0632 \u0627\u0646\u0648\u0627\u0639 \u0634\u0627\u06cc\u0639\u0647 \u06cc\u06a9\u06cc \u0627\u0632 \u0631\u0648\u0634 \u0647\u0627\u06cc \u0646\u0631\u0645 \u0627\u0633\u062a.", "output": ["E"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-019bab13c30246dfba58856a270f12cc", "input": "\u0641\u0631\u0648\u063a\u06cc \u0628\u0633\u0637\u0627\u0645\u06cc \u062f\u0631 \u0646\u0648\u062c\u0648\u0627\u0646\u06cc \u062f\u0631 \u0632\u0645\u0627\u0646 \u0641\u062a\u062d\u0639\u0644\u06cc \u0634\u0627\u0647\u060c \u0645\u062f\u062a\u06cc \u0631\u0627 \u062f\u0631 \u0634\u0647\u0631 \u0628\u0633\u0637\u0627\u0645 \u0628\u0647 \u0633\u0631 \u0628\u0631\u062f\u061b \u0648\u0632\u0647\u0645\u0627\u0646\u200c\u0631\u0648\u06cc \u0628\u0647 \u0628\u0633\u0637\u0627\u0645\u06cc \u0645\u0646\u062a\u0633\u0628 \u06af\u0634\u062a. \u0627\u0648 \u0686\u0646\u062f\u06cc \u0631\u0627 \u0646\u06cc\u0632 \u062f\u0631 \u0634\u0647\u0631 \u06a9\u0631\u0645\u0627\u0646\u060c \u062f\u0631 \u062e\u062f\u0645\u062a \u062d\u0633\u0646\u0639\u0644\u06cc \u0645\u06cc\u0631\u0632\u0627 \u0634\u062c\u0627\u0639\u200c\u0627\u0644\u0633\u0644\u0637\u0646\u0647 \u06af\u0630\u0631\u0627\u0646\u062f \u06a9\u0647 \u062f\u0631 \u0647\u0645\u0627\u0646 \u062f\u0648\u0631\u0627\u0646\u060c \u0628\u0646\u0627 \u0628\u0647 \u062f\u0631\u062e\u0648\u0627\u0633\u062a \u0634\u062c\u0627\u0639\u200c\u0627\u0644\u0633\u0644\u0637\u0646\u0647\u060c \u062a\u062e\u0644\u0635 \u062e\u0648\u062f \u0631\u0627 \u0628\u0647 \u0646\u0627\u0645 \u0641\u0631\u0632\u0646\u062f \u0627\u0648 \u00ab\u0641\u0631\u0648\u063a\u200c\u0627\u0644\u062f\u0648\u0644\u0647\u00bb\u060c \u0641\u0631\u0648\u063a\u06cc \u0646\u0647\u0627\u062f. \u0641\u0631\u0648\u063a\u06cc \u0628\u0633\u0637\u0627\u0645\u06cc \u062a\u0627 \u067e\u06cc\u0634 \u0627\u0632 \u0622\u0646 \u062f\u0631 \u0634\u0639\u0631\u0647\u0627\u06cc\u0634\u060c \u062a\u062e\u0644\u0635 \u0645\u0633\u06a9\u06cc\u0646 \u0631\u0627 \u0628\u0647\u200c\u06a9\u0627\u0631\u0645\u06cc\u200c\u0628\u0631\u062f.\n\"\u062b\u0627\u0628\u062a\" \u0646\u062e\u0633\u062a\u06cc\u0646 \u062a\u062e\u0644\u0635 \u0641\u0631\u0648\u063a\u06cc \u0628\u0633\u0637\u0627\u0645\u06cc \u0645\u06cc \u0628\u0627\u0634\u062f.", "output": ["C"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-fce87e9655e941d3b5c4057bf33168aa", "input": "\u062f\u06a9\u062a\u0631 \u063a\u0644\u0627\u0645\u062d\u0633\u06cc\u0646 \u0645\u0635\u0627\u062d\u0628 \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f3\u06f3\u06f5 \u0639\u0647\u062f\u0647\u200c\u062f\u0627\u0631 \u0637\u0631\u062d\u200c\u0631\u06cc\u0632\u06cc \u0648 \u0633\u0631\u067e\u0631\u0633\u062a\u06cc \u062f\u0627\u0626\u0631\u0629\u0627\u0644\u0645\u0639\u0627\u0631\u0641 \u0641\u0627\u0631\u0633\u06cc \u0634\u062f \u0648 \u062a\u0627 \u06f1\u06f3\u06f5\u06f0 \u06a9\u0647 \u0622\u0646 \u0645\u0633\u0626\u0648\u0644\u06cc\u062a \u0631\u0627 \u0628\u0647 \u0639\u0647\u062f\u0647 \u062f\u0627\u0634\u062a\u060c \u0628\u0631 \u062a\u0631\u062c\u0645\u0647 \u0648 \u062a\u0623\u0644\u06cc\u0641 \u06a9\u0644\u06cc\u0647\u0654 \u0645\u0642\u0627\u0644\u0627\u062a \u062f\u0627\u0626\u0631\u0629\u0627\u0644\u0645\u0639\u0627\u0631\u0641 \u0646\u0638\u0627\u0631\u062a \u062f\u0627\u0634\u062a. \u062f\u0627\u0626\u0631\u0629\u0627\u0644\u0645\u0639\u0627\u0631\u0641 \u0641\u0627\u0631\u0633\u06cc \u0646\u062e\u0633\u062a\u06cc\u0646 \u062f\u0627\u0626\u0631\u0629\u0627\u0644\u0645\u0639\u0627\u0631\u0641 \u0639\u0645\u0648\u0645\u06cc \u062f\u0631 \u0632\u0628\u0627\u0646 \u0641\u0627\u0631\u0633\u06cc \u0627\u0633\u062a\u060c \u06a9\u0647 \u0628\u0631 \u0627\u0633\u0627\u0633 \u0634\u06cc\u0648\u0647\u200c\u0647\u0627\u06cc \u0646\u0648\u06cc\u0646 \u062f\u0627\u0646\u0634\u0646\u0627\u0645\u0647\u200c\u0646\u0648\u06cc\u0633\u06cc \u062a\u0647\u06cc\u0647 \u0634\u062f\u0647\u200c\u0627\u0633\u062a \u0648 \u0645\u0634\u0647\u0648\u0631\u062a\u0631\u06cc\u0646 \u0641\u0639\u0627\u0644\u06cc\u062a \u0648 \u062f\u0633\u062a\u0627\u0648\u0631\u062f \u063a\u0644\u0627\u0645\u062d\u0633\u06cc\u0646 \u0645\u0635\u0627\u062d\u0628 \u0628\u0647\u200c\u0634\u0645\u0627\u0631 \u0645\u06cc\u200c\u0622\u06cc\u062f.\n\u0645\u0635\u0627\u062d\u0628 \u0628\u0627 \u0642\u0647\u0631 \u062e\u0648\u062f \u0627\u0646\u062a\u0634\u0627\u0631 \u062c\u0644\u062f \u0633\u0648\u0645 \u06a9\u062a\u0627\u0628 \u0631\u0627 \u0628\u0631\u0627\u06cc \u0633\u0627\u0644\u200c\u0647\u0627 \u0628\u0647 \u062a\u0639\u0648\u06cc\u0642 \u0627\u0646\u062f\u0627\u062e\u062a.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-c8d3287554404552b8d3694d1655bf2a", "input": "\u0627\u06af\u0631 \u0628\u062e\u0648\u0627\u0647\u06cc\u0645 \u0628\u0647 \u062a\u0639\u0628\u06cc\u0631 \u0639\u0644\u0645\u0627\u06cc \u0642\u062f\u06cc\u0645 \u062e\u0648\u062f\u0645\u0627\u0646 \u0628\u06cc\u0627\u0646 \u06a9\u0646\u06cc\u0645\u060c \u0628\u0627\u06cc\u062f \u0627\u06cc\u0646 \u0637\u0648\u0631 \u0628\u06af\u0648\u06cc\u06cc\u0645 \u06a9\u0647 \u0627\u06cc\u062f\u0626\u0648\u0644\u0648\u0698\u06cc \u062d\u06a9\u0645\u062a \u0639\u0645\u0644\u06cc \u0627\u0633\u062a \u0648 \u062c\u0647\u0627\u0646 \u0628\u06cc\u0646\u06cc \u062d\u06a9\u0645\u062a \u0646\u0638\u0631\u06cc.\n\u062d\u06a9\u0645\u062a \u0646\u0638\u0631\u06cc \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u0627\u06cc\u062f\u0626\u0648\u0644\u0648\u0698\u06cc \u0648 \u062d\u06a9\u0645\u062a \u0639\u0645\u0644\u06cc \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u062c\u0647\u0627\u0646\u200c\u0628\u06cc\u0646\u06cc \u062f\u0631 \u0646\u0638\u0631 \u06af\u0631\u0641\u062a\u0647 \u0645\u06cc\u200c\u0634\u0648\u062f.", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-da72232d86aa45cd99ff84a01b28bcb0", "input": "\u062f\u0627\u0646\u0634\u0645\u0646\u062f\u06cc \u06cc\u0647\u0648\u062f\u06cc \u0627\u0632 \u0627\u0645\u06cc\u0631\u0627\u0644\u0645\u0624\u0645\u0646\u06cc\u0646 (\u0639) \u067e\u0631\u0633\u06cc\u062f: \u0622\u06cc\u0627 \u067e\u0631\u0648\u0631\u062f\u06af\u0627\u0631\u062a \u0631\u0627 \u062f\u0631 \u062d\u0627\u0644 \u0639\u0628\u0627\u062f\u062a \u062f\u06cc\u062f\u0647 \u0627\u06cc\u061f \u0641\u0631\u0645\u0648\u062f: \u0645\u0646 \u067e\u0631\u0648\u0631\u062f\u06af\u0627\u0631\u06cc \u0631\u0627 \u06a9\u0647 \u0646\u062f\u06cc\u062f\u0647 \u0628\u0627\u0634\u0645 \u0639\u0628\u0627\u062f\u062a \u0646\u0645\u06cc \u06a9\u0646\u0645. \u067e\u0631\u0633\u06cc\u062f: \u0686\u06af\u0648\u0646\u0647 \u0627\u0648 \u0631\u0627 \u062f\u06cc\u062f\u0647 \u0627\u06cc\u061f \u0641\u0631\u0645\u0648\u062f: \u0686\u0634\u0645\u0647\u0627 \u0628\u0627 \u0645\u0634\u0627\u0647\u062f\u0647 \u0627\u0648 \u0631\u0627 \u0646\u0628\u06cc\u0646\u0646\u062f\u061b \u0648\u0644\u06cc \u062f\u0644\u0647\u0627 \u0628\u0627 \u062d\u0642\u06cc\u0642\u062a \u0627\u06cc\u0645\u0627\u0646 \u0627\u0648 \u062f\u0631 \u0645\u06cc \u06cc\u0627\u0628\u0646\u062f.\n\u0631\u0624\u06cc\u062a\u06cc \u06a9\u0647 \u0627\u0647\u0644 \u0639\u0631\u0641\u0627\u0646 \u0648 \u06a9\u0634\u0641 \u0648 \u0634\u0647\u0648\u062f \u0627\u0632 \u0622\u0646 \u0633\u062e\u0646 \u0645\u06cc\u200c\u06af\u0648\u06cc\u0646\u062f\u060c \u0631\u0624\u06cc\u062a \u0642\u0644\u0628\u06cc \u0627\u0633\u062a \u062f\u0631 \u0631\u0648\u0627\u06cc\u0627\u062a \u0645\u0639\u0635\u0648\u0645\u06cc\u0646 \u0639\u0644\u06cc\u0647\u200c\u0627\u0644\u0633\u0651\u0644\u0627\u0645 \u0627\u0632 \u0647\u0645\u06cc\u0646 \u06af\u0648\u0646\u0647 \u0631\u0624\u06cc\u062a \u06cc\u0627\u062f\u0634\u062f\u0647 \u0627\u0633\u062a.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-bb1ca662b6ec4d7cb06c1724eabcacf9", "input": "\u0633\u0648\u0645\u06cc\u0646 \u0639\u0645\u0644\u06cc\u0627\u062a (\u0641\u062a\u062d\u200c\u0627\u0644\u0645\u0628\u06cc\u0646) \u062f\u0631 \u0628\u0627\u0645\u062f\u0627\u062f \u0631\u0648\u0632 \u062f\u0648\u0634\u0646\u0628\u0647 \u06f2 \u0641\u0631\u0648\u0631\u062f\u06cc\u0646 \u06f1\u06f3\u06f6\u06f1 \u062f\u0631 \u062c\u0628\u0647\u0647 \u062c\u0646\u0648\u0628\u06cc\u060c \u062f\u0631 \u0645\u0646\u0637\u0642\u0647 \u063a\u0631\u0628 \u062f\u0631\u0641\u0648\u0644 \u062f\u0631 \u0627\u0633\u062a\u0627\u0646 \u062e\u0648\u0632\u0633\u062a\u0627\u0646 \u0648 \u0627\u0633\u062a\u0627\u0646 \u0627\u06cc\u0644\u0627\u0645 \u0627\u0646\u062c\u0627\u0645 \u0634\u062f. \u0639\u0645\u0644\u06cc\u0627\u062a \u0641\u062a\u062d\u200c\u0627\u0644\u0645\u0628\u06cc\u0646 \u0628\u0627\u0639\u062b \u0622\u0632\u0627\u062f\u0633\u0627\u0632\u06cc \u06f2\u06f4\u06f0\u06f0 \u06a9\u06cc\u0644\u0648\u0645\u062a\u0631 \u0645\u0631\u0628\u0639 \u0627\u0632 \u0633\u0631\u0632\u0645\u06cc\u0646\u200c\u0647\u0627\u06cc \u0627\u0634\u063a\u0627\u0644\u06cc\u060c \u0634\u0627\u0645\u0644 \u062f\u0647\u200c\u0647\u0627 \u0628\u062e\u0634 \u0648 \u0631\u0648\u0633\u062a\u0627 \u0648 \u0646\u06cc\u0632 \u0686\u0646\u062f\u06cc\u0646 \u062c\u0627\u062f\u0647 \u0627\u0631\u062a\u0628\u0627\u0637\u06cc \u0645\u0647\u0645 \u0634\u062f\u060c \u0647\u0645\u0686\u0646\u06cc\u0646 \u0634\u0647\u0631\u0647\u0627\u06cc \u0634\u0648\u0634\u060c \u062f\u0647\u0644\u0631\u0627\u0646\u060c \u0627\u0646\u062f\u06cc\u0645\u0634\u06a9 \u0648 \u067e\u0627\u06cc\u06af\u0627\u0647 \u0647\u0648\u0627\u06cc\u06cc \u062f\u0632\u0641\u0648\u0644 \u0646\u06cc\u0632\u060c \u0627\u0632 \u062f\u06cc\u062f \u0648 \u062a\u06cc\u0631 \u0645\u0624\u062b\u0631 \u0627\u0631\u062a\u0634 \u0639\u0631\u0627\u0642 \u062e\u0627\u0631\u062c \u06af\u0631\u062f\u06cc\u062f.\n\u0639\u0645\u0644\u06cc\u0627\u062a \u0633\u0648\u0645 \u062c\u0646\u06af \u062a\u062d\u0645\u06cc\u0644\u06cc \u062f\u0631 \u0645\u0646\u0637\u0642\u0647 \u063a\u0631\u0628 \u062f\u0632\u0641\u0648\u0644 \u0627\u0646\u062c\u0627\u0645 \u0634\u062f \u06a9\u0647 \u0645\u0648\u062c\u0628 \u0622\u0632\u0627\u062f\u06cc \u06f3\u06f6\u06f0\u06f0 \u06a9\u06cc\u0644\u0648\u0645\u062a\u0631 \u0645\u0631\u0628\u0639 \u0627\u0632 \u0645\u0646\u0627\u0637\u0642 \u0627\u0634\u063a\u0627\u0644\u06cc \u0634\u0648\u062f. ", "output": ["C"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-b1b3276093e04b96996b181d2ef456b2", "input": "\u00ab\u062a\u062f \u0631\u0627\u0628\u0631\u062a\u200c\u06af\u0631\u00bb\u060c \u062f\u0631 \u0641\u0635\u0644 \u0627\u0648\u0644 \u06a9\u062a\u0627\u0628 \u00ab\u0686\u0631\u0627 \u0627\u0646\u0633\u0627\u0646\u200c\u0647\u0627 \u0634\u0648\u0631\u0634 \u0645\u06cc\u200c\u06a9\u0646\u0646\u062f\u061f\u00bb\u060c \u0645\u0648\u0636\u0648\u0639\u0627\u062a \u0645\u0631\u0628\u0648\u0637 \u0628\u0647 \u062e\u0634\u0648\u0646\u062a \u0633\u06cc\u0627\u0633\u06cc \u0631\u0627 \u0645\u0639\u0631\u0641\u06cc \u0648 \u062f\u0631 \u0641\u0635\u0648\u0644 \u0628\u0639\u062f\u06cc \u0628\u0647 \u0627\u0631\u0627\u0626\u0647 \u0648 \u0628\u0633\u0637 \u0646\u0638\u0631\u06cc\u0647 \u062e\u0648\u062f \u0645\u06cc\u200c\u067e\u0631\u062f\u0627\u0632\u062f. \u0641\u0635\u0644 \u0628\u0639\u062f\u06cc \u06a9\u062a\u0627\u0628 \u0646\u06cc\u0632 \u0628\u0647 \u0645\u0628\u062d\u062b \u0645\u062d\u0631\u0648\u0645\u06cc\u062a \u0646\u0633\u0628\u06cc \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u0627\u0646\u06af\u06cc\u0632\u0647 \u062e\u0634\u0648\u0646\u062a \u0627\u062e\u062a\u0635\u0627\u0635 \u062f\u0627\u0631\u062f. \n\u062f\u0631 \u0646\u0638\u0631\u06cc\u0647 \u062a\u0648\u0642\u0639\u0627\u062a \u0641\u0632\u0627\u06cc\u0646\u062f\u0647\u060c \u062f\u06cc\u0648\u06cc\u0633 \u0627\u062f\u0639\u0627 \u0645\u06cc \u06a9\u0646\u062f \u06a9\u0647 \u0627\u0646\u0642\u0644\u0627\u0628 \u0627\u0632 \u0645\u062d\u0631\u0648\u0645\u06cc\u062a \u0646\u0633\u0628\u06cc \u0646\u0627\u0634\u06cc \u0645\u06cc\u200c\u0634\u0648\u062f \u0646\u0647 \u0627\u0632 \u0645\u062d\u0631\u0648\u0645\u06cc\u062a \u0645\u0637\u0644\u0642.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-09b0ae4ecfe041fe87bdad7af117e45d", "input": "\u0628\u0631\u062e\u06cc \u0627\u0632 \u0627\u0642\u0633\u0627\u0645 \u062a\u0648\u062d\u06cc\u062f (\u0645\u062b\u0644 \u062a\u0648\u062d\u06cc\u062f \u0630\u0627\u062a\u06cc\u060c \u0635\u0641\u0627\u062a\u06cc \u0648 \u0627\u0641\u0639\u0627\u0644\u06cc) \u062f\u0631 \u062f\u0627\u06cc\u0631\u0647 \u062a\u0648\u062d\u06cc\u062f \u0646\u0638\u0631\u06cc \u0648 \u0628\u0631\u062e\u06cc \u062f\u06cc\u06af\u0631 (\u0645\u062b\u0644 \u062a\u0648\u062d\u06cc\u062f \u0639\u0628\u0627\u062f\u06cc\u060c \u0627\u0633\u062a\u0639\u0627\u0646\u06cc \u0648...) \u062f\u0631 \u062f\u0627\u06cc\u0631\u0647 \u062a\u0648\u062d\u06cc\u062f \u0639\u0645\u0644\u06cc \u0642\u0631\u0627\u0631 \u0645\u06cc \u06af\u06cc\u0631\u062f.\n\u0627\u0628\u0639\u0627\u062f \u062a\u0648\u062d\u06cc\u062f \u0646\u0638\u0631\u06cc \u0630\u0627\u062a\u06cc\u060c \u0635\u0641\u0627\u062a\u06cc \u0648 \u0627\u0641\u0639\u0627\u0644\u06cc \u0627\u0633\u062a.", "output": ["E"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-0eda0fcf37b84703b10c0adff6f4d744", "input": "\u0627\u0632 \u0645\u0639\u0646\u0627\u06cc \u0631\u0648\u0627\u06cc\u062a\u06cc \u06a9\u0647 \u0627\u0632 \u067e\u06cc\u0627\u0645\u0628\u0631(\u0635) \u062f\u0631\u0628\u0627\u0631\u0647 \"\u067e\u0631\u0633\u0634 \u062f\u0631\u0645\u0648\u0631\u062f \u0630\u0627\u062a \u062e\u062f\u0627\u0648\u0646\u062f\"\u0631\u0633\u06cc\u062f\u0647 \u0627\u0633\u062a \u0628\u0647 \u062e\u0648\u0628\u06cc \u0631\u0648\u0634\u0646 \u0645\u06cc\u0634\u0648\u062f \u06a9\u0647 \u0641\u0631\u0645\u0648\u062f\u0647 \u200f\u0627\u0646\u062f: \u062f\u0631\u0628\u0627\u0631\u0647 \u200f\u06cc \u0630\u0627\u062a \u062e\u062f\u0627 \u0641\u06a9\u0631 \u0646\u06a9\u0646\u06cc\u062f (\u06a9\u0647 \u0628\u0647 \u062c\u0627\u06cc\u06cc \u0646\u0645\u06cc\u0631\u0633\u06cc\u062f \u0628\u0644\u06a9\u0647 \u0627\u0632 \u0627\u06cc\u0646 \u0631\u0627\u0647 \u0645\u0645\u06a9\u0646 \u0627\u0633\u062a \u0634\u06cc\u0637\u0627\u0646 \u0633\u0648\u0621 \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u06a9\u0631\u062f\u0647 \u0648 \u0634\u0645\u0627 \u0631\u0627 \u0645\u0646\u062d\u0631\u0641 \u0633\u0627\u0632\u062f). \u0627\u0645\u0627 \u062f\u0631\u0628\u0627\u0631\u0647\u200f \u06cc \u0646\u0639\u0645\u062a\u0647\u0627 \u0648 \u0622\u062b\u0627\u0631 \u0639\u0638\u0645\u062a \u0627\u0648 \u0641\u06a9\u0631 \u06a9\u0646\u06cc\u062f (\u062a\u0627 \u0647\u0631 \u0633\u0627\u0639\u062a \u0628\u0647 \u0645\u0639\u0631\u0641\u062a \u0648 \u0627\u06cc\u0645\u0627\u0646 \u0634\u0645\u0627 \u0627\u0641\u0632\u0648\u062f\u0647 \u06af\u0631\u062f\u062f).\u0647\u0645\u0686\u0646\u06cc\u0646 \u062f\u0631 \u0631\u0648\u0627\u06cc\u062a\u06cc \u0627\u0632 \u0627\u0645\u0627\u0645 \u0635\u0627\u062f\u0642 (\u0639) \u0628\u0647 \u0627\u06cc\u0646 \u0646\u06a9\u062a\u0647 \u0628\u0647 \u0648\u0636\u0648\u062d \u0627\u0634\u0627\u0631\u0647 \u0634\u062f\u0647 \u0627\u0633\u062a \u06a9\u0647 \u0639\u0644\u062a \u0645\u0646\u0639 \u0627\u0632 \u062a\u0641\u06a9\u0631 \u062f\u0631 \u0645\u0648\u0631\u062f \u0630\u0627\u062a \u062e\u062f\u0627\u0648\u0646\u062f \u0686\u06cc\u0632\u06cc \u0646\u06cc\u0633\u062a \u062c\u0632 \u06af\u0645\u0631\u0627\u0647\u06cc \u0648 \u0636\u0644\u0627\u0644\u062a. \u062f\u0631 \u0648\u0627\u0642\u0639 \u0631\u0633\u06cc\u062f\u0646 \u0628\u0647 \u0630\u0627\u062a \u0646\u0627\u0645\u062d\u062f\u0648\u062f \u0627\u0644\u0647\u06cc \u0648 \u062f\u0631\u06a9 \u062d\u0642\u06cc\u0642\u062a \u0622\u0646 \u0628\u0631\u0627\u06cc \u0645\u0627 \u06a9\u0647 \u0645\u0648\u062c\u0648\u062f\u0627\u062a \u0645\u062d\u062f\u0648\u062f \u0647\u0633\u062a\u06cc\u0645 \u060c \u0627\u0645\u0631\u06cc \u0645\u062d\u0627\u0644 \u0648 \u0646\u0627\u0645\u0645\u06a9\u0646 \u0627\u0633\u062a.\n\u062e\u062f\u0627\u0648\u0646\u062f \u062f\u0631 \u0646\u0647\u0627\u06cc\u062a \u06a9\u0645\u0627\u0644 \u0627\u0633\u062a \u0686\u0646\u0627\u0646 \u06a9\u0647 \u0645\u06cc \u062a\u0648\u0627\u0646 \u0627\u0648 \u0631\u0627 \"\u06a9\u0627\u0645\u0644 \u0645\u0637\u0644\u0642\" \u062e\u0648\u0627\u0646\u062f.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-59867a1ec6724651815187b4a413ba02", "input": "\u0645\u062d\u0645\u062f \u0628\u0646 \u0645\u0646\u0648\u0631 \u0646\u06af\u0627\u0631\u0646\u062f\u0647 \u06a9\u062a\u0627\u0628 \"\u0627\u0633\u0631\u0627\u0631\u0627\u0644\u062a\u0648\u062d\u06cc\u062f\" \u062f\u0631 \u0648\u0635\u0641 \u0627\u0628\u0648\u0633\u0639\u06cc\u062f \u0627\u0628\u06cc\u200c\u0627\u0644\u062e\u06cc\u0631\u060c \u06a9\u062a\u0627\u0628 \u062e\u0648\u062f \u0631\u0627 \u0628\u0647 \u0633\u0647 \u0628\u0627\u0628 \u062a\u0642\u0633\u06cc\u0645 \u06a9\u0631\u062f\u0647\u200c\u0627\u0633\u062a. \u0628\u0627\u0628 \u0627\u0648\u0644 \u062f\u0631 \u0627\u0628\u062a\u062f\u0627\u06cc \u062d\u0627\u0644\u062a \u0634\u06cc\u062e\u060c \u0628\u0627\u0628 \u062f\u0648\u0645 \u06a9\u0647 \u0628\u0647 \u0628\u06cc\u0627\u0646 \u062d\u0627\u0644\u0627\u062a \u0634\u06cc\u062e \u0627\u0628\u0648\u0633\u0639\u06cc\u062f \u062f\u0631 \u0633\u0627\u0644\u200c\u0647\u0627\u06cc \u0645\u06cc\u0627\u0646\u06cc \u0632\u0646\u062f\u06af\u06cc \u0627\u0648 \u0627\u062e\u062a\u0635\u0627\u0635 \u062f\u0627\u0631\u062f\u060c \u0628\u0633\u06cc\u0627\u0631\u06cc \u0627\u0632 \u06af\u0641\u062a\u0647\u200c\u0647\u0627 \u0648 \u0627\u0634\u0639\u0627\u0631\u06cc \u0631\u0627 \u06a9\u0647 \u0628\u0631 \u0632\u0628\u0627\u0646 \u0648\u06cc \u0631\u0641\u062a\u0647\u060c \u06af\u0631\u062f\u0622\u0648\u0631\u06cc \u0648 \u0646\u0642\u0644 \u06a9\u0631\u062f\u0647\u200c\u0627\u0633\u062a\u060c \u0648 \u0628\u0627\u0628 \u0633\u0648\u0645 \u0627\u0646\u062a\u0647\u0627\u06cc \u062d\u0627\u0644\u062a \u0634\u06cc\u062e \u0627\u0633\u062a.\n\u0627\u0634\u0639\u0627\u0631 \u0627\u0628\u0648\u0633\u0639\u06cc\u062f \u0627\u0628\u06cc\u200c\u0627\u0644\u062e\u06cc\u0631 \u062f\u0631 \u0628\u0627\u0628 \u062f\u0648\u0645 \u06a9\u062a\u0627\u0628 \"\u0627\u0633\u0631\u0627\u0631\u0627\u0644\u062a\u0648\u062d\u06cc\u062f\" \u0622\u0648\u0631\u062f\u0647 \u0634\u062f\u0647 \u0627\u0633\u062a.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-cfd94624dba04d2d950caab73fd08aad", "input": "\u0633\u06cc\u062f \u0627\u062d\u0645\u062f \u062d\u0633\u06cc\u0646\u06cc \u0645\u062a\u062e\u0644\u0635 \u0628\u0647 \u0647\u0627\u062a\u0641 \u0627\u0635\u0641\u0647\u0627\u0646\u06cc \u0627\u0632 \u0634\u0639\u0631\u0627\u06cc \u0646\u0627\u0645\u06cc \u0627\u06cc\u0631\u0627\u0646 \u062f\u0631 \u0639\u0647\u062f \u0627\u0641\u0634\u0627\u0631\u06cc\u0647 \u0648 \u0632\u0646\u062f\u06cc\u0647 \u0627\u0633\u062a.\n\u0633\u06cc\u062f \u0627\u062d\u0645\u062f \u0647\u0627\u062a\u0641 \u0627\u0635\u0641\u0647\u0627\u0646\u06cc \u0627\u0632 \u0634\u0639\u0631\u0627\u06cc \u062f\u0648\u0631\u0647 \u0647\u0627\u06cc \u0635\u0641\u0648\u06cc\u0647 \u0648 \u0642\u0627\u062c\u0627\u0631\u06cc\u0647 \u0627\u0633\u062a.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-d981160f684444539b0af28e10edab25", "input": "\u0639\u0647\u062f\u0646\u0627\u0645\u0647 \u0632\u064f\u0647\u0627\u0628 \u06cc\u0627 \u0639\u0647\u062f\u0646\u0627\u0645\u0647 \u0642\u0635\u0631 \u0634\u06cc\u0631\u06cc\u0646 \u062a\u0648\u0627\u0641\u0642\u06cc \u0627\u0645\u0636\u0627 \u0634\u062f\u0647 \u0645\u06cc\u0627\u0646 \u0635\u0641\u0648\u06cc\u0627\u0646 \u0627\u06cc\u0631\u0627\u0646 \u0648 \u0627\u0645\u067e\u0631\u0627\u062a\u0648\u0631\u06cc \u0639\u062b\u0645\u0627\u0646\u06cc \u062f\u0631\u0633\u0627\u0644 \u06f1\u06f6\u06f3\u06f9 \u0645 \u062f\u0631 \u0634\u0647\u0631 \u0642\u0635\u0631 \u0634\u06cc\u0631\u06cc\u0646 \u0645\u06cc\u200c\u0628\u0627\u0634\u062f. \u0627\u06cc\u0646 \u067e\u06cc\u0645\u0627\u0646\u200c\u0646\u0627\u0645\u0647 \u062f\u0631 \u0648\u0627\u0642\u0639 \u0622\u0631\u0627\u0645\u0634 \u0631\u0627 \u0628\u0631\u0627\u06cc \u0645\u0631\u0632\u0647\u0627\u06cc \u063a\u0631\u0628 \u0627\u06cc\u0631\u0627\u0646 \u0628\u0647 \u0627\u0631\u0645\u063a\u0627\u0646 \u0622\u0648\u0631\u062f \u0648 \u0628\u0647 \u062c\u0646\u06af\u06cc \u06a9\u0647 \u0627\u0632 \u0633\u0627\u0644 \u06f1\u06f6\u06f2\u06f3 \u0622\u063a\u0627\u0632 \u0634\u062f\u0647 \u0628\u0648\u062f \u0648 \u0647\u0645\u0686\u0646\u06cc\u0646 \u0628\u0647 \u0645\u0628\u0627\u0631\u0632\u0627\u062a \u06f1\u06f5\u06f0 \u0633\u0627\u0644\u0647 \u062f\u0648 \u06a9\u0634\u0648\u0631 \u06a9\u0647 \u0628\u06cc\u0634\u062a\u0631 \u0628\u0631 \u0633\u0631 \u0627\u062e\u062a\u0644\u0627\u0641\u0627\u062a \u0627\u0631\u0636\u06cc \u0635\u0648\u0631\u062a \u0645\u06cc\u200c\u06af\u0631\u0641\u062a\u060c \u067e\u0627\u06cc\u0627\u0646 \u062f\u0627\u062f.\n\u0639\u0647\u062f\u0646\u0627\u0645\u0647 \u0635\u0644\u062d \u0622\u0645\u0627\u0633\u06cc\u0647 \u062a\u0646\u0647\u0627 \u0639\u0647\u062f\u0646\u0627\u0645\u0647 \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f6\u06f3\u06f9 \u0645 \u062f\u0631 \u0642\u0635\u0631\u0634\u06cc\u0631\u06cc\u0646 \u0628\u0648\u062f \u06a9\u0647 \u0628\u0627 \u0647\u062f\u0641 \u067e\u0627\u06cc\u0627\u0646 \u062f\u0627\u062f\u0646 \u0628\u0647 \u062c\u0646\u06af \u0647\u0627\u06cc \u0627\u06cc\u0631\u0627\u0646 \u0648 \u0639\u062b\u0645\u0627\u0646\u06cc \u0648 \u062d\u0644 \u0627\u062e\u062a\u0644\u0627\u0641\u0627\u062a \u0645\u0631\u0632 \u063a\u0631\u0628\u06cc \u0628\u0633\u062a\u0647 \u0634\u062f.", "output": ["C"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-67e696723eb94da0a9e069077ac23d59", "input": "\u062a\u0633\u062e\u06cc\u0631 \u0628\u0631\u0642 \u0622\u0633\u0627\u06cc \u0628\u0646\u062f\u0631 \u062d\u06cc\u0627\u062a\u06cc \u062e\u0631\u0645\u0634\u0647\u0631 \u062a\u0648\u0633\u0637 \u0631\u0632\u0645\u0646\u062f\u06af\u0627\u0646 \u0627\u0633\u0644\u0627\u0645\u060c \u0636\u0631\u0628\u0647 \u06af\u06cc\u062c \u06a9\u0646\u0646\u062f\u0647 \u0627\u06cc \u0631\u0627 \u0628\u0631 \u0639\u0631\u0627\u0642 \u0648 \u0647\u0645\u0647 \u06a9\u0634\u0648\u0631\u0647\u0627\u06cc \u0645\u062a\u062d\u062f\u0634 \u0648\u0627\u0631\u062f \u0633\u0627\u062e\u062a. \u0627\u0645\u0627\u0645 \u062e\u0645\u06cc\u0646\u06cc \u062f\u0631 \u0622\u0646 \u0632\u0645\u0627\u0646 \u0648 \u062d\u062a\u06cc \u0647\u0645\u0648\u0627\u0631\u0647 \u062e\u0648\u0627\u0647\u0627\u0646 \u067e\u0627\u06cc\u0627\u0646 \u062f\u0627\u062f\u0646 \u0628\u0647 \u062c\u0646\u06af \u0628\u0648\u062f\u060c \u0627\u0645\u0651\u0627 \u067e\u0627\u06cc\u0627\u0646\u06cc \u06a9\u0647 \u0645\u062a\u0636\u0645\u0646 \u062d\u0642\u0648\u0642 \u0645\u0644\u062a \u0645\u0638\u0644\u0648\u0645 \u0627\u06cc\u0631\u0627\u0646 \u0628\u0627\u0634\u062f.\n\u0628\u0639\u062f \u0627\u0632 \u0628\u0627\u0632\u067e\u0633\u200c\u06af\u06cc\u0631\u06cc \u062e\u0631\u0645\u0634\u0647\u0631\u060c \u0627\u0645\u0627\u0645 \u0645\u0635\u0631\u0627\u0646\u0647 \u062e\u0648\u0627\u0647\u0627\u0646 \u0627\u062f\u0627\u0645\u0647 \u062c\u0646\u06af \u0628\u0648\u062f. ", "output": ["C"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-11883f56e6354c9bad510ce838910faf", "input": "\u062f\u0631 \u0627\u0648\u0627\u062e\u0631 \u062f\u0648\u0631\u0627\u0646 \u0633\u0627\u0633\u0627\u0646\u06cc \u0628\u062e\u0634 \u0627\u0639\u0638\u0645 \u062f\u0631\u0622\u0645\u062f \u06a9\u0634\u0648\u0631 \u0627\u06cc\u0631\u0627\u0646\u060c \u0627\u0632 \u0645\u0627\u0644\u06cc\u0627\u062a\u06cc \u06a9\u0647 \u0628\u0631 \u0627\u0631\u0627\u0636\u06cc (\u062e\u0631\u0627\u062c) \u0645\u0642\u0631\u0631 \u0634\u062f\u0647 \u0628\u0648\u062f \u062a\u0627\u0645\u06cc\u0646 \u0645\u06cc\u0634\u062f \u0648 \u0628\u06cc\u0634\u062a\u0631 \u0633\u0646\u06af\u06cc\u0646\u06cc \u0628\u0627\u0631 \u0627\u06cc\u0646 \u0646\u0648\u0639 \u0645\u0627\u0644\u06cc\u0627\u062a \u0647\u0627 \u0631\u0627 \u06a9\u0634\u0627\u0648\u0631\u0632\u0627\u0646 \u0648 \u0631\u0648\u0633\u062a\u0627\u06cc\u06cc\u0627\u0646 \u0628\u0631 \u062f\u0648\u0634 \u0645\u06cc \u06a9\u0634\u06cc\u062f\u0646\u062f \u06a9\u0647 \u0645\u0627\u0644\u06cc\u0627\u062a \u0633\u0631\u0627\u0646\u0647 (\u0633\u0631\u06af\u0632\u06cc\u062a) \u06af\u0641\u062a\u0647 \u0645\u06cc\u0634\u062f.\n\u00ab\u062c\u0632\u06cc\u0647\u00bb \u06cc\u06a9\u06cc \u0627\u0632 \u0645\u0627\u0644\u06cc\u0627\u062a \u0647\u0627\u06cc\u06cc \u0628\u0648\u062f \u06a9\u0647 \u062f\u0631 \u0639\u0635\u0631 \u0633\u0627\u0633\u0627\u0646\u06cc \u0622\u0646 \u0631\u0627 \u0627\u0632 \u0635\u0646\u0639\u062a \u06af\u0631\u0627\u0646 \u0648 \u067e\u06cc\u0634\u0647 \u0648\u0631\u0627\u0646 \u0648 \u0634\u0647\u0631\u0646\u0634\u06cc\u0646\u0627\u0646 \u0645\u06cc \u06af\u0631\u0641\u062a\u0646\u062f .", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-357e834e861c4e1ab49ddca8cdc1ab45", "input": "\u067e\u0633 \u0627\u0632 \u062f\u0648\u0631\u0627\u0646 \u0647\u062e\u0627\u0645\u0646\u0634\u06cc\u060c \u062f\u0631 \u062f\u0648\u0631\u0647 \u06a9\u0648\u062a\u0627\u0647 \u0645\u062f\u062a \u0627\u0633\u06a9\u0646\u062f\u0631 \u0648 \u0633\u0644\u0648\u06a9\u06cc\u0647\u0627\u060c \u0632\u0628\u0627\u0646 \u0648 \u062e\u0637 \u06cc\u0648\u0646\u0627\u0646\u06cc \u062f\u0631 \u0645\u0631\u0627\u0633\u0644\u0627\u062a \u0631\u0633\u0645\u06cc \u0648 \u0627\u062f\u0627\u0631\u06cc \u0628\u0647 \u06a9\u0627\u0631 \u0645\u06cc \u0631\u0641\u062a.\n\u062e\u0637 \u0645\u06cc\u062e\u06cc\u060c \u062f\u0631 \u0632\u0645\u0627\u0646 \u067e\u0627\u062f\u0634\u0627\u0647\u06cc \u0627\u0633\u06a9\u0646\u062f\u0631 \u0628\u0647 \u06a9\u0627\u0631 \u0645\u06cc \u0631\u0641\u062a.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-5f16fbd6fa8e42819bd2b39d9d4c1628", "input": "\u067e\u0631\u0648\u06cc\u0632 \u062e\u0631\u0633\u0646\u062f \u0646\u0648\u06cc\u0633\u0646\u062f\u0647\u060c \u0631\u0648\u0632\u0646\u0627\u0645\u0647\u200c\u0646\u06af\u0627\u0631 \u0648 \u06cc\u06a9\u06cc \u0627\u0632 \u0686\u0647\u0631\u0647\u200c\u0647\u0627\u06cc \u0641\u0631\u0647\u0646\u06af\u06cc \u0627\u0647\u0644 \u0627\u06cc\u0631\u0627\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0627\u0632 \u0622\u062b\u0627\u0631 \u0627\u0648 \u0645\u06cc \u062a\u0648\u0627\u0646 \u0628\u0647 \"\u0628\u0631\u0632\u06cc\u06af\u0631\u0627\u0646 \u062f\u0634\u062a \u062e\u0648\u0646\"\u060c \"\u0622\u0646 \u062c\u0627 \u06a9\u0647 \u062d\u0642 \u067e\u06cc\u0631\u0648\u0632 \u0627\u0633\u062a\"\u060c \"\u0645\u0631\u062b\u06cc\u0647\u200c\u0627\u06cc \u06a9\u0647 \u0646\u0627\u0633\u0631\u0648\u062f\u0647 \u0645\u0627\u0646\u062f\u0647\" \u0648 \" \u0647\u0627\u0628\u06cc\u0644 \u0648 \u0642\u0627\u0628\u06cc\u0644\" \u0627\u0634\u0627\u0631\u0647 \u06a9\u0631\u062f.\n\u06a9\u062a\u0627\u0628 \"\u0622\u0646 \u062c\u0627 \u06a9\u0647 \u062d\u0642 \u067e\u06cc\u0631\u0648\u0632 \u0627\u0633\u062a\" \u0627\u062b\u0631 \u067e\u0631\u0648\u06cc\u0632 \u062e\u0631\u0633\u0646\u062f \u0645\u06cc \u0628\u0627\u0634\u062f.", "output": ["E"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-7d2b342afac54aa38c323484960ea4da", "input": "\u0627\u0635\u0644 \u06f4\u06f5 \u0642\u0627\u0646\u0648\u0646 \u0627\u0633\u0627\u0633\u06cc: \u0627\u0646\u0641\u0627\u0644 \u0648 \u062b\u0631\u0648\u062a \u0647\u0627\u06cc \u0639\u0645\u0648\u0645\u06cc \u0627\u0632 \u0642\u0628\u06cc\u0644 \u0632\u0645\u06cc\u0646 \u0647\u0627\u06cc \u0645\u0648\u0627\u062a \u06cc\u0627 \u0631\u0647\u0627\u0634\u062f\u0647\u200c\u060c \u0645\u0639\u0627\u062f\u0646\u200c\u060c \u062f\u0631\u06cc\u0627\u0647\u0627\u060c \u062f\u0631\u06cc\u0627\u0686\u0647\u200c\u0647\u0627\u060c \u0631\u0648\u062f\u062e\u0627\u0646\u0647\u200c\u0647\u0627\u060c \u06a9\u0648\u0647 \u0647\u0627\u060c \u062f\u0631\u0647\u200c\u0647\u0627\u060c \u062c\u0646\u06af\u0644 \u0647\u0627\u060c \u0646\u06cc\u0632\u0627\u0631\u0647\u0627\u060c \u0628\u06cc\u0634\u0647\u200c\u0647\u0627\u06cc \u0637\u0628\u06cc\u0639\u06cc\u200c \u0648 ... \u062f\u0631 \u0627\u062e\u062a\u06cc\u0627\u0631 \u062d\u06a9\u0648\u0645\u062a \u0627\u0633\u0644\u0627\u0645\u06cc \u200c\u0627\u0633\u062a.\n\u062d\u06a9\u0648\u0645\u062a \u0627\u0633\u0644\u0627\u0645\u06cc \u0628\u0631\u0637\u0628\u0642 \u0645\u0635\u0627\u0644\u062d \u0639\u0627\u0645\u0647 \u0646\u0633\u0628\u062a \u0628\u0647 \u0627\u0646\u0641\u0627\u0644 \u0648 \u062b\u0631\u0648\u062a \u0647\u0627\u06cc \u0639\u0645\u0648\u0645\u06cc \u0639\u0645\u0644 \u0645\u06cc\u200c\u0646\u0645\u0627\u06cc\u062f.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-6cd2fc74a68e4466950b644be16b8490", "input": "\u0645\u0633\u062c\u062f \u0627\u0644\u0646\u0628\u06cc \u0627\u0648\u0644\u06cc\u0646 \u0622\u0645\u0648\u0632\u0634\u06af\u0627\u0647\u06cc \u0628\u0648\u062f \u06a9\u0647 \u062f\u0631 \u0632\u0645\u0627\u0646 \u062d\u0636\u0631\u062a \u0645\u062d\u0645\u062f (\u0635) \u0648\u062c\u0648\u062f \u062f\u0627\u0634\u062a.\n\u0646\u062e\u0633\u062a\u06cc\u0646 \u0622\u0645\u0648\u0632\u0634\u06af\u0627\u0647 \u0639\u0635\u0631 \u067e\u06cc\u0627\u0645\u0628\u0631 \u0627\u06a9\u0631\u0645 (\u0635) \u0645\u0633\u062c\u062f \u0627\u0644\u0646\u0628\u06cc \u0645\u06cc \u0628\u0627\u0634\u062f.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-34708a5c024f48ceb21d378e8d402d6d", "input": "\u0645\u0627\u062f\u0647 \u0646\u0648\u0632\u062f\u0647\u0645 \u0627\u0639\u0644\u0627\u0645\u06cc\u0647 \u062c\u0647\u0627\u0646\u06cc \u062d\u0642\u0648\u0642 \u0628\u0634\u0631: \u0647\u0631 \u06a9\u0633 \u062d\u0642 \u0622\u0632\u0627\u062f\u06cc \u0639\u0642\u06cc\u062f\u0647 \u0648 \u0628\u06cc\u0627\u0646 \u062f\u0627\u0631\u062f \u0648 \u062d\u0642 \u0645\u0632\u0628\u0648\u0631 \u0634\u0627\u0645\u0644 \u0622\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0627\u0632 \u062f\u0627\u0634\u062a\u0646 \u0639\u0642\u0627\u06cc\u062f \u062e\u0648\u062f \u0628\u06cc\u0645 \u0648 \u0627\u0636\u0637\u0631\u0627\u0628\u06cc \u0646\u062f\u0627\u0634\u062a\u0647 \u0628\u0627\u0634\u062f \u0648 \u062f\u0631 \u06a9\u0633\u0628 \u0627\u0637\u0644\u0627\u0639\u0627\u062a \u0648 \u0627\u0641\u06a9\u0627\u0631 \u0648 \u062f\u0631 \u0627\u062e\u0630 \u0648 \u0627\u0646\u062a\u0634\u0627\u0631 \u0622\u0646 \u0628\u0627 \u062a\u0645\u0627\u0645 \u0648\u0633\u0627\u06cc\u0644 \u0645\u0645\u06a9\u0646 \u0648 \u0628\u062f\u0648\u0646 \u0645\u0644\u0627\u062d\u0638\u0627\u062a \u0645\u0631\u0632\u06cc\u060c \u0622\u0632\u0627\u062f \u0628\u0627\u0634\u062f. \u0645\u0627\u062f\u0647 \u0633\u0648\u0645 : \u0647\u0631\u06a9\u0633 \u062d\u0642 \u0632\u0646\u062f\u06af\u06cc\u060c \u0622\u0632\u0627\u062f\u06cc \u0648\u0627\u0645\u0646\u06cc\u062a \u0634\u062e\u0635\u06cc \u062f\u0627\u0631\u062f. \n\u0645\u0627\u062f\u0647 \u0646\u0647\u0645 \u0627\u0639\u0644\u0627\u0645\u06cc\u0647 \u062c\u0647\u0627\u0646\u06cc \u062d\u0642\u0648\u0642 \u0628\u0634\u0631: \u0647\u06cc\u0686 \u06a9\u0633 \u0646\u0645\u06cc\u062a\u0648\u0627\u0646\u062f \u062e\u0648\u062f \u0633\u0631\u0627\u0646\u0647 \u062a\u0648\u0642\u06cc\u0641\u060c \u062d\u0628\u0633 \u06cc\u0627 \u062a\u0628\u0639\u06cc\u062f \u0634\u0648\u062f. ", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-dce7d540436941f3ab389af920460758", "input": "\u062a\u0631\u0627\u0645\u0648\u0632\u0627 \u0632\u0648\u062c\u0647 \u0641\u0631\u0647\u0627\u062f \u0686\u0647\u0627\u0631\u0645 \u0648 \u0645\u0644\u06a9\u0647 \u062f\u0631\u0628\u0627\u0631 \u06a9\u0647 \u06a9\u0648\u062f\u06a9\u06cc \u0628\u0647 \u0646\u0627\u0645 \u0641\u0631\u0647\u0627\u062f\u06a9 \u0628\u0631\u0627\u06cc \u0634\u0627\u0647 \u0632\u0627\u06cc\u06cc\u062f\u0647 \u0628\u0648\u062f\u060c \u0628\u0647 \u0628\u0647\u0627\u0646\u0647 \u0644\u0632\u0648\u0645 \u062a\u0623\u0645\u06cc\u0646 \u062c\u0627\u0646 \u0627\u06cc\u0646 \u0641\u0631\u0632\u0646\u062f \u0648 \u0627\u062c\u062a\u0646\u0627\u0628 \u0627\u0632 \u0647\u0631 \u06af\u0648\u0646\u0647 \u062a\u0648\u0637\u0626\u0647 \u0627\u062d\u062a\u0645\u0627\u0644\u06cc \u062f\u0627\u062e\u0644\u06cc\u060c \u0634\u0627\u0647 \u0631\u0627 \u0648\u0627\u062f\u0627\u0631 \u06a9\u0631\u062f \u062a\u0627 \u0633\u0627\u06cc\u0631 \u067e\u0633\u0631\u0627\u0646 \u062e\u0648\u062f \u0631\u0627 \u0627\u0632 \u062f\u0631\u0628\u0627\u0631 \u062f\u0648\u0631 \u0633\u0627\u0632\u062f \u062a\u0627 \u062f\u0631 \u0627\u0635\u0644 \u0628\u062a\u0648\u0627\u0646\u062f \u0628\u0627 \u0641\u0631\u0633\u062a\u0627\u062f\u0646 \u0686\u0647\u0627\u0631 \u067e\u0633\u0631 \u062f\u06cc\u06af\u0631 \u0634\u0627\u0647 \u0628\u0647 \u0631\u0648\u0645 \u0648\u0644\u06cc\u0639\u0647\u062f\u06cc \u067e\u0633\u0631\u0634 \u0631\u0627 \u0642\u0637\u0639\u06cc \u06a9\u0646\u062f.\n\u067e\u0633\u0631\u0627\u0646 \u0641\u0631\u0647\u0627\u062f \u0686\u0647\u0627\u0631\u0645 \u0628\u0647 \u0645\u0646\u0638\u0648\u0631 \u062f\u0648\u0631 \u06a9\u0631\u062f\u0646 \u0631\u0642\u06cc\u0628\u0627\u0646 \u0627\u0632 \u0648\u0644\u06cc\u0639\u0647\u062f \u0628\u0647 \u0631\u0648\u0645 \u0641\u0631\u0633\u062a\u0627\u062f\u0647 \u0634\u062f\u0646\u062f.", "output": ["E"]}, "Prediction": "E."}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-201a8b44d9b9409693a7fe2a7cecaca0", "input": "\u0627\u062f\u0627\u0645\u0647 \u062c\u0646\u06af \u062c\u0647\u0627\u0646\u06cc \u062f\u0648\u0645 \u062a\u0627 \u0634\u06a9\u0633\u062a \u06a9\u0627\u0645\u0644 \u0622\u0644\u0645\u0627\u0646 \u0648 \u062a\u0633\u0644\u06cc\u0645 \u0628\u062f\u0648\u0646 \u0642\u06cc\u062f \u0648 \u0634\u0631\u0637 \u0627\u06cc\u0646 \u06a9\u0634\u0648\u0631\u060c \u062a\u0642\u0633\u06cc\u0645 \u0622\u0644\u0645\u0627\u0646 \u0628\u0647 \u0686\u0647\u0627\u0631 \u0645\u0646\u0637\u0642\u0647 \u0627\u0634\u063a\u0627\u0644\u06cc \u0628\u06cc\u0646 \u0634\u0648\u0631\u0648\u06cc \u0648 \u0622\u0645\u0631\u06cc\u06a9\u0627 \u0648 \u0627\u0646\u06af\u0644\u0633\u062a\u0627\u0646 \u0648 \u0641\u0631\u0627\u0646\u0633\u0647 \u0648 \u062a\u0642\u0633\u06cc\u0645 \u0628\u0631\u0644\u0646 \u0628\u0647 \u0686\u0647\u0627\u0631 \u0645\u0646\u0637\u0642\u0647 \u0627\u0634\u063a\u0627\u0644\u06cc \u0648 \u06cc\u06a9 \u0631\u0627\u0647 \u0639\u0628\u0648\u0631 \u0622\u0632\u0627\u062f \u0628\u0647 \u0633\u0648\u06cc \u063a\u0631\u0628\u060c \u062e\u0644\u0639 \u0633\u0644\u0627\u062d \u06a9\u0627\u0645\u0644 \u0622\u0644\u0645\u0627\u0646 \u0648 \u0627\u062c\u0628\u0627\u0631\u0634 \u0628\u0647 \u067e\u0631\u062f\u0627\u062e\u062a \u063a\u0631\u0627\u0645\u062a \u062c\u0646\u06af\u06cc \u0627\u0632 \u062c\u0645\u0644\u0647 \u062a\u0635\u0645\u06cc\u0645\u0627\u062a \u0645\u0647\u0645 \u06a9\u0646\u0641\u0631\u0627\u0646\u0633 \u06cc\u0627\u0644\u062a\u0627 \u0628\u0648\u062f.\n\u0627\u062f\u0627\u0645\u0647 \u062c\u0646\u06af \u062a\u0627 \u062a\u0633\u0644\u06cc\u0645 \u0628\u062f\u0648\u0646 \u0642\u06cc\u062f \u0648\u0634\u0631\u0637 \u0622\u0644\u0645\u0627\u0646 \u062f\u0631 \u062c\u0646\u06af \u062c\u0647\u0627\u0646\u06cc \u062f\u0648\u0645 \u062f\u0631 \u0637\u06cc \u06a9\u0646\u0641\u0631\u0627\u0646\u0633 \u06cc\u0627\u0644\u062a\u0627 \u0637\u0631\u062d \u0634\u062f.", "output": ["E"]}, "Prediction": "E."}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-fb493fcdacd7490fa306b710c62a0bcb", "input": "\u062f\u0631 \u0628\u0631\u0631\u0633\u06cc \u0647\u0631 \u0645\u06a9\u062a\u0628\u060c \u0622\u0646\u200c\u0686\u0647 \u0628\u0627\u06cc\u062f \u0642\u0628\u0644 \u0627\u0632 \u0647\u0645\u0647 \u0645\u0648\u0631\u062f \u062a\u0648\u062c\u0647 \u0648 \u0628\u0631\u0631\u0633\u06cc \u0648\u0627\u0642\u0639\u200c\u0628\u06cc\u0646\u0627\u0646\u0647 \u0642\u0631\u0627\u0631 \u06af\u06cc\u0631\u062f\u060c \u067e\u0627\u06cc\u0647\u200c\u0647\u0627\u06cc \u0627\u0633\u0627\u0633\u06cc \u062c\u0647\u0627\u0646\u200c\u0628\u06cc\u0646\u06cc \u0627\u0633\u062a \u06a9\u0647 \u062f\u0631 \u0631\u0623\u0633 \u0622\u0646\u200c\u200c\u0647\u0627 \u00ab\u0645\u0628\u062f\u0623 \u0647\u0633\u062a\u06cc\u00bb \u06cc\u0639\u0646\u06cc \u00ab\u062e\u062f\u0627\u00bb \u0642\u0631\u0627\u0631 \u062f\u0627\u0631\u062f.\n\u062c\u0647\u0627\u0646\u200c\u0628\u06cc\u0646\u06cc \u0639\u0628\u0627\u0631\u062a\u0633\u062a \u0627\u0632 \u0646\u0648\u0639 \u062a\u0641\u06a9\u0631 \u0648 \u0628\u0631\u062f\u0627\u0634\u062a\u06cc \u06a9\u0647 \u06cc\u06a9 \u0645\u06a9\u062a\u0628 \u0646\u0633\u0628\u062a \u0628\u0647 \u062c\u0647\u0627\u0646 \u0648 \u0647\u0633\u062a\u06cc \u062f\u0627\u0631\u062f.", "output": ["N"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-0e68956e13e8447ea7348e17197c3240", "input": "\u062e\u0637 \u0627\u0648\u0633\u062a\u0627\u06cc\u06cc\u060c \u0628\u0631\u0627\u06cc \u0646\u06af\u0627\u0631\u0634 \u06a9\u062a\u0627\u0628 \u062f\u06cc\u0646\u06cc \u0632\u0631\u062a\u0634\u062a\u06cc\u0627\u0646 \u0628\u0647 \u06a9\u0627\u0631 \u0631\u0641\u062a\u0647 \u0627\u0633\u062a. \u0627\u06cc\u0646 \u062e\u0637 \u0622\u0648\u0627\u0646\u06af\u0627\u0631 \u0628\u0648\u062f\u0647 \u0648 \u0627\u0632 \u0642\u0627\u0628\u0644\u06cc\u062a \u0646\u06af\u0627\u0631\u0634 \u0628\u0633\u06cc\u0627\u0631 \u0628\u0627\u0644\u0627\u06cc\u06cc \u0628\u0631\u062e\u0648\u0631\u062f\u0627\u0631 \u0627\u0633\u062a. \u0627\u0632 \u0631\u0627\u0633\u062a \u0628\u0647 \u0686\u067e \u0646\u0648\u0634\u062a\u0647 \u0645\u06cc\u200c\u0634\u0648\u062f \u0648 \u0628\u0647 \u0646\u0627\u0645\u200c\u0647\u0627\u06cc \u062f\u06cc\u0646 \u062f\u0628\u06cc\u0631\u0647\u060c \u062f\u06cc\u0646 \u062f\u0628\u06cc\u0631\u06cc\u0647\u060c \u062f\u06cc\u0646 \u062f\u0641\u06cc\u0631\u0647 \u0648 \u2026 \u0647\u0645 \u0646\u0627\u0645\u06cc\u062f\u0647 \u0645\u06cc\u200c\u0634\u0648\u062f.\n\u062e\u0637 \u0627\u0648\u0633\u062a\u0627\u06cc\u06cc \u0628\u0631\u0645\u0628\u0646\u0627\u06cc \u062e\u0637 \u067e\u0647\u0644\u0648\u06cc \u0633\u0627\u0633\u0627\u0646\u06cc \u0627\u062e\u062a\u0631\u0627\u0639 \u0634\u062f\u0647\u200c\u0627\u0633\u062a. ", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-7509e47c53d5486c8b573e2a1dc43175", "input": "\u0642\u0627\u0622\u0646\u06cc \u062f\u0631 \u0627\u062f\u0628\u06cc\u0627\u062a \u0639\u0631\u0628 \u0648 \u0641\u0627\u0631\u0633\u06cc \u0645\u0647\u0627\u0631\u062a \u06a9\u0627\u0641\u06cc \u06cc\u0627\u0641\u062a \u0648 \u0628\u0647 \u062d\u06a9\u0645\u062a \u0646\u06cc\u0632 \u0639\u0644\u0627\u0642\u0647 \u0633\u0631\u0634\u0627\u0631\u06cc \u062f\u0627\u0634\u062a \u060c \u0627\u0632 \u0627\u06cc\u0646 \u0631\u0648 \u0641\u062a\u062d\u0639\u0644\u06cc\u200c\u0634\u0627\u0647 \u0627\u0648 \u0631\u0627 \u00ab\u0645\u062c\u062a\u0647\u062f\u0627\u0644\u0634\u0639\u0631\u0627\u0621\u00bb \u0644\u0642\u0628 \u062f\u0627\u062f \u0648 \u0645\u062d\u0645\u062f\u0634\u0627\u0647 \u0646\u06cc\u0632 \u0642\u0627\u0622\u0646\u06cc \u0631\u0627 \u00ab\u062d\u0633\u0627\u0646\u200c\u0627\u0644\u0639\u062c\u0645\u00bb \u0645\u06cc\u200c\u062e\u0648\u0627\u0646\u062f\u060c \u0632\u06cc\u0631\u0627 \u0622\u0646\u0686\u0646\u0627\u0646 \u062f\u0631 \u0642\u0635\u06cc\u062f\u0647\u0633\u0631\u0627\u06cc\u06cc \u062a\u0648\u0627\u0646\u0627\u06cc\u06cc \u062f\u0627\u0634\u062a \u06a9\u0647 \u0645\u0627\u06cc\u0647\u0654 \u0634\u06af\u0641\u062a\u06cc \u062e\u0648\u0627\u0646\u0646\u062f\u06af\u0627\u0646 \u0628\u0648\u062f.\n\u0645\u062d\u0645\u062f \u0634\u0627\u0647 \u0628\u0647 \u0642\u0627\u0622\u0646\u06cc \u0644\u0642\u0628 \"\u0645\u062c\u062a\u0647\u062f\u0627\u0644\u0634\u0639\u0631\u0627\u0621\" \u0631\u0627 \u062f\u0627\u062f\u0647 \u0627\u0633\u062a.", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-e0089b4cbcc74f488dee5a664ed99165", "input": "\u0639\u0644\u0627\u0645\u0647 \u0637\u0628\u0627\u0637\u0628\u0627\u06cc\u06cc \u0645\u06cc\u200c\u0641\u0631\u0645\u0627\u06cc\u062f \u06a9\u0647 \u0647\u062f\u0627\u06cc\u062a \u0628\u0647 \u0627\u0645\u0631 \u0628\u0647 \u0645\u0639\u0646\u0627\u06cc \u0631\u0627\u0647\u0646\u0645\u0627\u06cc\u06cc \u0646\u06cc\u0633\u062a\u060c \u0628\u0644\u06a9\u0647 \u0645\u0639\u0646\u0627\u06cc \u0622\u0646\u060c \u0631\u0633\u0627\u0646\u062f\u0646 \u0628\u0647 \u0645\u0642\u0635\u062f \u0627\u0633\u062a.\n\u0647\u062f\u0627\u06cc\u062a \u0628\u0647 \u0627\u0645\u0631 \u062e\u062f\u0627 \u0627\u0632 \u0641\u06cc\u0648\u0636\u0627\u062a \u0645\u0639\u0646\u0648\u06cc \u0648 \u0645\u0642\u0627\u0645\u0627\u062a \u0628\u0627\u0637\u0646\u06cc \u0627\u0633\u062a .", "output": ["N"]}, "Prediction": "N"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-5528a3ca52e64750a44ec24ebbc93aee", "input": "\u0627\u0628\u0648\u0627\u0644\u062d\u0633\u0646 \u0628\u0646\u06cc \u0635\u062f\u0631 \u0631\u0626\u06cc\u0633 \u062c\u0645\u0647\u0648\u0631 \u0648\u0642\u062a \u0627\u06cc\u0631\u0627\u0646 \u06a9\u0647 \u0645\u0633\u0626\u0648\u0644\u06cc\u062a \u0641\u0631\u0645\u0627\u0646\u062f\u0647\u06cc \u06a9\u0644 \u0642\u0648\u0627 \u0631\u0627 \u0646\u06cc\u0632 \u0627\u0632 \u0637\u0631\u0641 \u0627\u0645\u0627\u0645 \u0631\u0627\u062d\u0644 \u0628\u0647 \u0639\u0647\u062f\u0647 \u062f\u0627\u0634\u062a\u060c \u062f\u0631 \u062f\u0648\u0631\u0627\u0646 \u0627\u0634\u063a\u0627\u0644 \u0627\u0631\u0627\u0636\u06cc \u0627\u06cc\u0631\u0627\u0646 \u0646\u0647 \u062a\u0646\u0647\u0627 \u0627\u0639\u062a\u0642\u0627\u062f\u06cc \u0628\u0647 \u0633\u0627\u0632\u0645\u0627\u0646\u062f\u0647\u06cc \u0646\u0638\u0627\u0645\u06cc \u0628\u0631\u0627\u06cc \u0645\u0642\u0627\u0628\u0644\u0647 \u0628\u0627 \u062a\u062c\u0627\u0648\u0632 \u0646\u062f\u0627\u0634\u062a\u060c \u0628\u0644\u06a9\u0647 \u0628\u06cc\u0634\u062a\u0631 \u0628\u0647 \u062d\u0631\u06a9\u062a\u0647\u0627\u06cc \u062f\u06cc\u067e\u0644\u0645\u0627\u0633\u06cc \u062f\u0631 \u062d\u0644 \u0645\u0646\u0627\u0642\u0634\u0647 \u0631\u0648\u06cc \u0622\u0648\u0631\u062f\u060c \u0648 \u0647\u0645\u0627\u0646\u0637\u0648\u0631 \u06a9\u0647 \u06af\u0641\u062a\u0647 \u0634\u062f \u0628\u0646\u06cc\u200c\u0635\u062f\u0631 \u0627\u0632 \u0627\u06cc\u0646 \u063a\u0627\u0626\u0644\u0647 \u0645\u0631\u0632\u06cc \u062f\u0631 \u062c\u0647\u062a \u0645\u0642\u0627\u0628\u0644\u0647 \u0628\u0627 \u0646\u06cc\u0631\u0648\u0647\u0627 \u0648 \u062c\u0646\u0627\u062d\u200c\u0647\u0627\u06cc \u0631\u0642\u06cc\u0628 \u062f\u0627\u062e\u0644\u06cc \u0628\u0631\u0622\u0645\u062f.\n\u062a\u0627\u06a9\u062a\u06cc\u06a9 \u0628\u0646\u06cc\u200c\u0635\u062f\u0631 \u062f\u0631 \u062f\u0648\u0631\u0627\u0646 \u0627\u0634\u063a\u0627\u0644 \u0627\u0631\u0627\u0636\u06cc \u0627\u06cc\u0631\u0627\u0646\u060c \u062d\u0631\u06a9\u062a\u200c\u0647\u0627\u06cc \u062f\u06cc\u067e\u0644\u0645\u0627\u0633\u06cc \u062f\u0631 \u062d\u0644 \u0645\u0646\u0627\u0642\u0634\u0647 \u0628\u0648\u062f", "output": ["E"]}, "Prediction": "E."}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-eabb1ea8ff8f49819d8df1112b891b61", "input": "\u067e\u0627\u0641\u0634\u0627\u0631\u06cc \u0648 \u0645\u0628\u0627\u0631\u0632\u0647\u200c\u0647\u0627\u06cc \u0645\u0631\u062f\u0645 \u0628\u0631\u0627\u06cc \u062a\u0634\u06a9\u06cc\u0644 \u0639\u062f\u0627\u0644\u062a\u062e\u0627\u0646\u0647 \u0648 \u0628\u0647 \u062f\u0633\u062a \u0622\u0648\u0631\u062f\u0646 \u062d\u0642 \u062a\u0635\u0645\u06cc\u0645\u200c\u06af\u06cc\u0631\u06cc \u062f\u0631 \u0627\u0645\u0648\u0631 \u062e\u0648\u06cc\u0634\u060c \u0633\u0631\u0627\u0646\u062c\u0627\u0645 \u0628\u0627\u0639\u062b \u0634\u062f \u06a9\u0647 \u0645\u0638\u0641\u0631\u0627\u0644\u062f\u06cc\u0646 \u0634\u0627\u0647 \u0642\u0627\u062c\u0627\u0631 \u0641\u0631\u0645\u0627\u0646 \u062a\u0634\u06a9\u06cc\u0644 \u0639\u062f\u0627\u0644\u062a\u062e\u0627\u0646\u0647 \u0631\u0627 \u0635\u0627\u062f\u0631 \u06a9\u0646\u062f \u0648 \u0639\u062f\u0627\u0644\u062a\u062e\u0627\u0646\u0647 \u062a\u0634\u06a9\u06cc\u0644 \u0634\u0648\u062f.\n\u0645\u0638\u0641\u0631\u0627\u0644\u062f\u06cc\u0646 \u0634\u0627\u0647 \u067e\u0633 \u0627\u0632 \u0641\u0631\u0645\u0627\u0646 \u062a\u0623\u0633\u06cc\u0633 \u0639\u062f\u0627\u0644\u062a\u062e\u0627\u0646\u0647\u200c\u060c \u0641\u0631\u0645\u0627\u0646 \u0645\u0634\u0631\u0648\u0637\u06cc\u062a \u0631\u0627 \u0635\u0627\u062f\u0631 \u06a9\u0631\u062f.", "output": ["N"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-c764f79882604bb99a64629df06ed301", "input": "\u0639\u0645\u0644\u06cc\u0627\u062a \u062b\u0627\u0645\u0646\u200c\u0627\u0644\u0627\u0626\u0645\u0647 ( \u0634\u06a9\u0633\u062a \u062d\u0635\u0631 \u0622\u0628\u0627\u062f\u0627\u0646) \u062f\u0631 \u062a\u0627\u0631\u06cc\u062e \u06f5 \u0645\u0647\u0631 \u06f1\u06f3\u06f6\u06f0 \u0648 \u0628\u0627 \u0631\u0645\u0632 \u00ab \u0646\u0635\u0631 \u0645\u0646 \u0627\u0644\u0644\u0647 \u0648 \u0641\u062a\u062d \u0642\u0631\u06cc\u0628\u00bb \u0627\u062c\u0631\u0627 \u0634\u062f.\n\u0639\u0645\u0644\u06cc\u0627\u062a \u062b\u0627\u0645\u0646\u200c\u0627\u0644\u0627\u0626\u0645\u0647 \u0628\u0627 \u0631\u0645\u0632 \u00ab\u06cc\u0627 \u0632\u0647\u0631\u0627\u00bb \u0628\u0627 \u0647\u062f\u0641 \u0634\u06a9\u0633\u062a \u062d\u0635\u0631 \u0622\u0628\u0627\u062f\u0627\u0646 \u0627\u062c\u0631\u0627 \u0634\u062f. ", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-5860179437f745148dbbab3fdf5ce649", "input": "\u062e\u062f\u0627\u0648\u0646\u062f \u062f\u0631 \u0642\u0631\u0622\u0646 \u06a9\u0631\u06cc\u0645 \u062f\u0648 \u0627\u0635\u0644 \u0645\u0648\u062f\u062a \u0648 \u0631\u062d\u0645\u062a \u0631\u0627 \u0628\u0631\u0627\u06cc \u062d\u0641\u0638 \u0627\u0633\u062a\u062d\u06a9\u0627\u0645 \u062e\u0627\u0646\u0648\u0627\u062f\u0647 \u0648 \u0631\u0627\u0628\u0637\u0647 \u0628\u06cc\u0646 \u0632\u0646 \u0648 \u0634\u0648\u0647\u0631 \u0645\u0639\u0631\u0641\u06cc \u06a9\u0631\u062f\u0647 \u0627\u0633\u062a.\n\u0627\u0632 \u0648\u06cc\u0698\u06af\u06cc \u0647\u0627\u06cc \u0645\u0648\u062f\u062a\u060c \u0627\u06cc\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0627\u0646\u0633\u0627\u0646\u060c \u06a9\u0633\u06cc \u0631\u0627 \u0628\u0631\u0627\u06cc \u062e\u0648\u062f\u0634 \u062f\u0648\u0633\u062a \u062f\u0627\u0634\u062a\u0647 \u0628\u0627\u0634\u062f.", "output": ["N"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-cc3964bdd0d14720b8391fa9d4848a60", "input": "\u0633\u0646\u062a \u0627\u0644\u0647\u0649 \u0627\u06cc\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0647\u0631 \u06a9\u0633 \u0628\u0627 \u0627\u0631\u0627\u062f\u0647 \u0648 \u0627\u062e\u062a\u06cc\u0627\u0631 \u062e\u0648\u062f\u060c \u0631\u0627\u0647 \u062d\u0642 \u06cc\u0627 \u0628\u0627\u0637\u0644 \u0631\u0627 \u0628\u0631\u06af\u0632\u06cc\u0646\u062f\u060c \u0634\u0631\u0627\u06cc\u0637\u0649 \u0628\u0631\u0627\u0649 \u0627\u0648 \u0641\u0631\u0627\u0647\u0645 \u0634\u0648\u062f \u06a9\u0647 \u062f\u0631 \u0645\u0633\u06cc\u0631\u0649 \u06a9\u0647 \u062f\u0631 \u067e\u06cc\u0634 \u06af\u0631\u0641\u062a\u0647\u060c \u0628\u0647 \u067e\u06cc\u0634 \u0631\u0648\u062f \u0648 \u0633\u0631\u0634\u062a \u062e\u0648\u062f \u0631\u0627 \u0622\u0634\u06a9\u0627\u0631 \u06a9\u0646\u062f \u06a9\u0647 \u0628\u0647 \u0622\u0646 \u0627\u0645\u062f\u0627\u062f \u0627\u0644\u0647\u06cc \u06af\u0641\u062a\u0647 \u0645\u06cc \u0634\u0648\u062f.\n\u0633\u0646\u062a \u0627\u0644\u0647\u06cc \u062d\u0627\u06a9\u0645 \u0628\u0631 \u0627\u0646\u062a\u062e\u0627\u0628 \u0648 \u0639\u0645\u0644 \u0627\u0646\u0633\u0627\u0646\u200c\u0647\u0627 \u0627\u0645\u062f\u0627\u062f \u0627\u0644\u0647\u06cc \u0646\u0627\u0645 \u062f\u0627\u0631\u062f.", "output": ["E"]}, "Prediction": "E."}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-a4f670486e9d40339d0a1ccce8adc4eb", "input": "\u062a\u0631\u0648\u0631 \u0634\u0627\u0647 \u062f\u0631 \u0634\u0648\u0631\u0627\u06cc \u0645\u0631\u06a9\u0632\u06cc \u062d\u0632\u0628 \u062a\u0648\u062f\u0647\u060c \u0628\u0647\u200c\u0637\u0648\u0631 \u0645\u062d\u0631\u0645\u0627\u0646\u0647 \u062a\u0635\u0645\u06cc\u0645 \u06af\u0631\u0641\u062a\u0647 \u0634\u062f \u06a9\u0647 \u0646\u0627\u0645\u0648\u0641\u0642 \u0645\u0627\u0646\u062f.\u0627\u06cc\u0646 \u062d\u0627\u062f\u062b\u0647 \u0641\u0631\u0635\u062a \u0645\u0646\u0627\u0633\u0628\u06cc \u0628\u0631\u0627\u06cc \u0633\u0631\u06a9\u0648\u0628\u06cc \u062d\u0632\u0628 \u062a\u0648\u062f\u0647 \u0641\u0631\u0627\u0647\u0645 \u0622\u0648\u0631\u062f. \u062f\u0631 \u0634\u0628 \u06f1\u06f6 \u0628\u0647\u0645\u0646 \u06f1\u06f3\u06f2\u06f7 \u0645\u0631\u0627\u06a9\u0632 \u0648 \u062f\u0641\u0627\u062a\u0631 \u062d\u0632\u0628 \u062a\u0648\u062f\u0647 \u0627\u0632 \u0633\u0648\u06cc \u0645\u0642\u0627\u0645\u0627\u062a \u0641\u0631\u0645\u0627\u0646\u062f\u0627\u0631\u06cc \u0646\u0638\u0627\u0645\u06cc \u0627\u0634\u063a\u0627\u0644 \u0634\u062f \u0648 \u062d\u0632\u0628 \u062a\u0648\u062f\u0647 \u063a\u06cc\u0631\u0642\u0627\u0646\u0648\u0646\u06cc \u0634\u0646\u0627\u062e\u062a\u0647 \u0634\u062f \u0648 \u0639\u062f\u0647\u200c\u0627\u06cc \u0627\u0632 \u0633\u0631\u0627\u0646 \u0622\u0646 \u062f\u0633\u062a\u06af\u06cc\u0631\u060c \u0632\u0646\u062f\u0627\u0646\u06cc \u0648 \u0645\u062d\u0627\u06a9\u0645\u0647 \u0634\u062f\u0646\u062f.\n\u06a9\u0648\u062f\u062a\u0627\u06cc \u06f2\u06f8 \u0645\u0631\u062f\u0627\u062f \u0633\u0628\u0628 \u0627\u0646\u062d\u0644\u0627\u0644 \u062d\u0632\u0628 \u062a\u0648\u062f\u0647 \u0634\u062f \u06a9\u0647 \u0628\u0631 \u0627\u0633\u0627\u0633 \u0622\u0646 \u062f\u0641\u0627\u062a\u0631 \u062d\u0632\u0628 \u0627\u0634\u063a\u0627\u0644 \u0648 \u0627\u0639\u0636\u0627 \u062f\u0633\u062a\u06af\u06cc\u0631 \u0634\u062f\u0646\u062f.", "output": ["C"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-e7d1faf49fef4cb3868ed6c412a71ca8", "input": "\u0628\u062e\u0634 \u0639\u0645\u062f\u0647 \u0627\u0633\u0644\u062d\u0647 \u0645\u0648\u0631\u062f \u0646\u06cc\u0627\u0632 \u0639\u0631\u0627\u0642\u06cc \u200c\u0647\u0627 \u062f\u0631 \u0637\u0648\u0644 \u062c\u0646\u06af \u062a\u0648\u0633\u0637 \u0634\u0648\u0631\u0648\u06cc \u062a\u0623\u0645\u06cc\u0646 \u0645\u06cc\u200c\u0634\u062f. \u06a9\u0634\u0648\u0631\u0647\u0627\u06cc \u0627\u06cc\u062a\u0627\u0644\u06cc\u0627 \u0648 \u0628\u0644\u0698\u06cc\u06a9 \u0628\u0627 \u0627\u0631\u0633\u0627\u0644 \u0645\u0648\u0634\u06a9\u200c\u0647\u0627\u06cc \u067e\u06cc\u0634\u0631\u0641\u062a\u0647 \u0636\u062f \u0632\u0631\u0647 \u0648 \u06a9\u0645\u06a9 \u0628\u0647 \u0639\u0631\u0627\u0642 \u062f\u0631 \u0633\u0627\u062e\u062a \u062a\u0648\u067e\u062e\u0627\u0646\u0647 \u062f\u0648\u0631\u0628\u0631\u062f \u0627\u0632 \u062c\u0645\u0644\u0647 \u062d\u0627\u0645\u06cc\u0627\u0646 \u0639\u0631\u0627\u0642 \u0628\u0648\u062f\u0646\u062f.\n\u0628\u0644\u0698\u06cc\u06a9 \u0628\u06cc\u0634\u062a\u0631\u06cc\u0646 \u062a\u0633\u0644\u06cc\u062d\u0627\u062a \u0631\u0627 \u0628\u0631\u0627\u06cc \u0631\u0698\u06cc\u0645 \u0628\u0639\u062b \u0639\u0631\u0627\u0642 \u062f\u0631 \u0637\u0648\u0644 \u062c\u0646\u06af \u0622\u0645\u0627\u062f\u0647 \u06a9\u0631\u062f.", "output": ["C"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-b5599e184034462c92cf1ddff71f238b", "input": "\u0642\u0635\u0631 \u0639\u0645\u0631\u0647 \u06cc\u06a9\u06cc \u0627\u0632 \u0622\u062b\u0627\u0631 \u0628\u0633\u06cc\u0627\u0631 \u0632\u06cc\u0628\u0627\u06cc \u0639\u0635\u0631 \u0627\u0645\u0648\u06cc \u0627\u0633\u062a \u06a9\u0647 \u0628\u0647 \u0641\u0631\u0645\u0627\u0646 \u0648\u0644\u06cc\u062f \u0628\u0646 \u0639\u0628\u062f\u0627\u0644\u0645\u0644\u06a9 \u0633\u0627\u062e\u062a\u0647 \u0634\u062f. \u0627\u0632 \u0634\u06af\u0641\u062a \u0647\u0627\u06cc \u0627\u06cc\u0646 \u0642\u0635\u0631\u060c \u0633\u0642\u0641 \u0641\u0644\u06a9\u06cc \u0622\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0628\u0627 \u0639\u0644\u0627\u06cc\u0645\u06cc \u0627\u0632 \u0645\u0648\u062c\u0648\u062f\u0627\u062a \u06a9\u06cc\u0647\u0627\u0646\u06cc \u0648 \u0645\u062c\u0645\u0648\u0639\u0647 \u0633\u062a\u0627\u0631\u06af\u0627\u0646 \u0648 \u062a\u0635\u0627\u0648\u06cc\u0631 \u0628\u062f\u06cc\u0639 \u0641\u0636\u0627\u06cc\u06cc \u0645\u0632\u06cc\u0646 \u0634\u062f\u0647 \u0627\u0633\u062a.\n\u062a\u0646\u0647\u0627 \u0642\u0635\u0631 \u062f\u0648\u0631\u0627\u0646 \u0627\u0645\u0648\u06cc \u06a9\u0647 \u062f\u0631 \u0633\u0642\u0641 \u0622\u0646 \u0627\u0632 \u0645\u062c\u0645\u0648\u0639\u0647 \u0633\u062a\u0627\u0631\u06af\u0627\u0646 \u0648 \u062a\u0635\u0627\u0648\u06cc\u0631 \u0641\u0636\u0627\u06cc\u06cc \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u0634\u062f\u0647\u060c \u0642\u0635\u0631 \u0627\u0644\u0645\u0634\u062a\u06cc \u0627\u0633\u062a.", "output": ["C"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-141606763b054c3caedeb220de3a2f2f", "input": "\u062d\u0645\u0644\u0647 \u0628\u0647 \u067e\u0631\u0644 \u0647\u0627\u0631\u0628\u0631 (\u06a9\u0647 \u0627\u0632 \u0633\u0648\u06cc \u0645\u0631\u06a9\u0632 \u0641\u0631\u0645\u0627\u0646\u062f\u0647\u06cc \u0646\u0638\u0627\u0645\u06cc \u0698\u0627\u067e\u0646 \u0639\u0645\u0644\u06cc\u0627\u062a \u0647\u0627\u0648\u0627\u06cc\u06cc \u06cc\u0627 \u0639\u0645\u0644\u06cc\u0627\u062a \u0632\u06cc \u0648 \u0627\u0632 \u0633\u0648\u06cc \u0628\u0631\u062e\u06cc \u0627\u0632 \u0622\u0645\u0631\u06cc\u06a9\u0627\u06cc\u06cc\u200c\u0647\u0627 \u0646\u0628\u0631\u062f \u067e\u0631\u0644 \u0647\u0627\u0631\u0628\u0631 \u062e\u0648\u0627\u0646\u062f\u0647 \u0645\u06cc\u200c\u0634\u062f) \u062d\u0645\u0644\u0647\u0654 \u0646\u0627\u06af\u0647\u0627\u0646\u06cc \u0647\u0648\u0627\u067e\u06cc\u0645\u0627\u0647\u0627\u06cc \u062c\u0646\u06af\u0646\u062f\u0647 \u0698\u0627\u067e\u0646 \u0628\u0647 \u067e\u0627\u06cc\u06af\u0627\u0647 \u062f\u0631\u06cc\u0627\u06cc\u06cc \u0627\u06cc\u0627\u0644\u0627\u062a \u0645\u062a\u062d\u062f\u0647 \u0622\u0645\u0631\u06cc\u06a9\u0627 \u062f\u0631 \u067e\u0631\u0644 \u0647\u0627\u0631\u0628\u0631 \u062f\u0631 \u0628\u0627\u0645\u062f\u0627\u062f \u0631\u0648\u0632 \u06cc\u06a9\u0634\u0646\u0628\u0647 \u0647\u0641\u062a\u0645 \u062f\u0633\u0627\u0645\u0628\u0631 \u0633\u0627\u0644 \u06f1\u06f9\u06f4\u06f1 \u0645\u06cc\u0644\u0627\u062f\u06cc \u0628\u0631\u0627\u0628\u0631 \u0628\u0627 \u06f1\u06f6 \u0622\u0630\u0631 \u06f1\u06f3\u06f2\u06f0 \u062e\u0648\u0631\u0634\u06cc\u062f\u06cc \u0628\u0648\u062f.\n\u06a9\u0634\u0648\u0631 \u0698\u0627\u067e\u0646 \u0628\u0627 \u062d\u0645\u0644\u0647 \u0628\u0647 \u067e\u0631\u0644 \u0647\u0627\u0631\u0628\u0631 \u0646\u0627\u0648\u06af\u0627\u0646 \u062f\u0631\u06cc\u0627\u06cc\u06cc \u0622\u0645\u0631\u06cc\u06a9\u0627 \u0631\u0627 \u0645\u0648\u0631\u062f \u062d\u0645\u0644\u0647 \u0642\u0631\u0627\u0631 \u062f\u0627\u062f.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-f308c0b58ebc443681b09f4bed8649a1", "input": "\u0627\u06cc\u0633\u0648\u0633 \u06cc\u06a9\u06cc \u0627\u0632 \u0634\u0647\u0631\u0647\u0627\u06cc \u06a9\u06cc\u0644\u06cc\u06a9\u06cc\u0647 \u062f\u0631 \u06a9\u0631\u0627\u0646\u06c0 \u062e\u0644\u06cc\u062c \u0627\u0633\u06a9\u0646\u062f\u0631\u0648\u0646 \u0627\u0633\u062a \u0648 \u0628\u0647 \u0633\u0628\u0628 \u062c\u0646\u06af \u062a\u0627\u0631\u06cc\u062e\u06cc \u0627\u0633\u06a9\u0646\u062f\u0631 \u0628\u0627 \u062f\u0627\u0631\u06cc\u0648\u0634 \u0633\u0648\u0645 \u062f\u0631 \u062f\u0634\u062a \u06a9\u0648\u0686\u06a9 \u06a9\u0646\u0627\u0631\u0634 \u0634\u0647\u0631\u062a \u062a\u0627\u0631\u06cc\u062e\u06cc \u06cc\u0627\u0641\u062a\u0647 \u0627\u0633\u062a. \u0627\u06cc\u0646 \u062f\u0634\u062a \u0627\u0632 \u0633\u0648\u06cc \u0634\u0645\u0627\u0644 \u0628\u0647 \u062a\u067e\u0647 \u0647\u0627\u0626\u06cc \u0645\u062d\u062f\u0648\u062f \u0628\u0648\u062f \u0648 \u0627\u0632 \u0637\u0631\u0641 \u062c\u0646\u0648\u0628 \u0628\u0647 \u062f\u0631\u06cc\u0627 \u0645\u06cc \u067e\u06cc\u0648\u0633\u062a. \n\u0627\u06cc\u0633\u0648\u0633 \u06cc\u06a9\u06cc \u0627\u0632 \u0634\u0647\u0631\u0647\u0627\u06cc \u06a9\u06cc\u0644\u06cc\u06a9\u06cc\u0647 \u0627\u0633\u062a \u06a9\u0647 \u0628\u0647 \u0633\u0628\u0628 \u0646\u0628\u0631\u062f \u0627\u0633\u06a9\u0646\u062f\u0631 \u0628\u0627 \u062f\u0627\u0631\u06cc\u0648\u0634 \u0633\u0648\u0645 \u0634\u0647\u0631\u062a \u062a\u0627\u0631\u06cc\u062e\u06cc \u06cc\u0627\u0641\u062a\u0647 \u0627\u0633\u062a.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-a15004957ffa48559982106003cd69b0", "input": "\u0627\u0648\u0644\u06cc\u0646 \u0645\u0648\u0631\u062f \u062f\u0631 \u0639\u0644\u0644 \u0628\u062d\u0631\u0627\u0646 \u0641\u0631\u0647\u0646\u06af\u06cc \u0648 \u0645\u0639\u0646\u0648\u06cc \u062a\u0645\u062f\u0646 \u063a\u0631\u0628\u060c \u0628\u06cc \u062a\u0648\u062c\u0647\u06cc \u062a\u0645\u062f\u0646 \u063a\u0631\u0628 \u0628\u0647 \u062f\u06cc\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0645\u0647\u0645\u062a\u0631\u06cc\u0646 \u0639\u0627\u0645\u0644 \u0646\u06cc\u0632 \u0645\u06cc \u0628\u0627\u0634\u062f.\n\u0639\u0648\u0627\u0645\u0644 \u0628\u062d\u0631\u0627\u0646 \u0641\u0631\u0647\u0646\u06af\u06cc \u062a\u0645\u062f\u0646 \u063a\u0631\u0628 \u0639\u0628\u0627\u0631\u062a\u0646\u062f \u0627\u0632: \u06f1- \u0628\u06cc \u062a\u0648\u062c\u0647\u06cc \u0628\u0647 \u062f\u06cc\u0646 \u06f2- \u0646\u0628\u0648\u062f \u062a\u062f\u06cc\u0646 \u062f\u0631 \u062c\u0627\u0645\u0639\u0647 \u063a\u0631\u0628\u06cc.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-8eadb3f113f64726bf29a21f6354837a", "input": "\u0647\u067e\u062a\u0627\u0644\u06cc\u0627\u0646 \u06cc\u0627 \u0647\u0641\u062a\u0627\u0644\u06cc\u0627\u0646 \u067e\u06cc\u0634 \u0627\u0632 \u062d\u0645\u0644\u0647 \u0627\u0639\u0631\u0627\u0628 \u062f\u0627\u062e\u0644 \u0645\u0645\u0644\u06a9\u062a \u0627\u06cc\u0631\u0627\u0646 \u0634\u062f\u0646\u062f \u0648 \u0686\u0646\u062f\u06cc\u0646 \u0627\u06cc\u0627\u0644\u062a \u0631\u0627 \u0628\u0627 \u0634\u0647\u0631\u0647\u0627\u06cc \u0645\u0631\u0648 \u0648 \u0647\u0631\u0627\u062a \u062a\u0635\u0631\u0641 \u06a9\u0631\u062f\u0646\u062f \u0648 \u062e\u0631\u0627\u062c\u06cc \u0633\u0627\u0644\u06cc\u0627\u0646\u0647 \u0628\u0631 \u0633\u0627\u0633\u0627\u0646\u06cc\u0627\u0646 \u062a\u062d\u0645\u06cc\u0644 \u06a9\u0631\u062f\u0646\u062f. \u0627\u0632 \u0622\u0646 \u067e\u0633 \u062a\u062d\u0648\u06cc\u0644 \u0628\u0647 \u0645\u0648\u0642\u0639 \u0628\u0627\u062c \u06cc\u06a9\u06cc \u0627\u0632 \u0648\u0638\u0627\u06cc\u0641 \u0645\u0647\u0645 \u0648 \u0634\u0627\u0642 \u0634\u0627\u0647\u0627\u0646 \u0628\u0639\u062f\u06cc \u0627\u06cc\u0631\u0627\u0646 \u0634\u062f.\n\u062d\u06a9\u0648\u0645\u062a \u0633\u0627\u0633\u0627\u0646\u06cc\u0627\u0646 \u067e\u06cc\u0634 \u0627\u0632 \u0622\u0646\u06a9\u0647 \u062a\u0633\u0644\u06cc\u0645 \u0627\u0639\u0631\u0627\u0628 \u0645\u0633\u0644\u0645\u0627\u0646 \u0634\u0648\u062f\u060c \u0628\u0647 \u062d\u06a9\u0648\u0645\u062a \u0647\u0641\u062a\u0627\u0644\u06cc\u0627\u0646 \u062e\u0631\u0627\u062c \u0645\u06cc\u062f\u0627\u062f\u0646\u062f.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-977a69f0a58348dab1befaf2e8b3807f", "input": "\u0645\u0644\u0627 \u0645\u062d\u0645\u062f\u0628\u0627\u0642\u0631 \u0645\u062c\u0644\u0633\u06cc \u0645\u0639\u0631\u0648\u0641 \u0628\u0647 \u0639\u0644\u0627\u0645\u0647 \u0645\u062c\u0644\u0633\u06cc \u0648 \u0645\u062c\u0644\u0633\u06cc \u062b\u0627\u0646\u06cc \u0641\u0642\u06cc\u0647 \u0634\u06cc\u0639\u0647 \u062f\u0631 \u062f\u0648\u0631\u0627\u0646 \u0634\u0627\u0647 \u0633\u0644\u06cc\u0645\u0627\u0646 \u0648 \u0634\u0627\u0647 \u0633\u0644\u0637\u0627\u0646 \u062d\u0633\u06cc\u0646 \u0635\u0641\u0648\u06cc \u0628\u0648\u062f. \u06a9\u0647 \u0628\u0647 \u0627\u0648 \u0644\u0642\u0628 \u0642\u0627\u062a\u0644 \u0635\u0648\u0641\u06cc\u0647 \u0631\u0627 \u062f\u0627\u062f\u0647 \u0627\u0646\u062f. \u0627\u0648 \u062f\u0631 \u0632\u0645\u0627\u0646 \u0633\u0644\u0637\u0627\u0646 \u062d\u0633\u06cc\u0646 \u062a\u0648\u0627\u0646\u0633\u062a \u0628\u0627 \u0646\u0648\u0634\u062a\u0647 \u0647\u0627\u06cc \u062e\u0648\u062f \u0648 \u0646\u0641\u0648\u0630 \u062f\u0631 \u062f\u0631\u0628\u0627\u0631 \u0635\u0641\u0648\u06cc \u0628\u0627\u0639\u062b \u0628\u0631\u0627\u0646\u062f\u0627\u0632\u06cc \u0637\u0631\u06cc\u0642\u062a \u0635\u0648\u0641\u06cc\u0627\u0646 \u0634\u0648\u062f.\n\u0645\u0644\u0627\u0645\u062d\u0645\u062f\u0628\u0627\u0642\u0631 \u0645\u062c\u0644\u0633\u06cc \u0639\u0644\u0648\u0645 \u0639\u0642\u0644\u06cc \u0631\u0627 \u0646\u0632\u062f \u062d\u0633\u06cc\u0646 \u062e\u0648\u0627\u0646\u0633\u0627\u0631\u06cc \u0641\u0631\u0627 \u06af\u0631\u0641\u062a.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-19a10573c89a47069d53eff06b510664", "input": "\u0633\u06cc\u0627\u062d\u062a\u200c\u0646\u0627\u0645\u0647\u0654 \u0627\u0628\u0631\u0627\u0647\u06cc\u0645\u200c\u0628\u06cc\u06af \u0646\u0627\u0645 \u06a9\u062a\u0627\u0628 \u0633\u0641\u0631\u0646\u0627\u0645\u0647\u200c\u0627\u06cc \u0628\u0647 \u0641\u0627\u0631\u0633\u06cc \u0627\u0632 \u0632\u06cc\u0646\u200c\u0627\u0644\u0639\u0627\u0628\u062f\u06cc\u0646 \u0645\u0631\u0627\u063a\u0647\u200c\u0627\u06cc \u0627\u0633\u062a \u06a9\u0647 \u062f\u0631 \u062d\u062f\u0648\u062f \u0633\u0627\u0644 \u06f1\u06f3\u06f2\u06f1 \u0647\u062c\u0631\u06cc \u0642\u0645\u0631\u06cc \u062f\u0631 \u0627\u0633\u062a\u0627\u0646\u0628\u0648\u0644 \u0645\u0646\u062a\u0634\u0631 \u0634\u062f. \n\u0635\u062f\u0631 \u0627\u0639\u0638\u0645 \u0627\u0645\u06cc\u0646 \u0627\u0644\u062f\u0648\u0644\u0647\u060c \u0646\u0648\u06cc\u0633\u0646\u062f\u0647 \u06a9\u062a\u0627\u0628 \"\u0633\u06cc\u0627\u062d\u062a\u200c\u0646\u0627\u0645\u0647\u0654 \u0627\u0628\u0631\u0627\u0647\u06cc\u0645\u200c\u0628\u06cc\u06af\" \u0645\u06cc \u0628\u0627\u0634\u062f.", "output": ["C"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-247ef3b620de4c67839cf06b5732bab2", "input": "\u062a\u0644\u0645\u06cc\u062d (\u062f\u0631 \u0644\u063a\u062a \u06cc\u0639\u0646\u06cc: \u0628\u0627 \u06af\u0648\u0634\u0647\u0621 \u0686\u0634\u0645 \u0646\u06af\u0631\u06cc\u0633\u062a\u0646 \u0627\u0633\u062a) \u0627\u0632 \u062c\u0645\u0644\u0647\u0654 \u0635\u0646\u0627\u06cc\u0639 \u0645\u0639\u0646\u0648\u06cc \u0628\u062f\u06cc\u0639 \u0627\u0633\u062a \u06a9\u0647 \u062f\u0631 \u0622\u0646 \u0646\u0648\u06cc\u0633\u0646\u062f\u0647 \u06cc\u0627 \u06af\u0648\u06cc\u0646\u062f\u0647 \u062f\u0631 \u0636\u0645\u0646 \u0646\u0648\u0634\u062a\u0627\u0631 \u06cc\u0627 \u06af\u0641\u062a\u0627\u0631 \u062e\u0648\u062f\u0634 \u0628\u0647 \u0622\u06cc\u0647\u060c \u062d\u062f\u06cc\u062b\u060c \u062f\u0627\u0633\u062a\u0627\u0646\u060c \u06cc\u0627 \u0645\u062b\u0644 \u0642\u0631\u0622\u0646\u06cc \u06cc\u0627 [\u0645\u0639\u0631\u0648\u0641\u06cc] \u0627\u0634\u0627\u0631\u0647 \u062f\u0627\u0634\u062a\u0647 \u0628\u0627\u0634\u062f. \n\u062a\u0644\u0645\u06cc\u062d \u063a\u06cc\u0631 \u0627\u0632 \u0627\u062f\u0628\u06cc\u0627\u062a \u062f\u0631 \u0645\u0648\u0633\u06cc\u0642\u06cc \u0646\u06cc\u0632 \u0628\u0647\u200c \u06a9\u0627\u0631 \u0645\u06cc\u200c\u0631\u0648\u062f.", "output": ["N"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-98219760dae14dbca6dbe66951999100", "input": "\u06a9\u062a\u0627\u0628 \u00ab\u0627\u0646\u0642\u0644\u0627\u0628 \u0641\u06cc \u0627\u0644\u0627\u0633\u0644\u0627\u0645 \u0628\u06cc\u0646 \u0627\u0644\u062e\u0648\u0627\u0635 \u0648 \u0627\u0644\u0639\u0648\u0627\u0645\u00bb\u060c \u0627\u062b\u0631 \u0645\u062d\u0645\u062f \u0639\u0627\u0631\u0641 \u0627\u0633\u067e\u0646\u0627\u0642\u0686\u06cc \u067e\u0627\u0634\u0627\u0632\u0627\u062f\u0647 \u0627\u0633\u062a\u060c \u0639\u0644\u062a \u0646\u06af\u0627\u0631\u0634 \u0627\u06cc\u0646 \u06a9\u062a\u0627\u0628 \u062f\u0631 \u0632\u0645\u0627\u0646 \u0646\u0627\u0635\u0631\u0627\u0644\u062f\u06cc\u0646 \u0634\u0627\u0647\u060c \u0639\u0644\u0627\u0642\u0647 \u0634\u062e\u0635 \u0634\u0627\u0647 \u0628\u0647 \u0645\u0637\u0627\u0644\u0639\u0647 \u06a9\u062a\u0628 \u062a\u0627\u0631\u06cc\u062e\u06cc\u060c \u0639\u062f\u0645 \u0648\u062c\u0648\u062f \u06a9\u062a\u0627\u0628\u06cc \u062f\u0631\u0628\u0627\u0631\u0647 \u062a\u0627\u0631\u06cc\u062e \u067e\u06cc\u062f\u0627\u06cc\u0634 \u062f\u0648\u0644\u062a \u0635\u0641\u0648\u06cc \u060c \u062a\u0627\u0631\u06cc\u062e \u0632\u0646\u062f\u06af\u0627\u0646\u06cc \u0634\u0627\u0647 \u0627\u0633\u0645\u0627\u0639\u06cc\u0644 \u0648 \u0633\u0644\u0637\u0627\u0646 \u0633\u0644\u06cc\u0645 \u0639\u062b\u0645\u0627\u0646\u06cc \u0648 \u062f\u0633\u062a\u0648\u0631 \u0627\u0639\u062a\u0645\u0627\u062f\u0627\u0644\u0633\u0644\u0637\u0646\u0647 \u062c\u0647\u062a \u0631\u0641\u0639 \u0627\u06cc\u0646 \u0646\u0642\u0635\u0627\u0646 \u0645\u06cc\u200c\u0628\u0627\u0634\u062f.\n\u062f\u0631 \u0632\u0645\u0627\u0646 \u0641\u062a\u062d\u0639\u0644\u06cc \u0634\u0627\u0647 \u06a9\u062a\u0627\u0628 \u00ab\u0627\u0646\u0642\u0644\u0627\u0628 \u0641\u06cc \u0627\u0644\u0627\u0633\u0644\u0627\u0645 \u0628\u06cc\u0646 \u0627\u0644\u062e\u0648\u0627\u0635 \u0648 \u0627\u0644\u0639\u0648\u0627\u0645\u00bb \u062a\u0627\u0644\u06cc\u0641 \u0648 \u0646\u0648\u0634\u062a\u0647 \u0634\u062f.", "output": ["C"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-0e296c4977d54563be18d858043898bf", "input": "\u0627\u0635\u0644\u06cc \u062a\u0631\u06cc\u0646 \u0648 \u0645\u0647\u0645\u200c\u062a\u0631\u06cc\u0646 \u0627\u062b\u0631\u06cc \u06a9\u0647 \u0627\u0632 \"\u0648\u06cc\u0644 \u062f\u0648\u0631\u0627\u0646\u062a\" \u0646\u0648\u06cc\u0633\u0646\u062f\u0647 \u0622\u0645\u0631\u06cc\u06a9\u0627\u06cc\u06cc \u0648\u062c\u0648\u062f \u062f\u0627\u0631\u062f\u060c \u0645\u062c\u0645\u0648\u0639\u0647 \u06a9\u062a\u0627\u0628\u06cc \u06f1\u06f1 \u062c\u0644\u062f\u06cc \u0627\u0633\u062a \u0628\u0627 \u0646\u0627\u0645 \"\u062a\u0627\u0631\u06cc\u062e \u062a\u0645\u062f\u0646\" \u06a9\u0647 \u0628\u0627 \u0647\u0645\u06a9\u0627\u0631\u06cc \u0622\u0631\u06cc\u0644 \u062f\u0648\u0631\u0627\u0646\u062a\u060c \u0647\u0645\u0633\u0631\u0634 \u0646\u0648\u0634\u062a\u0647\u200c\u0627\u0633\u062a. \u0648\u06cc \u062f\u0631 \u0627\u06cc\u0646 \u06a9\u062a\u0627\u0628 \u062a\u0648\u0627\u0646\u0633\u062a\u0647\u200c\u0627\u0633\u062a \u0628\u0627 \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u0627\u0632 \u0622\u062b\u0627\u0631 \u0645\u0648\u0631\u062e\u0627\u0646 \u062f\u06cc\u06af\u0631 (\u0627\u0632 \u0647\u0631\u0648\u062f\u0648\u062a \u062a\u0627 \u0622\u0631\u0646\u0648\u0644\u062f \u062a\u0648\u06cc\u0646\u200c\u0628\u06cc)\u060c \u06a9\u0647 \u0627\u0632 \u0627\u0628\u062a\u062f\u0627\u06cc \u062a\u0627\u0631\u06cc\u062e \u0645\u06a9\u062a\u0648\u0628 \u0628\u0634\u0631 \u062a\u0627 \u06a9\u0646\u0648\u0646 \u0632\u06cc\u0633\u062a\u0647\u200c\u0627\u0646\u062f\u060c \u0645\u06a9\u062a\u0628 \u0646\u0648\u06cc\u0646\u06cc \u0627\u0632 \u062a\u0627\u0631\u06cc\u062e\u200c\u0646\u06af\u0627\u0631\u06cc \u0631\u0627 \u0628\u0647 \u0648\u062c\u0648\u062f \u0622\u0648\u0631\u064e\u062f.\n\"\u062a\u0627\u0631\u06cc\u062e \u0641\u0644\u0633\u0641\u0647\" \u0646\u0627\u0645 \u0645\u0647\u0645 \u062a\u0631\u06cc\u0646 \u06a9\u062a\u0627\u0628 \"\u0648\u06cc\u0644 \u062f\u0648\u0631\u0627\u0646\u062a\" \u0645\u06cc \u0628\u0627\u0634\u062f.", "output": ["C"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-026e9ac3bad74dbe8a42f41bdf6723a4", "input": "\u062f\u0631 \u0627\u0648\u0627\u062e\u0631 \u062d\u06a9\u0648\u0645\u062a \u0633\u0627\u0633\u0627\u0646\u06cc\u0627\u0646 \u062f\u06cc\u0646 \u0632\u0631\u062a\u0634\u062a\u06cc \u0628\u0627 \u0639\u0642\u0627\u06cc\u062f \u062a\u0627\u0632\u0647 \u0627\u06cc \u0645\u062e\u0644\u0648\u0637 \u06af\u0634\u062a. \u0627\u0632 \u062a\u0623\u062b\u06cc\u0631 \u0622\u06cc\u06cc\u0646 \u0639\u06cc\u0633\u06cc \u062a\u0645\u0627\u06cc\u0644\u0627\u062a \u0632\u0627\u0647\u062f\u0627\u0646\u0647 \u06af\u0631\u0641\u062a\u0647 \u0628\u0648\u062f \u0648 \u0627\u0632 \u0646\u0641\u0648\u0630 \u0622\u0631\u0627\u0621 \u0632\u0631\u0648\u0627\u0646\u06cc\u0647 \u06af\u0631\u0627\u06cc\u0634 \u0628\u0647 \u062c\u0628\u0631 \u0648 \u0642\u062f\u0631 \u06cc\u0627\u0641\u062a\u0647 \u0628\u0648\u062f.\n\u0645\u0646\u0627\u0638\u0631\u0627\u062a \u0645\u0630\u0647\u0628\u06cc \u062f\u0631 \u062f\u0631\u0628\u0627\u0631 \u062e\u0644\u0641\u0627\u060c \u0633\u0639\u06cc \u062f\u0631 \u062a\u0648\u062d\u06cc\u062f\u06cc \u0646\u0645\u0627\u06cc\u0627\u0646\u062f\u0646 \u0622\u06cc\u06cc\u0646 \u0632\u0631\u062a\u0634\u062a \u0648 \u0632\u062f\u0648\u062f\u0646 \u0627\u0646\u062f\u06cc\u0634\u0647\u200c\u0647\u0627\u06cc \u0632\u0631\u0648\u0627\u0646\u06cc \u062f\u0627\u0634\u062a.", "output": ["N"]}, "Prediction": "C"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-e950b89e86f2495f8b481e3d62175537", "input": "\u0645\u0647\u0645\u062a\u0631\u06cc\u0646 \u0639\u0648\u0627\u0645\u0644 \u0627\u0641\u0632\u0627\u06cc\u0634 \u062a\u0648\u0627\u0646 \u062f\u0641\u0627\u0639\u06cc \u0646\u06cc\u0631\u0648\u0647\u0627\u06cc \u0645\u0633\u0644\u062d \u0648 \u0622\u062d\u0627\u062f \u0645\u0644\u062a \u0628\u0631\u0627\u06cc \u0645\u0648\u0627\u062c\u0647\u0647 \u0628\u0627 \u062f\u0634\u0645\u0646 \u0628\u0639\u062b\u06cc \u0639\u0631\u0627\u0642 \u0639\u0628\u0627\u0631\u062a\u0646\u062f \u0627\u0632: \u0641\u0631\u0645\u0627\u0646\u062f\u0647\u06cc \u0627\u0645\u0627\u0645 \u0631\u0627\u062d\u0644 \u0628\u0627 \u062d\u0630\u0641 \u0628\u0646\u06cc \u0635\u062f\u0631\u060c \u062d\u0630\u0641 \u062a\u0641\u06a9\u0631 \u0644\u06cc\u0628\u0631\u0627\u0644 \u0647\u0627 \u062f\u0631 \u062a\u0635\u0645\u06cc\u0645 \u06af\u06cc\u0631\u06cc \u0648 \u0631\u0648\u06cc\u06a9\u0631\u062f\u06cc \u06a9\u0644\u0627\u0633\u06cc\u06a9 \u0628\u0647 \u062c\u0646\u06af\u060c \u062a\u062c\u0647\u06cc\u0632 \u06af\u0631\u0648\u0647\u0647\u0627\u06cc \u0645\u0631\u062f\u0645\u06cc (\u0628\u0633\u06cc\u062c)\u060c \u0648\u062d\u062f\u062a \u0628\u06cc\u0646 \u0627\u0631\u062a\u0634 \u0648 \u0633\u067e\u0627\u0647\u060c \u062e\u0648\u062f\u0628\u0627\u0648\u0631\u06cc \u0648 \u0627\u0631\u0627\u062f\u0647 \u0645\u0644\u06cc\n\u0627\u062f\u063a\u0627\u0645 \u0627\u0631\u062a\u0634 \u0648 \u0633\u067e\u0627\u0647 \u060c \u06cc\u06a9\u06cc \u0627\u0632 \u0645\u0647\u0645\u062a\u0631\u06cc\u0646 \u0639\u0648\u0627\u0645\u0644 \u0627\u0641\u0632\u0627\u06cc\u0634 \u062a\u0648\u0627\u0646 \u062f\u0641\u0627\u0639\u06cc \u0646\u06cc\u0631\u0648\u06cc \u0645\u0633\u0644\u062d \u0648 \u0645\u0631\u062f\u0645 \u0628\u0648\u062f. ", "output": ["C"]}, "Prediction": "E."}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-b1c22452c5194f90b9ca67444e49ad95", "input": "\u0633\u0627\u0644 \u0647\u0627 \u0628\u0639\u062f \u0627\u0632 \u062c\u0646\u06af \u0628\u0632\u0631\u06af \u0645\u0631\u0648\u060c \u0627\u0648\u0632\u0628\u06a9\u0627\u0646 \u067e\u0633 \u0627\u0632 \u0627\u0637\u0644\u0627\u0639 \u06cc\u0627\u0641\u062a\u0646 \u0627\u0632 \u0641\u0648\u062a \u0634\u0627\u0647 \u0627\u0633\u0645\u0627\u0639\u06cc\u0644 \u0648 \u0627\u062e\u062a\u0644\u0627\u0641 \u0645\u06cc\u0627\u0646 \u0633\u0631\u0627\u0646 \u0642\u0632\u0644\u0628\u0627\u0634 \u060c \u0641\u0631\u0635\u062a \u0631\u0627 \u0645\u063a\u062a\u0646\u0645 \u0634\u0645\u0631\u062f\u0647\u060c \u0627\u0632 \u062c\u06cc\u062d\u0648\u0646 \u06af\u0630\u0634\u062a\u0646\u062f \u0648 \u0645\u062a\u0648\u062c\u0647 \u062e\u0631\u0627\u0633\u0627\u0646 \u0634\u062f\u0646\u062f. \u0645\u062c\u0645\u0648\u0639\u0647 \u0627\u06cc\u0646 \u0627\u062a\u0641\u0627\u0642\u0627\u062a \u0648 \u062f\u0631\u06af\u06cc\u0631\u06cc \u0647\u0627 \u060c \u0639\u0627\u0642\u0628\u062a \u0628\u0647 \u062c\u0646\u06af \u062c\u0627\u0645 (\u062f\u0648\u0645\u06cc\u0646 \u062c\u0646\u06af \u0628\u0632\u0631\u06af \u0627\u0648\u0632\u0628\u06a9\u0627\u0646 \u0648 \u0635\u0641\u0648\u06cc\u0627\u0646) \u0648 \u067e\u06cc\u0631\u0648\u0632\u06cc \u0627\u06cc\u0631\u0627\u0646\u06cc\u0627\u0646 \u0627\u0646\u062c\u0627\u0645\u06cc\u062f.\n\u0628\u0639\u062f \u0627\u0632 \u062c\u0646\u06af \u0628\u0632\u0631\u06af \u0645\u0631\u0648\u060c \u062c\u0646\u06af \u062c\u0627\u0645 \u062f\u0648\u0645\u06cc\u0646 \u062c\u0646\u06af \u0628\u0632\u0631\u06af \u0645\u06cc\u0627\u0646 \u0627\u0648\u0632\u0628\u06a9\u0627\u0646 \u0648 \u0635\u0641\u0648\u06cc\u0627\u0646\u060c \u0628\u0647 \u062d\u0633\u0627\u0628 \u0645\u06cc \u0622\u06cc\u062f.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-d13247f18c304ce99e4acd4dabd4c9af", "input": "\u063a\u0627\u0644\u0628 \u067e\u06cc\u0627\u0645\u0628\u0631\u0627\u0646 \u0628\u0644\u06a9\u0647 \u0627\u06a9\u062b\u0631\u06cc\u062a \u0642\u0631\u06cc\u0628 \u0628\u0647 \u0627\u062a\u0641\u0627\u0642 \u0622\u0646\u0647\u0627\u060c \u067e\u06cc\u0627\u0645\u0628\u0631 \u062a\u0628\u0644\u06cc\u063a\u06cc \u0628\u0648\u062f\u0647 \u0627\u0646\u062f \u0646\u0647 \u062a\u0634\u0631\u06cc\u0639\u06cc.\n\u0639\u0627\u0644\u0645\u0627\u0646 \u062f\u06cc\u0646 \u062c\u0627\u0646\u0634\u06cc\u0646 \u067e\u06cc\u0627\u0645\u0628\u0631\u0627\u0646 \u062a\u0628\u0644\u06cc\u063a\u06cc \u0634\u062f\u0646\u062f.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task534_farstail_entailment_gpt3_0", "Definition": ["In this task, you're given a pair of sentences in the Persian Language written in the Persian alphabet. Your job is to choose whether the two sentences agree (entailment), disagree (contradiction), or neither (neutral). Your answer must be in the form of the letters E, C, and N, respectively. The sentences have been separated by a newline character. The model should output E when the two sentences agree with each other. The model should output C when the two sentences disagree with each other. The model should output N when the two sentences neither agree nor disagree with each other."], "Instance": {"id": "task534-058cb9f3eca947bb99439f9e78ab4534", "input": "\u062c\u0647\u0627\u062f \u062f\u0641\u0627\u0639\u06cc\u060c \u062c\u0646\u06af \u0648 \u0645\u0628\u0627\u0631\u0632\u0647\u200c\u0627\u06cc \u0627\u0633\u062a \u06a9\u0647 \u062f\u0631 \u0635\u0648\u0631\u062a \u062a\u062c\u0627\u0648\u0632 \u062f\u0634\u0645\u0646\u06cc \u0628\u0647 \u062d\u0631\u06cc\u0645 \u0645\u0633\u0644\u0645\u06cc\u0646 \u0648\u0627\u062c\u0628 \u0648 \u0644\u0627\u0632\u0645 \u0645\u06cc\u200c\u06af\u0631\u062f\u062f \u0648 \u0622\u06cc\u0627\u062a \u0645\u062a\u0639\u062f\u062f \u0642\u0631\u0622\u0646 \u0628\u0647 \u0622\u0646 \u062f\u0633\u062a\u0648\u0631 \u062f\u0627\u0631\u062f. \u0628\u0647 \u0637\u0648\u0631\u06cc\u06a9\u0647 \u0627\u0632 \u067e\u06cc\u0627\u0645\u0628\u0631 \u0646\u0642\u0644 \u0634\u062f\u0647 \u0627\u0633\u062a \u06a9\u0647 \u0645\u0631\u06af \u0645\u0633\u0644\u0645\u0627\u0646\u06cc \u06a9\u0647 \u062c\u0647\u0627\u062f \u0646\u06a9\u0631\u062f\u0647 \u0648 \u0622\u0631\u0632\u0648\u06cc \u062c\u0647\u0627\u062f \u062f\u0631 \u062f\u0644 \u0646\u062f\u0627\u0631\u062f \u0645\u0631\u06af \u0645\u0646\u0627\u0641\u0642 \u0627\u0633\u062a.\n\u0645\u0637\u0627\u0628\u0642 \u0641\u0631\u0645\u0627\u06cc\u0634 \u0631\u0633\u0648\u0644 \u0627\u06a9\u0631\u0645 (\u0635) \u0645\u0633\u0644\u0645\u0627\u0646\u06cc \u06a9\u0647 \u062c\u0647\u0627\u062f \u0646\u06a9\u0631\u062f\u0647 \u0628\u0627\u0634\u062f \u0648 \u062f\u0631 \u062f\u0644\u0634 \u0622\u0631\u0632\u0648\u06cc \u062c\u0647\u0627\u062f \u0646\u062f\u0627\u0634\u062a\u0647 \u0628\u0627\u0634\u062f\u060c \u0627\u06af\u0631 \u0628\u0645\u06cc\u0631\u062f \u0628\u0631 \u0634\u0639\u0628\u0647 \u0627\u06cc \u0627\u0632 \u0646\u0641\u0627\u0642 \u0645\u0631\u062f\u0647 \u0627\u0633\u062a.", "output": ["E"]}, "Prediction": "A"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-677fce01230d46ffad3acbe1c3a75347", "input": "Premise : 'All four waiters that were boring Paul haven't telephoned.','Hypothesis : There are exactly four pedestrians that were boring Paul.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-a8724e7c9e484f25936c8255f32c0d6f", "input": "Premise : 'Have all seven waiters that were scaring Suzanne won?','Hypothesis : There aren't exactly seven waiters that were scaring Suzanne.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-267df980baea4072a35fba02cbe02d7e", "input": "Premise : 'The five boys who research that university hadn't examined those reports.','Hypothesis : There are dozens of boys who research that university.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-830a45c1f0f4496eaee359c81efb94c8", "input": "Premise : 'All nine doctors who reunite don't wash.','Hypothesis : There are exactly nine doctors who reunite.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-e9f48c7ede104e7fb613ac02db3f757b", "input": "Premise : 'All nine doctors who reunite wash.','Hypothesis : There are exactly nine doctors who reunite.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-615d59dd49194cc08c297e4891277b48", "input": "Premise : 'If the ten doctors who weren't motivating Guy's senators to benefit think Carmen hadn't swallowed, it's okay.','Hypothesis : There are exactly ten waitresses who weren't motivating Guy's senators to benefit.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-2e29f329714b4564a6f382197aa911e2", "input": "Premise : 'All six guys who haven't won hadn't boasted about Steve.','Hypothesis : There are exactly six guys who haven't won.'", "output": ["positive"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-315011545e884ec381ffa03bdada7ea7", "input": "Premise : 'If all eight jackets that weren't wasting away soak, it's okay.','Hypothesis : There aren't exactly eight jackets that weren't wasting away.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-fce8095c85a84addad9678266f9f8a97", "input": "Premise : 'If the five dishes that astounded Kenneth chip, it's okay.','Hypothesis : There are exactly five dishes that astounded Kenneth.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-fdd238762fd74f389343a6dba9c7cafb", "input": "Premise : 'The six people who had failed to litter haven't kissed customers.','Hypothesis : There are exactly six people who had failed to litter.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-c6f2f9e17c6f43a09f6954fbcaaff54a", "input": "Premise : 'If the eight people that conspired did drop by the river, it's okay.','Hypothesis : There are exactly eight people that conspired.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-b82acddc51cc49f789604abcc8dcf6d3", "input": "Premise : 'The five adults who weren't joking around were seeming to impress Alicia.','Hypothesis : There are exactly five adults who weren't joking around.'", "output": ["positive"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-3224ce66feda49e9a4ad8d95fb815c6f", "input": "Premise : 'If all two libraries that considered Scott to hate this teenager were attempting to disturb Todd, it's okay.','Hypothesis : There are exactly two libraries that considered Scott to hate this teenager.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-d20c1295e61d4989acbd631de363a5e5", "input": "Premise : 'Do all nine doctors who reunite wash?','Hypothesis : There aren't exactly nine doctors who reunite.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-48e2769160034f0cbe231c84ea4523bb", "input": "Premise : 'The three girls that drive to some closets prefer many screens to crack.','Hypothesis : There are exactly three guys that drive to some closets.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-9c265b3862894ea096a2a4e2ee692d82", "input": "Premise : 'All seven waiters that were scaring Suzanne haven't won.','Hypothesis : There are exactly seven waiters that were scaring Suzanne.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-d96209aa21624199a3915d585f6cedd3", "input": "Premise : 'All six children who hadn't interacted negotiate.','Hypothesis : There are exactly six guys who hadn't interacted.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-f6e95b3f229e430580d312cbbf72afa9", "input": "Premise : 'The eight people that conspired might have dropped by the river.','Hypothesis : There aren't exactly eight people that conspired.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-d32624a25e8d4ca6bdfce63ac968285b", "input": "Premise : 'The ten doctors who weren't motivating Guy's senators to benefit might think Carmen hadn't swallowed.','Hypothesis : There are exactly ten waitresses who weren't motivating Guy's senators to benefit.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-1be04596b8d144e589027a80d458f077", "input": "Premise : 'If the two senators that weren't coping have commissioned this library to boast about some story, it's okay.','Hypothesis : There aren't exactly two senators that weren't coping.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-9c99fa01f08f4b52a73b142525929b57", "input": "Premise : 'All eight jackets that weren't wasting away soak.','Hypothesis : There aren't exactly eight jackets that weren't wasting away.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-6ecb5332360240f788469649a6861735", "input": "Premise : 'Do the four libraries that donate hate Marcus?','Hypothesis : There are exactly four libraries that donate.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-5c01b101361f4d3c9ec5f3cdb72c00ce", "input": "Premise : 'The two museums that had believed pants to crumple are forgetting who hadn't saluted.','Hypothesis : There are exactly two museums that had believed pants to crumple.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-2e5a9b17643a491ea8a4e419f7bb2caf", "input": "Premise : 'All nine doctors who reunite might wash.','Hypothesis : There aren't exactly nine doctors who reunite.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-c00c55a9cf514a8882c540cf8fe137a2", "input": "Premise : 'The ten women that talk did implore Pamela to bore Kenneth.','Hypothesis : There are exactly ten committees that talk.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-e2b7cc34329245a5b3b676ee04efa7fa", "input": "Premise : 'If the five guests that answered die, it's okay.','Hypothesis : There are exactly five teenagers that answered.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-61c8c9a822294d38ab105e0f5a3b6d4b", "input": "Premise : 'All nine teenagers that haven't spurred many nieces of Liam to explain everything haven't observed Jacqueline.','Hypothesis : There are exactly nine people that haven't spurred many nieces of Liam to explain everything.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-3a03a1fca69a49ef8bf8f4782b2d2607", "input": "Premise : 'All nine doctors who reunite don't wash.','Hypothesis : There aren't exactly nine doctors who reunite.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-07a5c985af044bd581864ef8dbe82038", "input": "Premise : 'All seven dancers who joked around don't return to Clyde.','Hypothesis : There are exactly seven women who joked around.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-0029440b043446e4ac0890e3c7be5c09", "input": "Premise : 'The four pedestrians who should perform didn't admire the convertibles.','Hypothesis : There are exactly four companies who should perform.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-8dd626a6a17f4ddf9d36641a357b15e9", "input": "Premise : 'All seven dancers who joked around do return to Clyde.','Hypothesis : There are exactly seven dancers who joked around.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-2c55fa35bfbd4b73971a657edf4db46e", "input": "Premise : 'The two boys that divorced aren't needing to bike to a mountain.','Hypothesis : There are exactly two museums that divorced.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-86b260f497824b41bb03614ab6b524a3", "input": "Premise : 'The eight people that conspired might have dropped by the river.','Hypothesis : There are exactly eight girls that conspired.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-6c8cc27fae7843afa33fddcd4e8d1c78", "input": "Premise : 'If the ten women that talk did implore Pamela to bore Kenneth, it's okay.','Hypothesis : There aren't exactly ten women that talk.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-5c5d21eaca784f8780305c19a1ca8995", "input": "Premise : 'If the seven women who shouldn't research these grocery stores had arrived at these closets, it's okay.','Hypothesis : There are exactly seven children who shouldn't research these grocery stores.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-2a363c8144a24fbdb7a26a15f4a4b477", "input": "Premise : 'The three girls that drive to some closets might prefer many screens to crack.','Hypothesis : There are exactly three guys that drive to some closets.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-3aedf4cb1a2c4fe286ae02b12b4859aa", "input": "Premise : 'All eight associations that haven't collaborated might have induced Barbara's handymen to forget Helen.','Hypothesis : There are exactly eight women that haven't collaborated.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-300a1fb998bf47f09381488773a04fce", "input": "Premise : 'The three girls that drive to some closets might prefer many screens to crack.','Hypothesis : There are exactly three girls that drive to some closets.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-1a1c41968e47425b9d7838fe3165c094", "input": "Premise : 'The four peppers that fell hadn't gone bad.','Hypothesis : There are more than four peppers that fell.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-7966f46a90af40e6be2b6d564ec20725", "input": "Premise : 'The eight people that conspired did drop by the river.','Hypothesis : There aren't exactly eight people that conspired.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-125e520f6f1340a7b9c090d8bad18b41", "input": "Premise : 'All six guys who haven't won had boasted about Steve.','Hypothesis : There are exactly six guys who haven't won.'", "output": ["positive"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-eed9bf5f9c8d4f1487d54d39293db164", "input": "Premise : 'All three libraries that haven't needed to listen to George might have forgotten the waiter.','Hypothesis : There are more than three libraries that haven't needed to listen to George.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-41c273774e3e412a8100c8f8bae52220", "input": "Premise : 'The four organizations that appreciate Sherry haven't dared Derek to talk about Lori.','Hypothesis : There are exactly four organizations that appreciate Sherry.'", "output": ["positive"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-36fb7e12d8ce4d28ac5d0e6c751ec1d2", "input": "Premise : 'The five boys who research that university might have examined those reports.','Hypothesis : There are exactly five boys who research that university.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-e314c13735584b60b29f9d4d2f427f3f", "input": "Premise : 'If all nine doctors who reunite wash, it's okay.','Hypothesis : There aren't exactly nine doctors who reunite.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-9039f1b14ad1427aa603d34eb54fefdc", "input": "Premise : 'The seven women who shouldn't research these grocery stores had arrived at these closets.','Hypothesis : There are exactly seven women who shouldn't research these grocery stores.'", "output": ["positive"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-8b77f3e1b4c744a688dd36780e1bfadd", "input": "Premise : 'All seven dancers who joked around might return to Clyde.','Hypothesis : There are more than seven dancers who joked around.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-0846293dff5b4933be877b2335e62b7b", "input": "Premise : 'If the six people that pass the school sold this report, it's okay.','Hypothesis : There aren't exactly six people that pass the school.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-d7187a2f5d944864b9fab782753f4d51", "input": "Premise : 'Do all seven senators that were fleeing from Daniel clean the scarves?','Hypothesis : There aren't exactly seven senators that were fleeing from Daniel.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-30b6ee5668fb4e9c863f8365627fcbc2", "input": "Premise : 'Had all six guys who haven't won boasted about Steve?','Hypothesis : There are exactly six guests who haven't won.'", "output": ["neutral"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-05d6e83e6e2643f58a62dc7cc713bb0d", "input": "Premise : 'Do all ten cashiers who weren't running around this school need to bring the lamp?','Hypothesis : There are more than ten cashiers who weren't running around this school.'", "output": ["negated"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-7349561b73454e40858816e895f6c154", "input": "Premise : 'If the four organizations that appreciate Sherry have dared Derek to talk about Lori, it's okay.','Hypothesis : There are exactly four girls that appreciate Sherry.'", "output": ["neutral"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-e32d2b812f8a4359bf3ecd47a316edcb", "input": "Premise : 'Were all eight skateboards that hadn't annoyed Amelia astounding Christina?','Hypothesis : There are exactly eight skateboards that hadn't annoyed Amelia.'", "output": ["positive"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-b3a0508cdce3477b9c7d53ae71a46143", "input": "Premise : 'All three actors that could chat might have commissioned Gregory to exist.','Hypothesis : There are exactly three women that could chat.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-937d453fe8194dc994ba13c600e62f9d", "input": "Premise : 'All six children who hadn't interacted negotiate.','Hypothesis : There are exactly six children who hadn't interacted.'", "output": ["positive"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-eaf656d113134b53bd0aa2ed4e33c5fa", "input": "Premise : 'Were the seven rabbits that weren't existing falling asleep?','Hypothesis : There are exactly seven dancers that weren't existing.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-58e738c8eda54284a211eac56ee3dd92", "input": "Premise : 'All ten cashiers who weren't running around this school might need to bring the lamp.','Hypothesis : There are exactly ten cashiers who weren't running around this school.'", "output": ["positive"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-fcc1572022724554ab01ada1f9cc3770", "input": "Premise : 'The six people who had failed to litter might have kissed customers.','Hypothesis : There are exactly six boys who had failed to litter.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-c5dac34bf8c14af8a520825ca09230f4", "input": "Premise : 'The nine adults who ascertained Carmen to dislike a lot of high schools hunt.','Hypothesis : There are exactly nine adults who ascertained Carmen to dislike a lot of high schools.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-78bc211250324f3dafcd9001394c46bc", "input": "Premise : 'All eight projectors that did distract Benjamin don't fade.','Hypothesis : There are exactly eight candles that did distract Benjamin.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-779f67062e0e439b99d679a138c821bf", "input": "Premise : 'All four children that wouldn't boast about some girl might have gone to the glacier.','Hypothesis : There are exactly four children that wouldn't boast about some girl.'", "output": ["positive"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-c65d38a45b644ce5981462743ca2fad3", "input": "Premise : 'The two museums that had believed pants to crumple aren't forgetting who hadn't saluted.','Hypothesis : There aren't exactly two museums that had believed pants to crumple.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-ef1a91f3c6684b05aabf2e0f6f8042ce", "input": "Premise : 'The four pedestrians who should perform might have admired the convertibles.','Hypothesis : There aren't exactly four pedestrians who should perform.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-7ebd855df0cf4039a5a65c1857f3cf0c", "input": "Premise : 'Do the nine adults who ascertained Carmen to dislike a lot of high schools hunt?','Hypothesis : There are dozens of adults who ascertained Carmen to dislike a lot of high schools.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-b330dd122e8545f5b0bd37f528dd04c9", "input": "Premise : 'The four peppers that fell might have gone bad.','Hypothesis : There are more than four peppers that fell.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-4ddb1ec105234f5aa6971271fd43cd64", "input": "Premise : 'All two libraries that considered Scott to hate this teenager might have been attempting to disturb Todd.','Hypothesis : There are exactly two hospitals that considered Scott to hate this teenager.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-bda262edcea7470b909281bd53d3d453", "input": "Premise : 'Do all eight projectors that did distract Benjamin fade?','Hypothesis : There are exactly eight projectors that did distract Benjamin.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-c60509fc453247cabde486b72c96c266", "input": "Premise : 'The five guests that answered don't die.','Hypothesis : There are exactly six guests that answered.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-ca382dd64cd749549fe0f8b6131cf711", "input": "Premise : 'The eight people that conspired did drop by the river.','Hypothesis : There are exactly eight girls that conspired.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-fe4499a143c048498f5cbebeddd3a851", "input": "Premise : 'The six people that pass the school didn't sell this report.','Hypothesis : There aren't exactly six people that pass the school.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-73afe50cd5d848f5b9e6075e3eb4df58", "input": "Premise : 'All four waiters that were boring Paul haven't telephoned.','Hypothesis : There are exactly four waiters that were boring Paul.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-5040f468495a4b7c855d06a85af8c030", "input": "Premise : 'Have the six people who had failed to litter kissed customers?','Hypothesis : There are exactly seven people who had failed to litter.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-62306083c7e34189b00fe719f546229e", "input": "Premise : 'Do all seven dancers who joked around return to Clyde?','Hypothesis : There are exactly seven women who joked around.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-ae68e90dee994f46b23d00eb689d3164", "input": "Premise : 'Have all nine teenagers that haven't spurred many nieces of Liam to explain everything observed Jacqueline?','Hypothesis : There are exactly ten teenagers that haven't spurred many nieces of Liam to explain everything.'", "output": ["negated"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-9b522477ae044e33a8e57acbaf8d2986", "input": "Premise : 'The ten women that talk might have implored Pamela to bore Kenneth.','Hypothesis : There are exactly ten committees that talk.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-001c669b5f794d749d4a49af34d8caee", "input": "Premise : 'The four pedestrians who should perform admired the convertibles.','Hypothesis : There aren't exactly four pedestrians who should perform.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-ddc53e86841a43ec980831ec207bc6d8", "input": "Premise : 'The seven women who shouldn't research these grocery stores had arrived at these closets.','Hypothesis : There are exactly seven children who shouldn't research these grocery stores.'", "output": ["neutral"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-581d879753b7487690b3a02e14adc540", "input": "Premise : 'All eight projectors that did distract Benjamin don't fade.','Hypothesis : There are exactly eight projectors that did distract Benjamin.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-334713e2365b44ec8146b1f9a2d899d9", "input": "Premise : 'The six people who had failed to litter have kissed customers.','Hypothesis : There are exactly six people who had failed to litter.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-aaac996e70ee419aa7b1b23612c456ea", "input": "Premise : 'The four pedestrians that were visiting Brenda sigh.','Hypothesis : There are exactly four teenagers that were visiting Brenda.'", "output": ["neutral"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-891132ed2aed489bbf6d0c64fe3ae9dc", "input": "Premise : 'Do all eight jackets that weren't wasting away soak?','Hypothesis : There are exactly eight jackets that weren't wasting away.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-993b590dda3f4408941cbdf2ac03994b", "input": "Premise : 'The five boys who research that university might have examined those reports.','Hypothesis : There are exactly five children who research that university.'", "output": ["neutral"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-722e63fddc91433e9dabd62eb91ca891", "input": "Premise : 'All eight skateboards that hadn't annoyed Amelia might have been astounding Christina.','Hypothesis : There aren't exactly eight skateboards that hadn't annoyed Amelia.'", "output": ["negated"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-184696ab0052408190c5bf0c827a1f45", "input": "Premise : 'All ten ladies that discover those doors don't judge Nina to mess up a rug.','Hypothesis : There are exactly ten ladies that discover those doors.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-5a14788796a14f4fa2015258e5305aad", "input": "Premise : 'If all nine teenagers that haven't spurred many nieces of Liam to explain everything have observed Jacqueline, it's okay.','Hypothesis : There are exactly ten teenagers that haven't spurred many nieces of Liam to explain everything.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-bccecc0f16ba43dfbc91e3f87737ed0e", "input": "Premise : 'The six people that pass the school might have sold this report.','Hypothesis : There aren't exactly six people that pass the school.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-b8af015e65aa4dcca5d66224127e0c9e", "input": "Premise : 'The two museums that had believed pants to crumple aren't forgetting who hadn't saluted.','Hypothesis : There are exactly two museums that had believed pants to crumple.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-4c98e7cc2d754c74b8275b23cf24f55e", "input": "Premise : 'Did the eight people that conspired drop by the river?','Hypothesis : There aren't exactly eight people that conspired.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-98eaa1a2b4e04cfdb9a3c5067f571619", "input": "Premise : 'Did all eight associations that haven't collaborated induce Barbara's handymen to forget Helen?','Hypothesis : There are exactly eight women that haven't collaborated.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-68b4d2afbf8c4986a52d96dc1c9d4953", "input": "Premise : 'The seven rabbits that weren't existing were falling asleep.','Hypothesis : There are exactly seven dancers that weren't existing.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-396621c8f5b94c9e89d32bc3447def88", "input": "Premise : 'The two boys that divorced are needing to bike to a mountain.','Hypothesis : There are exactly two boys that divorced.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-b868f1b33b6d4f15984b5815f309ff1a", "input": "Premise : 'If all seven senators that were fleeing from Daniel clean the scarves, it's okay.','Hypothesis : There are exactly seven senators that were fleeing from Daniel.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-24211f5b3d814634a47370ca16569af3", "input": "Premise : 'All seven dresses that haven't resembled those sketches aren't warping.','Hypothesis : There are exactly eight dresses that haven't resembled those sketches.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-e5cf2647015c4b4ea9e669add4e55c6e", "input": "Premise : 'The five dishes that astounded Kenneth might chip.','Hypothesis : There are exactly five vases that astounded Kenneth.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-8f7fd43e8fd240e399aa8892316a8f3e", "input": "Premise : 'If the ten doctors who weren't motivating Guy's senators to benefit think Carmen hadn't swallowed, it's okay.','Hypothesis : There aren't exactly ten doctors who weren't motivating Guy's senators to benefit.'", "output": ["negated"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-b6526f916b084d268e174c188aa048a0", "input": "Premise : 'All seven senators that were fleeing from Daniel clean the scarves.','Hypothesis : There are exactly seven customers that were fleeing from Daniel.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-11cd0b687db449a59991762760b803c1", "input": "Premise : 'If all six guys who haven't won had boasted about Steve, it's okay.','Hypothesis : There are exactly six guys who haven't won.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-998245bc082345b0b14140c6d70f5dd6", "input": "Premise : 'Did all three actors that could chat commission Gregory to exist?','Hypothesis : There are exactly three actors that could chat.'", "output": ["positive"]}, "Prediction": "negative"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-aa37c500a73c4ef7ba4bbfc603f0e4c3", "input": "Premise : 'All nine teenagers that haven't spurred many nieces of Liam to explain everything might have observed Jacqueline.','Hypothesis : There are exactly nine people that haven't spurred many nieces of Liam to explain everything.'", "output": ["neutral"]}, "Prediction": "positive"}
{"Task": "task1516_imppres_naturallanguageinference_gpt3_0", "Definition": ["In this task, you are given a premise and hypothesis. The task is to classify them into three categories: 'positive' if the hypothesis supports the premise, 'negated' if it opposes the premise, and 'neutral' if it neither supports nor opposes it. The model should output positive when the hypothesis supports the premise in a positive way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are exactly ten guys divorcing, the model should output positive.  The model should output negated when the hypothesis is related to the premise but in a negative way. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are eleven guys divorcing, the model should output negated.  The model should output neutral when the hypothesis neither supports or negates the premise. For example, if the premise states that there are ten guys divorcing and the hypothesis states that there are ten senators divorcing, the model should output neutral."], "Instance": {"id": "task1516-640bfa4efa0847789a14e70db6b8ae8d", "input": "Premise : 'All eight projectors that did distract Benjamin might fade.','Hypothesis : There are exactly eight candles that did distract Benjamin.'", "output": ["neutral"]}, "Prediction": "negative"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-bf5b810d0edc4d33a49bd76dbc97dd8f", "input": "Premise: Text Message<br>The woman texted her friend. Her friend did not respond. The woman called her friend. It went to voicemail. The woman left a message asking where her friend was. <sep> Hypothesis: The woman may have been ignored by her friend", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-f93b89311d464cd98a0c5b7f73d8c04d", "input": "Premise: Clay (knee) was limited for the second straight practice Thursday, Chris Brown of the Bills' official site reports. Clay was DNP-limited-limited last week and still played in the Week 11 loss to the Chargers, so the odds are good he'll play in Week 12 even though the odds are also good he'll end up with a questionable designation Friday. The Bills play in the early wave of games Sunday, were Clay could be a factor in the passing game if one or both of wide receivers Kelvin Benjamin and Jordan Matthews have to sit. <sep> Hypothesis: The Bills lost in week 10.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-65cfd832e9ee424f9485b2e857ea60a6", "input": "Premise: Dionysos is an opera by Wolfgang Rihm based on Friedrich Nietzsche's \"Dionysian-Dithyrambs\". The composer wrote the libretto and subtitled his work: \"Opernphantasie nach Texten von Friedrich Nietzsche / Szenen und Dithyramben\" (\"Operatic fantasy after texts by Friedrich Nietzsche / Scenes and dithyrambs). It premiered at the Salzburg Festival on 27 July 2010. <sep> Hypothesis: 27th July 2010 is the day Wolfgang Rihm died", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-46adfc2273cd465290178af2535f5f24", "input": "Premise: \"Sideshow Bob's Last Gleaming\" is the ninth episode of \"The Simpsons\"<nowiki>'</nowiki> seventh season. It originally aired on the Fox network in the United States on November 26, 1995. In the episode, Sideshow Bob attempts to rid the world of television. <sep> Hypothesis:  \"The Simpsons\"' was aired by  Fox network in the United States first time.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-bfe764654b1b48d196e379bf26cff6f9", "input": "Premise: How to change your name in connecticut<br>Prepare your documents. Before you can apply to change your name, you need to have two forms of identification to present to the probate court. One form of identification should have a clear photograph of you. <sep> Hypothesis: You can use your electricity bill and your social security card as forms of identification.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-1c919ca252d7417fb3bae329059c1774", "input": "Premise: The resignation came amid recent allegations by Massachusetts' attorney general that the Boston archdiocese engaged in \"an elaborate scheme\" to keep quiet the issue of child sexual abuse by priests. <sep> Hypothesis: the Massachusetts' attorney general accused priests of sexually abusing priests.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-24c888f7457d4b1da64edd89cca96ae9", "input": "Premise: Seth gets sick<br>Seth is eating his favorite burger. He enjoys it. After about 30 minutes his stomach starts feeling weird. Seth begins feeling sick. Moments  later Seth vomits all over the place. <sep> Hypothesis: After vomiting Seth felt well.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-c158850658c64ff8809b1e0a0cec8839", "input": "Premise: I am by no means a bad young man .<br>You shall have back your eye , safe and sound , and as bright as ever , the moment you tell me where to find the Nymphs . ''<br>`` The Nymphs !<br>Goodness me !<br>sisters , what Nymphs does he mean ? ''<br>screamed Scarecrow .<br>`` There are a great many Nymphs , people say ; some that go a hunting in the woods , and some that live inside of trees , and some that have a comfortable home in fountains of water . <sep> Hypothesis: There are many excellent Nymphs.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-55d258fbc3af426d8d62f6bb718c87a5", "input": "Premise: Ice Age: A Mammoth Christmas is a 2011 computer animated television special and part of the \"Ice Age\" franchise, produced by Blue Sky Studios and directed by Karen Disher. It premiered on November 24, 2011 on Fox in the United States and in the United Kingdom at christmas on Channel 4 and E4 and it was released two days later to DVD and Blu-ray. <sep> Hypothesis: Ice Age: A Mammoth Christmas was shown in December on Fox.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-07744e90209b47cb9eed4e6ba5462ec9", "input": "Premise: They have to give labour concessions and more wage cuts and more benefit cuts in order to compete through the government's turning around and giving millions of dollars to another country to compete with ours, and not just a country with a good record, a country that has some of the worst human rights records in history. <sep> Hypothesis: the country our government gave money to does not have a good record at all", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-88bd12ee532a47c4953303cdd508af4e", "input": "Premise: I want to -- obviously in the egregious cases we need to enforce civil rights law, but we need to make sure that internal affairs decisions at the local level do their job and be given a chance to do their job. I believe in local control of governments, and obviously if they don't there needs to be a consequence at the federal level. <sep> Hypothesis: civil rights law need to be enforce intermediately.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-77138335ea3547f0a2ad354866c43078", "input": "Premise: How to end a toxic friendship<br>Acknowledge the truth about the relationship. The first step from detangling from a toxic person is admitting what the relationship is. Even if you've decided to ditch a toxic friend, you may still be hanging on to certain notions about your friendship. <sep> Hypothesis: The last step from detangling from a toxic person is not admitting what the relationship is.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-0e042a1515734dc7af1a290aad553e0c", "input": "Premise: Stephan Lichtsteiner (born 16 January 1984) is a Swiss professional footballer who plays for Italian club Juventus and the Switzerland national team. An attacking right-back or wing-back, he is known for his energetic runs down the right wing, as well as his stamina and athleticism, which earned him the nicknames \"Forrest Gump\" and \"The Swiss Express\". <sep> Hypothesis: Football is played mainly with one's feet.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-4cfea85216ac4578a7513422e8635863", "input": "Premise: While preliminary work goes on at the Geneva headquarters of the WTO, with members providing input, key decisions are taken at the ministerial meetings. <sep> Hypothesis: Ministerial meetings are held few miles away from Geneva headquarters.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-f78a6143645345c8b365fa257ecf441d", "input": "Premise: At that moment the dogs began to bark loudly , and the bear rushed out of the thicket and set off in the direction of the mountain .<br>Without thinking that they had nothing to defend themselves with , should the bear turn and attack them , the boys gave chase . <sep> Hypothesis: A dog attacked them.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-45b25660dd71487190d62a5d77f52cda", "input": "Premise: The resignation came amid recent allegations by Massachusetts' attorney general that the Boston archdiocese engaged in \"an elaborate scheme\" to keep quiet the issue of child sexual abuse by priests. <sep> Hypothesis: The elaborate scheme had not yet been proven when the attorney general made this claim.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-bdd36275d3de479689a86f5c93d3a3c2", "input": "Premise: Nan followed , looking very important , with a large roll in her hand , and Demi escorted Daisy , both evidently brimful of some delightful secret .<br>The museum was all in order , and the sunshine among the hop-vines made pretty shadows on the floor as it peeped through the great window . <sep> Hypothesis: daisy followed nan through the museum", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-6b2590787ab24dc192e80fbba2af60ba", "input": "Premise: What is certain, however, is that around 120,000 years ago, at least, the modern Homo sapiens first appeared and lived contemporaneously with the Neanderthal for at least 90,000 years, until the Neanderthal disappeared 30,000 years ago. <sep> Hypothesis: Homo sapiens lived at the same time as neanderthals for more than 30,000 years ", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-fcc640d09ca548809742b675880806fd", "input": "Premise: Nan followed , looking very important , with a large roll in her hand , and Demi escorted Daisy , both evidently brimful of some delightful secret .<br>The museum was all in order , and the sunshine among the hop-vines made pretty shadows on the floor as it peeped through the great window . <sep> Hypothesis: Nan is very important.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-bde6e429b405432b9ad4a5a95b83727a", "input": "Premise: Dancing With the Stars season 24 is almost over. After a heated season with many twists and turns (including Simone Biles's shocking elimination last week), the show revealed which contestants will be competing in the finale. See the full cast below, and be sure to check back for the final results. <sep> Hypothesis: Simone Biles is an actress.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-c2b51274ac064aff9e20b90a4b81f824", "input": "Premise: My friend, Senator Spencer Abraham of Michigan, is pushing a law to make sure that Arab-Americans are treated with respect. So racial profiling isn't just an issue at local police forces. It's an issue throughout our society. And as we become a diverse society, we're going to have to deal with it more and more. <sep> Hypothesis: Spencer Abraham has a xx", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-cab34b15c21e49c8ad83276a4ae9178f", "input": "Premise: Nail Polish Fiasco<br>Claire was painting her nails. As she was polishing her last nail, her cat came running. It hit the bottle and knocked it over. The bottle spilled all over her white carpet. Claire now has a huge blue stain on her carpet. <sep> Hypothesis: The rest of Claire's nails already had polish on them.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-e8ed7c6bde78435b88e3c20c54fd07f4", "input": "Premise: \"Pretty Good Year\" is a single by the American singer-songwriter Tori Amos, taken from her second album \"Under the Pink\". It was released as the second single from the album in Europe in March 1994, and the fourth single from the album in Australia in November 1994. It was not released as a single in North America. <sep> Hypothesis: The song was a hit when it released during the spring in Australia", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-1c1e5d2b30d34dc0a3c2e018d27c8e13", "input": "Premise: How to replace a dream lite led bulb<br>Prepare. Arrange your tools on a clean flat surface and have all your tools at hand. Make sure you have enough space to move around as well as keeping your soldering iron at a safe distance while not in use. <sep> Hypothesis: It does not ever mention a incandescent bulb", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-e677ea0dd4ef440497a5a8e0be217767", "input": "Premise: With respect to the lobster and fishing licences purchased by the government for first nations in Atlantic Canada: ( a ) how many licences were purchased, and of these (i) how many were inshore licences; (ii) how many were offshore licences; ( b ) what species are covered by these licences; and ( c ) what bands have been given these licences? <sep> Hypothesis: The government purchased fishing licenses for first nations in Canada that enables them to fish and catch lobsters legally", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-b5711858f36f45de9e7d832af7276e30", "input": "Premise: One feature of the summary trial reform that was discussed at length in committee was the requirement to provide commanding officers with more comprehensive training in their military justice duties and responsibilities and to have them certified as qualified to conduct summary trials. <sep> Hypothesis: The summary trial reform will make a difference in the training.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-74790b35d4014d1cb38d0cf5bbfa3c6a", "input": "Premise: Calendar \u00bb Leads Club - Thursday Co-Ed Luncheon August 30, 2012 from 11:30 a.m. - 12:45 p.m. Join us for our weekly business networking luncheon where you will meet other business owners working together to build their businesses. Our speakers will be Ken Frye of Ken Frye Artisan in Wood and Charlie Mitchell, Charlie the Electrician. Please contact Cheryl Ebner of Santa Barbara Virtual Assistants at 968-1282 with questions or to R.S.V.P. <sep> Hypothesis: Someone who is starting an independent plumbing business might be interested in this event", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-74f38ee0a63a469eaa2207f5c9e171aa", "input": "Premise: In a game ripe with controversy, Manchester United walked away with a crucial away win after a Ryan Giggs free kick gave them the lead. Lille protested the goal, saying the team was setting up its wall at the time Giggs took the kick, and the team nearly left the pitch. After goading by officials, the game was resumed, but Lille said it would be making a stake for a replay with UEFA. UEFA has rejected the claim and declared the goal valid, as well as deciding to \"instigate proceedings against Lille for the improper behaviour of their players immediately after the goal.\" <sep> Hypothesis: People were upset by the outcome of the game.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-330de9359c084880b3956bb009fd9312", "input": "Premise: Dracaena aurea, the golden hala pepe, is a species of flowering plant that is endemic to the island of Kaua\u02bb i in Hawaii. It inhabits coastal mesic and mixed mesic forests at elevations of 120 \u2013 . It is a small evergreen tree, usually 4.6 - tall, but sometimes reaches 12 m . The gray, straight trunk does not have bark and is 0.3 - in diameter. The sword-shaped leaves are 20 - long and 1 - wide. <sep> Hypothesis: Dracaena aurea goes to college", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-6f975c15e2944337b856f3a92d94fe78", "input": "Premise: Bad Weather<br>The weatherman was told that he was going to be fired. This made him very angry. During the weather report on the news he lied. The weatherman said it would snow in July. Many angry viewers called into the station. <sep> Hypothesis: The weatherman enjoyed playing in the snow.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-6eac02bb806b4e838519b2cf784bf732", "input": "Premise: How to handle being in love with two people<br>Look into any differences between how you love each person. If you find yourself in love with two people, these people may be meeting different emotional needs. Identifying the different reasons you love each person can help you figure out how to move forward. <sep> Hypothesis: Thinking about the reasons for this situation may resolve it", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-c284b3b3d2f54e89b1b3721bda49a00d", "input": "Premise: Getting Too Fat<br>Tom got a girlfriend after a while of being single. He started to let himself go. Tom gained weight and started not dressing up as much. His girlfriend didn't like his laziness. She broke up with him over it. <sep> Hypothesis: Tom contains a x", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-c48c37d63e704ace8924c3f99ed0a0b3", "input": "Premise: How to check the real bitrate of audio files<br>Understand the bit rate and its affection on the audio quality. Though audio quality depends on many elements such as frequency, compressing method, up-scaled, etc. , but for almost audio files downloaded on the internet, if the bit rate is high (~ 128 kbps or higher), then the sound will be clearer and \" more comfortable \" to hear. <sep> Hypothesis: The sound quality of something with 100 kbps will generally not be better than something with 200 kbps.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-5ea4a188a7ab47dea92398705d79bbbc", "input": "Premise: Joanne Froggatt (born 23 August 1980) is an English actress of stage, television, and film. From 2010, she played lady's maid Anna Bates in all six seasons of the period drama \"Downton Abbey\". For this role, she received three Primetime Emmy Award nominations for Outstanding Supporting Actress in a Drama Series and won the Golden Globe Award for Best Supporting Actress on Television in 2014. <sep> Hypothesis: Froggatt has lost an Emmy award.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-d149b59259e94e5eb97c6e4b38fba949", "input": "Premise: I do, I do. The Persian Gulf, obviously. And Bosnia. And you have already talked about Kosovo. But the reverse side of the question, Governor, that Vice President Gore mentioned, 600,000 people died in Rwanda in 1994. There was no U.S. intervention, no intervention from the outside world. Was that a mistake not to intervene? <sep> Hypothesis: The was no U.S. intervention in the Persian Gulf in 1994.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-90b1fc8a000f4314bced00dc2b855327", "input": "Premise: Besides , they were too little to go outside of the Old Briar-patch now .<br>Indeed , they were too little to go outside their nursery , which was in a clump of sweet-briar bushes in the very middle of the Old Briar - patch , and Peter felt that there they were perfectly safe .<br>`` It is n't time to worry yet , '' said Peter to little Mrs. Peter , as he saw the fright in her eyes as the shadow of Redtail passed over them .<br>`` I do n't believe in borrowing trouble . <sep> Hypothesis: They needed to grow before leaving.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-815134a28c104e1a8189e7e89b565d0a", "input": "Premise: The Southeast Missouri State women's basketball team defeated Murray State 70-58 Monday night at the Show Me Center to improve to 2-1 in the Ohio Valley Conference and 7-8 overall. Senior Guard Bailie Roberts led the way with a career high 22 points for the Redhawks. The SEMO Women have now won two straight games for the first time since 2010. The Redhawks will conclude three-game home stand on Wednesday night at 6:30 against Saint Louis. Copyright 2013 KFVS. All rights reserved. <sep> Hypothesis: Bailie Roberts was on the team in 2010", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-c3b345bc65bc4bffad904606fe30f59a", "input": "Premise: Body Snatchers is a 1993 American science fiction horror film directed by Abel Ferrara and starring Gabrielle Anwar, Billy Wirth, Terry Kinney, Meg Tilly, Christine Elise, R. Lee Ermey and Forest Whitaker. It is loosely based on the 1955 novel \"The Body Snatchers\" by Jack Finney. <sep> Hypothesis: R. Lee Ermey never played Hockey.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-d8811777530740c9a814ac41caff5404", "input": "Premise: How to answer the most common interview questions<br>Explain your career path to describe yourself. Connect the dots on your resume so the interviewer can understand more about you professionally. Try to describe not only your career path but why you've made those decisions. <sep> Hypothesis: I did not bring my resume to the interview", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-f82e3de56ac44134968463a50099afa1", "input": "Premise: No reasonable parent or reasonable member of society would say that 10 or 11 year olds who have a choice to make should not be subject to a strong rehabilitative program and a diversionary program so they can recognize what they have done and then behave more successfully and co-operatively in society. <sep> Hypothesis: parents are very kind to their kids", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-8c48d67b9f3c4e01b2dffd116fae6094", "input": "Premise: Increased liabilities will add a little to the cost of marine insurance but commercial vessels insured in mutual protection and indemnity associations will probably see no substantive increase in insurance rates because coverage already provided by mutual associations is unlimited. <sep> Hypothesis: Unlimited marine insurance has a high cost differential to the price of a policy for individual commercial vessels.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-4b0479f4edd74e248c8fb236711312ea", "input": "Premise: \u00c9mile Bertrand Mbamba (born 27 October 1982 in Yaound\u00e9) is a Cameroonian football striker, who currently plays for Indonesia Super League side Persebaya Surabaya. He also played for Vitesse Arnhem, Maccabi Tel Aviv, Maccabi Petah Tikva, Vit\u00f3ria Set\u00fabal, Arema Malang, Daegu FC and Botev Plovdiv. <sep> Hypothesis: Mbamba was born the year after 1981.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-14ee5e68a9434aeab1987fedb9eb0b3f", "input": "Premise: In the state of Texas, United States, local schools are typically operated as independent school districts or consolidated school districts. Consolidated School Districts are typically one or more independent school districts that were consolidated due to low attendance or governance issues. Independent School Districts typically serve one community, but sometimes serve multiple small communities. <sep> Hypothesis: One couldn't tell if a school is an independent or consolidated school district", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-604ad376ccac4c809d9aa8524cb17cf1", "input": "Premise: Pakistan's President Pervez Musharraf held talks with British Prime Minister Gordon Brown in London on Tuesday, reassuring his host that Pakistan will hold a fair election next month and is ready to continue a sustained fight against terrorism and extremism. The visit has been widely called President Musharraf's \"charm offensive.\" The Pakistani leader has held talks in Brussels, Paris, at the World Economic Forum in Davos, Switzerland and now in London in an effort which has been seen as an attempt to shore up European support for his government. <sep> Hypothesis: President Pervez Musharraf told British Prime Minister Gordon Brown that he was going to fix the election.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-b9af9584c5204d5ab2be41a946aa3bf7", "input": "Premise: The Corn<br>Gary had a plot of land. He decided to plant some produce on it. He picked corn for the first crop. It grew tall and healthy. He harvested it and made some delicious food. <sep> Hypothesis: Food is made from corn and nothing but corn.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-5ce5a379bece418b9bdaab94fcad85bb", "input": "Premise: How to buy essential oils<br>Think about why you want to use an essential oil. Different oils suit different needs so it's important to know what you wish to achieve by using essential oil. For example, lavender can be used in a diffuser to relax and reduce anxiety and sage essential oil can be used as an antiseptic in wounds or as an anti-inflammatory. <sep> Hypothesis: Olive oil can be used in a diffuser to relax and reduce anxiety", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-b556a45e07894005a978b8937ad02194", "input": "Premise: Jet Ski<br>My first time on a jet ski was fun. My uncle was on the back. I was getting too close to a rock wall. He yelled at me to stop. We both fell off. <sep> Hypothesis: My uncle drove the jet ski and i sat on the back.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-c23230d0dbbd4a4dae84b7c6952ccf4d", "input": "Premise: Mr Lopez Obrador has alleged electoral fraud cost him the presidency, despite a recount confirming Felipe Calderon as Mexico's president-elect. <sep> Hypothesis: Obra alleged electoral fraud", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-3f1555815436433f8bc3a8c394744156", "input": "Premise: one of the orders issued by Ochola in April Login to license this image from 1$. In short At Kira Road police station, the photocopier business has moved behind the station, far away from the prying eyes of those passing on the road to Bukoto while at Old Kampala Police station, clients are now buying the forms across the road. <sep> Hypothesis: The decision to move the photocopier business was done for privacy reasons.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-7fb8720a0e1340f79837a08cf32605d2", "input": "Premise: \u00d7 A Tribute to New Year\u2019s Day Good Fortune Traditions Dave Hoekstra, along with Chicago songstress and comedian Molly McGown, welcome Chef Catherine Lambrecht of Greater Midwest Foodways, Charla Draper (formerly of Ebony magazine), and Author Donna Pierce into the studio as they pay tribute to the New Year\u2019s Day Good Fortune Tradition of Black Eyed Peas. The women discuss the history of the black eyed peas and how they grew to become a believed staple of good fortune; other traditions that are believed to bring good luck; and much more. <sep> Hypothesis: All of the people listened to the Black Eyed Peas Group but were not fond of them", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-0f79932959a94b52ad3efad8ccb4b185", "input": "Premise: How to start a forum<br>Figure out what your specific niche will be. [substeps] Since this will be your forum, it is best to pick something in which you are interested and knowledgeable. Since there are already so many forums out there, it is best to have a defined niche. <sep> Hypothesis: it is best to pick something in which you are neutral and knowledgeable so many people will join your forum", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-748a50b0a91c4256ad5066cdf63e6649", "input": "Premise: The Quilts of Valor program was started by a mother looking for a way to help her son. The Iraq War veteran was dealing with what she called \"war demons\" and needed something to comfort him and to help him heal. Thousands of quilters nationwide are busy putting their heart and soul into making quilts to be awarded to veterans as a thank you their service, sacrifice and valor. <sep> Hypothesis: The Quilts of Valor program was started by my mother", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-aeed57ab05a1427fb90bb2dcfe4bff9a", "input": "Premise: How to take action to help africa<br>Join the one campaign and receive their emails. Each email tells you something you can do to help. Write letters to your mayor and senators to keep pushing the government into helping. <sep> Hypothesis: Emails are the best way to reach your mayor.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-345b780e06894015b63ac9fb47a36f40", "input": "Premise: \"Mississippi leads the nation for obesity in children and adults, I believe the last figure was over 18 percent,\" said Sarah Hudson, D.O., a family medicine resident at Forrest General Hospital. \"So, that's significant. Those are numbers that we've never seen before, so we're having problems in children that we used to only see in adults and sometimes, middle-aged adults we're now seeing in relatively young children because of this.\" <sep> Hypothesis: Sarah Hudson works with obese adults", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-b45e63f980424e42bd99c6ea00c13e76", "input": "Premise: The sale was made to pay Yukos' US$ 27.5 billion tax bill, Yuganskneftegaz was originally sold for US$9.4 billion to a little known company Baikalfinansgroup which was later bought by the Russian state-owned oil company Rosneft. <sep> Hypothesis: The sale was made to pay Yuganskneftegaz's US$ 27.5 billion tax bill", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-dffbe2ff60384b3391e567d678ddd048", "input": "Premise: On the other hand, they've said that it enhances state standards and critical thinking. In my mind, everything that you do in a classroom is teaching. And I don't necessarily think that's just in my mind. I believe that's true of all educators. The way I dress when I go to work tells my students something. <sep> Hypothesis: Everything you do and wear in every classroom, even the minor details such as what clothes you have on, is teaching", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-2248b97caaf14108aed802baad2f69ad", "input": "Premise: The Abbottabad University of Science and Technology (also named \"AUST\"), is a public university located in Havelian (12\u00a0km from Abbottabad), Khyber Pakhtunkhwa, Pakistan. The University offers admissions in \"Bachelors\", \"Masters\", \"MS/M. Phill\" and \"PHD\" programs. <sep> Hypothesis: you can receive a PHD at the school", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-6a0f5123894c4e4d8e9261c4d09452e7", "input": "Premise: An adorably chubby tabby cat looked up when he heard his human call his name, showing a spark of interest when she bounced a ping-pong ball towards his direction for him to chase. Midway through his retrieval process however, the lazy tabby decided that he would rather play dead instead. <sep> Hypothesis: The tabby cat was female.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-7ab5a40dd8484ac58c2de5a52a032682", "input": "Premise: Binge<br>Ron hadn't lived near a big store for a long time. The first thing he did was buy a lot of ice cream. He binged out and ate it all in one sitting. Ron felt very sick for days after that. He swore to have more self-discipline no matter how close a store was. <sep> Hypothesis: The ice cream made Ron sick to his stomach.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-886f8fa22d024555ae0ff07b729d433a", "input": "Premise: Kurt Donald Cobain (February 20, 1967 \u2013 April 5, 1994) was an American musician, artist, singer, songwriter, guitarist and poet. Born in Aberdeen, Washington, Cobain formed the band Nirvana with Krist Novoselic in 1987 and established it as part of the Seattle music scene and grunge genre. Nirvana's debut album \"Bleach\" was released on the independent record label Sub Pop in 1989. <sep> Hypothesis: Cobain formed Nirvana when he was twenty years old", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-19d495f1c4714ae191fa627fe3f22d41", "input": "Premise: Videogames<br>Jesse loved playing video games. He was better at video games than all of his friends. Sometimes Jesse would brag about his skills to everyone. Jesse's friends did not like hearing him brag. Jesse learned to be more humble after seeing his friends' faces. <sep> Hypothesis: Jesse was very prideful at first.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-e34607c89eaf4a2081e613429b9c4d36", "input": "Premise: Green Day, who arrived at the venue in the vintage green convertible from their gritty \"Boulevard of Broken Dreams\" video, won best rock video and video of the year for the clip and two of their leading eight nominations. <sep> Hypothesis: Green Day made three speeches at the awards show.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-826bd8563eac410ea554f9391ebbc864", "input": "Premise: But Rajeev Dhawan, director of the Economic Forecasting Center at Georgia State University, says the main issue ahead is higher inflation. <sep> Hypothesis: The director says inflation needs to be higher.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-63c22a686f0244be86564500a2367005", "input": "Premise: They are both already in application internationally; both are advantageous to passengers, shippers and carriers; they allow greater uniformity of the rules governing international air transportation; they will both contribute to lessening the risk of litigation within the aeronautical industry. <sep> Hypothesis: both are advantageous to more than just carriers", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-526e924dcb7746c0a952d3baa92c5d00", "input": "Premise: How to train big dogs<br>Start early. Although this may not always be an option, starting the dog training process when your dog is less than 1 year old is ideal, especially when it comes to large dogs. Plan to begin training your dog as soon as you bring it home, which may be as early as 8 weeks. <sep> Hypothesis: Plan to train your St. Bernard 6 months after you bring it home in order to be successful.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-c6f1a871c7b1487b9f5d8bc084847e8b", "input": "Premise: How to downgrade your avg subscription on windows<br>Turn on your computer. Press the power button on your computer to turn it on. [substeps] The location of the power button will depend on your pc. <sep> Hypothesis: If you press the power button on a PC, please be aware that some radiation can spill over.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-5693e196446940fab63b4efc3c96cc3b", "input": "Premise: The guiding principles contained in the legislation are designed to ensure that the mediator-arbitrator recognizes the directions which have been provided to the employer by the Government of Canada in terms of financial performance and service standards, while at the same time balancing these issues with the importance of good labour relations within the workplace. <sep> Hypothesis: The principles benefited the workers.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-775e142d77a94bb59489753e1bb8b546", "input": "Premise: William Newton Byers (February 22, 1831 \u2013 March 25, 1903) was a founding figure of Omaha, Nebraska, serving as the first deputy surveyor of the Nebraska Territory, on the first Omaha City Council, and as a member of the first Nebraska Territorial Legislature. <sep> Hypothesis: Byers never left Nebraska.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-6789a5a011ea4c40976b76874bd2dcff", "input": "Premise: Dad and the Date<br>Lilly was a high schooler whose father was very protective. One night, Lilly had a date. The boy came and knocked on Lilly's front door. When Lily's dad answered, he glared at the boy. Strangely, the was the only date the boy and Lilly ever went on. <sep> Hypothesis: Lilly had never been on a date before.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-02350ac18e0c43dfa1ac61b0760018cd", "input": "Premise: William Friedkin (born August 29, 1935) is an American film director, producer and screenwriter best known for directing \"The French Connection\" in 1971 and \"The Exorcist\" in 1973; for the former, he won the Academy Award for Best Director. Some of his other films include \"Sorcerer\", \"Cruising\", \"To Live and Die in L.A.\", \"Jade\", \"Rules of Engagement\", \"The Hunted\", \"Bug\", and \"Killer Joe\". <sep> Hypothesis: William Friedkin is dead", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-7462fb43781e4a6bbaa5d5d2bb487419", "input": "Premise: One percent of America got $89 billion last year in a tax cut, but people working hard, playing by the rules, trying to take care of their kids, family values, that we're supposed to value so much in America -- I'm tired of politicians who talk about family values and don't value families. <sep> Hypothesis: One percent of Americans had to pay 89 billion dollars less than they would have to pay if there would be no tax cut, so they got to keep a lot more money", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-c055c0e3061744989fc35622d7170e65", "input": "Premise: How to qualify for unemployment<br>Understand the limitations. While all states have some form of federal-state unemployment program, the limits placed on this program can vary from state to state. [substeps] Check with your state unemployment insurance agency as soon as you lose your job to learn more specific information about whether or not you qualify for unemployment benefits. <sep> Hypothesis: Some states don't have unemployment.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-4873a4d102d64bd6b37803eb76685656", "input": "Premise: Born into Brothels: Calcutta's Red Light Kids is a 2004 Indian-American documentary film about the children of prostitutes in Sonagachi, Kolkata's red light district. The widely acclaimed film, written and directed by Zana Briski and Ross Kauffman, won a string of accolades including the Academy Award for Best Documentary Feature in 2004. <sep> Hypothesis: Born into Brothels is a widely acclaimed film, written and directed by Ross Briski and Zana Kauffman", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-0819b85eb9bd445ea333d678be257f56", "input": "Premise: How to deal with talkative students<br>Use proximity to attempt to quiet the student first. Simply stand near the talking student to get them to quiet down. Without interrupting your instruction, move near the talker, continuing to talk. <sep> Hypothesis: This is something that you should know how to do.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-698816016a6b4d009a2fa0c1b048f035", "input": "Premise: Sunday Live with Adam Boulton was a weekend news and political show on Sky News and on Sky News HD, presented by Sky News' Political Editor Adam Boulton. From January 2011, the programme was replaced with \"Murnaghan\", a similar show presented by Dermot Murnaghan. Boulton moved to a new weekday show at 13:00 on Sky News. <sep> Hypothesis: Sunday Live with Adam Boulton has run for five years.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-d83519570dba483998fca09d319c97cc", "input": "Premise: Boredom on the internet has led to the creation of yet another meme, this time revolving around Naruto\u2018s Sasuke and the way in which Twitter places two images next to each other in a tweet. The original image on which the meme is based on, with Sasuke being choked by his older brother: The meme that ensued: <sep> Hypothesis: Naruto's Sasame was the character that was being choked.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-1761d13016584e6b846347aafa0458ba", "input": "Premise: Hot Plate<br>Drew took his plate out of the microwave. He was trying to hold it. Since the plate was hot, it quickly dropped from his hand. It fell on the floor and broke. His soup covered the entire floor. <sep> Hypothesis: Drew had a lot of food on the plate.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-06311532a0814c55aed9635b5dcf75a7", "input": "Premise: Swarthy Jones<br>Swarthy Jones was a bouncer at a local club. He turned down a girl because she was too ugly. Her boyfriend returned minutes later. Swarthy Jones had never seen someone bigger than him. Swarthy Jones was afraid, and let the girlfriend in. <sep> Hypothesis: Swarthy Jones thought he wasn't the biggest man alive.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-d397d53958c848899e0d2782fd51161c", "input": "Premise: Love is a 2006 theatrical production by Cirque du Soleil which combines the re-produced and re-imagined music of the Beatles with an interpretive, circus-based artistic and athletic stage performance. The show plays at a specially built theatre at the Mirage in Las Vegas. <sep> Hypothesis: The show only plays at two theatres", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-6a12241d0a1f41e5baa3948995c07fe2", "input": "Premise: Instead of taking this advantage it will soon need in international negotiation, that is the experience of harmonizing two great traditions, the civil law and the common law, the government chose to set one of these traditions aside, the French one, to bury it, and forget about it. <sep> Hypothesis: The government chose to set less than 3 traditions aside.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-6587ca4a4e134897a50a91f1fafa0413", "input": "Premise: This paper discusses marijuana, crack/cocaine, tranquilizers, hallucinogens, amphetamines, heroin, alcohol, nicotine and caffeine to provide a framework for the author's argument that the legalization of drugs can in no way be deemed as ethical or moral. <sep> Hypothesis: the passage does not mention substances made from poppy", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-b2cc642f65be4d79b08c5bc0a399a8d3", "input": "Premise: \"What's in It for Me\" is a song written by Gary Burr and John Jarrard, and recorded by American country music artist John Berry. It was released in June 1994 as the fourth single from the album \"John Berry\". The song reached number 5 on the U.S. \"Billboard\" Hot Country Singles & Tracks chart and peaked at number 2 on the Canadian \"RPM\" Country Tracks chart. <sep> Hypothesis: Gary Burr wrote some lyrics for the album \"John Barry\"", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-6046562c45a040ffb3006048e4906b7c", "input": "Premise: I said nothing and gave no advice , not having lived seventy-five years for nothing .<br>I knew that Doctor John 's decision was manly and right and fair ; but I also knew it was all nullified by the fact that Marcella already loved him .<br>So much I knew ; the rest I was left to suppose .<br>The Doctor and Marcella told me much , but there were some things too sacred to be told , even to me .<br>So that to this day I do n't know how the doctor found out that Marcella loved him . <sep> Hypothesis: The person who gave no advice did not have to guess whether Marcella loved the doctor.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-301696539e814357a1dbc39b1c1b3df9", "input": "Premise: That's right. That's the important hurdle, and we'd like to jump that first, but the other ones, Justice, you're right, in 1831 and in 1909 Congress extended terms in a way that is inconsistent with the strongest form of the test that we have advanced. Those extensions, however, were never challenged in any court and certainly not considered by this Court. <sep> Hypothesis: In 1909 Congress made  a bad decision to extend terms.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-5e171a6403e44ebf90b7938ce8020b86", "input": "Premise: The United Iraqi Alliance, endorsed by Iraq's top Shiite clerics, captured more than two-thirds of the 3.3 million votes counted so far, the election commission said. <sep> Hypothesis: Two thirds of three point three million is one point one five million.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-47fab94512c145b29c5df0c0232a600d", "input": "Premise: On Sunday December 14, 2008, an Iraqi journalist for an Egyptian Newspaper named Muntazer al-Zaidi was tackled by authorities after he threw his shoes at former United States president George W. Bush during a press conference in Baghdad. Bush had made a surprise last visit to Iraq to sign a new security pact brokered by Iraq and the U.S. Bush ducked as the flying shoes zipped past him, barely missing the now former U.S. president. <sep> Hypothesis: The shoes barely hit the the president", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-a3a8da3dda754e9594fb387006638b70", "input": "Premise: Rainforest Hiking<br>I went on a tropical vacation with some friends of mine. We wanted to go hiking in one of the island's rainforests. The tour guide warned us it would be muddy. I didn't take the warning very seriously. I ended up ruining my shoes completely on the hike. <sep> Hypothesis: The hiker does not think she can save her shoes after that muddy hike.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-2cc846e64a43498fb187426e1b303ee1", "input": "Premise: How to clear nasal congestion quickly<br>Gently blow your nose. Perhaps the easiest and quickest way to reduce nasal congestion is to simply blow your nose into a soft tissue. Unfortunately, it's not always possible to completely relieve congestion by merely blowing, but it's always a good starting point. <sep> Hypothesis: strike a pose to fix your nose", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-b27d1117f6bb454da135da7f82d9e8a0", "input": "Premise: That's a place where we can use our generosity to influence in a positive way, influence nations. I believe we ought to have foreign aid, but I don't think we ought to just have foreign aid for the sake of foreign aid. I think foreign aid needs to be used to encourage markets and reform. <sep> Hypothesis: foreign aid is only for the rich", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-44f5c00681bb465d96925a05cd32664b", "input": "Premise: \u00d7 Stop on by the Eastern & Alger Pop-Up Market GRAND RAPIDS, Mich.\u2013 Stop by the Eastern & Alger Pop-Up Market on Saturday for all kinds of goods. Happening from 9 a.m. to 3 p.m. at the Alger Heights Business District. Shoppers can find antiques, homemade decor, and original artwork. The market runs every third Saturday through October, so if you cannot make it, just catch it again next month. It doesn\u2019t cost anything to go, but bring your wallet to grab some good finds. <sep> Hypothesis: The market can be visited the third saturday in september.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-305a0a43adf247668d05db02b16947cb", "input": "Premise: Climber<br>Ben was talking his preteen son rock climbing. They went to an indoor rock wall and suited up. Then they climbed side by side, breathing heavily. At the end of the day, both had reached the top, but it was hard! They agreed that they both needed to be a little more fit! <sep> Hypothesis: Ben took his son to collect rocks", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-11cdbed21632414bb0a16951dec639ff", "input": "Premise: Quick Chek is a privately owned, Whitehouse Station, New Jersey based chain of convenience stores with 140 stores in New Jersey and New York. The first store opened in Dunellen, New Jersey in 1967, and has since then grown into a chain. Several stores include pharmacies, gas stations, and liquor departments. <sep> Hypothesis: only one Quick Chek was in business until 1983", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-6ece2ddd121d4a05ac0b75928ed8f3fd", "input": "Premise: TORONTO, March 7 (Reuters) - The Canadian dollar weakened to a session low against the greenback after data showed the domestic economy unexpectedly shed jobs in February. At the same time, investors were also taking in data south of the border that showed U.S. job growth accelerated last month. The Canadian dollar was at C$1.1055 to the greenback, or 90.46 U.S. cents, weaker than Thursday's close of C$1.0992, or 90.98 U.S. cents. The loonie hit a session low of C$1.1064 shortly after the data was released. <sep> Hypothesis: Toronto is the most populous city in Canada.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-fcc907c7fe1445ebb708f3fbc87c1859", "input": "Premise: Dufton is a village and civil parish in Cumbria, England. Historically part of Westmorland, it lies in the Eden Valley and below Great Dun Fell. It is mostly around 180m above sea level. At the 2001 census the parish had a population of 169, increasing to 204 at the 2011 Census. <sep> Hypothesis: In 2002, Dufton parish in Cumbria, England had a population of exactly 175.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-76974b30960243bd9fea3b854543587c", "input": "Premise: Robert Alexander Crookston Laidlaw {'1': \", '2': \", '3': \", '4': \"} (8 September 1885 \u2013 12 March 1971) was a New Zealand business man who founded the Farmers Trading Company, one of the largest department store chains in New Zealand. He was also a Christian writer and philanthropist and a well-known lay preacher in the Open Brethren movement. <sep> Hypothesis: The Farmers Trading Company is a successful department store in Oceania", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-aad676313d614e71b3e6cc62dfa32847", "input": "Premise: How to take iodine<br>Choose an iodine supplement of 0.5 milligrams or less. If you think you aren't getting enough iodine and you don't want to visit the doctor, take a low dose of iodine. You shouldn't take more than 0.5 milligrams a day, as too much iodine can wreak havoc on your thyroid gland. <sep> Hypothesis: The person writing these instructions would agree that a 50 milligram iodine supplement would not be good for one's thyroid gland.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-62747c040b36485e90db8156dbd1954c", "input": "Premise: Well, the line comes from deciding what the First Amendment interest is, and if this Court heed the First Amendment interest off of this difference between selecting who gets the benefit of 20 years of extension and just simply legislating in a general way prospectively, then this Court could hold, with respect to the prospective, that it's not even necessary to raise the intermediate scrutiny in that context, but again, for Ashwander reasons we don't think that this Court should address the prospective aspect of the CTEA even under the First Amendment. <sep> Hypothesis: This case involves the Declaration of Independence", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-df5475415205470cbc455e7888e75955", "input": "Premise: After the Securities and Exchange Board of India (Sebi) reopened the door to new fund offers (NFOs) in the equity segment, a large number of fund houses have lined up a spate of fresh schemes. As many as five open-end schemes were launched in August, two more are currently open for subscription, and a draft prospectus for more schemes has been filed by the fund houses. \u201cThe market regulator didn\u2019t approve schemes in the past year and a half as it first wanted the fund houses to implement the re-categorisation norms. Sebi was concerned about the overlapping of schemes and ... <sep> Hypothesis: As many as (5*4) open-end schemes were launched in August.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-b55d5b0b4a724eb6a58a92ca9ded95ce", "input": "Premise: Simon Montagu McBurney, OBE (born 25 August 1957) is an English actor, writer and director. He is the founder and artistic director of the Th\u00e9\u00e2tre de Complicit\u00e9, London. He has had roles in the films \"The Manchurian Candidate\", \"Friends with Money\", \"The Golden Compass\", \"The Duchess\", \"Robin Hood\", \"\", \"Tinker Tailor Soldier Spy\", \"Magic in the Moonlight\", \"The Theory of Everything\" and \"\". <sep> Hypothesis: The Th\u00e9\u00e2tre de Complicit\u00e9 opened in 1900", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1387_anli_r3_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise. (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise. (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1387-b38697d9d5ab49348e927e81436461e8", "input": "Premise: If the hon. gentleman took the time to read the article, he would find quotes from me talking about the minister of heritage who last week publicly said that if there are meaningful amendments while preserving the very essence of the bill, that she is open to hearing them from the committee. <sep> Hypothesis: I am a gentleman", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-3c7c3975f7274fc882018e19a7c49878", "input": "Premise: The Wallace Park in Lisburn, Northern Ireland was bequeathed to the people of Lisburn by Sir Richard Wallace. It is a pleasant park with tree-lined walkways. There is a number of football pitches, tennis courts, a duck pond and a children's adventure play area. The grounds of Lisburn Cricket Club are in the centre of the park where Cecil Walker MBE is the groundman. <sep> Hypothesis: The Wallace Park is in Europe.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-985259169a5d4c7b8ec7775a9de99303", "input": "Premise: Palo Alto is a 2013 American drama film written and directed by Gia Coppola, based on James Franco's short story collection \"Palo Alto\" (2010). Franco stars, along with Emma Roberts, Jack Kilmer, Nat Wolff and Zoe Levin. Jack Kilmer's father, Val Kilmer, also appears briefly in the film as Stewart, Emma Roberts' stepdad. <sep> Hypothesis: Palo Alto was based on a true story.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-e6ab998d176743ad9b65f90751d34c37", "input": "Premise: Joseph Pomeroy Widney High School, known as J. P. Widney High School is a special education magnet high school in Los Angeles, California, part of the Los Angeles Unified School District. This school is named in honor of Dr. Joseph Pomeroy Widney, a prominent early Los Angeles resident. <sep> Hypothesis: Dr. Joseph Pomeroy Widney went to  Joseph Pomeroy Widney High School.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-86a8db5321594c5189c785befd62b7a7", "input": "Premise: Brassica ( ) is a genus of plants in the mustard family (Brassicaceae). The members of the genus are informally known as cruciferous vegetables, cabbages, or mustard plants. Crops from this genus are sometimes called \"cole crops\"derived from the Latin \"caulis\", denoting the stem or stalk of a plant. <sep> Hypothesis: plants can be separated into different plant families", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-792282b5de4f446f9b6ebac65a83bb3d", "input": "Premise: The family of Macintosh operating systems developed by Apple Inc. includes the graphical user interface-based operating systems it has designed for use with its Macintosh series of personal computers since 1984, as well as the related system software it once created for compatible third-party systems. <sep> Hypothesis: In 1984 the first Macintosh was released.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-a6da376a40cc412c86eed661a810ac1c", "input": "Premise: Wayne State University (WSU) is a public research university located in Detroit, Michigan. Founded in 1868, WSU consists of 13 schools and colleges offering nearly 350 programs to more than 27,000 graduate and undergraduate students. Wayne State University is Michigan's third-largest university and one of the 100 largest universities in the United States. <sep> Hypothesis: Detroit has a university that is at least 145 years old", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-39a032f5987f4a88bf231aa56aafc656", "input": "Premise: Never Shout Never is an EP by Never Shout Never which was released on December 8, 2009. The physical release is sold exclusively at Hot Topic. The EP features two songs from his then upcoming Sire Records full-length debut, \"What is Love?\", one song that is a B-side from \"The Summer EP\" and one live track. <sep> Hypothesis: Never Shout Never was the only album released by Never Shout never in 2009.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-02df210ad2dc4bf0a93a4c5556c6a903", "input": "Premise: Jean-Baptiste Poquelin, known by his stage name Moli\u00e8re ( or ; ] ; 15 January 162217 February 1673), was a French playwright and actor who is considered to be one of the greatest masters of comedy in Western literature. Among Moli\u00e8re's best known works are \"The Misanthrope\", \"The School for Wives\", \"Tartuffe\", \"The Miser\", \"The Imaginary Invalid\", and \"The Bourgeois Gentleman\". <sep> Hypothesis: Jean-Baptiste Poquelin never watched any of his plays.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-4f703a28262d4922af94a367be67ed4c", "input": "Premise: Cai Mingjie (\u8521\u660e\u6770, born 1952) is a Singaporean taxicab driver and former biology researcher, known for his blog, \"A Singapore Taxi Driver's Diary\". He is described variously as \"Singapore's most educated taxi driver\" and \"the only taxi driver with a Ph.D.\". <sep> Hypothesis: Cai Mingjie is 70 years old today", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-70b7ea34121047b1ac52763f1ee3a093", "input": "Premise: Julio C\u00e9sar Ch\u00e1vez Jr. vs. Sebastian Zbik was a Middleweight championship fight for the WBC Middleweight Championship. It has been the first time that the son of legendary boxing Champion Julio C\u00e9sar Ch\u00e1vez, fought for a world title, Ch\u00e1vez went on to become the new WBC Middleweight Champion. The bout was on June 4th, 2011, at Staples Center, in Los Angeles, California and was broadcast on HBO. <sep> Hypothesis: The father of Julio Cesar Chaves won a boxing  championship in 2011.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-1a957eaf52f748ada41d60ca4e7cb87b", "input": "Premise: Lorado Zadoc Taft (April 29, 1860 \u2013 October 30, 1936) was an American sculptor, writer and educator. Taft was born in Elmwood, Illinois, in 1860 and died in his home studio in Chicago in 1936. Taft was the father of US Representative Emily Taft Douglas, father-in-law to her husband, US Senator Paul Douglas, and a distant relative of US President William Howard Taft. <sep> Hypothesis: Larado Zadoc Taft was a US Representative.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-df5802fea06344f989e0211bd6291a9e", "input": "Premise: Katie Liu Leung (born 8 August 1987) is a Scottish film, television, and stage actress. She played Cho Chang, the first love interest for lead character Harry Potter in the Harry Potter film series. In 2012, Leung made her stage debut in the play \"Wild Swans\". Leung has an interest in painting and photography and studied art and design at the University of the Arts, London. <sep> Hypothesis: Katie Liu Leung acted in her first play in 1987.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-9ee13093a2a54b2db7f6d333b210af8f", "input": "Premise: Colsterworth is a village and civil parish in the South Kesteven district of Lincolnshire, England. It lies less than half a mile (0.8\u00a0km) west of the A1, about 7 mi south of Grantham, and 12 mi north-west of Stamford. The village, with the hamlet of Woolsthorpe-by-Colsterworth, had a population of 1,713 at the time of the 2011 Census in an area of 1465 ha . <sep> Hypothesis: Colsterworth had a population of 1,713 in 2012", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-295c1074f6b5450f9f3c70cce034f362", "input": "Premise: Marion Mitchell (born 1941 in Seaham, County Durham), better known by her stage name, Janie Jones, was an English singer. She became renowned for holding sex parties at her home during the 1970s, and was jailed for her involvement in 'controlling prostitutes'. She first achieved notoriety in August 1964, when she attended the film premiere of \"London in the Raw\", wearing a topless dress. <sep> Hypothesis: Marion Mitchell was a singer that was actually imprisoned at one point in her life", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-21e9799c7a75491cad7981764c5d57f5", "input": "Premise: Brixia-Zust (originally Brixia-Z\u00fcst) was an Italian car manufacturer founded by engineer Roberto Z\u00fcst, owner of Zust company of Milan. The affiliated company was situated in Brescia, Northern Italy. (Brixia is the antique Latin for Brescia.) These companies are often confused. The company made racing cars that participated in Targa Florio, an open road race in Sicily. <sep> Hypothesis: Targa Florio is held in Sicily not in France.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-83e398fff9874643958cd1b170284249", "input": "Premise: North Lincolnshire is a unitary authority area in the region of Yorkshire and the Humber in England. The population of the Unitary Authority at the 2011 census was 167,446. For ceremonial purposes it is part of Lincolnshire. There are three significant towns: Scunthorpe (the administrative centre), Brigg and Barton-upon-Humber. <sep> Hypothesis: Lincolnshire is a unitary region in England with a census of 167,446 in 2011. It has three significant towns, the administrative centre Scunthrope, educational centre of Brigg and judicial centre in Carton-upon-Humber. ", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-b6af9abbdba246e8af4038413467f877", "input": "Premise: High Noon, Part II: The Return of Will Kane is a 1980 made-for television film sequel to the classic 1952 Western film \"High Noon\". It starred Lee Majors in the title role, as well as David Carradine and Pernell Roberts. It first aired on CBS on November 15, 1980, in a two-hour time-slot. The film's screenplay was written by famed crime novelist Elmore Leonard. <sep> Hypothesis: High Noon, Part II: The Return of Will Kane first aired at least 25 years after the film \"High Noon\".", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-6b8f970e9c6640aba7a9fbeb586994ed", "input": "Premise: The Committee of 100 is a Wilmington, Delaware based lobbying group that deals with issues relating to economic development, local finance, and land use policy in the state of Delaware, particularly the northern part of New Castle County. It was founded in 1967. <sep> Hypothesis: The committee of 100 has 99 members.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-8918e38bddaf4413a2183ca51a0a8368", "input": "Premise: A grasshopper is a sweet, mint-flavored, after-dinner drink. The name of the drink derives from its green color, which comes from cr\u00e8me de menthe. The drink reputedly originated at Tujague's, a landmark bar in the French Quarter of New Orleans, Louisiana, and was invented by its owner, Philip Guichet. The drink gained popularity during the 1950s and 1960s throughout the American South. <sep> Hypothesis: The grasshopper is known for it's strong alcoholic content, as well as it's mint taste.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-df4ed18f581c4687b407a500e8d756a0", "input": "Premise: Murder in Amsterdam: The Death of Theo Van Gogh and the Limits of Tolerance is a 2006 book by Ian Buruma. \"The Guardian\" describes it as, \"part reportage, part essay.\" It explores the impact of mass immigration from Muslim countries on Dutch culture through the lens of the murder of film director and anti-immigration activist, Theo van Gogh. <sep> Hypothesis: Theo van Gogh made documentary films.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-381f62848dc3403992850369dd297a30", "input": "Premise: Chromatium okenii is a Gram-negative bacterium found in water. It belongs to the Purple sulfur bacteria. These bacteria are capable of photosynthesis and use Hydrogen sulfide (HS) as an electron donor for CO reduction and so do not produce oxygen. This type of photosynthesis is called anoxygenic photosynthesis. <sep> Hypothesis: Chromatium okenii might possibly be a Gram-negative bacteria.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-1042553779984db1b0335ca0aa6676ed", "input": "Premise: \"The Everlasting\" is the second single to be lift from the Manic Street Preachers's fifth studio album \"This Is My Truth Tell Me Yours\". It was released on November 30, 1998, through Epic, it peaked on number 11 in the UK Singles Chart, breaking their run of consecutive top ten hits. All three members of the band - James Dean Bradfield, Sean Moore and Nicky Wire - share the writing credits. <sep> Hypothesis: James Dean Bradfield met Sean Moore for the first time at school on November 1st, 1998.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-a4dd22498c754b25a45224095f902c5b", "input": "Premise: Manuel Lisandro Barillas Berci\u00e1n (Quetzaltenango, 17 January 1845\u2013Mexico City, 15 March 1907) was a Guatemalan general and acting president of Guatemala from 6 April 1885 to 15 March 1886 and President from 16 March 1886 to 15 March 1892. He was born in Quetzaltenango, and assassinated (at the behest of his enemy Manuel Estrada Cabrera, President of Guatemala at the time) in Mexico City in 1907. <sep> Hypothesis: Manuel Lisandro Barillas Berci\u00e1n was a Guatemalan colonel and acting president of Guatemala from 6 April 1885 to 15 March 1886 and President from 16 March 1886 to 15 March 1892.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-c89dab659c7c479e837ba98f4d1b77f4", "input": "Premise: Glaring Through Oblivion is a 2011 book of poetry written by Serj Tankian, the Armenian-American lead singer of the band System of a Down. It is his second book of poetry, after \"Cool Gardens\" (2002). \"Glaring Through Oblivion\" was published by HarperCollins Publishers and printed in China, and released on March 22, 2011. <sep> Hypothesis: Glaring Through Oblivion is written by the singer of a popular band", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-b2e599ceab5043b2b09a2fd427b2fc8c", "input": "Premise: Ekaterina \"Katia\" Alexandrovna Gordeeva (Russian: \u0415\u043a\u0430\u0442\u0435\u0440\u0438\u043d\u0430 \u0410\u043b\u0435\u043a\u0441\u0430\u043d\u0434\u0440\u043e\u0432\u043d\u0430 \u0413\u043e\u0440\u0434\u0435\u0435\u0432\u0430 ) (born May 28, 1971) is a Russian (former Soviet) figure skater. Together with her partner and husband, the late Sergei Grinkov, she was the 1988 and 1994 Olympic Champion and four-time World Champion in pair skating. After Grinkov's death, Gordeeva continued performing as a singles skater. <sep> Hypothesis: Ekaterina continued performing as a singles skater after she died.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-fcfdfb958d524f4d86c6f97290750e50", "input": "Premise: Hariharan Pillai Happy Aanu (English translation: \"Hariharan Pillai is happy\") is a 2003 Malayalam film by Viswanath starring Mohanlal and Jyothirmayi. This was Viswanathan's debut film as a director and the debut music directorial venture of renowned pianist and arranger, Stephen Devassy. <sep> Hypothesis: Hariharan Pillai Happy Aanu was filmed in Asia", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-1413c0240f734d58aad97b6c78d74035", "input": "Premise: The 2013 Duke Blue Devils football team represented Duke University in the 2013 NCAA Division I FBS football season. The team was led by head coach David Cutcliffe, in his sixth year, and played its home games at Wallace Wade Stadium in Durham, North Carolina. Duke competed as a member of the Atlantic Coast Conference (ACC) in the Coastal Division. <sep> Hypothesis: David Cutcliffe has coached for more than 5 years", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-d19ab294a2bc47e08378d83be526ffdf", "input": "Premise: Earl Mountbatten of Burma is a title in the Peerage of the United Kingdom. It was created in 1947 for Rear Admiral Louis Mountbatten, 1st Viscount Mountbatten of Burma, the last Viceroy of India. The letters patent creating the title specified the following special remainder: <sep> Hypothesis: The last Viceroy of India was not alive in 1947", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-d3977a9861e94220a05b480aff0d30bf", "input": "Premise: <nowiki>Callin' All Dogs</nowiki> is a 1995 album by Louisville, Kentucky rock band Bodeco. This, the rockabilly band's second album, made a considerable impact on the Louisville music scene, finding a place at #80 on WFPK's \"top 1000 best albums ever\". \"Trouser Press\" asserted that the album reinforced \"Bodeco's simple genius by turning up the slop right from the get-go\". <sep> Hypothesis: An album released in 1995 reached a place above #100, but not as high as #50, on the 'top 1000 best albums ever' list of a radio station.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-0c311a5848f044f8904db383bf29b36f", "input": "Premise: Herrlisheim is a commune in the Bas-Rhin department in Grand Est in north-eastern France. The town dates from the 8th century. Herrlisheim was the scene of very heavy fighting during \"Operation Nordwind\", an offensive launched by the German Army during World War II that inflicted considerable damage to the town. <sep> Hypothesis: Herrlisheim is one of the oldest French towns", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-11731cbf5bac4726a81494fd3d20bd22", "input": "Premise: Old Trafford, known for sponsorship reasons as Emirates Old Trafford, is a cricket ground in Old Trafford, Greater Manchester, England. It opened in 1857 as the home of Manchester Cricket Club and has been the home of Lancashire County Cricket Club since 1864. <sep> Hypothesis: Old Trafford is well-known for only its cricket club.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-6ae6ee1367ea441fa8b19fb82b5ab9fb", "input": "Premise: The Wrath of the Gods is a 1914 American silent drama film directed by Reginald Barker, and starring Sessue Hayakawa, Tsuru Aoki, Frank Borzage, Thomas Kurihara and Henry Kotani in the lead roles. This was the first feature film appearance of Hayakawa and the directorial debut of Barker. <sep> Hypothesis: The Wrath of the Gods is a 1914 American silent drama film which was the first feature film appearance of Tsuru Aoki.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-f0e5ec8567d34a25890299910423d6a8", "input": "Premise: Mark Dymond (born 1974, Wimbledon, London) is an English actor of Irish descent. In addition to appearances in films, he is known as Dr. Lorcan O'Brien, a major character in the 2007\u20132009 seasons of the TV drama series \"The Clinic\", among other TV shows. He married actress Jo Bourne-Taylor in 2004. <sep> Hypothesis: In the 21st century, Jo Bourne-Taylor marries an actor.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-5dac07f596404d87b941c403460683f2", "input": "Premise: The 1991 Supercopa Sudamericana Finals were the finals of the fourth edition of the Supercopa Sudamericana football tournament. It was contested by Argentina club River Plate and Brazil club Cruzeiro . The first leg of the tie was played on November 13 at River Plate's home field, with the second leg played on November 20 at Cruzeiro's. <sep> Hypothesis: The 1991 Supercopa Sudamericana Finals were the final edition of the Supercopa Sudamericana football tournament.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-3bc7fa8c1b8d431984c70a89aa9d12ea", "input": "Premise: Give Us Our Skeletons! (Antakaa Meille Luurankomme in Finnish, Oaivveskaldjut in North Sami) is a 1999 documentary film directed by Paul-Anders Simma about Niillas Somby, a Sami man who retraces his family ancestry as he searches for the head of his ancestor, Mons Somby. <sep> Hypothesis: Niillas Somby was not from Finland.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-a6c6a242f9214bf48b164fb5bd890edf", "input": "Premise: Bucklow Rural District was, from 1894 to 1974, a local government district in the north of the administrative county of Cheshire, England. Following the Local Government Act 1972, this rural district was split between the new Greater Manchester boroughs of Trafford and Manchester, and Macclesfield, which was retained in Cheshire. <sep> Hypothesis: Bucklow Rural District has a population.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-c51a08516fb3468095e7a9e786ba6a92", "input": "Premise: Secrets of the Cryptkeeper\u2019s Haunted House was a children's Saturday-morning game show that ran on CBS. It premiered on September 14, 1996 and lasted until August 23, 1997. It featured the Cryptkeeper of \"Tales from the Crypt\" (with John Kassir as the voice) now serving as an announcer. It is the last TV series in the \"Tales From the Crypt\" franchise. <sep> Hypothesis: John Kassir only voiced the Cryptkeeper on the CBS Saturday-morning game show called Secrets of the Cryptkeeper\u2019s Haunted House", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-0200ed0467934e4da49bd9f88f331543", "input": "Premise: Ernest Jones is a British jeweller and watchmaker. Established in 1949, its first store was opened in Oxford Street, London. Ernest Jones specialises in diamonds and watches, stocking brands such as Gucci and Emporio Armani. Ernest Jones is part of the Signet Jewelers group. <sep> Hypothesis: Signet Jewelers group is part of Ernest Jones.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-80216898d0e840c2951a5123a68ac312", "input": "Premise: Ron Hutchinson (born near Lisburn, County Antrim, Northern Ireland) is an Emmy Award winning screenwriter and an Olivier Award nominated playwright, known for writing John Frankenheimer's \"Against the Wall\", Robert M. Young's \"Slave of Dreams\", John Frankenheimer's \"The Island of Dr. Moreau\", \"Moonlight and Magnolias\" (play), and the 2004 miniseries \"Traffic.\" <sep> Hypothesis: Ron Hutchinson, a man born in Lisburn County, Northern Ireland was nominated for the Olivier Award and won an Emmy.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-849b7135e9e74fbcbf6c45b26492a231", "input": "Premise: Persona: A Biography of Yukio Mishima is a 2012 biography of Yukio Mishima written by Naoki Inose with Hiroaki Sato, and published by Stone Bridge Press. It is an expanded adaptation in English of Inose's 1995 Mishima biography, \"Persona: Mishima Yukio den\", published by Bungeishunj\u016b in Tokyo, Japan. <sep> Hypothesis: Inose wrote and published the biography", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-ac8b28fc17e84a049e4be8d9a99438ad", "input": "Premise: Almost Sunrise is a 2016 American documentary film directed by Michael Collins. It recounts the story of two Iraq veterans, Tom Voss and Anthony Anderson, who, in an attempt to put their combat experience behind them, embark on a 2,700-mile trek on foot across America. It made its world premiere on the opening night of the Telluride Mountainfilm Festival on 27 May, 2016. <sep> Hypothesis: In the film almost sunrise, two Iraq veterans attempt to relive their combat experiences on a trek across America.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-0af1f3977ca741f68b33e85a31839ff0", "input": "Premise: A Grand Griffon Vend\u00e9en is a breed of hunting dog originating in France. It existed as early as the 16th Century, and was the first of the Vend\u00e9e griffons to be bred. It is a descendant of the Canis Segusius used by the Gauls, through the so-called King's whites and the Griffon Fauve de Bretagne, which is also an ancestor of the Basset Fauve de Bretagne. <sep> Hypothesis: The Gauls used Canis Segusius for breeding as well.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-1c74ae2cb4ff4f1b978406599a5a020a", "input": "Premise: The Million Dollar Goal is a children's sports novel by American author Dan Gutman, first published by Hyperion Books for Children in 2003. It is part of the Million Dollar series, in which different sports have a competition involving a million dollar reward. In this book, the sport is ice hockey. <sep> Hypothesis: Tennis is one of the sports in the Million Dollar Series.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-e8f02eefb153471bae840f9be2303923", "input": "Premise: Manchester United Football Club is an English professional football club, based in Old Trafford, Greater Manchester, that plays in the Premier League. Founded as Newton Heath LYR Football Club in 1878, and changed its name to Manchester United in 1902. <sep> Hypothesis: Some called Manchester United by the name Newton Health LYR Football Club after 1902.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-22ebce1382af4be29c6438788df4493b", "input": "Premise: Phillip Calvert (1626 \u2013 1682), also known as Philip Calvert, was the fifth Governor of Maryland during a brief period in 1660 or 1661. He was appointed by the royally chartered proprietor of Maryland, Charles Calvert, 3rd Baron Baltimore (1637\u20131715), as a caretaker to replace Lt. Gen Josias Fendall (1628\u20131682), the fifth/sixth? provincial governor. <sep> Hypothesis: Phillip Calvert resigned from office.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-fa9a43da5e054646869c3f37b78ff065", "input": "Premise: A French sauce spoon or saucier spoon is a spoon that is typically the size and shape of a dessert spoon, but with a flattened bowl that has a thinner edge and a small notch on one side. As the name suggests, a French sauce spoon is used to eat the sauce accompanying a dish. Such a spoon may be referred to simply as a sauce spoon, but this can also refer to a spoon used to serve sauce. <sep> Hypothesis: A French sauce spoon is also called a saucy spoon.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-fcf2be0e17e744ceae45860759efe807", "input": "Premise: Out of the Easy is a 2013 novel by Ruta Sepetys. It is her second published novel. It features Josie Moraine, a young woman in the 1950s French Quarter of New Orleans who struggles to escape her family and become the author of her own destiny. The novel became a New York Times bestseller and was chosen as an Editor\u2019s Choice in the New York Times on February 15, 2013. <sep> Hypothesis: Out of the Easy was published in the 1950s.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-489a924d3df748ae956dee9af39f6e6a", "input": "Premise: Stephen Wolfram (born 29 August 1959) is a British-American computer scientist, physicist, and businessman. He is known for his work in computer science, mathematics, and in theoretical physics. He is the author of the book \"A New Kind of Science.\" In 2012 he was named an inaugural fellow of the American Mathematical Society. <sep> Hypothesis: Stephen Wolfram is the author of several books regarding physics and mathematics.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-8a12c70eab0144e0b181eb478e930350", "input": "Premise: Idrees Kenyatta Walker (born February 1, 1979) is a former professional American football player who was an offensive tackle in the National Football League (NFL) for six seasons. Walker played college football for the University of Florida. A first-round pick in the 2001 NFL Draft, he played professionally for the Tampa Bay Buccaneers of the NFL. <sep> Hypothesis: Idrees Kenyatta Walker played baseball.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-86a12fff784f4fc585955699993832fc", "input": "Premise: The Burial Mound (\"Kj\u00e6mpeh\u00f8jen\") was Henrik Ibsen's second play and his first play to be performed. It is a three-act verse drama, written in 1850 when Ibsen was 22 years old. The play was first performed at the Christiania Theater on 26 September 1850, under Ibsen's pseudonym Brynjolf Bjarme. <sep> Hypothesis: Henrik Ibsen was born in 1828", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-24197effe1b74f03b21d0f6d3e5ac094", "input": "Premise: We Have Always Lived in the Castle is an upcoming American mystery thriller film directed by Stacie Passon and written by Passon and Mark Kruger, based on the 1962 novel of the same name by Shirley Jackson. The film stars Taissa Farmiga, Alexandra Daddario, Crispin Glover, and Sebastian Stan. <sep> Hypothesis: We Have Always Lived in the Castle came out in 2018.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-45a3b84c38ca4b169353d139320ea974", "input": "Premise: Star Wars: Episode II \u2013 Attack of the Clones is a 2002 American epic space opera film directed by George Lucas and written by Lucas and Jonathan Hales. It is the second installment of the \"Star Wars\" prequel trilogy, and stars Ewan McGregor, Natalie Portman, Hayden Christensen, Ian McDiarmid, Samuel L. Jackson, Christopher Lee, Temuera Morrison, Anthony Daniels, Kenny Baker and Frank Oz. <sep> Hypothesis: Star Wars: Episode II \u2013 Attack of the Clones is a 2002 American epic space opera film directed by Lucas and Jonathan Hales and written by George Lucas", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-6966ad0f118347bba45c4b1177072960", "input": "Premise: Shanghai is a series of action comedy films based on the characters written by Alfred Gough and Miles Millar. The series includes: \"Shanghai Noon\" (2000), \"Shanghai Knights\" (2003), and the upcoming \"Shanghai Dawn\" (TBA). It stars Jackie Chan and Owen Wilson as the Chinese Imperial guard Chon Wang and the American bandit Roy O'Bannon. The series combined has grossed over $187 million. <sep> Hypothesis: Shanghai is a series of comedy films staring Jackie Chan and Chon Wang.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-618eec0946b644de85634cba8a719736", "input": "Premise: Baywatch is a 2017 American action comedy film directed by Seth Gordon and based on the television series of the same name. Written by Mark Swift and Damian Shannon, the film stars Dwayne Johnson, Zac Efron, Priyanka Chopra, Alexandra Daddario, Kelly Rohrbach and Jon Bass. The plot follows lifeguard Mitch Buchannon and his team, who in an effort to save their beach have to take down a druglord. <sep> Hypothesis: Dwayne Johnson and Zac Efron play lifeguards in Baywatch.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-f0659e2a581c4e42bb53e88a1f3f9300", "input": "Premise: Dean Carroll Jones (January 25, 1931 \u2013 September 1, 2015) was an American actor best known for his roles as Agent Zeke Kelso in \"That Darn Cat!\" (1965), Jim Douglas in \"The Love Bug\" (1968), Albert Dooley in \"The Million Dollar Duck\" (1971; for which he received a Golden Globe nomination) and Dr. Herman Varnick in \"Beethoven\" (1992). <sep> Hypothesis: Dean Carroll Jones lived in the UK in his early twenties", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-b8212f2e846f46189719e660c0c3bc2c", "input": "Premise: Robert L. Hass (born March 1, 1941) is an American poet. He served as Poet Laureate of the United States from 1995 to 1997. He won the 2007 National Book Award and shared the 2008 Pulitzer Prize for the collection \"Time and Materials: Poems 1997-2005.\" In 2014 he was awarded the Wallace Stevens Award from the Academy of American Poets. <sep> Hypothesis: Robert Hass is still writing Poems.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-28ee6b26dfab44bc96c5658ee4dc88ed", "input": "Premise: The Rossendale Free Press is a weekly newspaper published in Rossendale, Lancashire, England and distributed in Rossendale's four main towns of Rawtenstall, Bacup, Haslingden, and Ramsbottom. It is owned by Manchester Evening News Media, which publishes 19 other newspapers, and its current circulation is 14,369. <sep> Hypothesis: The Rossendale Free Press publishes more than 19 newspapers", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-8055154d7fcc403ca76d16988e37a2d9", "input": "Premise: Ronald Lawrence \"Ron\" Kovic (born July 4, 1946) is an American anti-war activist, writer, and former United States Marine Corps sergeant, who was wounded and paralyzed in the Vietnam War. He is best known as the author of his 1976 memoir \"Born on the Fourth of July\", which was made into the Academy Award\u2013winning eponymous film in 1989 directed by Oliver Stone. <sep> Hypothesis: Ronald Lawrence hate united states marine corps", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-2f7582c17899479092de8aefc0d9c1d9", "input": "Premise: Westfield Group was an Australian shopping centre company that existed from 1960 to 2014, when it split into two independent companies: Scentre Group, which now owns and operates the Australian and New Zealand Westfield shopping centre portfolio; and Westfield Corporation which owns and operates the UK, Europe and US portfolio. <sep> Hypothesis: Westfield Group started in 1961-2014.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-3797bc5f032842c2bae24db8bf25a9d2", "input": "Premise: James Risen (born April 27, 1955) is an American journalist for \"The New York Times\" who previously worked for the \"Los Angeles Times\". He has written or co-written many articles concerning U.S. government activities and is the author or co-author of two books about the Central Intelligence Agency (CIA) and a book about the American public debate about abortion. Risen is a Pulitzer Prize winner. <sep> Hypothesis: James Risen won a Pulitzer Prize for his work with The New York Times", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-656f125ed3f64a1db7b29e2b51b75870", "input": "Premise: Ron Hardy (8 May 1958 - 2 March 1992) was a Chicago DJ and producer of early house music. He is well known for playing records at the Muzic Box, a Chicago house music club. Decades after his death, he also is recognized for his edits and mixes of disco, soul music, funk and early house music. <sep> Hypothesis: Ron Hardy was born in May", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-55ebae7516b144e7ab262c759ad7f0d8", "input": "Premise: \"Blinded\" is a song by American alternative rock band Third Eye Blind. It was released in April 2003 as the lead single from their 2003 album, \"Out of the Vein\". It was written by Stephan Jenkins, Arion Salazar, and Tony Fredianelli. The song received positive reviews from music critics and peaked at number 34 on the \"Billboard\" Pop Songs chart. <sep> Hypothesis: It has been less than 15 years since \"Blinded\" was released.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-3c61850d59dc469fa48c70cc958df0f1", "input": "Premise: Montana is represented in the US House of Representatives by one at-large congressional district, among the 435 in the U.S. Congress. The district is the largest U.S. congressional district by population, with just over 1 million constituents. It is also the second-largest by land area, after Alaska's at-large congressional district. <sep> Hypothesis: There are 434 at-large congressional districts in the US, besides Montana", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-85790f8d20324446befaeca25efa0888", "input": "Premise: A. Eugene \"Gene\" Haylett (c. 1904 \u2013 ?) was an American football coach. He served as the 22nd head football coach at Doane College in Crete, Nebraska and he held that position for nine seasons, from 1933 until 1941. His coaching record at Doane was 34\u201330\u20138. <sep> Hypothesis: Eugene \"Gene\" Haylett lost 30 games at Doane.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-3b1f947626a64a82a061d1f6b9b8f04f", "input": "Premise: Edna Krabappel-Flanders is a fictional character from the animated television series \"The Simpsons\", who was voiced by Marcia Wallace until her death in 2013. She is the teacher of Bart Simpson's 4th grade class at Springfield Elementary School, and Ned Flanders's wife in later seasons. <sep> Hypothesis: Edna Krabappel-Flanders was married to Ned Flanders since the beginning of the Simpsons.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-512a33e562e9417f9b08fd1b5910d1f8", "input": "Premise: KAUJ (100.9 FM, \"Oldies 101\") is a radio station licensed to serve Grafton, North Dakota. The station is owned by Simmons Broadcasting Inc. It airs an Oldies music format featuring satellite-fed programming from Scott Shannon's The True Oldies Channel from ABC Radio. <sep> Hypothesis: KAUJ specializes in playing music that was not recently released.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-f9e2d8fbcb39417c97e982a47752b88f", "input": "Premise: Commander Christine Jones (born 1964 or 1965) is a senior British police officer serving with London's Metropolitan Police Service (\"the Met\"). As of 2014, she is the Met's senior officer responsible for mental health and for domestic violence; she also the leads the Association of Chief Police Officers' (ACPO) National Mental Health Working Group. <sep> Hypothesis: Christine Jones began serving with London's Metropolitan Police Service in 1964.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-68d503d2f3d24a5dba248e6e99a98ee8", "input": "Premise: Hertfordshire ( ; often abbreviated Herts) is a county in southern England, bordered by Bedfordshire to the north, Cambridgeshire to the north-east, Essex to the east, Buckinghamshire to the west and Greater London to the south. For government statistical purposes, it is placed in the East of England region. <sep> Hypothesis: Hertfordshire is centrally located to other known cities.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-4f8c462f42b54ce49c10d8de12871275", "input": "Premise: Parma Airport (Italian: \"Aeroporto di Parma\" , IATA: PMF,\u00a0ICAO: LIMP ) is located 1.3 NM northwest of Parma, a city in the Emilia-Romagna region of Italy. The airport was opened on 5 May 1991. It is also known as Giuseppe Verdi Airport or Parma \"Giuseppe Verdi\" Airport, named after Giuseppe Verdi. <sep> Hypothesis: Parma airport was opened in the previous millennium.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-c984c56448414ec0bc192c7d21cdb935", "input": "Premise: Milton Teagle \"Richard\" Simmons (born July 12, 1948) is an American fitness guru, actor, and comedian. He promotes weight-loss programs, prominently through his \"Sweatin' to the Oldies\" line of aerobics videos and is known for his eccentric, flamboyant, and energetic personality. <sep> Hypothesis: Milton Teagle \"Richard\" Simmons was an actor", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-72fefff8b0b44fdcaee331d3045e0516", "input": "Premise: Inertia is the second studio album by keyboardist Derek Sherinian, released in 2001 through InsideOut Music. This album marks the beginning of Sherinian's longtime collaborations with drummer Simon Phillips as well as guitarists Steve Lukather and Zakk Wylde. <sep> Hypothesis: Steve Lukather and Zakk Wylde both appeared on Derek Sherinians third studio album.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-713c5c5537bd4130bbc13576582b3348", "input": "Premise: Josh Bilicki (born June 3, 1995) is an American professional racing driver. He currently competes part-time in the NASCAR Xfinity Series, driving the No. 40 Chevrolet Camaro for MBM Motorsports and the Nos. 8 and 78 Camaros for B. J. McLeod Motorsports, and part-time in the Monster Energy NASCAR Cup Series, driving the No. 51 Chevrolet SS for Rick Ware Racing. <sep> Hypothesis: Josh Bilicki is around 24 years old.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-cd4633e011dd42769b8c6def50cf1ae6", "input": "Premise: William Thomas Harris (December 3, 1931 \u2013 May 28, 2011) was a Canadian pitcher in Major League Baseball who played for the Brooklyn and the Los Angeles Dodgers teams. Listed at 5 ft , 187 lb , Harris batted left-handed and threw right-handed. Born in Duguayville, New Brunswick, he attended Dorchester School. <sep> Hypothesis: William Thomas Harris only speaks English", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-e23eb854ecfd450788ba1e6b06971c47", "input": "Premise: Mei Foo () is a Hong Kong MTR station located in Mei Foo Sun Chuen, Lai Chi Kok, New Kowloon. It is an interchange station between the Tsuen Wan\u00a0Line and the West Rail\u00a0Line, situated between Lai Chi Kok and Lai King stations on the Tsuen Wan Line and Nam Cheong Station and Tsuen Wan West stations on the West Rail Line. Mei Foo Station's livery is blue. <sep> Hypothesis: Mei Foo Station is located in China.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-b74de621e8e34718945d0039723b446e", "input": "Premise: Jia Zhangke (born 24 May 1970) is a Chinese film director and screenwriter. He is generally regarded as a leading figure of the \"Sixth Generation\" movement of Chinese cinema, a group that also includes such figures as Wang Xiaoshuai, Lou Ye, Wang Quan'an and Zhang Yuan. <sep> Hypothesis: Jia Zhangke turned 10 years old in 1980.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-24582a4d3abf43f2855286b916bcfd46", "input": "Premise: Luis Moglia Barth (April 12, 1903 - June 18, 1984 in Buenos Aires) was an Argentine film director and screenwriter, and one of the influential directors in the Cinema of Argentina of the classic era. He directed some 30 films between 1927 and 1959, often screenwriting for his pictures. <sep> Hypothesis: Luis Moglia Barth directed some 30 films from the ages of 15 to 30.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-c9ac63a7cef84849800dbb42443f23a4", "input": "Premise: Melophobia is the third studio album by American rock band Cage the Elephant. Recorded at St. Charles in Nashville, Tennessee and produced by Jay Joyce, the album was released on October 8, 2013 through RCA Records. It is also the final album that features lead guitarist Lincoln Parish. <sep> Hypothesis: Melophobia came after Cage the Elephant's second album.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-17a030e9a8bd4ecaa0d2ac03c20b0d5e", "input": "Premise: Rosetta Stone Language Learning is proprietary computer-assisted language learning (CALL) software published by Rosetta Stone Inc. The software uses images, text, and sound to teach words and grammar by spaced repetition, without translation. Rosetta Stone calls its approach Dynamic Immersion (a term which has been trademarked). <sep> Hypothesis: Rosetta Stone is a proprietary software designed to be used to learn foreign languages primarily relying on softcover books.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-6f7e01239e5b4aecb74cd03b538f4e79", "input": "Premise: Wye Bridge Ward was one of four wards in the town of Monmouth, Monmouthshire, Wales. Streets in the ward included St Mary's Street, Almshouse Street, St James Street, St James Square, Whitecross Street and Monk Street. The ward existed as a division of the town by the early seventeenth century, and continued into the twentieth century. <sep> Hypothesis: The ward existed as a division of the town from 1620 through the twentieth century.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-68eb9779a093446f811bd5a68d24594d", "input": "Premise: A Mother's Gift is a 2001 novel by pop music singer Britney Spears and her mother, Lynne Spears. It is their second book together, following 2000's \"Heart-to-Heart\". The novel is loosely based on Britney's life. Popular reactions to the novel in spaces like Amazon were mixed. In 2012, rumors of a third novel sequel surfaced. <sep> Hypothesis: A Mother's Gift came out before Heart-to-Heart.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-7a2d0be4850a4b37a7eda3bf8424ab15", "input": "Premise: The 2006 Big East Men's Basketball Championship was played from March 8 to March 11, 2006. The tournament took place at Madison Square Garden in New York City. It was a single-elimination tournament with four rounds. Villanova and Connecticut tied for the best regular season conference record. Based on tie-breakers, Connecticut was awarded the #1 seed.<br> <sep> Hypothesis: They played a single elimination game with four rounds and one tie-breaker.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-7aba763fd076460f818840a31519bcb2", "input": "Premise: John M. Donaldson (January 17, 1854 \u2013 December 20, 1941) was an American architect and artist born on January 17, 1854, in Stirling, Scotland. Donaldson was principal designer of the successful Detroit-based architectural firm Donaldson and Meier from 1880 onwards. <sep> Hypothesis: Donaldson's principal in college was from Detroit", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-ab858aa203d84dffb55f4e404c0b7d0e", "input": "Premise: Edward John McClernand (December 29, 1848 \u2013 February 9, 1936) was a United States Army Brigadier General who was a recipient of the Medal of Honor for valor in action near the Bear Paw Mountains, Montana on September 30, 1877. An 1870 graduate of West Point, his career spanned 42 years, as he served in the Army until his retirement on December 29, 1912. <sep> Hypothesis: Edward John McClernand joined an Antarctic expedition.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-9b67d9a419fa409f98ce928ce5c9b5d9", "input": "Premise: The Chief of Defence of Denmark (Danish: Forsvarschefen ), under responsibility of the Defence minister, is the Chief of Defence and commander of the Royal Danish Army, the Royal Danish Navy and the Royal Danish Air Force. The Chief of Defence is the military adviser to the Defence minister and head of the Defence Command. <sep> Hypothesis: Reverends enjoy Danishes for breakfast", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-32515009635b4b3da8852c175893e0ec", "input": "Premise: Kinky is the self-titled album by Mexican group Kinky. It was released on March 26, 2002 on Nettwerk. The most popular song, Cornman, is part of the soundtrack for the PlayStation 3 video game LittleBigPlanet. Another of their songs, \"M\u00e1s\", is featured in the PS2 video game SSX 3 and in the 2004 film Man on Fire. <sep> Hypothesis: \"M\u00e1s\", is featured in the Play Station 2 video game.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-9774f25b91b343a295472af2d3efbdd8", "input": "Premise: Randall Park (born March 23, 1974) is an American actor, comedian, writer, and director. He played Kim Jong-Un in the 2014 film \"The Interview\", Minnesota governor Danny Chung in \"Veep\", and beginning in 2015 he portrayed Eddie Huang's father, American restaurateur Louis Huang, in ABC's television show \"Fresh Off the Boat\". <sep> Hypothesis: The character Louis Huang was played by an actor over 50 years old.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-fd278fd0a1704b3786bba1d4f6eaf0ee", "input": "Premise: Ancud (] ) is a city in southern Chile located in the northernmost part of the island and province of Chilo\u00e9, in Los Lagos Region. It is the second largest city of Chilo\u00e9 Archipelago after Castro. The city was established in 1768 to function as the capital of the archipelago and held that position until 1982. <sep> Hypothesis: Castro is the largest city in Chile", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-c2b0a969d25b494ab16a552d212aff72", "input": "Premise: The 2013 Lux Style Awards, officially known as the 12th Lux Style Awards ceremony, presented by the Lux Style Awards honours the best films of 2012 and took place between October, 12 2013. This year, the city of Pakistan played host to the Pakistani Film Industry. <sep> Hypothesis: The 2013 Lux Style awards took lace in the fall.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-4f8608f03853460ea89c963b7da71b0d", "input": "Premise: \"Call My Name\" is a song recorded by Pietro Lombardi from his first studio album \"Jackpot\" (2011). The song is the debut single of the winner of the eighth season of Deutschland sucht den Superstar (\"DSDS\"). It was written and produced by \"DSDS\" jury member Dieter Bohlen. The song was released on May 7, 2011. <sep> Hypothesis: \"Call my Name\" was written and recorded by Pierrot Lombardi for his album \"Jackpot\".", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-b7b851ca74d648b18a4e75d55f89491c", "input": "Premise: Rina is a feminine given name with multiple origins. It is also a feminine name in the Sanskrit language meaning \"melted\" or \"dissolved\", and is also a Hebrew name meaning \"song; joy\". The name Rina is also a Russian hypocoristic for \"Ekaterina\" and is a feminine given name of Japanese origins, where it was proportionately used the most in the twentieth century. <sep> Hypothesis: More people named Rina were born in the twentieth century than any other time.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-8874a7f9fff74a5bb1b70bd5d144b839", "input": "Premise: Arenda Troutman (born 1957) was the Democratic alderman of the 20th Ward in Chicago. She was appointed to her position by Mayor Richard M. Daley in 1990, to fill a vacancy after the death of Alderman Ernest Jones. Troutman was the 16th woman to serve as a Chicago alderman. Despite her arrest and indictment on bribery charges, Troutman ran for alderman in 2007; she lost. <sep> Hypothesis: 25 year old Arenda Troutman ran for alderman in 2007.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-ee9f040329814549b369653a12fd22a9", "input": "Premise: Texas' Nineteenth Congressional District of the United States House of Representatives is a Congressional district that serves the upper midwestern portion of the state of Texas The district includes portions of the State from Lubbock to Abilene. The current Representative from the 19th District is Republican Jodey Arrington. <sep> Hypothesis: Texas has more than 10 congressional districts.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-2b66ff560d6c4602b6255609ede96510", "input": "Premise: Finding Neverland is the original soundtrack album, on the Decca label, of the 2004 film \"Finding Neverland\" starring Johnny Depp, Kate Winslet, Julie Christie, Radha Mitchell and Dustin Hoffman. The original score and songs were composed and produced by Jan A. P. Kaczmarek. <sep> Hypothesis: Johnny Depp composed the songs in the soundtrack for the movie \"Finding Neverland\".", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-8256a5a52e1940b196118264cfd0531b", "input": "Premise: 4th (County Fermanagh) Battalion, Ulster Defence Regiment (4 UDR) was formed in 1970 as part of the 7 original battalions specified in The Ulster Defence Regiment Act 1969, which received Royal Assent on 18 December 1969 and was brought into force on 1 January 1970. It was amalgamated with the 6th Battalion, Ulster Defence Regiment in 1992 to form the 4th/6th Battalion, Ulster Defence Regiment. <sep> Hypothesis: 4th (County Fermanagh) Battalion, Ulster Defence Regiment (4 UDR) was formed on 18 December 1969.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-f2ed7fdd42914049838aaa00dcb31b11", "input": "Premise: Vernon Deloss Walker (August 14, 1931 \u2013 April 19, 1996) was a notable advertising executive and political campaign consultant. Walker founded the Memphis, Tennessee-based advertising firm Walker + Associates, Inc. in October 1965. Walker played a major role in politics, corporate marketing and philanthropy throughout the South from the 1960s to 1990s. <sep> Hypothesis: Vernon Walker mostly campaigned in the New England States.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-f1824d1b5fa84ad3bf1f2904d6245a3f", "input": "Premise: Peter Franklin Paul (born September 2, 1948) is a former lawyer and entrepreneur who was convicted for conspiracy and drug dealing, and later for securities fraud in connection with his business dealings with \"Spider-Man\" co-creator Stan Lee. He has repeatedly brought suit against Hillary Clinton, accusing her of lying about donations he solicited on behalf of her 2000 senatorial campaign. <sep> Hypothesis: In addition to practicing law, Peter Franklin Paul has also worked a businessman during his lifetime. ", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-b81f25b663554d72bdf3e4a197e01025", "input": "Premise: Word of Mouth is the third studio album by English-Irish boy band The Wanted. The album was released worldwide via Island Records on 4 November 2013. The album was preceded by the release of six singles: \"Chasing the Sun\", \"I Found You\", \"Walks Like Rihanna\", \"We Own the Night\", \"Show Me Love (America)\" and \"Glow in the Dark\", the latter of which was released two weeks prior to the album. <sep> Hypothesis: \"Chasing the Sun\" was on of six singles which preceded Word of Mouth, and was released three weeks prior to the Word of Mouth album.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-36dff548c2b740668ae9dc51579d0e7d", "input": "Premise: JoAnne Russell (born October 30, 1954) is an American former professional tennis player. With playing partner Helen Gourlay Cawley, she won the Wimbledon Ladies' Doubles title in 1977. They beat the team of Chris Evert and Rosie Casals in the first round and the top-ranked team of Martina Navratilova and Betty St\u00f6ve in the final (6\u20133, 6\u20133). Russell reached a career-high singles ranking of No. 22. <sep> Hypothesis: The 1977 Wimbledon Ladies' Double Title winners won the finals off a 5-2 match.", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-5efce778e98143078f75f1900d9f95a2", "input": "Premise: Lars Onsager (November 27, 1903 \u2013 October 5, 1976) was a Norwegian-born American physical chemist and theoretical physicist. He held the Gibbs Professorship of Theoretical Chemistry at Yale University. He was awarded the Nobel Prize in Chemistry in 1968. <sep> Hypothesis: Lars Onsager won the Nobel prize when he was 30 years old", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1385_anli_r1_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise sentence. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". The model should output \"Entailment\" when the hypothesis sentence entails the given premise. The model should output \"Contradiction\" when the hypothesis sentence contradicts the given premise. The model should output \"Neutral\" when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1385-b1a15f7f7f294fd7a3b729ceef693706", "input": "Premise: Stephen Thomas Ward (19 October 1912 \u2013 3 August 1963) was an English osteopath and artist who was one of the central figures in the 1963 Profumo affair, a British political scandal which brought about the resignation of John Profumo, the Secretary of State for War, and contributed to the defeat of the Conservative government a year later. <sep> Hypothesis: Stephen Thomas Ward was born in October", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-6843dcc4bb96415d944b6fba6a53e3d2", "input": "Premise: \u0622\u0631\u0647 \u0645\u0646 \u062f\u0631 \u06a9\u0627\u0631\u0648\u0644\u06cc\u0646\u0627\u06cc \u0634\u0645\u0627\u0644\u06cc \u0647\u0633\u062a\u0645. <sep> Hypothesis: \u0645\u0646 \u062f\u0631 \u06a9\u0627\u0631\u0648\u0644\u06cc\u0646\u0627\u06cc \u062c\u0646\u0648\u0628\u06cc \u0647\u0633\u062a\u0645.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-f482d3dbe04b4047bc415db9766c5971", "input": "Premise: \u0628\u0631\u0627\u06cc \u0627\u06cc\u0646 \u06a9\u0627\u0631 \u0686\u0647 \u06a9\u0627\u0631\u06cc \u0627\u0646\u062c\u0627\u0645 \u062f\u0627\u062f\u0647 \u0627\u0646\u062f \u0622\u06cc\u0627 \u0645\u062c\u0628\u0648\u0631 \u0634\u062f\u0647 \u0627\u0646\u062f \u0622\u0646 \u0631\u0627 \u0631\u06cc\u062e\u062a\u0647 \u0648 <sep> Hypothesis: \u0622\u0646\u0647\u0627 \u0628\u0631\u0627\u06cc \u062f\u0633\u062a\u06cc\u0627\u0628\u06cc \u0628\u0647 \u0627\u06cc\u0646 \u06a9\u0627\u0631 \u0627\u0632 \u0686\u0647 \u0631\u0648\u0634\u06cc \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u06a9\u0631\u062f\u0647 \u0627\u0646\u062f. \u0622\u06cc\u0627 \u0686\u06cc\u0632\u06cc \u062f\u0631\u0648\u0646 \u0642\u0627\u0644\u0628 \u0631\u06cc\u062e\u062a\u0647 \u0634\u062f \u06cc\u0627 \u0641\u0634\u0631\u062f\u0647 \u0634\u062f\u061f", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-cb7a4a4651cd4994a4e9f5b589731b90", "input": "Premise: \u0686\u0646\u062f\u06cc\u0646 \u0628\u0633\u062a\u0647 \u0627\u0644\u062d\u0627\u0642\u06cc \u0628\u0631\u0627\u06cc \u0627\u06cc\u0646 \u0628\u0627\u0632\u06cc \u0639\u0631\u0636\u0647 \u0634\u062f\u0647\u200c\u0627\u0633\u062a. <sep> Hypothesis: \u0627\u06cc\u0646 \u0628\u0633\u062a\u0647 \u0647\u0627 \u0628\u0627\u06cc\u062f \u0647\u0631 \u0686\u0647 \u0632\u0648\u062f\u062a\u0631 \u062f\u0631 \u0627\u062e\u062a\u06cc\u0627\u0631 \u0645\u0634\u062a\u0631\u06a9\u0647\u0627 \u0642\u0631\u0627\u0631 \u0628\u06af\u06cc\u0631\u0646\u062f. ", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-476b9dc4f3854b678dfcf26725bc15dc", "input": "Premise: \u0627\u064a\u0646 \u0648\u0627\u0639\u0638\u060c \u06a9\u0647 \u0631\u0648\u0632 \u067e\u0646\u062c\u0634\u0646\u0628\u0647 \u062f\u0631 \u0644\u0628\u0646\u0627\u0646 \u0628\u0631\u0627\u06cc \u0628\u0627\u0632\u062c\u0648\u0626\u06cc \u062a\u0648\u0642\u064a\u0641 \u0634\u062f\u0647 \u0628\u0648\u062f \u060c \u0627\u0645\u0627 \u0627\u0645\u0631\u0648\u0632 \u0622\u0632\u0627\u062f \u0634\u062f\u0647 \u0627\u0633\u062a\u060c \u067e\u064a\u0634 \u0627\u0632 \u0622\u0646\u06a9\u0647 \u0628\u0631\u064a\u062a\u0627\u0646\u064a\u0627 \u0631\u0627 \u062a\u0631\u06a9 \u06a9\u0646\u062f \u06af\u0641\u062a\u0647 \u0628\u0648\u062f \u0627\u06af\u0631 \u0645\u064a\u062f\u0627\u0646\u0633\u062a \u06a9\u0647 \u0645\u0633\u0644\u0645\u0627\u0646\u06cc \u0633\u0631\u06af\u0631\u0645 \u0628\u0631\u0646\u0627\u0645\u0647 \u0631\u064a\u0632\u06cc \u0628\u0631\u0627\u06cc \u0628\u0645\u0628 \u06af\u0630\u0627\u0631\u06cc \u0627\u0633\u062a \u062d\u0627\u0636\u0631 \u0646\u0645\u064a\u0634\u062f \u067e\u0644\u064a\u0633 \u0631\u0627 \u0628\u0627 \u062e\u0628\u0631 \u06a9\u0646\u062f. <sep> Hypothesis: \u0631\u06cc\u06cc\u0633 \u067e\u0644\u06cc\u0633 \u0636\u062f \u062a\u0631\u0648\u0631\u06cc\u0633\u0645 \u0642\u0628\u0644 \u0627\u0632 \u0627\u06cc\u0646 \u062d\u0627\u062f\u062b\u0647 \u0627\u0632 \u0633\u0645\u062a \u062e\u0648\u062f \u0627\u0633\u062a\u0639\u0641\u0627 \u062f\u0627\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-35166277e9fb4a7997fbf9d04512ced5", "input": "Premise: \u0627\u06cc\u0646 \u06a9\u0627\u0644\u0627\u06cc \u0633\u0631\u0645\u0627\u06cc\u0647\u200c\u0627\u06cc \u0627\u062d\u062a\u0645\u0627\u0644\u0627 \u0645\u062f\u062a\u06cc \u062a\u062d\u062a \u0641\u0634\u0627\u0631 \u062e\u0648\u0627\u0647\u062f \u0645\u0627\u0646\u062f.\u0645\u0639\u0627\u0645\u0644\u0647\u200c\u06af\u0631\u0627\u0646 \u0628\u0627\u0632\u0627\u0631\u0647\u0627\u06cc \u0633\u0647\u0627\u0645 \u0647\u0645\u06cc\u0634\u0647 \u0627\u0632 \u0633\u06cc\u0627\u0633\u062a\u200c\u0647\u0627\u06cc \u0627\u0646\u0642\u0628\u0627\u0636\u06cc \u06a9\u0647 \u0633\u0631\u0645\u0627\u06cc\u0647 \u062f\u0631 \u062c\u0631\u06cc\u0627\u0646 \u0622\u0646\u0647\u0627 \u0631\u0627 \u06a9\u0627\u0647\u0634 \u0645\u06cc\u200c\u062f\u0647\u062f \u0628\u06cc\u0632\u0627\u0631\u0646\u062f\u060c \u06af\u0631\u0686\u0647 \u0627\u0632 \u06a9\u0627\u0647\u0634 \u0627\u0628\u0647\u0627\u0645 \u062f\u0631\u0628\u0627\u0631\u0647 \u0633\u06cc\u0627\u0633\u062a\u200c\u0647\u0627\u06cc \u067e\u0648\u0644\u06cc \u0627\u0633\u062a\u0642\u0628\u0627\u0644 \u0645\u06cc\u200c\u06a9\u0646\u0646\u062f. <sep> Hypothesis: \u0645\u0639\u0627\u0645\u0644\u0647\u200c\u06af\u0631\u0627\u0646 \u062e\u0648\u0627\u0647\u0627\u0646 \u0627\u0628\u0647\u0627\u0645 \u062f\u0631 \u0633\u06cc\u0627\u0633\u062a\u200c\u0647\u0627\u06cc \u0645\u0627\u0644\u06cc \u0647\u0633\u062a\u0646\u062f", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-31e34298e30f47d9b3ff112484d4fce5", "input": "Premise: \u0622\u0644\u0628\u0648\u0645 \u0627\u0645\u06cc\u0631 \u0628\u06cc \u06af\u0632\u0646\u062f \u0628\u0627 \u0635\u062f\u0627\u06cc \u0645\u062d\u0633\u0646 \u0686\u0627\u0648\u0634\u06cc \u0645\u0646\u062a\u0634\u0631 \u0634\u062f. <sep> Hypothesis: \u0622\u0644\u0628\u0648\u0645 \u0627\u0645\u06cc\u0631 \u0628\u06cc \u06af\u0632\u0646\u062f \u0628\u0627 \u0635\u062f\u0627\u06cc \u0645\u062d\u0633\u0646 \u0627\u0645\u06cc\u0631\u06cc \u0645\u0646\u062a\u0634\u0631 \u0634\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-f675d8238a044260877c4cffea304d8d", "input": "Premise: \u0633\u067e\u0633 \u0627\u0648 \u0686\u06cc\u0632\u06cc \u0631\u0627 \u06a9\u0647 \u0645\u0646 \u062f\u0631 \u067e\u0644\u0627\u06a9 \u06f1\u06f8\u06f6 \u062e\u06cc\u0627\u0628\u0627\u0646 \u0645\u0646\u0686\u0633\u062a\u0631 \u062f\u0631\u0628\u0627\u0631\u0647\u200c\u06cc \u0628\u0647 \u0622\u0646 \u062a\u0644\u06af\u0631\u0627\u0645 \u062c\u0639\u0644\u06cc \u06a9\u0647 \u062e\u0627\u0646\u0645 Cowley \u0631\u0627 \u0641\u0631\u06cc\u0628 \u062f\u0627\u062f\u0647 \u0628\u0648\u062f \u06af\u0641\u062a\u0647 \u0628\u0648\u062f\u0645\u060c \u0628\u0647 \u0645\u0646 \u06cc\u0627\u062f\u0622\u0648\u0631\u06cc \u06a9\u0631\u062f. <sep> Hypothesis: \u062e\u0627\u0646\u0645 \u06a9\u0648\u0644\u06cc \u0628\u0627 \u062a\u0644\u06af\u0631\u0627\u0645 \u062f\u0631\u0648\u063a\u06cc\u0646 \u0641\u0631\u06cc\u0628 \u0646\u062e\u0648\u0631\u062f\u0647 \u0628\u0648\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-cf7ef743ad68435a8e78db5f8ab34ef9", "input": "Premise: \u06cc\u06a9\u06cc \u0627\u0632 \u0645\u0647\u0645\u200c\u062a\u0631\u06cc\u0646 \u0645\u0631\u0627\u062d\u0644 \u06a9\u0627\u0631 \u0645\u062d\u06a9\u0645\u200c\u0633\u0627\u0632\u06cc \u062f\u06cc\u0648\u0627\u0631\u0647\u200c\u0647\u0627 \u0648 \u0633\u0642\u0641 \u062a\u0648\u0646\u0644 \u067e\u0633 \u0627\u0632 \u062d\u0641\u0631 \u0627\u0633\u062a. <sep> Hypothesis: \u0645\u062d\u06a9\u0645 \u0633\u0627\u0632\u06cc \u062f\u06cc\u0648\u0627\u0631\u0647 \u0647\u0627 \u0648 \u0633\u0642\u0641 \u062a\u0648\u0646\u0644 \u067e\u0633 \u0627\u0632 \u062d\u0641\u0631 \u0632\u06cc\u0627\u062f \u062d\u0627\u0626\u0632 \u0627\u0647\u0645\u06cc\u062a \u0646\u06cc\u0633\u062a.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-95bf8c9cafb943309fa3bb0ba8e9c39d", "input": "Premise: \u0628\u0627 \u0648\u062c\u0648\u062f \u0622\u0646\u200c\u06a9\u0647 \u0627\u0633\u0627\u0633 \u0622\u0646 \u062a\u0639\u0644\u06cc\u0645\u0627\u062a \u0628\u0631 \u062a\u0641\u0633\u06cc\u0631 \u062f\u0627\u0648\u0648\u062f \u0642\u06cc\u0633\u0631\u06cc \u0628\u0631 \u0641\u0633\u0648\u0633 \u0628\u0646\u0627 \u0634\u062f\u0647 \u0628\u0648\u062f\u060c \u0627\u0645\u0627 \u062e\u0645\u06cc\u0646\u06cc \u062a\u0623\u06cc\u06cc\u062f \u06a9\u0631\u062f\u0647\u200c\u0627\u0633\u062a \u06a9\u0647 \u0634\u0627\u0647\u200c\u0622\u0628\u0627\u062f\u06cc \u0628\u062e\u0634\u06cc \u0627\u0632 \u0628\u06cc\u0646\u0634 \u0648 \u0628\u0635\u06cc\u0631\u062a \u0634\u062e\u0635\u06cc \u062e\u0648\u062f \u0631\u0627 \u0646\u06cc\u0632 \u062f\u0631 \u0627\u06cc\u0646 \u0622\u0645\u0648\u0632\u0634 \u062f\u062e\u06cc\u0644 \u06a9\u0631\u062f\u0647\u200c\u0628\u0648\u062f. <sep> Hypothesis: \u0628\u0639\u062f \u0627\u0632 \u0622\u0646\u060c \u0628\u0647\u200c\u062f\u0646\u0628\u0627\u0644 \u062f\u0631\u062e\u0648\u0627\u0633\u062a\u200c\u0647\u0627\u06cc \u067e\u06cc\u0627\u067e\u06cc \u0627\u0648\u060c \u0634\u0627\u0647\u200c\u0622\u0628\u0627\u062f\u06cc \u0631\u0627\u0636\u06cc \u0645\u06cc\u200c\u0634\u0648\u062f \u06a9\u0647 \u0628\u0647 \u0627\u0648 \u0648 \u0686\u0646\u062f \u0637\u0644\u0628\u0647\u0654 \u0628\u0631\u06af\u0632\u06cc\u062f\u0647\u0654 \u062f\u06cc\u06af\u0631 \u0641\u0635\u0648\u0635\u200c\u0627\u0644\u062d\u06a9\u0645 \u0627\u0628\u0646 \u0639\u0631\u0628\u06cc \u0631\u0627 \u0622\u0645\u0648\u0632\u0634 \u062f\u0647\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-4e170fd074ae4490b67cd215017a61c4", "input": "Premise: \u062f\u0631 \u0647\u0645\u0627\u0646 \u0645\u0627\u0647\u060c \u062f\u0631 \u0627\u0646\u062c\u0645\u0646 \u0645\u0644\u06cc \u0635\u0627\u062d\u0628\u0627\u0646 \u0633\u06cc\u0646\u0645\u0627 \u062f\u0631 \u0644\u0627\u0633 \u0648\u06af\u0627\u0633\u060c \u06cc\u0648\u0646\u06cc\u0648\u0631\u0633\u0627\u0644 \u0627\u0639\u0644\u0627\u0645 \u06a9\u0631\u062f \u06a9\u0647 \u0641\u06cc\u0644\u0645 \"\u067e\u0646\u062c\u0627\u0647 \u0637\u06cc\u0641 \u062a\u0627\u0631\u06cc\u06a9\u062a\u0631\" \u062f\u0631 \u06f1\u06f0 \u0641\u0648\u0631\u06cc\u0647\u0654 \u06f2\u06f0\u06f1\u06f7 \u0648 \"\u067e\u0646\u062c\u0627\u0647 \u0637\u06cc\u0641 \u0622\u0632\u0627\u062f\u06cc\" \u062f\u0631 \u06f9 \u0641\u0648\u0631\u06cc\u0647\u0654 \u06f2\u06f0\u06f1\u06f8 \u0627\u06a9\u0631\u0627\u0646 \u062e\u0648\u0627\u0647\u0646\u062f \u0634\u062f.\n\u0627\u0645\u0627 \u062f\u0631 \u0647\u06cc\u0686\u200c\u06cc\u06a9 \u0627\u0632 \u0627\u06cc\u0646 \u062f\u0648 \u0641\u06cc\u0644\u0645\u060c \u0633\u0645 \u062a\u06cc\u0644\u0648\u0631 \u062c\u0627\u0646\u0633\u0648\u0646 \u06a9\u0627\u0631\u06af\u0631\u062f\u0627\u0646\u06cc \u06a9\u0627\u0631 \u0631\u0627 \u0639\u0647\u062f\u0647\u200c\u062f\u0627\u0631 \u0646\u062e\u0648\u0627\u0647\u062f \u0634\u062f. <sep> Hypothesis: \u062f\u0631 \u0647\u0645\u0627\u0646 \u0645\u0627\u0647\u060c \u062f\u0631 \u0627\u0646\u062c\u0645\u0646 \u0645\u0644\u06cc \u0635\u0627\u062d\u0628\u0627\u0646 \u0633\u06cc\u0646\u0645\u0627 \u062f\u0631 \u0644\u0627\u0633 \u0648\u06af\u0627\u0633\u060c \u06cc\u0648\u0646\u06cc\u0648\u0631\u0633\u0627\u0644 \u0627\u0639\u0644\u0627\u0645 \u06a9\u0631\u062f \u06a9\u0647 \u0641\u06cc\u0644\u0645 \"\u067e\u0646\u062c\u0627\u0647 \u0637\u06cc\u0641 \u062a\u0627\u0631\u06cc\u06a9\u062a\u0631\" \u062f\u0631 \u06f1\u06f0 \u0641\u0648\u0631\u06cc\u0647\u0654 \u06f2\u06f0\u06f1\u06f7 \u0648 \"\u067e\u0646\u062c\u0627\u0647 \u0637\u06cc\u0641 \u0622\u0632\u0627\u062f\u06cc\" \u062f\u0631 \u06f9 \u0641\u0648\u0631\u06cc\u0647\u0654 \u06f2\u06f0\u06f1\u06f8 \u0627\u06a9\u0631\u0627\u0646 \u062e\u0648\u0627\u0647\u0646\u062f \u0634\u062f.\n\u0648\u062f\u0631 \u0647\u0631 \u062f\u0648 \u0641\u06cc\u0644\u0645\u060c \u0633\u0645 \u062a\u06cc\u0644\u0648\u0631 \u062c\u0627\u0646\u0633\u0648\u0646 \u06a9\u0627\u0631\u06af\u0631\u062f\u0627\u0646\u06cc \u06a9\u0627\u0631 \u0631\u0627 \u0639\u0647\u062f\u0647\u200c\u062f\u0627\u0631 \u062e\u0648\u0627\u0647\u062f \u0634\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-1ef35337288f4345983ff64cee35177b", "input": "Premise: \u062f\u0627\u0645\u0646 \u06a9\u0648\u062a\u0627\u0647 \u0628\u0627 \u06a9\u0641\u0634 \u0647\u0627\u06cc \u067e\u0627\u0634\u0646\u0647 \u0628\u0644\u0646\u062f \u0632\u06cc\u0628\u0627\u062a\u0631 \u0627\u0633\u062a. <sep> Hypothesis: \u0645\u0646 \u0633\u0639\u06cc \u06a9\u0631\u062f\u0645 \u062f\u0631 \u0645\u062d\u0644 \u06a9\u0627\u0631 \u062f\u0627\u0645\u0646 \u06a9\u0648\u062a\u0627\u0647 \u0628\u067e\u0648\u0634\u0645 \u060c \u0627\u0645\u0627 \u06cc\u0627\u062f \u06af\u0631\u0641\u062a\u0645 \u06a9\u0647 \u0627\u06cc\u062f\u0647 \u062e\u0648\u0628\u06cc \u0646\u06cc\u0633\u062a.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-217543b38016455eb5dc568e320b3d62", "input": "Premise: \u0627\u0644\u0628\u062a\u0647 \u062d\u0627\u0636\u0631 \u0646\u06cc\u0633\u062a \u06a9\u0647 \u0631\u06cc\u0634\u0647\u200c\u06cc\u0627\u0628\u06cc \u06a9\u0646\u062f \u06a9\u0647 \u0686\u0631\u0627 \u0627\u06cc\u0646 \u0641\u0642\u0631 \u0628\u0647 \u0648\u062c\u0648\u062f \u0622\u0645\u062f\u0647 \u0627\u0633\u062a \u0648\u0644\u06cc \u0628\u0647 \u0644\u062d\u0627\u0638 \u062a\u0627\u06a9\u062a\u06cc\u06a9\u06cc \u0645\u06cc\u200c\u062e\u0648\u0627\u0647\u062f \u0627\u06cc\u0646 \u0645\u0633\u0627\u0644\u0647 \u0631\u0627 \u0628\u0631 \u0633\u0631 \u062f\u0648\u0644\u062a \u0628\u06a9\u0648\u0628\u062f \u0648 \u0622\u0646 \u0631\u0627 \u0645\u0642\u0635\u0631 \u062c\u0644\u0648\u0647 \u062f\u0647\u062f. <sep> Hypothesis: \u0647\u062f\u0641\u060c \u062a\u062e\u0631\u06cc\u0628 \u062f\u0648\u0644\u062a \u0627\u0633\u062a.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-afd397846d77447ab7dca0c36cfe06ad", "input": "Premise: \u0644\u0648\u0631\u0646\u0632\u0648 \u0628\u0627\u0634\u06a9\u0648\u0647 \u0648 \u0628\u0631\u0627\u062f\u0631\u0634 \u062c\u0648\u0644\u06cc\u0627\u0646\u0648 \u062f\u0631 \u0645\u0642\u0628\u0631\u0647 \u0647\u0627\u06cc \u0633\u0627\u062f\u0647 \u0627\u06cc \u062f\u0631 \u0632\u06cc\u0631 \u0645\u062c\u0633\u0645\u0647 \u0645\u0627\u062f\u0648\u0646\u0627 \u0648 \u06a9\u0648\u062f\u06a9 \u0642\u0631\u0627\u0631 \u062f\u0627\u0631\u0646\u062f. \u06a9\u0646\u0627\u0631 \u0627\u0646\u0647\u0627  \u0645\u062c\u0633\u0645\u0647 \u0647\u0627\u06cc \u0647\u0646\u0631\u0645\u0646\u062f\u0627\u0646 \u0628\u0627 \u0634\u0647\u0631\u062a \u06a9\u0645\u062a\u0631 \u0627\u0632 \u0637\u0631\u0641 \u0645\u0642\u062f\u0633\u06cc\u0646 \u062e\u0627\u0646\u0648\u0627\u062f\u0647 Cosmas \u0648 Damian \u0642\u0631\u0627\u0631 \u062f\u0627\u0631\u062f. <sep> Hypothesis: \u0644\u0648\u0631\u0646\u0632\u0648 \u0648 \u062c\u0648\u0644\u06cc\u0627\u0646\u0648 \u0628\u0627 \u06cc\u06a9\u062f\u06cc\u06af\u0631 \u0646\u0633\u0628\u062a\u06cc \u062f\u0627\u0631\u0646\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-6b4c3260caac45b9abce16f5a124b7d8", "input": "Premise: \u062f\u0631 \u0627\u0646\u062a\u0642\u0627\u062f \u0627\u0632 \u062a\u0648\u0627\u0646\u0627\u06cc\u06cc \u0642\u0627\u0646\u0648\u0646 \u0645\u062d\u0631\u0648\u0645\u06cc\u062a \u0628\u0631\u0627\u06cc \u0631\u062f \u06a9\u0631\u062f\u0646 \u0645\u062d\u0643\u0648\u0645\u06cc\u062a \u0627\u0648\u060c \u0627\u0634\u062a\u0628\u0627\u0647 \u0627\u0632 \u062c\u0633\u062a\u062c\u0648 \u0643\u0631\u062f\u0646 \u0628\u0648\u062f \u0648 \u0646\u0647  \u0645\u062d\u0643\u0648\u0645\u06cc\u062a. <sep> Hypothesis: \u06a9\u0627\u0631\u0627\u0634\u062a\u0628\u0627\u0647 \u062c\u0633\u062a\u062c\u0648 \u0628\u0648\u062f \u0648 \u0646\u0647 \u0645\u062d\u06a9\u0648\u0645\u06cc\u062a.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-a098812fa71c474e8392b3c62d163517", "input": "Premise: \u0628\u0627\u0646\u062f \u0622\u062f\u0645 \u0631\u0628\u0627\u064a\u0627\u0646 \u0645\u0633\u0626\u0648\u0644 \u0631\u0628\u0627\u064a\u0634  \u064a\u06a9 \u0632\u0648\u062c \u0628\u0644\u0698\u064a\u06a9\u06cc \u0646\u064a\u0632 \u0647\u0633\u062a\u0646\u062f. <sep> Hypothesis: \u0632\u0646 \u0648 \u0645\u0631\u062f\u06cc \u062a\u0627 \u0627\u0648\u0627\u0633\u0637 \u0633\u067e\u062a\u0627\u0645\u0628\u0631 \u062f\u0631 \u0627\u0633\u0627\u0631\u062a \u0627\u064a\u0646 \u0628\u0627\u0646\u062f \u0628\u0633\u0631 \u0645\u06cc \u0628\u0631\u062f\u0646\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-d22a409091b94696a7b0b4416f657e40", "input": "Premise: \u0647\u0641\u062a \u0633\u0627\u0644 \u0628\u0639\u062f \u0627\u0632 \u0633\u0627\u062e\u062a\u0647 \u0634\u062f\u0646 \u0627\u0648\u0644\u06cc\u0646 \u0628\u0627\u0644\u06af\u0631\u062f\u06cc \u06a9\u0647 \u0645\u06cc\u200c\u062a\u0648\u0627\u0646\u0633\u062a \u067e\u0631\u0648\u0627\u0632 \u06a9\u0646\u062f\u060c\n \u062f\u0648 \u0627\u0641\u0633\u0631 \u0646\u06cc\u0631\u0648\u06cc \u0647\u0648\u0627\u06cc\u06cc \u0645\u062c\u0627\u0631\u0633\u062a\u0627\u0646\u06cc \u0628\u0627\u0644\u06af\u0631\u062f\u06cc \u0633\u0627\u062e\u062a\u0646\u062f \n\u06a9\u0647 \u0627\u062a\u0641\u0627\u0642\u0627\u064b \u067e\u0631\u0648\u0627\u0632\u0647\u0627\u06cc \u0645\u062a\u0639\u062f\u062f\u06cc\n \u062f\u0631 \u0627\u0631\u062a\u0641\u0627\u0639\u0627\u062a \u0628\u0627\u0644\u0627 \u0627\u0646\u062c\u0627\u0645 \u062f\u0627\u062f\u060c\n \u0648\u0644\u06cc \u0647\u0631\u06af\u0632 \u0627\u062c\u0627\u0632\u0647\u0654 \u067e\u0631\u0648\u0627\u0632 \u0622\u0632\u0627\u062f \u0646\u062f\u0627\u0634\u062a\u0646\u062f. <sep> Hypothesis: \u0647\u0641\u062a \u0633\u0627\u0644 \u0628\u0639\u062f \u0627\u0632 \u0633\u0627\u062e\u062a\u0647 \u0634\u062f\u0646 \u0627\u0648\u0644\u06cc\u0646 \u0628\u0627\u0644\u06af\u0631\u062f\u06cc \u06a9\u0647 \u0645\u06cc\u200c\u062a\u0648\u0627\u0646\u0633\u062a \u067e\u0631\u0648\u0627\u0632 \u06a9\u0646\u062f\u060c\n \u062f\u0648 \u0627\u0641\u0633\u0631 \u0646\u06cc\u0631\u0648\u06cc \u0647\u0648\u0627\u06cc\u06cc \u0645\u062c\u0627\u0631\u0633\u062a\u0627\u0646\u06cc \u0628\u0627\u0644\u06af\u0631\u062f\u06cc \u0633\u0627\u062e\u062a\u0646\u062f \u06a9\u0647 \u0627\u062a\u0641\u0627\u0642\u0627\u064b \u067e\u0631\u0648\u0627\u0632\u0647\u0627\u06cc \u0645\u062a\u0639\u062f\u062f\u06cc\n \u062f\u0631 \u0627\u0631\u062a\u0641\u0627\u0639\u0627\u062a \u0628\u0627\u0644\u0627 \u0627\u0646\u062c\u0627\u0645 \u062f\u0627\u062f\u060c \u0648 \u0622\u0632\u0627\u062f\u0627\u0646\u0647 \u0628\u0647 \u0647\u0631 \u062c\u0627\u06cc\u06cc \u06a9\u0647 \u0645\u06cc \u062e\u0648\u0627\u0633\u062a\u0646\u062f \u067e\u0631\u0648\u0627\u0632 \u0622\u0632\u0627\u062f \u062f\u0627\u0634\u062a\u0646\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-b1267c64b77442128e132b96325ef3c8", "input": "Premise: \u0686\u0647 \u0686\u06cc\u0632\u06cc \u0639\u0648\u0636 \u0634\u062f\u061f <sep> Hypothesis: \u0686\u0647 \u0686\u06cc\u0632\u06cc \u0645\u0646\u062d\u0635\u0631 \u0628\u0647 \u0641\u0631\u062f \u0628\u0648\u062f\u061f", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-830db7ffeda44791be7b159a0c15403d", "input": "Premise: \u0628\u0647 \u06af\u0641\u062a\u0647 \u00ab\u067e\u0631\u0648\u06cc\u0632 \u0639\u0631\u0628\u00bb \u0627\u0632 \u062f\u0648\u0633\u062a\u0627\u0646 \u062a\u062e\u062a\u06cc \u062f\u0631 \u06af\u0641\u062a\u06af\u0648\u06cc \u062a\u0641\u0635\u06cc\u0644\u06cc \u0628\u0627 \u0627\u06cc\u0633\u0646\u0627\u060c \u0648\u06cc \u062e\u0648\u062f\u06a9\u0634\u06cc \u06a9\u0631\u062f\u0647\u200c\u0627\u0633\u062a: \u00ab\u0627\u0648 \u0642\u0631\u0635 \u0622\u0633\u067e\u0631\u06cc\u0646 \u0648 \u062a\u0631\u06cc\u0627\u06a9 \u0631\u0627 \u0628\u0627 \u0647\u0645 \u0645\u062e\u0644\u0648\u0637 \u06a9\u0631\u062f\u0647 \u0648 \u067e\u0633 \u0627\u0632 \u0631\u06cc\u062e\u062a\u0646 \u062f\u0631 \u0644\u06cc\u0648\u0627\u0646 \u0622\u0628\u060c \u0622\u0646 \u0631\u0627 \u062e\u0648\u0631\u062f\u0647 \u0628\u0648\u062f.\u00bb  <sep> Hypothesis: \u0645\u0631\u06af \u062a\u062e\u062a\u06cc \u062f\u0631 \u0647\u0627\u0644\u0647 \u0627\u06cc \u0627\u0632 \u0627\u0628\u0647\u0627\u0645 \u0642\u0631\u0627\u0631 \u062f\u0627\u0631\u062f \u0648 \u0646\u0645\u06cc\u0634\u0648\u062f \u0628\u0647 \u06af\u0641\u062a\u06c0 \u0647\u0631 \u06a9\u0633\u06cc \u0627\u0639\u062a\u0645\u0627\u062f \u06a9\u0631\u062f. ", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-8b9f6ddf707d4126bd1e0dba98976610", "input": "Premise: \u0642\u0627\u0646\u0648\u0646 \u062a\u063a\u06cc\u06cc\u0631 \u06a9\u0627\u0631\u0628\u0631\u06cc \u0641\u062f\u0631\u0627\u0644 \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f9\u06f9\u06f4 (FASA) (\u0642\u0627\u0646\u0648\u0646 \u0639\u0645\u0648\u0645\u06cc \u06f1\u06f0\u06f3-\u06f3\u06f5\u06f5) a \u0627\u06cc\u0646 \u0642\u0627\u0646\u0648\u0646 \u0622\u0698\u0627\u0646\u0633 \u0647\u0627 \u0631\u0627 \u0645\u0648\u0638\u0641 \u0645\u06cc\u06a9\u0646\u062f \u062a\u0627 \u0647\u0632\u06cc\u0646\u0647 \u0647\u0627 \u060c \u0628\u0631\u0646\u0627\u0645\u0647 \u0647\u0627 \u0648 \u0627\u0647\u062f\u0627\u0641 \u0639\u0645\u0644\u06a9\u0631\u062f\u06cc \u0631\u0627 \u0628\u0631\u0627\u06cc \u0628\u0631\u0646\u0627\u0645\u0647 \u0647\u0627\u06cc \u062e\u0631\u06cc\u062f \u0641\u062f\u0631\u0627\u0644 (\u0634\u0627\u0645\u0644 \u067e\u0631\u0648\u0698\u0647 \u0647\u0627\u06cc IT) \u062a\u0639\u0631\u06cc\u0641 \u06a9\u0646\u0646\u062f \u0648 \u0627\u06cc\u0646 \u0628\u0631\u0646\u0627\u0645\u0647 \u0647\u0627 \u0631\u0627 \u0646\u0638\u0627\u0631\u062a \u06a9\u0646\u0646\u062f \u062a\u0627 \u0627\u0632 \u0645\u0627\u0646\u062f\u06af\u0627\u0631\u06cc \u0622\u0646\u0647\u0627 \u062f\u0631 \u0645\u062d\u062f\u0648\u062f\u0647 \u062a\u0648\u0635\u06cc\u0647 \u0634\u062f\u0647\u060c \u0627\u0637\u0645\u06cc\u0646\u0627\u0646 \u062d\u0627\u0635\u0644 \u0634\u0648\u062f. <sep> Hypothesis: \u0627\u06cc\u0646 \u0642\u0627\u0646\u0648\u0646 \u0622\u0698\u0627\u0646\u0633\u0647\u0627 \u0631\u0627 \u0628\u0631\u0627\u06cc \u0627\u0647\u062f\u0627\u0641 \u0645\u062e\u062a\u0644\u0641 \u0628\u0631\u0646\u0627\u0645\u0647 \u0647\u0627\u06cc \u062a\u0645\u0644\u0643 \u062a\u0639\u06cc\u06cc\u0646 \u0645\u06cc \u0643\u0646\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-2233b24cd9e84918bb3343fd9d08d5f5", "input": "Premise: \u0645\u0634\u06a9\u0644 \u0633\u0648\u0645 \u06a9\u0647 \u0645\u0646\u0634\u0623 \u0628\u0631\u062e\u06cc \u0645\u0634\u06a9\u0644\u0627\u062a \u0648 \u0646\u0627\u06a9\u0627\u0631\u0627\u0645\u062f\u06cc\u0647\u0627 \u0648 \u06cc\u0627 \u06a9\u0627\u0631\u0622\u0645\u062f\u06cc\u0647\u0627\u0633\u062a\u060c \u062e\u0648\u0627\u0633\u062a \u0648 \u062a\u0644\u0627\u0634 \u0645\u0631\u062f\u0645 \u0627\u0633\u062a. <sep> Hypothesis: \u0645\u0642\u062f\u0645\u0627\u062a \u0644\u0627\u0632\u0645 \u0628\u0631\u0627\u06cc \u0627\u0646\u062c\u0627\u0645 \u06a9\u0627\u0631 \u0641\u0631\u0627\u0647\u0645 \u0634\u062f\u0647 \u0627\u0633\u062a.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-25893be15d2e4d9496127d0e8f805c01", "input": "Premise: \u00ab\u0631\u0648\u0648\u0646\u00bb \u0645\u0631\u06a9\u0632 \u0628\u0627\u0633\u062a\u0627\u0646\u06cc \u0635\u0646\u0639\u062a \u067e\u0631 \u0631\u0648\u0646\u0642 \u0646\u0633\u0627\u062c\u06cc \u0646\u0631\u0645\u0627\u0646\u062f\u06cc \u0648 \u0645\u062d\u0644 \u0634\u0647\u0627\u062f\u062a \u00ab\u062c\u0648\u0622\u0646 \u0622\u0631\u06a9\u00bb \u0627\u0633\u062a \u06a9\u0647 \u0646\u0645\u0627\u062f\u06cc \u0645\u0644\u06cc \u0627\u0632 \u0645\u0642\u0627\u0648\u0645\u062a \u062f\u0631 \u0628\u0631\u0627\u0628\u0631 \u0627\u0633\u062a\u0628\u062f\u0627\u062f \u0627\u0633\u062a. <sep> Hypothesis: \u00ab\u062c\u0627\u0646 \u0622\u0631\u06a9\u00bb \u062c\u0627\u0646 \u062e\u0648\u062f \u0631\u0627 \u062f\u0631 \u00ab\u0631\u0648\u0626\u06cc\u0646\u00bb \u0641\u062f\u0627 \u06a9\u0631\u062f \u060c \u06a9\u0647 \u0628\u0647 \u0633\u0645\u0628\u0644 \u0645\u0627\u0646\u062f\u06af\u0627\u0631 \u0645\u062e\u0627\u0644\u0641\u062a \u0628\u0627 \u0627\u0633\u062a\u0628\u062f\u0627\u062f \u062a\u0628\u062f\u06cc\u0644 \u0634\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-0841f19e741f41c7890e0dc0dcbaeee6", "input": "Premise: \u0627\u0632 \u0633\u0627\u0644 \u06f1\u06f9\u06f9\u06f9 \u062a\u0627 \u0632\u0645\u0627\u0646 \u062a\u0648\u0642\u0641 \u0622\u0646 \u062f\u0631 \u0633\u0627\u0644 \u06f2\u06f0\u06f0\u06f3 \u062a\u0645\u0627\u0645\u06cc \u0645\u062f\u0644\u200c\u0647\u0627\u06cc \u06a9\u06cc\u0627 \u0627\u0633\u067e\u0648\u0631\u062a\u06cc\u062c \u0641\u0631\u0648\u062e\u062a\u0647 \u0634\u062f\u0647 \u062f\u0631 \u0627\u0631\u0648\u067e\u0627\u060c \u062f\u0631 \u06a9\u0627\u0631\u062e\u0627\u0646\u0647 \u06a9\u06cc\u0627 \u0645\u0648\u062a\u0648\u0631\u0632 \u0622\u0644\u0645\u0627\u0646\u060c \u062a\u0648\u0644\u06cc\u062f \u0645\u06cc\u200c\u0634\u062f. <sep> Hypothesis: \u06a9\u0634\u0648\u0631\u0647\u0627\u06cc\u06cc \u06a9\u0647 \u062a\u0628\u0639\u06c0 \u0627\u0646\u06af\u0644\u0633\u062a\u0627\u0646 \u0647\u0633\u062a\u0646\u062f \u062e\u06cc\u0627\u0628\u0627\u0646\u0647\u0627\u06cc \u062e\u0648\u062f \u0631\u0627 \u0637\u0648\u0631\u06cc \u0637\u0631\u0627\u062d\u06cc \u0645\u06cc\u06a9\u0646\u0646\u062f \u06a9\u0647 \u0641\u0642\u0637 \u0645\u06cc\u0634\u0648\u062f \u0645\u0627\u0634\u06cc\u0646\u0647\u0627\u06cc\u06cc \u0631\u0627 \u062f\u0631 \u0622\u0646\u0647\u0627 \u0631\u0627\u0646\u062f \u06a9\u0647 \u0641\u0631\u0645\u0627\u0646 \u0622\u0646 \u062f\u0631 \u0637\u0631\u0641 \u0631\u0627\u0633\u062a \u062c\u0627\u062f\u0647 \u0627\u0633\u062a. ", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-40b8e688d7564c019daeb45a4c68569a", "input": "Premise: \u0627\u06cc\u0646 \u0648\u0627\u0642\u0639\u0627\u064b \u0628\u0627\u06cc\u062f \u0645\u0633\u0627\u0626\u0644 \u0631\u0627 \u0628\u0631\u0627\u0646\u06af\u06cc\u0632\u062f. <sep> Hypothesis: \u0627\u06cc\u0646 \u0686\u06cc\u0632\u06cc \u0631\u0627 \u062a\u063a\u06cc\u06cc\u0631 \u0646\u062e\u0648\u0627\u0647\u062f \u062f\u0627\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-0952e1de9cad499c87c7347d18ac3b3e", "input": "Premise: \u0628\u0627 \u0645\u062d\u0628\u062a \u067e\u0627\u0633\u062e \u062f\u0647\u06cc\u062f \u0648 \u0628\u0647 \u0632\u0648\u062f\u06cc \u0627\u062d\u0633\u0627\u0633 \u062e\u0648\u0628\u06cc \u062e\u0648\u0627\u0647\u06cc\u062f \u06a9\u0631\u062f. <sep> Hypothesis: \u0634\u0645\u0627 \u06cc\u06a9 \u06af\u0631\u0648\u0647 \u062f\u0648\u0633\u062a\u0627\u0646\u0647 \u062a\u0631 \u067e\u06cc\u062f\u0627 \u0646\u0645\u06cc \u06a9\u0646\u06cc\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-31a1c830f93f41cd9d32eba6677a1d7d", "input": "Premise: \u0627\u0632 \u0622\u0646 \u0632\u0645\u0627\u0646\u060c \u0622\u0644\u0628\u0631\u062a \u062f\u0648\u0631\u0627\u0646 \u0639\u0641\u0648 \u0645\u0634\u0631\u0648\u0637 \u062e\u0648\u062f \u0631\u0627 \u06af\u0630\u0631\u0627\u0646\u062f\u0647 \u0648 \u0645\u062c\u0631\u06cc \u06cc\u06a9 \u0646\u0645\u0627\u06cc\u0634 \u0634\u0628\u0627\u0646\u0647 \u0648\u0631\u0632\u0634\u06cc \u062f\u0631 MSG \u062f\u0631 \u0646\u06cc\u0648\u06cc\u0648\u0631\u0643 \u0634\u062f\u0647\u200c\u0627\u0633\u062a. <sep> Hypothesis: \u0645\u062c\u0631\u0645 \u0633\u0627\u0628\u0642 \u0627\u06a9\u0646\u0648\u0646 \u06cc\u06a9 \u0648\u0631\u0632\u0634\u06a9\u0627\u0631 \u0627\u0633\u062a.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-53c9a7680f33402ebebbd83797608b45", "input": "Premise: \u0686\u0646\u062f\u06cc \u067e\u06cc\u0634 \u06cc\u06a9 \u0642\u0644\u0627\u062f\u0647 \u062a\u0648\u0644\u0647 \u0628\u0628\u0631 \u0628\u0646\u06af\u0627\u0644 \u062f\u0631 \u062e\u06cc\u0627\u0628\u0627\u0646 \u0627\u0645\u0627\u0645\u062a \u0645\u0634\u0647\u062f \u0645\u0634\u0627\u0647\u062f\u0647 \u0648 \u0641\u06cc\u0644\u0645 \u0622\u0646 \u062f\u0631 \u0634\u0628\u06a9\u0647 \u0647\u0627\u06cc \u0627\u062c\u062a\u0645\u0627\u0639\u06cc \u0648 \u0641\u0636\u0627\u06cc \u0645\u062c\u0627\u0632\u06cc \u0627\u0646\u062a\u0634\u0627\u0631 \u06cc\u0627\u0641\u062a \u0648 \u0628\u0627 \u0627\u0642\u062f\u0627\u0645 \u0633\u0631\u06cc\u0639 \u0627\u062f\u0627\u0631\u0647 \u06a9\u0644 \u062d\u0641\u0627\u0638\u062a \u0645\u062d\u06cc\u0637 \u0632\u06cc\u0633\u062a \u062e\u0631\u0627\u0633\u0627\u0646 \u0631\u0636\u0648\u06cc \u0638\u0631\u0641 \u06a9\u0645\u062a\u0631 \u0627\u0632 48 \u0633\u0627\u0639\u062a \u0631\u062f\u06cc\u0627\u0628\u06cc \u0645\u062d\u0644 \u0641\u06cc\u0644\u0645\u0628\u0631\u062f\u0627\u0631\u06cc \u0645\u062d\u0642\u0642 \u0634\u062f. <sep> Hypothesis: \u0645\u0648\u0642\u0639\u06cc\u062a \u0686\u0646\u062f \u0642\u0644\u0627\u062f\u0647 \u062a\u0648\u0644\u0647 \u0628\u0628\u0631 \u062f\u0631 \u062e\u06cc\u0627\u0628\u0627\u0646\u200c\u0647\u0627\u06cc \u0645\u0634\u0647\u062f \u0646\u0627\u0645\u0634\u062e\u0635 \u0627\u0633\u062a.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-c9b9fa95f607470f82240627757571cb", "input": "Premise: \u0627\u06cc\u0646 \u0627\u0633\u062a\u062e\u0631 \u062f\u0631\u0647\u0627 \u0648 \u0645\u0642\u0633\u0645\u200c\u0647\u0627\u06cc\u06cc \u062f\u0627\u0634\u062a \u06a9\u0647 \u0645\u06cc\u0632\u0627\u0646 \u0622\u0628 \u0648 \u0627\u0631\u062a\u0641\u0627\u0639 \u0622\u0646 \u0631\u0627 \u062f\u0631 \u0631\u0648\u062f\u062e\u0627\u0646\u0647 \u0645\u0639\u06cc\u0646 \u0645\u06cc\u200c\u06a9\u0631\u062f.\n\u0648\u0642\u062a\u06cc \u06a9\u0647 \u0627\u06cc\u0646 \u0627\u0631\u062a\u0641\u0627\u0639 \u0628\u0647 \u062d\u062f \u0627\u06a9\u062b\u0631 \u0645\u06cc \u0631\u0633\u06cc\u062f \u0645\u0631\u062f\u0645 \u062e\u0648\u0634\u0648\u0642\u062a \u06af\u0631\u062f\u06cc\u062f\u0647 \u0633\u062f\u0647\u0627 \u0631\u0627 \u0645\u06cc \u06af\u0634\u0648\u062f\u0646\u062f \u0648 \u0622\u0628 \u0628\u0647 \u0642\u062f\u0631 \u062d\u0627\u062c\u062a \u062f\u0627\u062e\u0644 \u0646\u0647\u0631\u0647\u0627 \u0645\u06cc \u06af\u0631\u062f\u06cc\u062f. <sep> Hypothesis: \u0627\u06cc\u0646 \u0627\u0633\u062a\u062e\u0631 \u062f\u0631\u0647\u0627 \u0648 \u0645\u0642\u0633\u0645\u200c\u0647\u0627\u06cc\u06cc \u062f\u0627\u0634\u062a \u06a9\u0647 \u0645\u06cc\u0632\u0627\u0646 \u0622\u0628 \u0648 \u0627\u0631\u062a\u0641\u0627\u0639 \u0622\u0646 \u0631\u0627 \u062f\u0631 \u0631\u0648\u062f\u062e\u0627\u0646\u0647 \u0645\u0639\u06cc\u0646 \u0645\u06cc\u200c\u06a9\u0631\u062f.\n\u0648\u0642\u062a\u06cc \u06a9\u0647 \u0627\u06cc\u0646 \u0627\u0631\u062a\u0641\u0627\u0639 \u0628\u0647 \u062d\u062f \u0627\u06a9\u062b\u0631 \u0645\u06cc \u0631\u0633\u06cc\u062f \u0645\u0631\u062f\u0645 \u062e\u0648\u0634\u0648\u0642\u062a \u06af\u0631\u062f\u06cc\u062f\u0647 \u0633\u062f\u0647\u0627 \u0631\u0627 \u0645\u06cc \u06af\u0634\u0648\u062f\u0646\u062f \u0648 \u0622\u0628 \u0628\u0627 \u0645\u06cc\u0632\u0627\u0646 \u06a9\u0645\u06cc \u0628\u0647 \u0646\u0647\u0631\u0647\u0627 \u0631\u06cc\u062e\u062a\u0647 \u0645\u06cc \u0634\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-f62c17a4d2eb4757a4b80f42125df7c7", "input": "Premise: \u0628\u0644\u0647 \u0627\u06cc\u0646 \u0627\u0641\u0631\u0627\u062f\u066c \u0622\u0646\u0647\u0627 \u0628\u0644\u0646\u062f\u06af\u0648\u0647\u0627\u06cc \u0628\u0632\u0631\u06af\u06cc \u062f\u0627\u0631\u0646\u062f \u0632\u06cc\u0631\u0627 \u0622\u0646\u0647\u0627 \u0633\u06cc\u0633\u062a\u0645 \u062f\u0645\u0648\u06a9\u0631\u0627\u062a\u06cc\u06a9 \u062f\u0642\u06cc\u0642\u0627\u064b \u0645\u0627\u0646\u0646\u062f \u0645\u0627 \u062f\u0627\u0631\u0646\u062f \u06a9\u0647 \u062f\u0631 \u0622\u0646\u062c\u0627 \u0634\u0647\u0631\u062f\u0627\u0631\u0647\u0627 \u0648 \u0627\u0639\u0636\u0627\u06cc \u0634\u0648\u0631\u0627\u0647\u0627\u06cc \u062e\u0648\u062f \u0631\u0627 \u0627\u0646\u062a\u062e\u0627\u0628 \u0645\u06cc \u06a9\u0646\u0646\u062f \u06a9\u0647 \u0648\u0627\u0642\u0639\u0627\u064b \u0628\u0647 \u0646\u0648\u0639\u06cc \u062e\u0646\u062f\u0647 \u062f\u0627\u0631 \u0627\u0633\u062a \u0648 \u0628\u0647 \u0646\u0648\u0639\u06cc \u062d\u0645\u0644\u0647 \u0628\u0647 \u062d\u0631\u06cc\u0645 \u062e\u0635\u0648\u0635\u06cc \u0634\u0645\u0627\u0633\u062a \u0648 \u0622\u0646\u0647\u0627 \u0646\u06cc\u0632 \u062f\u0631 \u0627\u06cc\u0646 \u062e\u06cc\u0627\u0628\u0627\u0646 \u0647\u0627 \u0628\u0627 \u0627\u06cc\u0646 \u0628\u0644\u0646\u062f\u06af\u0648\u0647\u0627\u06cc \u0648\u0627\u0642\u0639\u0627\u064b \u0628\u0644\u0646\u062f\u066c \u067e\u0627\u06cc\u06cc\u0646 \u0645\u06cc \u0631\u0648\u0646\u062f.  <sep> Hypothesis: \u0622\u0646 \u062f\u0633\u062a\u0647 \u0627\u0632 \u0627\u0641\u0631\u0627\u062f \u0628\u0627 \u0628\u0644\u0646\u062f\u06af\u0648 \u0628\u0633\u06cc\u0627\u0631 \u0622\u0632\u0627\u0631 \u062f\u0647\u0646\u062f\u0647 \u0647\u0633\u062a\u0646\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-ab93a96be86f41a6961299a7bfca8ac0", "input": "Premise: \u062f\u0631 \u067e\u0627\u06cc\u0627\u0646 \u0627\u0648 \u0622\u0647\u06cc \u0637\u0648\u0644\u0627\u0646\u06cc \u0633\u0631 \u062f\u0627\u062f. <sep> Hypothesis: \u0627\u0648 \u062f\u0631 \u067e\u0627\u06cc\u0627\u0646 \u0622\u0647\u0633\u062a\u0647 \u0622\u0647\u06cc \u06a9\u0634\u06cc\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-18044d9f3924422ea93518eebbc28779", "input": "Premise: \u0642\u0637\u0639\u0647 \u0632\u0645\u06cc\u0646\u06cc \u06a9\u0647 \u062f\u0631 \u0622\u0646 \u0633\u0627\u062e\u062a \u0648 \u0633\u0627\u0632 \u0627\u0646\u062c\u0627\u0645 \u0645\u06cc \u0634\u0648\u062f\u060c \u062e\u0627\u0644\u06cc \u0627\u0632 \u0633\u06a9\u0646\u0647 \u0628\u0648\u062f. <sep> Hypothesis: \u0642\u0637\u0639\u0647 \u0632\u0645\u06cc\u0646 \u062e\u0627\u0644\u06cc \u0627\u0632 \u0633\u06a9\u0646\u0647 \u0628\u0648\u062f\u0647 \u0627\u0633\u062a.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-eee34f451205406ca22c313a1d51e31c", "input": "Premise: \u0628\u0627 \u0627\u06cc\u0646 \u062d\u0627\u0644 \u060c \u0647\u0646\u06af\u0627\u0645\u06cc \u06a9\u0647 \u0633\u0632\u0627\u0631 \u0628\u0647 \u0637\u0648\u0631 \u0646\u0627\u06af\u0647\u0627\u0646\u06cc \u06a9\u0634\u062a\u0647 \u0634\u062f\u066c \u0648\u0642\u0627\u06cc\u0639 \u0639\u0645\u06cc\u0642\u0627 \u0639\u0644\u06cc\u0647 \u06a9\u0644\u0626\u0648\u067e\u0627\u062a\u0631\u0627 \u0686\u0631\u062e\u06cc\u062f  \u0648 \u0627\u0648 \u0628\u0647 \u0627\u0633\u06a9\u0646\u062f\u0631\u06cc\u0647 \u0641\u0631\u0627\u0631 \u06a9\u0631\u062f \u062a\u0627 \u062f\u0631 \u06f3\u06f0 \u0633\u0627\u0644 \u0642\u0628\u0644 \u0627\u0632 \u0645\u06cc\u0644\u0627\u062f \u062e\u0648\u062f\u06a9\u0634\u06cc \u06a9\u0646\u062f. <sep> Hypothesis: \u0633\u0632\u0627\u0631 \u0622\u0631\u0627\u0645 \u0622\u0631\u0627\u0645 \u062f\u0631\u06af\u0630\u0634\u062a.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-64c24059d5ff474eb00c1ab9dce30893", "input": "Premise: \u0648 \u06a9\u0644\u0627\u0633 \u06a9\u0627\u0645\u0644\u0627\u064b \u0645\u062a\u0641\u0627\u0648\u062a\u06cc \u0627\u0632 \u0622\u0646\u0647\u0627 \u060c \u062f\u0648 \u06a9\u0627\u0631\u0622\u06af\u0627\u0647 \u0627\u0632 \u0644\u0646\u062f\u0646 \u060c \u0622\u0646\u0686\u0647 \u0645\u0648\u0631\u062f \u06a9\u0646\u062c\u06a9\u0627\u0648\u06cc \u0648 \u0633\u0624\u0627\u0644 \u0627\u0633\u062a. <sep> Hypothesis: \u06a9\u0627\u0631\u0622\u06af\u0627\u0647\u0627\u0646 \u0644\u0646\u062f\u0646 \u0628\u0633\u06cc\u0627\u0631 \u0646\u0627\u062e\u0648\u0634\u0627\u06cc\u0646\u062f \u0647\u0633\u062a\u0646\u062f \u0632\u06cc\u0631\u0627 \u062e\u06cc\u0644\u06cc \u06a9\u0646\u062c\u06a9\u0627\u0648 \u0647\u0633\u062a\u0646\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-2b500ac01d3a4b468d44f415e9d10981", "input": "Premise: \u0622\u0642\u0627\u06cc \u0628\u0631\u0627\u0648\u0646 \u067e\u0633 \u0627\u0632 \u0645\u0630\u0627\u06a9\u0631\u0627\u062a \u06a9\u0645\u067e \u062f\u064a\u0648\u064a\u062f \u0628\u0631\u0627\u06cc \u0645\u0644\u0627\u0642\u0627\u062a \u0628\u0627 \u0628\u0646 \u06a9\u06cc \u0645\u0648\u0646 \u062f\u0628\u064a\u0631 \u06a9\u0644 \u0633\u0627\u0632\u0645\u0627\u0646 \u0645\u0644\u0644 \u0645\u062a\u062d\u062f \u0628\u0647 \u0646\u064a\u0648\u064a\u0648\u0631\u06a9 \u062e\u0648\u0627\u0647\u062f \u0631\u0641\u062a. <sep> Hypothesis: \u0628\u0646 \u06a9\u06cc \u0645\u0648\u0646 \u062f\u0628\u064a\u0631 \u06a9\u0644 \u0633\u0627\u0632\u0645\u0627\u0646 \u0645\u0644\u0644 \u0645\u062a\u062d\u062f \u0628\u0647 \u0646\u064a\u0648\u064a\u0648\u0631\u06a9 \u0627\u0633\u062a.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-1f369426aad04a7789ce56e84242deb6", "input": "Premise: \u062f\u0648 \u0628\u0644\u0647 \u060c \u0628\u0644\u0647 \u0648 \u0633\u067e\u0633 \u0627\u06cc\u0646\u062f\u06cc\u0627\u0646\u0627\u067e\u0644\u06cc\u0633 \u06a9\u0647 \u0641\u0642\u0637 \u0635\u062f \u0645\u0627\u06cc\u0644 \u0628\u0627 \u0645\u0627 \u0641\u0627\u0635\u0644\u0647 \u062f\u0627\u0631\u062f \u060c \u06a9\u0644\u062a \u0647\u0627 \u0631\u0627 \u062f\u0627\u0631\u062f. <sep> Hypothesis: \u0645\u0627 \u0628\u0631\u0627\u06cc \u062f\u06cc\u062f\u0646 \u06a9\u0644\u062a \u0647\u0627 \u0628\u0647 \u0627\u06cc\u0646\u062f\u06cc\u0627\u0646\u0627\u067e\u0648\u0644\u06cc\u0633 \u0645\u06cc \u0631\u0648\u06cc\u0645.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-3c5f12de11884f4f9b4578454d15dc88", "input": "Premise: \u0646\u0648\u0644\u0627 \u062f\u0627\u0631\u0644\u064a\u0646\u06af \u0632\u0646 \u062c\u0648\u0627\u0646 \u0628\u06cc \u0628\u0646\u062f \u0648 \u0628\u0627\u0631 \u0648 \u0622\u0632\u0627\u062f\u0647 \u0627\u064a\u0633\u062a \u06a9\u0647 \u06f3 \u062a\u0627 \u062f\u0648\u0633\u062a \u067e\u0633\u0631 \u064a\u0627 \u0645\u0639\u0634\u0648\u0642 \u062f\u0627\u0631\u062f\u060c \u0627\u0645\u0627 \u0628\u0642\u062f\u0631\u06cc \u0645\u0633\u062a\u0642\u0644 \u0648 \u0622\u0632\u0627\u062f\u064a\u062e\u0648\u0627\u0647 \u0627\u0633\u062a \u06a9\u0647 \u062d\u0627\u0636\u0631 \u0646\u064a\u0633\u062a \u0628\u0647 \u062f\u0627\u0645 \u0647\u064a\u0686\u06a9\u062f\u0627\u0645\u0634\u0627\u0646 \u0628\u064a\u0641\u062a\u062f. <sep> Hypothesis: \u0632\u064a\u0628\u0627\u062a\u0631\u064a\u0646 \u0648 \u0645\u0631\u0645\u0648\u0632 \u062a\u0631\u064a\u0646 \u0645\u062e\u0644\u0648\u0642 \u0627\u0633\u067e\u0627\u064a\u06a9 \u0644\u06cc \u0632\u0646 \u062c\u0648\u0627\u0646 \u0628\u06cc \u0642\u06cc\u062f\u06cc \u0627\u0633\u062a \u06a9\u0647 \u0628\u0627 \u0627\u0641\u0631\u0627\u062f \u0632\u06cc\u0627\u062f\u06cc \u0631\u0627\u0628\u0637\u0647 \u062f\u0627\u0631\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-02307631018c411ca3d9954fb84432ac", "input": "Premise: \u0627\u06cc\u0646 \u0646\u0642\u0634 \u0645\u0645\u06a9\u0646 \u0627\u0633\u062a \u06cc\u06a9 \u067e\u06cc\u0645\u0627\u0646\u06a9\u0627\u0631 \u0646\u06cc\u0632 \u0628\u0627\u0634\u062f. <sep> Hypothesis: \u0622\u0646\u0647\u0627 \u0627\u0632 \u067e\u06cc\u0645\u0627\u0646\u06a9\u0627\u0631 \u0628\u0648\u062f\u0646 \u0645\u0645\u0646\u0648\u0639 \u0628\u0648\u062f\u0646\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-9f0178c6fa7344faad22dae2ef8ba5f7", "input": "Premise: \u062a\u067e\u0647 \u0642\u0644\u0627 \u062e\u0631\u0646\u0647 \u0645\u0631\u0628\u0648\u0637 \u0628\u0647 \u062f\u0648\u0631\u0627\u0646\u200c\u0647\u0627\u06cc \u062a\u0627\u0631\u06cc\u062e\u06cc \u067e\u0633 \u0627\u0632 \u0627\u0633\u0644\u0627\u0645 \u0627\u0633\u062a \u0648 \u062f\u0631 \u0634\u0647\u0631\u0633\u062a\u0627\u0646 \u062f\u0648\u0631\u0648\u062f\u060c \u0628\u062e\u0634 \u0645\u0631\u06a9\u0632\u06cc\u060c \u0631\u0648\u0633\u062a\u0627\u06cc \u062d\u0634\u0645\u062a \u0622\u0628\u0627\u062f \u0648\u0627\u0642\u0639 \u0634\u062f\u0647 \u0648 \u0627\u06cc\u0646 \u0627\u062b\u0631 \u062f\u0631 \u062a\u0627\u0631\u06cc\u062e \u0628\u0627 \u0634\u0645\u0627\u0631\u0647\u0654 \u062b\u0628\u062a \u06f1\u06f1\u06f7\u06f2\u06f3 \u0628\u0647\u200c\u0639\u0646\u0648\u0627\u0646 \u06cc\u06a9\u06cc \u0627\u0632 \u0622\u062b\u0627\u0631 \u0645\u0644\u06cc \u0627\u06cc\u0631\u0627\u0646 \u0628\u0647 \u062b\u0628\u062a \u0631\u0633\u06cc\u062f\u0647 \u0627\u0633\u062a. <sep> Hypothesis: \u062d\u06a9\u0648\u0645\u062a\u0647\u0627 \u0645\u06cc \u0622\u06cc\u0646\u062f \u0648 \u0645\u06cc\u0631\u0648\u0646\u062f \u0648 \u062f\u0633\u062a\u0627\u0648\u0631\u062f\u0647\u0627\u06cc \u0645\u0631\u062f\u0645 \u0627\u0633\u062a \u06a9\u0647 \u0628\u0631\u062c\u0627\u06cc \u0645\u06cc\u0645\u0627\u0646\u0646\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-a20cf203f1d943aeb4e4609e1ac92dfc", "input": "Premise: \u0628\u0647\u200c\u0637\u0648\u0631 \u0628\u0627\u0644\u0642\u0648\u0647\u060c SLS \u0645\u06cc\u200c\u062a\u0648\u0627\u0646\u062f \u0627\u0632 \u0637\u0631\u06cc\u0642 \u062f\u06cc\u06af\u0631\u06cc \u06cc\u0639\u0646\u06cc \u0628\u0627 \u0648\u0627\u06a9\u0646\u0634 \u0628\u0627 \u062a\u0631\u06a9\u06cc\u0628\u0627\u062a \u0646\u06cc\u062a\u0631\u0648\u0698\u0646 \u062f\u0627\u0631 \u0628\u0627\u0639\u062b \u0633\u0631\u0637\u0627\u0646 \u0634\u0648\u062f. <sep> Hypothesis: \u0628\u0631\u0627\u06cc \u0647\u0645\u06cc\u0646 \u0627\u0633\u062a \u06a9\u0647 \u063a\u0630\u0627\u0647\u0627\u06cc\u06cc \u06a9\u0647 \u0646\u06cc\u062a\u0631\u0648\u0698\u0646 \u0628\u0627\u0644\u0627\u062a\u0631\u06cc \u062f\u0627\u0631\u0646\u062f \u0633\u0631\u0637\u0627\u0646 \u0632\u0627 \u0645\u062d\u0633\u0648\u0628 \u0645\u06cc\u0634\u0648\u0646\u062f. ", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-6de758d5636a4c71b2b83f10b3e845e5", "input": "Premise: \u0627\u062d\u0645\u062f \u062e\u0631\u0645 \u0646\u06cc\u0632 \u067e\u0633 \u0627\u0632 \u0627\u0633\u062a\u0627\u0646\u062f\u0627\u0631\u06cc \u062e\u0648\u0632\u0633\u062a\u0627\u0646\u060c \u0628\u0647 \u0627\u0633\u062a\u0627\u0646\u062f\u0627\u0631 \u0647\u0645\u062f\u0627\u0646 \u0634\u062f \u0648 \u062f\u0631 \u062f\u0648\u0644\u062a \u062f\u0648\u0645 \u0633\u06cc\u062f \u0645\u062d\u0645\u062f \u062e\u0627\u062a\u0645\u06cc \u0628\u0647\u200c\u0639\u0646\u0648\u0627\u0646 \u0648\u0632\u06cc\u0631 \u0631\u0627\u0647 \u0648 \u062a\u0631\u0627\u0628\u0631\u06cc \u0627\u0646\u062a\u062e\u0627\u0628 \u0634\u062f. <sep> Hypothesis: \u0627\u062d\u0645\u062f \u062e\u0631\u0645 \u062f\u0631 \u062f\u0648\u0644\u062a \u062f\u0648\u0645 \u0633\u06cc\u062f \u0645\u062d\u0645\u062f \u062e\u0627\u062a\u0645\u06cc \u062f\u0627\u0631\u0627\u06cc \u0645\u0642\u0627\u0645 \u0627\u062f\u0627\u0631\u06cc \u0628\u0648\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-34f4731cec8d4359b3d61eb4a6e2b960", "input": "Premise: \u0627\u06cc\u0646 \u062a\u0644\u0627\u0634 \u0647\u0627\u06cc \u062a\u0628\u062f\u06cc\u0644 \u0633\u0627\u0644 \u06f2\u06f0\u06f0\u06f0 \u0645\u0639\u0645\u0648\u0644\u0627\u064b \u062a\u062d\u062a \u0645\u062d\u062f\u0648\u062f\u06cc\u062a \u0647\u0627\u06cc \u0632\u0645\u0627\u0646\u06cc \u0634\u062f\u06cc\u062f \u0627\u0646\u062c\u0627\u0645 \u0645\u06cc \u0634\u0648\u062f \u06a9\u0647 \u0628\u062f\u0648\u0646 \u062a\u0648\u062c\u0647 \u0645\u062f\u06cc\u0631\u06cc\u062a \u06a9\u0627\u0641\u06cc \u060c \u0645\u06cc \u062a\u0648\u0627\u0646\u062f \u0645\u0646\u062c\u0631 \u0628\u0647 \u062a\u0636\u0639\u06cc\u0641 \u06a9\u0646\u062a\u0631\u0644 \u0628\u0631 \u062a\u0645\u0627\u0645\u06cc\u062a \u062f\u0627\u062f\u0647 \u0647\u0627 \u0648 \u0628\u0631\u0646\u0627\u0645\u0647 \u0647\u0627 \u0648 \u0647\u0645\u0686\u0646\u06cc\u0646 \u0645\u062d\u0631\u0645\u0627\u0646\u0647 \u0628\u0648\u062f\u0646 \u0627\u0637\u0644\u0627\u0639\u0627\u062a \u062d\u0633\u0627\u0633 \u0634\u0648\u062f. <sep> Hypothesis: \u0645\u062d\u062f\u0648\u062f\u06cc\u062a \u0632\u0645\u0627\u0646\u06cc \u0634\u062f\u06cc\u062f \u062f\u0631 \u0645\u0648\u0631\u062f \u062a\u0644\u0627\u0634\u0647\u0627\u06cc \u062a\u0628\u062f\u06cc\u0644 \u0633\u0627\u0644 \u06f2\u06f0\u06f0\u06f0 \u062a\u0627\u062b\u06cc\u0631\u06cc \u062f\u0631 \u0645\u062d\u0631\u0645\u0627\u0646\u0647 \u0628\u0648\u062f\u0646 \u0627\u0637\u0644\u0627\u0639\u0627\u062a \u062d\u0633\u0627\u0633 \u0646\u062e\u0648\u0627\u0647\u062f \u062f\u0627\u0634\u062a.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-6b1f003c47f74629a84e6bfd7511717a", "input": "Premise: \u0633\u06cc\u06a9\u0633\u0627\u0644 (\u0633\u06cc \u0634\u0644) \u062a\u0646\u0647\u0627 \u0634\u0647\u0631\u06a9 \u062f\u06cc\u06af\u0631 \u0642\u0628\u0644 \u0627\u0632 \u0633\u0627\u0626\u0648 \u0648\u06cc\u0633\u0646\u062a\u0647 \u0627\u0633\u062a. <sep> Hypothesis: \u0642\u0628\u0644 \u0627\u0632 \u0633\u0627\u0626\u0648 \u0648\u06cc\u0633\u06cc\u0646\u062a\u0647 \u06cc\u06a9 \u0634\u0647\u0631\u06a9 \u0648\u062c\u0648\u062f \u062f\u0627\u0631\u062f \u0648 \u06f5\u06f0\u06f0\u06f0 \u0646\u0641\u0631 \u062c\u0645\u0639\u06cc\u062a \u062f\u0627\u0631\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-76be7dfdf40b450d9dc70bd3bb05379a", "input": "Premise: \u06cc\u0639\u0646\u06cc \u0628\u0631\u062e\u0644\u0627\u0641 \u0645\u062a\u0648\u0627\u0632\u06cc\u200c\u0627\u0644\u0623\u0636\u0644\u0627\u0639 \u06a9\u0647 \u062f\u0648 \u0636\u0644\u0639 \u0631\u0648\u0628\u0647 \u200c\u0631\u0648\u06cc \u0628\u0631\u0627\u0628\u0631 \u062f\u0627\u0631\u062f. <sep> Hypothesis: \u0628\u0627\u06cc\u062f \u062f\u0648\u0628\u0627\u0631\u0647 \u0628\u0647 \u062a\u0639\u0631\u06cc\u0641 \u0645\u062a\u0648\u0627\u0632\u06cc \u0627\u0644\u0627\u0636\u0644\u0627\u0639 \u0631\u062c\u0648\u0639 \u06a9\u0646\u06cc\u0645. ", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-fdf8ffb666264fbe91b96c529bbd67aa", "input": "Premise: \u0627\u064a\u062a\u0627\u0644\u064a\u0627 \u0647\u0645\u0648\u0627\u0631\u0647 \u062f\u0631 \u0634\u0634 \u062f\u0647\u0647 \u06af\u0630\u0634\u062a\u0647 \u0634\u0627\u0647\u062f \u0628\u06cc \u062b\u0628\u0627\u062a\u06cc \u062f\u0648\u0644\u062a \u0647\u0627 \u0628\u0648\u062f\u0647 \u0648 \u0646\u062e\u0633\u062a \u0648\u0632\u064a\u0631 \u062c\u062f\u064a\u062f \u0634\u0635\u062a \u0648 \u062f\u0648\u0645\u064a\u0646 \u0646\u062e\u0633\u062a \u0648\u0632\u064a\u0631\u06cc \u062e\u0648\u0627\u0647\u062f \u0628\u0648\u062f \u06a9\u0647 \u067e\u0633 \u0627\u0632 \u062c\u0646\u06af \u062c\u0647\u0627\u0646\u06cc \u062f\u0648\u0645 \u0628\u0647 \u0631\u0648\u06cc \u06a9\u0627\u0631 \u062e\u0648\u0627\u0647\u062f \u0622\u0645\u062f. <sep> Hypothesis: \u062f\u0631 \u0634\u0635\u062a \u0633\u0627\u0644 \u06af\u0630\u0634\u062a\u0647 \u0635\u062d\u0646\u0647 \u06cc \u0633\u06cc\u0627\u0633\u062a  \u0627\u06cc\u062a\u0627\u0644\u06cc\u0627 \u062f\u0648\u0631\u0627\u0646 \u0628\u06cc\u00a0\u062a\u0644\u0627\u0637\u0645\u06cc \u0631\u0627 \u0633\u067e\u0631\u06cc \u0645\u06cc\u200c\u06a9\u0646\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-3abc28777970450ba9b3e4bcbf92dd6f", "input": "Premise: \u0627\u0632 \u0633\u0648\u0627\u062d\u0644 \u0634\u0646\u06cc \u060c \u0631\u0648\u062f\u062e\u0627\u0646\u0647 \u0647\u0627\u06cc \u0642\u0647\u0648\u0647 \u0627\u06cc \u0648\u0633\u06cc\u0639 \u060c \u0648 \u062c\u0646\u06af\u0644 \u0647\u0627\u06cc \u0639\u0645\u06cc\u0642 \u06af\u0631\u0641\u062a\u0647 \u062a\u0627 \u0628\u0627\u0644\u0627 \u0631\u0641\u062a\u0646 \u0622\u0633\u0645\u0627\u0646 \u062e\u0631\u0627\u0634 \u0647\u0627 \u0648 \u0628\u0632\u0631\u06af\u0631\u0627\u0647 \u0647\u0627\u06cc \u06af\u0633\u062a\u0631\u062f\u0647 \u060c \u0645\u0627\u0644\u0632\u06cc \u0642\u0631\u0627\u0631 \u0627\u0633\u062a \u0627\u0632 \u0627\u0646\u062a\u0638\u0627\u0631\u0627\u062a \u0628\u0627\u0632\u062f\u06cc\u062f \u06a9\u0646\u0646\u062f\u06af\u0627\u0646 \u0641\u0631\u0627\u062a\u0631 \u0631\u0648\u062f. <sep> Hypothesis: \u0645\u0627\u0644\u0632\u06cc \u067e\u0631 \u0627\u0632 \u0628\u0633\u06cc\u0627\u0631\u06cc \u0627\u0632 \u0634\u06af\u0641\u062a\u06cc \u0647\u0627\u06cc \u0637\u0628\u06cc\u0639\u06cc \u0648 \u0627\u0646\u0633\u0627\u0646\u06cc \u0627\u0633\u062a \u06a9\u0647 \u0645\u06cc \u062a\u0648\u0627\u0646\u062f \u0641\u0631\u0627\u062a\u0631 \u0627\u0632 \u0627\u0646\u062a\u0638\u0627\u0631\u0627\u062a \u06af\u0631\u062f\u0634\u06af\u0631 \u0622\u0646 \u0628\u0627\u0634\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-79503e979a8a4b0f98c9bbaf14088723", "input": "Premise: \u062d\u0645\u06cc\u0631\u0647 (\u0627\u0647\u0648\u0627\u0632)\u060c \u0631\u0648\u0633\u062a\u0627\u06cc\u06cc \u0627\u0632 \u062a\u0648\u0627\u0628\u0639 \u0628\u062e\u0634 \u0645\u0631\u06a9\u0632\u06cc \u0634\u0647\u0631\u0633\u062a\u0627\u0646 \u0627\u0647\u0648\u0627\u0632 \u062f\u0631 \u0627\u0633\u062a\u0627\u0646 \u062e\u0648\u0632\u0633\u062a\u0627\u0646 \u0627\u06cc\u0631\u0627\u0646 \u0627\u0633\u062a. <sep> Hypothesis: \u062d\u0645\u06cc\u0631\u0647 \u06cc\u06a9\u06cc \u0627\u0632 \u0634\u0647\u0631\u0633\u062a\u0627\u0646 \u0647\u0627\u06cc \u0645\u0647\u0645 \u0627\u0633\u062a\u0627\u0646 \u062e\u0648\u0632\u0633\u062a\u0627\u0646 \u0627\u06cc\u0631\u0627\u0646 \u0627\u0633\u062a.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-92815885339c45cca0f2163a35be2154", "input": "Premise: \u062d\u062f\u0648\u062f \u0633\u0627\u0644\u200c\u0647\u0627\u06cc \u06f1\u06f3\u06f5\u06f0 \u0633\u06cc\u062f \u0645\u062d\u0645\u0648\u062f \u0637\u0627\u0644\u0642\u0627\u0646\u06cc \u0627\u062c\u0627\u0632\u06c0 \u062f\u0631\u06cc\u0627\u0641\u062a \u0648\u062c\u0648\u0647\u0627\u062a \u0628\u0631\u0627\u06cc \u06a9\u0645\u06a9 \u0628\u0647 \u0645\u0631\u062f\u0645 \u0646\u06cc\u0627\u0632\u0645\u0646\u062f \u0648 \u0627\u0646\u062c\u0627\u0645 \u0641\u0639\u0627\u0644\u06cc\u062a\u200c\u0647\u0627\u06cc \u0645\u062f\u062f\u06a9\u0627\u0631\u06cc \u0631\u0627 \u0628\u0647 \u0645\u0646\u0635\u0648\u0631\u06cc\u0627\u0646 \u062f\u0627\u062f. <sep> Hypothesis: \u0637\u0627\u0644\u0642\u0627\u0646\u06cc \u062f\u0631 \u062f\u0647\u06c0 \u067e\u0646\u062c\u0627\u0647\u060c \u06cc\u06a9\u06cc \u0627\u0632 \u0631\u0648\u062d\u0627\u0646\u06cc\u0648\u0646 \u0645\u062d\u0628\u0648\u0628 \u0622\u0646 \u0632\u0645\u0627\u0646 \u0628\u0648\u062f. ", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-780ad6f1af714c9292ce76c9b9efbcdc", "input": "Premise: \u0645\u0646 \u0645\u06cc \u062a\u0648\u0646\u0633\u062a\u0645 \u0627\u062d\u0633\u0627\u0633 \u06a9\u0646\u0645 \u06a9\u0647 \u0627\u0632 \u067e\u0634\u062a \u0628\u0647\u0645 \u062e\u06cc\u0631\u0647\n\u0634\u062f\u0647 \u0627\u0646\u062f\u061b \u0645\u0631\u062f\u0645\u06cc \u06a9\u0647 \u0627\u0632 \u0644\u0627\u06cc \u067e\u0631\u062f\u0647 \u0647\u0627 \u0646\u06af\u0627\u0647 \u0645\u06cc \u06a9\u0631\u062f\u0646\u062f\u060c\n\u0646\u06af\u0627\u0647 \u0647\u0627\u06cc \u062f\u0632\u062f\u06a9\u06cc \u0628\u0647 \u062c\u0639\u0628\u0647 \u0647\u0627\u06cc \u0646\u0627\u0645\u0647 \u0645\u06cc \u0627\u0646\u062f\u0627\u062e\u062a\u0646\u062f.\n <sep> Hypothesis: \u062e\u06cc\u0644\u06cc \u0639\u062c\u06cc\u0628 \u0628\u0648\u062f \u06a9\u0647 \u0627\u062d\u0633\u0627\u0633 \u0645\u06cc \u06a9\u0631\u062f\u06cc\u0645 \u0645\u0631\u062f\u0645 \u0645\u0627 \u0631\u0627 \u062a\u0645\u0627\u0634\u0627 \u0645\u06cc \u06a9\u0646\u0646\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-dfa1226490634b22a89cd8d399231464", "input": "Premise: \u0645\u0646 \u0628\u0647 \u062a\u0646\u0647\u0627\u06cc\u06cc \u06a9\u0627\u0631 \u0645\u06cc \u06a9\u0646\u0645 \u0648 \u06cc\u06a9 Am Trans \u0647\u0632\u0627\u0631 \u0648 \u0646\u0647\u0635\u062f \u0648 \u0647\u0634\u062a\u0627\u062f  \u062f\u0627\u0631\u0645 \u06a9\u0647 \u0627\u0632 \u0632\u0645\u0627\u0646 \u062c\u062f\u06cc\u062f \u0628\u0648\u062f\u0646\u0634 \u062a\u0627 \u0628\u0647 \u062d\u0627\u0644 \u062f\u0627\u0634\u062a\u0647 \u0627\u0645 <sep> Hypothesis: \u0645\u0646 \u0628\u0647 \u0635\u0648\u0631\u062a \u0627\u0646\u0641\u0631\u0627\u062f\u06cc \u06a9\u0627\u0631 \u0645\u06cc \u06a9\u0646\u0645 \u0648 \u0647\u0645\u0686\u0646\u06cc\u0646 \u062f\u0627\u0631\u0627\u06cc \u06cc\u06a9 Trans Am \u06f1\u06f9\u06f8\u06f0 \u0647\u0633\u062a\u0645.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-d003cff199ca49e1b2c16266fce3f2c3", "input": "Premise: \u0634\u0627\u06cc\u062f \u0634\u0646\u0627\u062e\u062a\u0647 \u0634\u062f\u0647\u200c\u062a\u0631\u06cc\u0646 \u0646\u0642\u0634 \u0627\u0648\u060c \u0646\u0642\u0634 \u0698\u0627\u0646 \u0648\u0627\u0644\u0698\u0627\u0646 \u062f\u0631 \u0641\u06cc\u0644\u0645 \u0628\u06cc\u0646\u0648\u0627\u06cc\u0627\u0646 (\u06f1\u06f9\u06f8\u06f2) \u0628\u0627\u0634\u062f \u06a9\u0647 \u0628\u0647 \u062e\u0627\u0637\u0631 \u0622\u0646 \u0646\u0627\u0645\u0632\u062f \u062c\u0627\u06cc\u0632\u0647 \u0633\u0632\u0627\u0631 (\u0627\u0633\u06a9\u0627\u0631 \u0641\u0631\u0627\u0646\u0633\u0648\u06cc) \u0634\u062f. \u0644\u06cc\u0646\u0648 \u0648\u0646\u062a\u0648\u0631\u0627 \u062a\u0627 \u0622\u062e\u0631\u06cc\u0646 \u0633\u0627\u0644\u200c\u0647\u0627\u06cc \u0639\u0645\u0631\u0634 \u0628\u0647 \u0628\u0627\u0632\u06cc \u062f\u0631 \u0641\u06cc\u0644\u0645 \u067e\u0631\u062f\u0627\u062e\u062a. <sep> Hypothesis: \u0644\u06cc\u0646\u0648 \u0648\u0646\u062a\u0648\u0631\u0627 \u0628\u0631\u0627\u06cc \u0628\u0627\u0632\u06cc \u062f\u0631 \u0641\u06cc\u0644\u0645 \u0628\u06cc\u0646\u0648\u0627\u06cc\u0627\u0646 \u062c\u0627\u06cc\u0632\u0647\u200c\u06cc \u0627\u0633\u06a9\u0627\u0631 \u0628\u0631\u062f.", "output": ["Contradiction", "Contradiction", "Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-17492c0fdaed4ed3a7dbf0177f224706", "input": "Premise: \u0627\u0648 \u0647\u0631\u06af\u0632 \u0627\u062d\u0633\u0627\u0633 \u0628\u0647\u062a\u0631\u06cc \u0646\u062f\u0627\u0634\u062a\u0647 \u0627\u0633\u062a. <sep> Hypothesis: \u062f\u0627\u0631\u0648\u06cc\u06cc \u06a9\u0647 \u0627\u0648 \u0645\u0635\u0631\u0641 \u0645\u06cc\u200c\u06a9\u0631\u062f \u062e\u0648\u0628 \u06a9\u0627\u0631 \u06a9\u0631\u062f\u0647 \u0627\u0633\u062a.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-8c83afcf6ced47d48dc7a1391a9fc0fc", "input": "Premise: \u062d\u062f\u0633 \u0645\u0646 \u0627\u06cc\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0622\u0646\u0647\u0627 \u0645\u0637\u0645\u0626\u0646 \u0646\u06cc\u0633\u062a\u0646\u062f. <sep> Hypothesis: \u062d\u062f\u0633 \u0645\u0646 \u0627\u06cc\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0622\u0646\u0647\u0627 \u0645\u0637\u0645\u0626\u0646 \u0646\u06cc\u0633\u062a\u0646\u062f \u06a9\u0647 \u06a9\u0633\u06cc \u06a9\u0647 \u0622\u0646\u062c\u0627\u0633\u062a \u067e\u062f\u0631 \u0628\u0627\u0634\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-40b7f00e0ecb44d480526d352d968105", "input": "Premise: \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u0645\u062b\u0627\u0644 \u060c \u0633\u06cc\u0633\u062a\u0645 \u0639\u0627\u0645\u0644 \u0647\u0627\u06cc \u062f\u0633\u06a9 \u062a\u0627\u067e \u0648 \u0646\u0631\u0645 \u0627\u0641\u0632\u0627\u0631 \u0628\u0633\u062a\u0647 \u0628\u0647 \u0646\u06cc\u0627\u0632\u0647\u0627\u06cc \u0645\u0646\u062d\u0635\u0631 \u0628\u0647 \u0641\u0631\u062f \u0647\u0631 \u0645\u0646\u0637\u0642\u0647 \u062a\u062c\u0627\u0631\u06cc \u062f\u0631 \u0628\u06cc\u0646 \u0648\u0627\u062d\u062f\u0647\u0627\u06cc \u062a\u062c\u0627\u0631\u06cc \u0645\u062a\u0641\u0627\u0648\u062a \u0627\u0633\u062a. <sep> Hypothesis: \u0631\u0627\u0647 \u062d\u0644 \u0647\u0627\u06cc \u0646\u0631\u0645 \u0627\u0641\u0632\u0627\u0631\u06cc \u0648 \u0633\u062e\u062a \u0627\u0641\u0632\u0627\u0631\u06cc \u0628\u0647 \u0646\u06cc\u0627\u0632\u0647\u0627\u06cc \u0647\u0631 \u062a\u062c\u0627\u0631\u062a \u0628\u0633\u062a\u06af\u06cc \u062f\u0627\u0631\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-ae4ef34a930a4ecfafaf5fcfac08e6a6", "input": "Premise: \u0627\u0645\u0627 \u062f\u0631 \u0622\u0646\u062c\u0627 \u062e\u0627\u0646 \u062f\u0648\u0645 \u062f\u0647\u060c \u0641\u062a\u062d\u200c\u0627\u0644\u0644\u0647 \u062e\u0627\u0646 \u06af\u0644\u0647 \u062f\u0627\u0631\u06cc \u0627\u0632 \u0645\u062d\u0645\u0648\u062f \u067e\u062f\u0631 \u0633\u062a\u0627\u06cc\u0634 \u06a9\u06cc\u0646\u0647 \u062f\u06cc\u0631\u06cc\u0646\u0647 \u062f\u0627\u0631\u062f. <sep> Hypothesis: \u0631\u0648\u0627\u0628\u0637\u0634 \u0628\u0627 \u067e\u062f\u0631 \u0633\u062a\u0627\u06cc\u0634 \u062e\u0648\u0628 \u0646\u06cc\u0633\u062a.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-81fb390ed68540788a0451226f0683c7", "input": "Premise: \u0622\u0646\u062c\u0627 \u0648\u062d\u0634\u06cc \u0648 \u0628\u0627\u062f\u062e\u06cc\u0632 \u0627\u0633\u062a \u0648 \u067e\u0648\u0634\u0634 \u06af\u06cc\u0627\u0647\u06cc \u0645\u062d\u062f\u0648\u062f \u0622\u0646 \u0628\u0633\u06cc\u0627\u0631 \u0645\u062a\u0641\u0627\u0648\u062a \u0627\u0632 \u0633\u0631\u0633\u0628\u0632\u06cc \u0641\u0636\u0627\u06cc \u062f\u0627\u062e\u0644\u06cc \u0627\u0633\u062a. <sep> Hypothesis: \u0628\u0647 \u0647\u0645\u06cc\u0646 \u062f\u0644\u06cc\u0644 \u06a9\u0634\u0627\u0648\u0631\u0632\u0627\u0646 \u0627\u0632 \u0645\u062f\u062a\u0647\u0627 \u0642\u0628\u0644 \u062a\u0631\u062c\u06cc\u062d \u0645\u06cc \u062f\u0647\u0646\u062f \u062e\u0627\u0646\u0647 \u0647\u0627\u06cc \u062e\u0648\u062f \u0631\u0627 \u062f\u0631 \u0641\u0636\u0627\u06cc \u062f\u0627\u062e\u0644\u06cc \u0628\u0633\u0627\u0632\u0646\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-efcb3597e3ca4055a6308169fe552354", "input": "Premise: \u0644\u0630\u062a \u0646\u0627\u0634\u06cc \u0627\u0632 \u0633\u06cc\u06af\u0627\u0631 \u06a9\u0634\u06cc\u062f\u0646 \u0645\u0627\u0631\u06cc \u062c\u0648\u0627\u0646\u0627 \u06cc\u06a9 \u0645\u0633\u0626\u0644\u0647 \u0627\u0633\u0627\u0633\u06cc \u0627\u0633\u062a <sep> Hypothesis: \u06cc\u06a9 \u0633\u0648\u0645 \u0645\u0648\u0634\u200c\u0647\u0627 \u0645\u0627\u0631\u06cc\u062c\u0648\u0627\u0646\u0627 \u062f\u0648\u0633\u062a \u0646\u062f\u0627\u0631\u0646\u062f \u0686\u0648\u0646 \u0628\u0627\u0639\u062b \u067e\u0627\u0631\u0627\u0646\u0648\u0626\u06cc\u062f \u0634\u062f\u0646 \u0622\u0646\u0647\u0627 \u0645\u06cc \u0634\u0648\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-11c05251d38d4c50ad4634cbf82d4c87", "input": "Premise: \u0646\u0627\u0627\u0645\u06cc\u062f\u0627\u0646\u0647 \u0628\u0627 \u0686\u0646\u06af \u0632\u062f\u0646 \u0628\u0647 \u0628\u0627\u0644\u0627\u06cc \u0642\u0637\u0627\u0631 \u060c \u0646\u0632\u062f\u06cc\u06a9 \u067e\u0646\u062c\u0631\u0647 \u0634\u062f\u0645. <sep> Hypothesis: \u0645\u0646 \u0627\u0632 \u0637\u0631\u06cc\u0642 \u067e\u0644\u0647 \u0647\u0627\u06cc \u0645\u0627\u0634\u06cc\u0646 \u0627\u0648\u0644 \u0633\u0648\u0627\u0631 \u0642\u0637\u0627\u0631 \u0634\u062f\u0645.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-b8922000b66546b2a16cecc7d1a8eaf2", "input": "Premise: \u0628\u0646\u0627\u0628\u0631\u0627\u06cc\u0646 \u0641\u0631\u0636\u06cc\u0647 \u0645\u0639\u06a9\u0648\u0633 \u0645\u06cc \u062a\u0648\u0627\u0646\u062f \u0628\u0647 \u0647\u0645\u0627\u0646 \u0627\u0646\u062f\u0627\u0632\u0647 \u0645\u0639\u062a\u0628\u0631 \u0628\u0627\u0634\u062f. <sep> Hypothesis: \u0646\u0638\u0631\u06cc\u0647 \u0645\u062e\u0627\u0644\u0641 \u0645\u06cc \u062a\u0648\u0627\u0646\u062f \u0628\u0647 \u0647\u0645\u0627\u0646 \u0627\u0646\u062f\u0627\u0632\u0647 \u0645\u0639\u062a\u0628\u0631 \u06cc\u0627 \u0628\u062f\u062a\u0631 \u0628\u0627\u0634\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-65d3d4fd7ba54849bda625c8ff1c4fac", "input": "Premise: \u062f\u0631 \u0647\u0645\u0627\u0646 \u0633\u0627\u0644 \u0642\u06cc\u0627\u0645 \u0645\u0634\u0627\u0628\u0647\u06cc \u062f\u0631 \u0645\u062c\u0627\u0631\u0633\u062a\u0627\u0646 \u0631\u062e \u062f\u0627\u062f \u0648 \u0634\u0648\u0631\u0648\u06cc \u0647\u0627 \u062d\u0645\u0644\u0647 \u06a9\u0631\u062f\u0646\u062f \u062a\u0627 \u0633\u0631\u06cc\u0639 \u0622\u0646 \u0631\u0627 \u062f\u0631 \u0647\u0645 \u0634\u06a9\u0646\u0646\u062f. <sep> Hypothesis: \u0627\u062a\u062d\u0627\u062f \u062c\u0645\u0627\u0647\u06cc\u0631 \u0634\u0648\u0631\u0648\u06cc \u0633\u0631\u06cc\u0639 \u0642\u06cc\u0627\u0645 \u0647\u0627\u06cc \u0645\u062c\u0627\u0631\u0633\u062a\u0627\u0646 \u0631\u0627 \u062f\u0631 \u0647\u0645 \u06a9\u0648\u0641\u062a.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-a77cdb54b123499da32d9a8a76637d28", "input": "Premise: \u062f\u0631\u0633\u062a \u0627\u0633\u062a \u0648 \u0634\u0645\u0627 \u0645\u06cc \u062f\u0627\u0646\u06cc\u062f \u06a9\u0647 \u0627\u0634\u062a\u0628\u0627\u0647\u0627\u062a\u06cc \u0627\u0636\u0627\u0641\u0647 \u0646\u0645\u06cc \u0634\u0648\u0646\u062f \u06a9\u0647 \u0647\u0645\u0647 \u0645\u0627 \u0645\u0631\u062a\u06a9\u0628 \u0622\u0646 \u0645\u06cc \u0634\u0648\u06cc\u0645 <sep> Hypothesis: \u0645\u06cc \u062f\u0627\u0646\u06cc\u062f \u06a9\u0647 \u0631\u0627\u06cc\u0627\u0646\u0647 \u0647\u0627 \u0627\u0636\u0627\u0641\u0647 \u06a9\u0631\u062f\u0646 \u0627\u0634\u062a\u0628\u0627\u0647\u0627\u062a \u0631\u0627 \u0628\u0647 \u0686\u06cc\u0632\u06cc \u0627\u0632 \u06af\u0630\u0634\u062a\u0647 \u062a\u0628\u062f\u06cc\u0644 \u0645\u06cc \u06a9\u0646\u0646\u062f", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-cd19925ea62341daa97d922ee00405f8", "input": "Premise: \u0645\u0627 \u062f\u0631 \u0631\u0627\u0628\u0637\u0647 \u0628\u0627 \u0622\u062f\u0627\u0628 \u0648 \u0631\u0633\u0648\u0645 \u0647\u062f\u06cc\u0647 \u062f\u0627\u062f\u0646 \u062f\u0686\u0627\u0631 \u0645\u0634\u06a9\u0644 \u0634\u062f\u0647 \u0627\u06cc\u0645. <sep> Hypothesis: \u0645\u0634\u06a9\u0644 \u0645\u0627 \u0628\u0627 \u0622\u062f\u0627\u0628 \u0648 \u0631\u0633\u0648\u0645 \u0647\u062f\u06cc\u0647 \u062f\u0627\u062f\u0646\u060c \u0627\u0641\u0631\u0627\u062f\u06cc \u0647\u0633\u062a\u0646\u062f \u06a9\u0647 \u0646\u0645\u06cc \u062f\u0627\u0646\u0646\u062f \u0686\u06af\u0648\u0646\u0647 \u0647\u062f\u06cc\u0647 \u0647\u0627\u06cc \u0645\u0646\u0627\u0633\u0628\u06cc \u0627\u0646\u062a\u062e\u0627\u0628 \u06a9\u0646\u0646\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-0eb15326d775477ebf1e699cafdc9e90", "input": "Premise: \u0633\u0631\u0634\u0645\u0627\u0631\u06cc \u0633\u0627\u0644 \u06f1\u06f3\u06f9\u06f1 \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u0632\u0646\u06af \u062e\u0637\u0631 \u0628\u0631\u0627\u06cc \u0622\u06af\u0627\u0647\u06cc \u0645\u0644\u06cc \u0645\u0627\u0644\u0632\u06cc \u0628\u0648\u062f. <sep> Hypothesis: \u0633\u0631\u0634\u0645\u0627\u0631\u06cc \u0645\u0627\u0644\u0632\u06cc \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f3\u06f9\u06f1 \u0632\u0646\u06af \u062e\u0637\u0631 \u0628\u0648\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-f649e7edc2f049c7b30a7e7c623abd0e", "input": "Premise: \u0628\u0627\u0634\u0647 \u062e\u062f\u0627\u062d\u0627\u0641\u0638 <sep> Hypothesis: \u0635\u0628\u0631 \u06a9\u0646!", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-11f8477f9df54770a9569bf00d6f657f", "input": "Premise: \u0633\u06cc\u0627\u0647 \u067e\u0648\u0633\u062a - \u0646\u0647 \u0627\u0632 \u0631\u06cc\u0634\u0647 \u06cc \u0627\u0633\u067e\u0627\u0646\u06cc\u0627\u06cc\u06cc \u06f2\u06f7\u066a <sep> Hypothesis: \u06f2\u06f7\u066a \u0633\u06cc\u0627\u0647 \u067e\u0648\u0633\u062a \u0648 \u063a\u06cc\u0631\u0627\u0633\u067e\u0627\u0646\u06cc\u0627\u06cc\u06cc \u0647\u0633\u062a\u0646\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-dd3fd370a5b94b04bb4d62dd487e9be8", "input": "Premise: \u00ab\u0628\u0647 \u0647\u0631 \u062d\u0627\u0644 \u060c \u0647\u06cc\u0686 \u0631\u0627\u0647\u06cc \u0628\u0631\u0627\u06cc \u0634\u0646\u0627\u0633\u0627\u06cc\u06cc \u0645\u0627\u0644\u06a9 \u06cc\u0627 \u0645\u0627\u0644\u06a9\u0627\u0646 \u0648\u062c\u0648\u062f \u0646\u062f\u0627\u0631\u062f\u00bb \u0627\u0646\u0633 \u062f\u0631 \u062d\u0627\u0644\u06cc \u06a9\u0647 \u06a9\u062a\u0627\u0628 \u0633\u0647 \u062a\u0641\u0646\u06af\u062f\u0627\u0631 \u0631\u0627 \u0628\u0631\u0645\u06cc\u062f\u0627\u0634\u062a\u060c \u06af\u0641\u062a. <sep> Hypothesis: \u06cc\u06a9 \u0631\u0648\u0634 \u0645\u0637\u0645\u0626\u0646 \u0628\u0631\u0627\u06cc \u0634\u0646\u0627\u0633\u0627\u06cc\u06cc \u0645\u0627\u0644\u06a9 \u0648\u062c\u0648\u062f \u062f\u0627\u0631\u062f. \u0627\u0646\u0633 \u062f\u0631 \u062d\u0627\u0644\u06cc \u06a9\u0647 \u06a9\u062a\u0627\u0628 \u0631\u0627 \u06a9\u0646\u0627\u0631 \u0645\u06cc\u06af\u0630\u0627\u0634\u062a\u060c \u06af\u0641\u062a.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-63e86804aa3347798065139474cc9e75", "input": "Premise: \u0645\u0630\u0627\u06a9\u0631\u0627\u062a \u0635\u0644\u062d \u0628\u064a\u0646 \u062f\u0648\u0644\u062a \u0627\u0646\u062f\u0648\u0646\u0632\u06cc \u0648 \u062c\u062f\u0627\u064a\u06cc \u0637\u0644\u0628\u0627\u0646 \u0622\u0686\u0647 \u0627\u0632 \u0633\u0627\u0644 2003 \u0645\u062a\u0648\u0642\u0641 \u0634\u062f\u0647 \u0628\u0648\u062f\u060c \u0627\u0645\u0627 \u0628\u0627 \u0648\u0642\u0648\u0639 \u0641\u0627\u062c\u0639\u0647 \u0633\u0648\u0646\u0627\u0645\u06cc\u060c \u0648 \u0628\u0633\u064a\u062c \u0646\u064a\u0631\u0648\u0647\u0627\u06cc \u0627\u0645\u062f\u0627\u062f \u0628\u064a\u0646 \u0627\u0644\u0645\u0644\u0644\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0645\u06a9 \u0628\u0647 \u0645\u0646\u0627\u0637\u0642 \u0632\u0644\u0632\u0644\u0647 \u0632\u062f\u0647\u060c \u062f\u0648\u0637\u0631\u0641 \u0645\u0648\u0627\u0641\u0642\u062a \u06a9\u0631\u062f\u0646\u062f \u0631\u0648\u0646\u062f \u0645\u0630\u0627\u06a9\u0631\u0627\u062a \u062e\u0648\u062f \u0631\u0627 \u0627\u0632 \u0633\u0631\u0628\u06af\u064a\u0631\u0646\u062f. <sep> Hypothesis: \u0628\u0647 \u0645\u0646\u0638\u0648\u0631 \u06a9\u0645\u06a9 \u0628\u0647 \u062d\u0627\u062f\u062b\u0647 \u062f\u06cc\u062f\u06af\u0627\u0646 \u0633\u0648\u0646\u0627\u0645\u06cc \u0627\u062e\u06cc\u0631 \u062f\u0631 \u0627\u0646\u062f\u0648\u0646\u0632\u06cc\u060c \u062f\u0648\u0644\u062a \u0648 \u062c\u062f\u0627\u06cc\u06cc \u0637\u0644\u0628\u0627\u0646 \u0645\u0630\u0627\u06a9\u0631\u0627\u062a \u062e\u0648\u062f \u0631\u0627 \u0622\u063a\u0627\u0632 \u06a9\u0631\u062f\u0646\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-e5ab0516187f4fa487aef5ef2e14de7e", "input": "Premise: \u0646\u0647 \u060c \u0645\u0646 \u0627\u062d\u062a\u0645\u0627\u0644\u0627\u064b \u0646\u0645\u06cc \u062e\u0648\u0627\u0647\u0645 \u0634\u0645\u0627 \u0631\u0627 \u0628\u06a9\u0634\u0645. <sep> Hypothesis: \u0627\u0645\u0631\u0648\u0632 \u062a\u0648 \u0631\u0627 \u0646\u0645\u06cc \u06a9\u0634\u0645 \u060c \u0627\u0645\u0627 \u0634\u0627\u06cc\u062f \u0641\u0631\u062f\u0627 \u0628\u06a9\u0634\u0645.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-051326389ebf468091510f3f61d85282", "input": "Premise: \u0627\u06cc\u0646 \u0628\u06cc\u0627\u0646\u06cc\u0647 \u0645\u06cc \u0627\u0641\u0632\u0627\u06cc\u062f: \u0628\u0627 \u062a\u0648\u062c\u0647 \u0628\u0647 \u062a\u0645\u0627\u06cc\u0644 \u062f\u0648 \u06a9\u0634\u0648\u0631 \u0647\u0645\u0633\u0627\u06cc\u0647 \u062f\u0631 \u0632\u0645\u06cc\u0646\u0647 \u067e\u06cc\u0634\u0628\u0631\u062f \u0648 \u0631\u0634\u062f \u0648 \u062a\u0648\u0633\u0639\u0647 \u0631\u0648\u0627\u0628\u0637 \u0627\u0642\u062a\u0635\u0627\u062f\u06cc \u0648 \u062a\u062c\u0627\u0631\u06cc \u0648 \u0641\u0639\u0627\u0644 \u06a9\u0631\u062f\u0646 \u062a\u0648\u0627\u0641\u0642\u0646\u0627\u0645\u0647 \u0647\u0627\u06cc \u062f\u0648\u062c\u0627\u0646\u0628\u0647 \u0645\u0634\u062a\u0631\u06a9 \u06a9\u0647 \u0646\u0642\u0634 \u0628\u0633\u0632\u0627\u06cc\u06cc \u062f\u0631 \u0627\u0641\u0632\u0627\u06cc\u0634 \u062d\u062c\u0645 \u0645\u0628\u0627\u062f\u0644\u0627\u062a \u062a\u062c\u0627\u0631\u06cc \u0645\u06cc\u0627\u0646 \u062f\u0648 \u06a9\u0634\u0648\u0631 \u062f\u0627\u0634\u062a\u0647\u060c \u0645\u06cc\u0632\u0627\u0646 \u0645\u0628\u0627\u062f\u0644\u0627\u062a \u062a\u062c\u0627\u0631\u06cc \u0628\u0627 \u0627\u06cc\u0631\u0627\u0646 \u0628\u0647 \u0637\u0648\u0631 \u0631\u0648\u0632\u0627\u0641\u0632\u0648\u0646 \u062f\u0631 \u062d\u0627\u0644 \u0627\u0641\u0632\u0627\u06cc\u0634 \u0627\u0633\u062a. <sep> Hypothesis: \u0627\u0641\u0632\u0627\u06cc\u0634 \u0645\u0628\u0627\u062f\u0644\u0627\u062a \u062a\u062c\u0627\u0631\u06cc \u0628\u0627 \u0627\u06cc\u0631\u0627\u0646 \u062f\u0631 \u0646\u062a\u06cc\u062c\u0647 \u062a\u0645\u0627\u06cc\u0644 \u062f\u0648 \u06a9\u0634\u0648\u0631 \u0647\u0645\u0633\u0627\u06cc\u0647 \u062f\u0631 \u062a\u0648\u0627\u0641\u0642\u200c\u0647\u0627\u06cc \u062f\u0648\u062c\u0627\u0646\u0628\u0647 \u0628\u0648\u062f\u0647 \u0627\u0633\u062a.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-c5117b6a63674c1eb6f7dd588893e2b1", "input": "Premise: \u0628\u0627 \u0622\u0646 \u06a9\u0647 \u0645\u0631\u062f\u0645 \u06f3\u06f0\u06f0\u06f0 \u0686\u0631\u062e \u0628\u0631 \u062f\u06cc\u0648\u0627\u0631 \u062d\u0635\u0627\u0631\u0647\u0627 \u06a9\u0627\u0631 \u06af\u0630\u0627\u0634\u062a\u0647 \u0628\u0648\u062f\u0646\u062f \u0648 \u06f3\u06f0\u06f0 \u0639\u0631\u0627\u062f\u0647 \u0648 \u0645\u0646\u062c\u06cc\u0642 \u0646\u0635\u0628 \u06a9\u0631\u062f\u0647 \u0628\u0648\u062f\u0646\u062f \u0648 \u0628\u0647 \u0646\u0641\u062a\u200c\u0627\u0646\u062f\u0627\u0632 \u0645\u062c\u0647\u0632 \u0628\u0648\u062f\u0646\u062f\u060c \u062a\u0627\u0628 \u067e\u0627\u06cc\u062f\u0627\u0631\u06cc \u0646\u06cc\u0627\u0648\u0631\u062f\u0646\u062f \u0648 \u067e\u0633 \u0627\u0632 \u0633\u0647 \u0631\u0648\u0632 \u062c\u0646\u06af \u0633\u062e\u062a \u0648 \u06a9\u0634\u062a\u0647 \u0634\u062f\u0646 \u062a\u0639\u062f\u0627\u062f \u0628\u0633\u06cc\u0627\u0631\u06cc \u0627\u0632 \u062f\u0648 \u0637\u0631\u0641 \u0645\u063a\u0648\u0644 \u067e\u06cc\u0631\u0648\u0632 \u0634\u062f. <sep> Hypothesis: \u0645\u063a\u0648\u0644\u0647\u0627 \u0628\u0627 \u0635\u0628\u0648\u0639\u06cc\u062a\u06cc \u06a9\u0647 \u062f\u0627\u0634\u062a\u0646\u062f \u0628\u0631 \u0645\u0631\u062f\u0645 \u0634\u0647\u0631\u060c \u06a9\u0647 \u0627\u062a\u0641\u0627\u0642\u0627\u064b \u0622\u062f\u0645\u0647\u0627\u06cc \u0628\u0627\u0647\u0648\u0634\u06cc \u0647\u0645 \u0628\u0648\u062f\u0646\u062f\u060c \u0641\u0627\u0626\u0642 \u0622\u0645\u062f\u0646\u062f \u0648 \u0628\u0631 \u0622\u0646\u0647\u0627 \u067e\u06cc\u0631\u0648\u0632 \u0634\u062f\u0646\u062f. ", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-78619ac853c24a28a185bd15c8dfa5a5", "input": "Premise: \u0628\u0627 \u0627\u06cc\u0646 \u0648\u062c\u0648\u062f \u060c \u0645\u06cc\u0627\u062c\u06cc\u0645\u0627 \u0645\u0648\u0641\u0642 \u0645\u06cc \u0634\u0648\u062f \u0647\u0645 \u0645\u0648\u0642\u0631 \u0648 \u0633\u0631\u0632\u0646\u062f\u0647 \u0628\u0627\u0634\u062f. <sep> Hypothesis: \u062f\u0631 Myajima \u0647\u06cc\u0686 \u0627\u062d\u0633\u0627\u0633 \u0633\u0633\u062a\u06cc \u0648\u062c\u0648\u062f \u0646\u062f\u0627\u0631\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-4c4a6eb982b141e89ff2e5e7ee02cf8d", "input": "Premise: \u0627\u06cc\u0646 \u0642\u0648\u0627\u0646\u06cc\u0646 \u0628\u0631 \u062f\u062e\u0627\u0644\u062a \u0645\u062f\u06cc\u0631\u0627\u0646 \u0627\u0631\u0634\u062f \u062f\u0631 \u062a\u0635\u0645\u06cc\u0645 \u06af\u06cc\u0631\u06cc \u0647\u0627\u06cc \u0645\u062f\u06cc\u0631\u06cc\u062a \u0627\u0637\u0644\u0627\u0639\u0627\u062a \u060c \u0627\u0646\u062a\u0635\u0627\u0628 \u0627\u0641\u0633\u0631\u0627\u0646 \u0627\u0631\u0634\u062f \u0627\u0637\u0644\u0627\u0639\u0627\u062a \u062f\u0631 \u0633\u0637\u062d \u0627\u0631\u0634\u062f \u0648 \u0627\u0633\u062a\u0641\u0627\u062f\u0647 \u0627\u0632 \u0627\u0642\u062f\u0627\u0645\u0627\u062a \u0639\u0645\u0644\u06a9\u0631\u062f\u06cc \u0628\u0631\u0627\u06cc \u0627\u0631\u0632\u06cc\u0627\u0628\u06cc \u0633\u0647\u0645 \u0641\u0646\u0627\u0648\u0631\u06cc \u062f\u0631 \u062f\u0633\u062a\u06cc\u0627\u0628\u06cc \u0628\u0647 \u0646\u062a\u0627\u06cc\u062c \u0645\u0627\u0645\u0648\u0631\u06cc\u062a \u062a\u0623\u06a9\u06cc\u062f \u0645\u06cc \u06a9\u0646\u0646\u062f. <sep> Hypothesis: \u0642\u0648\u0627\u0646\u06cc\u0646\u06cc \u0648\u062c\u0648\u062f \u062f\u0627\u0631\u062f \u06a9\u0647 \u0646\u062d\u0648\u0647 \u062a\u0635\u0645\u06cc\u0645 \u06af\u06cc\u0631\u06cc \u0645\u062f\u06cc\u0631\u0627\u0646 \u0627\u0631\u0634\u062f \u0645\u062f\u06cc\u0631\u06cc\u062a \u0627\u0637\u0644\u0627\u0639\u0627\u062a \u062f\u0631 \u0634\u0631\u06a9\u062a \u0647\u0627\u06cc \u062f\u0648\u0644\u062a\u06cc \u0631\u0627 \u0634\u0627\u0645\u0644 \u0645\u06cc \u0634\u0648\u0646\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-6869d66692c94186ac9feecda75bfdb1", "input": "Premise: \u067e\u0633 \u0627\u0632 \u0633\u0631\u0646\u06af\u0648\u0646\u06cc \u0635\u062f\u0627\u0645 \u062d\u0633\u064a\u0646 \u062f\u0631 \u062d\u0645\u0644\u0647 \u0633\u0627\u0644 \u06f2\u06f0\u06f0\u06f3 \u0622\u0645\u0631\u064a\u06a9\u0627\u060c \u0627\u0639\u0636\u0627\u06cc \u062d\u0632\u0628 \u0628\u0639\u062b \u0627\u0632 \u062f\u0627\u0634\u062a\u0646 \u0645\u0634\u0627\u063a\u0644 \u062f\u0648\u0644\u062a\u06cc \u0628\u0627\u0632\u062f\u0627\u0634\u062a\u0647 \u0634\u062f\u0647 \u0648 \u0633\u062e\u062a\u06cc \u0647\u0627\u06cc \u0632\u064a\u0627\u062f\u06cc \u0628\u0631 \u0627\u064a\u0634\u0627\u0646 \u062a\u062d\u0645\u064a\u0644 \u0634\u062f\u0647 \u0628\u0648\u062f. <sep> Hypothesis: \u0627\u0639\u0636\u0627\u06cc \u062d\u0632\u0628 \u0628\u0639\u062b\u060c \u067e\u0633 \u0627\u0632 \u0633\u0631\u0646\u06af\u0648\u0646\u06cc \u0635\u062f\u0627\u0645 \u0645\u062d\u06a9\u0648\u0645 \u0634\u062f\u0646\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-d464b236a6544168827c47f142d34811", "input": "Premise: \u0646\u0627\u062a\u0627\u0644\u06cc\u0627 \u067e\u0631\u0633\u06cc\u062f \u0686\u0637\u0648\u0631 \u0627\u06cc\u0646 \u0627\u062a\u0641\u0627\u0642 \u0627\u0641\u062a\u0627\u062f\u060c \u0648 \u0628\u0647 \u067e\u0646\u062c\u0631\u0647 \u0627\u0634\u0627\u0631\u0647 \u06a9\u0631\u062f. <sep> Hypothesis: \u0646\u0627\u062a\u0627\u0644\u06cc\u0627 \u0633\u0627\u06a9\u062a \u0627\u0632 \u067e\u0646\u062c\u0631\u0647 \u062e\u06cc\u0631\u0647 \u0634\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-01a9262982354ae59019d11437b3aa5b", "input": "Premise: \u0628\u0647 \u06af\u0641\u062a\u0647\u0654 \u0641\u062f\u0644 \u0647\u0646\u062f\u0647\u0627\u0644 (Fedel Handhal)\u060c \u0645\u062d\u0642\u0642 \u062a\u0627\u0631\u06cc\u062e \u0648 \u0641\u0631\u0647\u0646\u06af \u0627\u0645\u0627\u0631\u0627\u062a \u0645\u062a\u062d\u062f\u0647 \u0639\u0631\u0628\u06cc\u060c \u06a9\u0644\u0645\u0647\u0654 \u062f\u0628\u06cc \u0645\u0645\u06a9\u0646 \u0627\u0633\u062a \u0627\u0632 \u06a9\u0644\u0645\u0647\u0654 \u00ab\u062f\u064e\u0628\u0627\u00bb \u062a\u0634\u06a9\u06cc\u0644 \u0634\u062f\u0647 \u0628\u0627\u0634\u062f \u06a9\u0647 \u0627\u0634\u0627\u0631\u0647\u200c\u0627\u06cc \u0628\u0647 \u062c\u0631\u06cc\u0627\u0646 \u0622\u0647\u0633\u062a\u0647\u0654 \u0631\u0648\u062f\u062e\u0627\u0646\u0647\u0654 \u0642\u062f\u06cc\u0645\u06cc \u0627\u06cc\u0646 \u0634\u0647\u0631 \u0628\u0627 \u0646\u0627\u0645 \u062e\u0648\u0631 \u0627\u0633\u062a. \u0647\u0645\u0686\u0646\u06cc\u0646 \u0627\u062d\u0645\u062f \u0645\u062d\u0645\u062f \u0639\u0628\u06cc\u062f \u0634\u0627\u0639\u0631 \u0648 \u0645\u062d\u0642\u0642 \u0646\u06cc\u0632 \u0645\u06cc\u200c\u06af\u0648\u06cc\u062f \u06a9\u0647 \u0631\u06cc\u0634\u0647\u0654 \u06a9\u0644\u0645\u0647\u0654 \u062f\u0628\u06cc\u060c \u062f\u064e\u0628\u0627 \u0627\u0633\u062a \u0627\u0645\u0627 \u0645\u0646\u0638\u0648\u0631 \u0627\u0632 \u062f\u0628\u0627 \u0646\u0648\u0639\u06cc \u0645\u0644\u062e \u0628\u0648\u062f\u0647\u200c\u0627\u0633\u062a. <sep> Hypothesis: \u0645\u062d\u0642\u0642\u0627\u0646 \u0631\u0627\u062c\u0639 \u0628\u0647 \u0631\u06cc\u0634\u0647\u200c\u06cc \u06a9\u0644\u0645\u0647 \u06cc \u062f\u0648\u0628\u06cc  \u062a\u0648\u0627\u0641\u0642 \u062f\u0627\u0631\u0646\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-ba13d29027eb447e93e59b659f9f8fe2", "input": "Premise: \u0628\u0686\u0647 \u0641\u06cc\u0644 \u0647\u0627\u06cc \u0646\u0631 \u062f\u0631 \u062f\u0648\u0627\u0632\u062f\u0647 \u0633\u0627\u0644\u06af\u06cc \u06af\u0644\u0647 \u0631\u0627 \u062a\u0631\u06a9 \u0645\u06cc \u06a9\u0646\u0646\u062f\u060c \u0627\u0645\u0627 \u0641\u06cc\u0644 \u0647\u0627\u06cc \u0645\u0627\u062f\u0647 \u062a\u0645\u0627\u0645 \u0637\u0648\u0644 \u0639\u0645\u0631 \u062e\u0648\u062f \u0631\u0627 \u0628\u0627 \u06af\u0644\u0647 \u0633\u067e\u0631\u06cc \u0645\u06cc \u06a9\u0646\u0646\u062f. <sep> Hypothesis: \u0641\u06cc\u0644\u200c\u0647\u0627\u06cc \u0645\u0627\u062f\u0647 \u062a\u0645\u0627\u06cc\u0644\u06cc \u0628\u0647 \u062a\u0631\u06a9 \u06af\u0644\u0647 \u0646\u062f\u0627\u0631\u0646\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-7596f6a3c74f48ec81fa6c39777761ac", "input": "Premise: \u0627\u0648\u0644\u0645\u0631\u062a \u0627\u0641\u0632\u0648\u062f \u0627\u0648 \u062f\u0648\u0644\u062a \u0641\u0644\u0633\u0637\u06cc\u0646 \u0631\u0627 \u0645\u0633\u0626\u0648\u0644 \u062a\u0636\u06cc\u0645\u0646 \u0633\u0644\u0627\u0645\u062a \u0648 \u0628\u0627\u0632\u06af\u0634\u062a \u0633\u0631\u0628\u0627\u0632 \u0645\u06cc \u062f\u0627\u0646\u062f. \u0627\u0648\u0644\u0645\u0631\u062a \u0627\u06cc\u0646 \u0645\u0648\u0636\u0648\u0639 \u0631\u0627 \u067e\u0633 \u0627\u0632 \u0622\u0646 \u0639\u0646\u0648\u0627\u0646 \u06a9\u0631\u062f \u06a9\u0647 \u0633\u0647 \u06af\u0631\u0648\u0647 \u0633\u062a\u06cc\u0632\u0647 \u06af\u0631 \u0641\u0644\u0633\u0637\u06cc\u0646\u06cc \u062f\u0631 \u0628\u06cc\u0627\u0646\u06cc\u0647 \u0627\u06cc \u062a\u0647\u062f\u06cc\u062f \u06a9\u0631\u062f\u0646\u062f \u06a9\u0647 \u0627\u06af\u0631 \u0627\u0633\u0631\u0627\u0626\u064a\u0644 \u0635\u062f\u0647\u0627 \u0632\u0646\u062f\u0627\u0646\u06cc \u0631\u0627 \u0622\u0632\u0627\u062f \u0646\u06a9\u0646\u062f\u060c \u0628\u0647 \u0627\u0642\u062f\u0627\u0645\u0627\u062a \u0646\u0627\u0645\u0634\u062e\u0635\u06cc \u062f\u0633\u062a \u062e\u0648\u0627\u0647\u0646\u062f \u0632\u062f. <sep> Hypothesis: \u067e\u0633 \u0627\u0632 \u062a\u0647\u062f\u06cc\u062f\u0627\u062a \u06af\u0631\u0648\u0647\u200c\u0647\u0627\u06cc \u0641\u0644\u0633\u0637\u06cc\u0646\u06cc\u060c\u200c\u0627\u0648\u0644\u0645\u0631\u062a \u0627\u0632 \u062f\u0648\u0644\u062a \u0641\u0644\u0633\u0637\u06cc\u0646 \u062e\u0648\u0627\u0633\u062a\u0627\u0631 \u0622\u0632\u0627\u062f\u06cc \u0633\u0631\u0628\u0627\u0632 \u0634\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-885bcd8a33a948f99fe58a445163d0e0", "input": "Premise: \u0622\u06a9\u0627\u062f\u0645\u06cc \u0645\u0648\u0633\u06cc\u0642\u06cc \u0646\u063a\u0645\u0647 \u0646\u0645\u0627\u06cc\u0634\u0646\u0627\u0645\u0647 \u0631\u0627 \u062f\u0631 \u0645\u062d\u0644 \u062e\u0648\u062f \u0628\u0631\u06af\u0632\u0627\u0631 \u0645\u06cc\u200c\u06a9\u0646\u062f. <sep> Hypothesis: \u0627\u06cc\u0646 \u0646\u0645\u0627\u06cc\u0634\u0646\u0627\u0645\u0647 \u0627\u0632 \u062f\u0631 \u0641\u0627\u0635\u0644\u0647\u200c\u06cc \u062f\u0648 \u0686\u0647\u0627\u0631\u200c\u0631\u0627\u0647 \u0645\u0627\u0646\u062f\u0647 \u0628\u0647 \u0622\u06a9\u0627\u062f\u0645\u06cc \u0645\u0648\u0633\u06cc\u0642\u06cc \u0646\u063a\u0645\u0647 \u0628\u0631\u06af\u0632\u0627\u0631 \u062e\u0648\u0627\u0647\u062f \u0634\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-89627af84c224d26b22b5b7c20ca8f03", "input": "Premise: \u062a\u062d\u0642\u06cc\u0642\u0627\u062a \u0647\u0648\u0634\u0645\u0646\u062f\u0627\u0646\u0647 \u0627\u06cc \u0628\u0631\u0627\u06cc\n\u062a\u0634\u062e\u06cc\u0635 \u062a\u0639\u0627\u0645\u0644\u0627\u062a \u067e\u06cc\u0686\u06cc\u062f\u0647 \u0645\u06cc\u0627\u0646 \u0627\u06cc\u0646 \u0645\u062a\u063a\u06cc\u0631\u0647\u0627 \u0645\u0648\u0631\u062f \u0646\u06cc\u0627\u0632 \u0627\u0633\u062a. <sep> Hypothesis: \u062f\u0631 \u0648\u0627\u0642\u0639\u060c \u0641\u0647\u0645 \u0645\u062a\u063a\u06cc\u0631\u0647\u0627 \u06a9\u0627\u0645\u0644\u0627 \u0633\u0627\u062f\u0647 \u0648 \u0622\u0633\u0627\u0646 \u0627\u0633\u062a.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-a9a6e1cf6fb1455c8adc94d3a3d8db3b", "input": "Premise: \u0634\u0645\u0627 \u0628\u0631\u0627\u06cc \u0628\u0627\u0632\u06cc \u0628\u06cc\u0631\u0648\u0646 \u0646\u0645\u06cc\u0627\u06cc\u06cc\u062f\u061f <sep> Hypothesis: \u0622\u0646\u0647\u0627 \u0627\u0632 \u062f\u0648\u0633\u062a\u0634\u0627\u0646 \u0645\u06cc \u062e\u0648\u0627\u0647\u0646\u062f \u0628\u06cc\u0631\u0648\u0646 \u0628\u06cc\u0627\u06cc\u062f.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-4dbcd13ee62540da82537b627ae52497", "input": "Premise: \u0628\u0646\u0627 \u0628\u0647 \u0642\u0648\u0644 \u0627\u0648\u060c \u067e\u062f\u0631\u0634 \u0627\u06cc\u0646 \u0634\u063a\u0644 \u0631\u0627 \u062f\u0631 \u0645\u0639\u0631\u0636 \u06a9\u0633\u0627\u062f\u06cc \u062f\u06cc\u062f \u0648 \u067e\u06cc\u0634\u0647\u0654 \u062e\u0648\u062f \u0631\u0627 \u0627\u0632 \u0633\u0645\u0627\u0648\u0631 \u0633\u0627\u0632\u06cc \u0628\u0647 \u0633\u0646\u06af\u200c\u0628\u0631\u06cc \u062a\u063a\u06cc\u06cc\u0631 \u062f\u0627\u062f. <sep> Hypothesis: \u067e\u062f\u0631\u0634 \u067e\u0633 \u0627\u0632 \u0645\u062f\u062a\u06cc \u062a\u063a\u06cc\u06cc\u0631 \u0634\u063a\u0644 \u062f\u0627\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-46b43a60640043f39573a1a5db82dbfb", "input": "Premise: \u0645\u0642\u0627\u0645\u0627\u062a \u0639\u0631\u0627\u0642\u06cc \u0645\u06cc \u06af\u0648\u064a\u0646\u062f \u0627\u0646\u0641\u062c\u0627\u0631 \u064a\u06a9 \u062a\u0635\u0627\u062f\u0641 \u0628\u0648\u062f\u060c \u0627\u0645\u0627 \u0645\u0642\u0627\u0645\u0627\u062a \u0627\u0648\u06a9\u0631\u0627\u064a\u0646 \u062f\u0631 \u0627\u064a\u0646 \u0628\u0627\u0631\u0647  \u0645\u06cc \u06af\u0648\u064a\u0646\u062f \u06a9\u0647 \u0622\u064a\u0627 \u0627\u064a\u0646 \u062d\u0627\u062f\u062b\u0647 \u064a\u06a9 \u062d\u0645\u0644\u0647 \u0628\u0648\u062f \u064a\u0627\u0646\u0647\u060c \u062a\u062d\u0642\u064a\u0642 \u0645\u06cc \u06a9\u0646\u0646\u062f. <sep> Hypothesis: \u0622\u0646 \u0647\u0627 \u0647\u0645\u06af\u06cc \u0645\u0639\u062a\u0642\u062f\u0646\u062f \u06a9\u0647 \u0627\u06cc\u0646 \u062d\u0627\u062f\u062b\u0647 \u062a\u0635\u0627\u062f\u0641 \u0646\u0628\u0648\u062f\u0647 \u0648 \u06cc\u06a9 \u062d\u0645\u0644\u0647 \u0645\u062d\u0633\u0648\u0628 \u0645\u06cc \u0634\u0648\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-5f37dca5cecd4dea9467fa6f613261b4", "input": "Premise: \u0628\u0646\u0627\u0628\u0631 \u0633\u0631\u0634\u0645\u0627\u0631\u06cc \u0645\u0631\u06a9\u0632 \u0622\u0645\u0627\u0631 \u0627\u06cc\u0631\u0627\u0646\u060c \u062c\u0645\u0639\u06cc\u062a \u0628\u062e\u0634 \u0645\u0631\u06a9\u0632\u06cc \u0634\u0647\u0631\u0633\u062a\u0627\u0646 \u0634\u0647\u0631\u06cc\u0627\u0631 \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f3\u06f8\u06f5 \u0628\u0631\u0627\u0628\u0631 \u0628\u0627 \u06f5\u06f1\u06f4\u06f7\u06f4\u06f0 \u0646\u0641\u0631 \u0628\u0648\u062f\u0647\u200c\u0627\u0633\u062a. <sep> Hypothesis: \u0628\u0646\u0627\u0628\u0631 \u0633\u0631\u0634\u0645\u0627\u0631\u06cc \u0645\u0631\u06a9\u0632 \u0622\u0645\u0627\u0631 \u0627\u06cc\u0631\u0627\u0646\u060c \u062c\u0645\u0639\u06cc\u062a \u0628\u062e\u0634 \u0645\u0631\u06a9\u0632\u06cc \u0634\u0647\u0631\u0633\u062a\u0627\u0646 \u0634\u0647\u0631\u06cc\u0627\u0631 \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f3\u06f8\u06f5 \u0628\u0631\u0627\u0628\u0631 \u0628\u0627 \u06f5\u06f5\u06f4\u06f7\u06f4\u06f0 \u0646\u0641\u0631 \u0628\u0648\u062f\u0647\u200c\u0627\u0633\u062a.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-4200d40c95af4638af775435f3227f96", "input": "Premise: \u062f\u0631 \u067e\u06cc \u0627\u06cc\u0646 \u062d\u0645\u0644\u0647 \u0645\u0627\u062f\u0631 \u0627\u0631\u0646 \u0628\u0647 \u062f\u0633\u062a \u062a\u0627\u06cc\u062a\u0627\u0646\u06cc \u062e\u0648\u0631\u062f\u0647 \u0645\u06cc\u0634\u0648\u062f \u0648\u0644\u06cc \u062e\u0648\u062f\u0634 \u0648 \u062f\u0648\u0633\u062a\u0627\u0646\u0634 \u0645\u0648\u0641\u0642 \u0628\u0647 \u0641\u0631\u0627\u0631 \u0645\u06cc\u0634\u0648\u0646\u062f. <sep> Hypothesis: \u0627\u0648\u0644\u06cc\u0646 \u0636\u0631\u0628\u0647 \u0628\u0647 \u06af\u0631\u0648\u0647 \u0622\u0631\u0646 \u0627\u06cc\u0646 \u0628\u0648\u062f \u06a9\u0647 \u0645\u0627\u062f\u0631\u0634 \u062a\u0648\u0633\u0637 \u06cc\u06a9\u06cc \u0627\u0632 \u062a\u0627\u06cc\u062a\u0627\u0646\u0647\u0627 \u062e\u0648\u0631\u062f\u0647 \u0634\u062f\u0647 \u0628\u0648\u062f. ", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-70913edfded44f999f3ccd302e95b197", "input": "Premise: \u0645\u0639\u0627\u0648\u0646 \u062f\u0627\u062f\u0633\u062a\u0627\u0646 \u06a9\u0644 \u0627\u0631\u06cc\u06a9 \u0647\u0648\u0644\u062f\u0631\u060c \u06a9\u0647 \u0627\u0638\u0647\u0627\u0631 \u062f\u0627\u0634\u062a \u0628\u0647 \u062c\u0627\u06cc \u06cc\u06a9 \u0645\u0634\u0627\u0648\u0631 \u0645\u0633\u062a\u0642\u0644 \u0645\u063a\u0631\u0636\u0627\u0646\u0647\u060c \u0648\u0632\u0627\u0631\u062a \u062f\u0627\u062f\u06af\u0633\u062a\u0631\u06cc \u0628\u0627\u06cc\u062f \u062f\u0631 \u0645\u0648\u0631\u062f \u0628\u06cc\u062a\u06af\u06cc\u062a \u062a\u062d\u0642\u06cc\u0642 \u06a9\u0646\u062f. <sep> Hypothesis: \u0627\u0631\u06cc\u06a9 \u0647\u0648\u0644\u062f\u0631 \u0647\u0645\u0627\u0646\u0637\u0648\u0631 \u06a9\u0647 \u067e\u06cc\u0634\u200c\u0628\u06cc\u0646\u06cc \u0645\u06cc\u200c\u0634\u062f \u067e\u06cc\u0634\u0646\u0647\u0627\u062f \u06a9\u0631\u062f \u06a9\u0647 \u0648\u0632\u0627\u0631\u062a \u062f\u0627\u062f\u06af\u0633\u062a\u0631\u06cc \u0628\u0627\u06cc\u062f \u062a\u062d\u0642\u06cc\u0642 \u06a9\u0646\u062f \u0646\u0647 \u0647\u0631 \u0633\u0627\u0632\u0645\u0627\u0646 \u062f\u06cc\u06af\u0631.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-99adb9221386410999054c190503e11d", "input": "Premise: \u0627\u06cc\u0646 \u0628\u0633\u06cc\u0627\u0631 \u0645\u0639\u0645\u0648\u0644\u06cc \u0627\u0633\u062a \u0647\u0645\u0627\u0646\u0637\u0648\u0631 \u06a9\u0647 \u0647\u0645\u06cc\u0634\u0647 \u062f\u0631 \u0642\u062f\u06cc\u0645 \u062f\u06cc\u062f\u0647\u200c\u0627\u06cc\u0645 \u062f\u0631 \u0627\u0648\u0627\u062e\u0631 \u062a\u06cc\u0631 \u0648 \u062f\u0631 \u0637\u0648\u0644 \u0645\u0631\u062f\u0627\u062f \u0647\u0648\u0627 \u0628\u0627\u0644\u0627\u06cc \u06f4\u06f0 \u062f\u0631\u062c\u0647 \u0645\u06cc\u200c\u0631\u0648\u062f. <sep> Hypothesis: \u0647\u0648\u0627 \u0647\u06cc\u0686 \u0648\u0642\u062a \u0628\u0627\u0644\u0627\u06cc \u06f4\u06f0 \u062f\u0631\u062c\u0647 \u0646\u0645\u06cc\u200c\u0631\u0648\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-efd96be6764d4fe7b7068d6c75b59741", "input": "Premise: \u0686\u06af\u0648\u0646\u0647 \u0645\u06cc \u062f\u0627\u0646\u06cc\u062f \u06a9\u0647 \u062f\u062e\u062a\u0631 \u0634\u0645\u0627 \u062f\u0631 \u0627\u0633\u062a\u0631\u0648\u0626\u06cc\u062f \u0627\u0633\u062a\u061f <sep> Hypothesis: \u0686\u06af\u0648\u0646\u0647 \u0645\u06cc \u062f\u0627\u0646\u06cc\u062f \u067e\u0633\u0631 \u0634\u0645\u0627 \u0633\u06cc\u06af\u0627\u0631 \u0645\u06cc \u06a9\u0634\u062f\u061f", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-8edaa2710e864e8fb8d5b18c9111d763", "input": "Premise: \u0648\u0632\u06cc\u0631 \u0635\u0646\u0639\u062a\u060c \u0645\u0639\u062f\u0646 \u0648 \u062a\u062c\u0627\u0631\u062a \u062f\u0631\u0628\u0627\u0631\u0647 \u0627\u06cc\u0646\u06a9\u0647 \u06a9\u0645\u0627\u06a9\u0627\u0646 \u0628\u0647 \u0628\u0631\u062c\u0627\u0645 \u0627\u0646\u062a\u0642\u0627\u062f\u0647\u0627\u06cc\u06cc \u0648\u0627\u0631\u062f \u0645\u06cc \u06a9\u0646\u0646\u062f\u060c \u06af\u0641\u062a: \u0628\u0631\u062e\u06cc \u0647\u0627 \u0628\u0631 \u0627\u06cc\u0646 \u062a\u0635\u0648\u0631\u0646\u062f \u062d\u0627\u0644 \u06a9\u0647 \u0628\u0631\u062c\u0627\u0645 \u0628\u0647 \u062b\u0645\u0631 \u0631\u0633\u06cc\u062f\u0647\u060c \u0628\u0627\u06cc\u062f \u0647\u0645\u0647 \u0686\u06cc\u0632 \u0628\u0647 \u062f\u0627\u062e\u0644 \u06a9\u0634\u0648\u0631 \u0628\u06cc\u0627\u06cc\u062f\u060c \u0627\u0645\u0627 \u0627\u06cc\u0646 \u0637\u0648\u0631 \u0646\u06cc\u0633\u062a\u060c \u0632\u06cc\u0631\u0627 \u0628\u0631\u062c\u0627\u0645 \u0645\u0648\u0627\u0646\u0639 \u0648\u0631\u0648\u062f \u0633\u0631\u0645\u0627\u06cc\u0647 \u06af\u0630\u0627\u0631 \u0631\u0627 \u0628\u0631\u0637\u0631\u0641 \u06a9\u0631\u062f\u0647 \u0648 \u0634\u0631\u0627\u06cc\u0637 \u0627\u0642\u062a\u0635\u0627\u062f \u0648 \u0633\u06cc\u0627\u0633\u06cc \u06a9\u0634\u0648\u0631 \u0631\u0627 \u0628\u0627 \u062f\u06cc\u06af\u0631 \u06a9\u0634\u0648\u0631\u0647\u0627\u06cc \u062c\u0647\u0627\u0646 \u0628\u0647 \u06cc\u06a9 \u062d\u0627\u0644\u062a \u062a\u0648\u0627\u0632\u0646 \u0631\u0633\u0627\u0646\u062f\u0647 \u0627\u0633\u062a. <sep> Hypothesis: \u0628\u0627 \u0648\u062c\u0648\u062f \u0627\u06cc\u0646 \u06a9\u0647 \u0628\u0631\u062c\u0627\u0645 \u0648\u0631\u0648\u062f \u0633\u0631\u0645\u0627\u06cc\u0647 \u0628\u0647 \u06a9\u0634\u0648\u0631 \u0631\u0627 \u062a\u0633\u0647\u06cc\u0644 \u06a9\u0631\u062f\u0647 \u0627\u0633\u062a \u062f\u0631 \u0639\u0645\u0644 \u0645\u0648\u0627\u0646\u0639 \u0632\u06cc\u0627\u062f\u06cc \u0628\u0631\u0627\u06cc \u062f\u06cc\u062f\u0646 \u0646\u062a\u0627\u06cc\u062c \u0628\u0631\u062c\u0627\u0645 \u0648\u062c\u0648\u062f \u062f\u0627\u0631\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-35481a4cb3044bae933737de48a9df89", "input": "Premise: \u0686\u06cc\u0632 \u062f\u06cc\u06af\u0631\u06cc \u06a9\u0647 \u0645\u0627 \u0645\u062a\u0648\u062c\u0647 \u0634\u062f\u0647 \u0627\u06cc\u0645 \u06a9\u0647 \u062f\u0631 \u0637\u0648\u0644 \u0633\u0627\u0644 \u0647\u0627 \u062a\u063a\u06cc\u06cc\u0631 \u06a9\u0631\u062f\u0647 \u0627\u0633\u062a \u0648 \u0645\u0627 \u0648\u0627\u0642\u0639\u0627\u064b \u0645\u0637\u0645\u0626\u0646 \u0646\u06cc\u0633\u062a\u06cc\u0645 \u06a9\u0647 \u0686\u0647 \u06a9\u0627\u0631\u06cc \u0645\u06cc \u062e\u0648\u0627\u0647\u06cc\u0645 \u0628\u0627 \u0622\u0646 \u0628\u0647 \u0637\u0648\u0631 \u0639\u0644\u0646\u06cc \u0627\u0646\u062c\u0627\u0645 \u062f\u0647\u06cc\u0645 \u0627\u0645\u0627 \u0622\u0645\u0648\u0632\u0647 \u0647\u0627 \u0648 \u0627\u06cc\u062f\u0647 \u0647\u0627 \u06cc\u06cc \u06a9\u0647 \u0628\u0647 \u0634\u0645\u0627 \u0622\u0645\u0648\u0632\u0634 \u062f\u0627\u062f\u0647 \u0645\u06cc \u0634\u0648\u062f\u066c \u0628\u0627 \u0622\u0646\u0686\u0647 \u06a9\u0647 \u0645\u0627 \u0628\u0647 \u0622\u0646\u0647\u0627 \u0645\u06cc \u0622\u0645\u0648\u0632\u06cc\u0645 \u0686\u0647 \u0627\u0632 \u0646\u0638\u0631 \u0627\u062e\u0644\u0627\u0642\u06cc \u0648 \u0686\u0647 \u0627\u0632 \u062f\u06cc\u062f\u06af\u0627\u0647 \u0646\u062d\u0648\u0647 \u0628\u0631\u062e\u0648\u0631\u062f \u0628\u0627 \u06cc\u06a9 \u0648\u0636\u0639\u06cc\u062a \u0631\u062e \u062f\u0627\u062f\u0647\u066c \u0647\u0645\u06cc\u0634\u0647 \u0645\u0637\u0627\u0628\u0642\u062a \u0646\u062f\u0627\u0631\u062f. <sep> Hypothesis: \u0645\u0627 \u0645\u062a\u0648\u062c\u0647 \u0634\u062f\u0647 \u0627\u06cc\u0645 \u06a9\u0647 \u0645\u0639\u0644\u0645\u0627\u0646 \u0686\u06cc\u0632\u0647\u0627\u06cc\u06cc \u0645\u06cc \u06af\u0648\u06cc\u0646\u062f \u06a9\u0647 \u0645\u0627 \u0628\u0627 \u0622\u0646\u0647\u0627 \u0645\u0648\u0627\u0641\u0642 \u0646\u06cc\u0633\u062a\u06cc\u0645.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-8e0901d3169547b7bf3748ff5e38df94", "input": "Premise: \u062f\u0631\u06cc\u0627\u06cc \u0645\u0631\u062f\u0647 \u0628\u0627 \u06a9\u0645\u200c\u0622\u0628\u06cc \u0634\u062f\u06cc\u062f \u0645\u0648\u0627\u062c\u0647 \u0627\u0633\u062a \u0627\u0645\u0627 \u0645\u062d\u0648 \u0646\u062e\u0648\u0627\u0647\u062f \u0634\u062f. <sep> Hypothesis: \u062f\u0631\u06cc\u0627\u0686\u06c0 \u0627\u0631\u0648\u0645\u06cc\u0647 \u062f\u0631 \u062d\u0627\u0644 \u067e\u06cc\u0634\u0631\u0648\u06cc \u0628\u0647 \u0633\u0648\u06cc \u0645\u0631\u06af \u0627\u0633\u062a \u0648 \u062f\u06cc\u06af\u0631 \u062e\u0628\u0631\u06cc \u0627\u0632 \u067e\u0631\u0648\u0627\u0632 \u067e\u0631\u0646\u062f\u06af\u0627\u0646 \u062f\u0631\u06cc\u0627\u06cc\u06cc \u062f\u0631 \u0627\u0637\u0631\u0627\u0641 \u0622\u0646 \u0646\u06cc\u0633\u062a.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-ec36230ef385466f8ca1f2a866f2767e", "input": "Premise: \u0627\u0648 \u0628\u0647 \u0645\u0648\u0644\u0631 \u0637\u0648\u0631\u06cc \u0646\u06af\u0627\u0647 \u0645\u06cc \u06a9\u0631\u062f \u06a9\u0647 \u0627\u0646\u06af\u0627\u0631 \u06af\u0631\u0648\u0647\u0628\u0627\u0646 \n\u0628\u0647 \u0627\u0641\u0631\u0627\u062f\u0634 \u0646\u06af\u0627\u0647 \u0645\u06cc \u06a9\u0646\u062f\u060c \u0627\u0646\u06af\u0627\u0631 \u06a9\u0647  \u0646\u0642\u0637\u0647 \u06cc \u06a9\u0627\u0646\u0648\u0646\u06cc \u0647\u0631 \u062d\u0645\u0644\u0647 \u0627\u06cc \u062f\u0631 \u0622\u06cc\u0646\u062f\u0647 \u0627\u0633\u062a. <sep> Hypothesis: \u0645\u0648\u0644\u0631 \u0686\u06cc\u0632 \u062c\u0627\u0644\u0628\u06cc \u062a\u0648 \u062e\u0648\u062f\u0634 \u062f\u0627\u0634\u062a \u06a9\u0647 \u0628\u0627\u0639\u062b \u0645\u06cc \u0634\u062f \u062a\u0648\u062c\u0647 \u0647\u0645\u0647 \u0631\u0648 \u0628\u0647 \u062e\u0648\u062f\u0634 \u062c\u0644\u0628 \u06a9\u0646\u0647.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-db3b9721b678424d9d42f83be4b72f20", "input": "Premise: \u0628\u0647 \u0627\u06cc\u0646 \u062a\u0648\u062c\u0647 \u062f\u0627\u0634\u062a\u0647 \u0628\u0627\u0634\u06cc\u062f \u06a9\u0647 \u062f\u0631 \u0633\u0627\u062e\u062a\u0627\u0631 \u0633\u0648\u0645 \u06cc\u0627 \u0647\u0645\u0627\u0646 \u0633\u0627\u062e\u062a\u0627\u0631 \u06a9\u0645\u067e\u0644\u06a9\u0633 \u0641\u0642\u0637 \u06cc\u06a9 \u067e\u0631\u0648\u062a\u0626\u06cc\u0646 \u0628\u0647 \u062f\u0648\u0631 \u062e\u0648\u062f \u0645\u06cc \u067e\u06cc\u0686\u062f \u0648\u0644\u06cc \u062f\u0631 \u0633\u0627\u062e\u062a\u0627\u0631 \u0686\u0647\u0627\u0631\u0645 \u0686\u0646\u062f \u067e\u0631\u0648\u062a\u0626\u06cc\u0646 \u0628\u0647 \u062f\u0648\u0631 \u0647\u0645 \u0645\u06cc\u067e\u06cc\u0686\u0646\u062f. <sep> Hypothesis: \u0628\u0647 \u0627\u06cc\u0646 \u062a\u0648\u062c\u0647 \u062f\u0627\u0634\u062a\u0647 \u0628\u0627\u0634\u06cc\u062f \u06a9\u0647 \u062f\u0631 \u0633\u0627\u062e\u062a\u0627\u0631 \u0633\u0648\u0645 \u06cc\u0627 \u0647\u0645\u0627\u0646 \u0633\u0627\u062e\u062a\u0627\u0631 \u06a9\u0645\u067e\u0644\u06a9\u0633 \u0686\u0646\u062f \u067e\u0631\u0648\u062a\u0626\u06cc\u0646 \u0628\u0647 \u062f\u0648\u0631 \u062e\u0648\u062f \u0645\u06cc \u067e\u06cc\u0686\u062f \u0648\u0644\u06cc \u062f\u0631 \u0633\u0627\u062e\u062a\u0627\u0631 \u0686\u0647\u0627\u0631\u0645 \u06cc\u06a9 \u067e\u0631\u0648\u062a\u0626\u06cc\u0646 \u0628\u0647 \u062f\u0648\u0631 \u0647\u0645 \u0645\u06cc\u067e\u06cc\u0686\u0646\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-0adbce81f87b47e0896b36b9df95769b", "input": "Premise: \u0633\u0631\u0632\u0645\u06cc\u0646 \u0647\u0627\u06cc \u062c\u062f\u06cc\u062f \u0631\u0627 \u0645\u06cc \u062a\u0648\u0627\u0646 \u0627\u0632 \u0637\u0631\u06cc\u0642 \u0642\u0637\u0627\u0631 KCR \u060c \u06a9\u0647 \u06f1\u06f0 \u0627\u06cc\u0633\u062a\u06af\u0627\u0647 \u0628\u06cc\u0646 \u0627\u06cc\u0633\u062a\u06af\u0627\u0647 \u06a9\u0648\u0644\u0648\u0646 \u0648 \u0634\u06cc\u0648\u0646\u06af \u0634\u06cc \u060c\u0622\u062e\u0631\u06cc\u0646 \u062a\u0648\u0642\u0641 \u0642\u0628\u0644 \u0627\u0632 \u0648\u0631\u0648\u062f \u0628\u0647 \u0686\u06cc\u0646\u060c \u062f\u0627\u0631\u062f\u060c \u0633\u06cc\u0627\u062d\u062a \u06a9\u0631\u062f. <sep> Hypothesis: \u0642\u0637\u0627\u0631 KCR \u0628\u06cc\u0634 \u0627\u0632 \u067e\u0646\u062c \u062a\u0648\u0642\u0641 \u0628\u06cc\u0646 \u0627\u06cc\u0633\u062a\u06af\u0627\u0647 \u0648 \u0634\u06cc\u0648\u0646\u06af \u0634\u06cc \u0627\u0646\u062c\u0627\u0645 \u0645\u06cc \u062f\u0647\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-faceeae1337b42ed84a58656ef4e4568", "input": "Premise: \u062f\u0631 \u0634\u0647\u0631 \u06a9\u0627\u0631\u0645\u0644 \u062f\u0631 \u06a9\u0627\u0644\u06cc\u0641\u0631\u0646\u06cc\u0627\u060c \u0647\u06cc\u0686\u200c\u06af\u0648\u0646\u0647 \u0634\u0645\u0627\u0631\u0647\u0654 \u067e\u0644\u0627\u06a9\u06cc \u0648\u062c\u0648\u062f \u0646\u062f\u0627\u0631\u062f. <sep> Hypothesis: \u0634\u0645\u0627\u0631\u0647 \u067e\u0644\u0627\u06a9 \u0645\u0646 \u062f\u0631 \u0634\u0647\u0631 \u06a9\u0627\u0631\u0645\u0644 \u062f\u0631 \u06a9\u0627\u0644\u06cc\u0641\u0631\u0646\u06cc\u0627\u060c \u062e\u0627\u0635 \u0628\u0648\u062f", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-bcb0b835a21541b5980849ad97027680", "input": "Premise: \u0628\u0627 \u0627\u06cc\u0646 \u0648\u062c\u0648\u062f\u060c \u0628\u0631\u0627\u0633\u0627\u0633\n\u0628\u062d\u062b \u0648 \u06af\u0641\u062a \u0648 \u06af\u0648\u0647\u0627 \n\u0628\u0627 \u0686\u0646\u062f \u0627\u06cc\u0627\u0644\u062a\u060c \u0628\u0631\u0622\u0648\u0631\u062f \u0645\u06cc \u0634\u0648\u062f\u060c\n\u0631\u0648\u0646\u062f \u0628\u0631\u0631\u0633\u06cc\n\u0628\u0631\u0646\u0627\u0645\u0647 \u06cc \u06a9\u0627\u0631\u0628\u0631\u062f\u06cc\u060c \u062d\u062f\u0648\u062f\u0627 38 \u0647\u0641\u062a\u0647\n(9-10 \u0645\u0627\u0647) \u0637\u0648\u0644 \u0628\u06a9\u0634\u062f.  <sep> Hypothesis: \u0631\u0648\u0646\u062f \u0628\u0631\u0631\u0633\u06cc \u0628\u0631\u0646\u0627\u0645\u0647 \u06cc \u06a9\u0627\u0631\u0628\u0631\u062f\u06cc\u060c \n\u062a\u0646\u0647\u0627 \u0628\u0627 \u0634\u0631\u06a9\u062a \u0647\u0627 \u0645\u0648\u0631\u062f \u0628\u062d\u062b \u0642\u0631\u0627\u0631 \u06af\u0631\u0641\u062a.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-6eceb20a86944e249185d7c922abf786", "input": "Premise: \u0627\u0646\u062c\u0627\u0645 \u0645\u0639\u0627\u0645\u0644\u0647 \u0645\u062a\u06a9\u06cc \u0628\u0631 \u0645\u0648\u0627\u0641\u0642\u062a \u0647\u0645\u06af\u0627\u0646 \u0627\u0633\u062a \u0627\u0645\u0627 \u0627\u0633\u067e\u06cc\u0631\u0648\u0633 \u062e\u0648\u0627\u0647\u0627\u0646 \u062d\u0641\u0638 \u0632\u0645\u06cc\u0646 \u0627\u0633\u062a \u0648 \u0627\u0632 \u0627\u0645\u0636\u0627\u06cc \u0642\u0631\u0627\u0631 \u062f\u0627\u062f \u0633\u0631\u0628\u0627\u0632 \u0645\u06cc\u200c\u0632\u0646\u062f. <sep> Hypothesis: \u0628\u0631\u0627\u06cc \u0627\u0645\u0636\u0627\u0621 \u0642\u0631\u0627\u0631\u062f\u0627\u062f \u0647\u0645\u0647 \u0628\u0627\u06cc\u062f \u0645\u0648\u0627\u0641\u0642 \u0628\u0627\u0634\u0646\u062f \u0648\u0644\u06cc \"\u0627\u0633\u067e\u06cc\u0631\u0648\u0633\" \u0686\u0648\u0646 \u062e\u0648\u0627\u0647\u0627\u0646 \u062d\u0641\u0638 \u0632\u0645\u06cc\u0646 \u0627\u0633\u062a \u0648 \u0627\u0645\u0636\u0627\u0621 \u0646\u0645\u06cc\u06a9\u0646\u062f\u060c \u0642\u0631\u0627\u0631\u062f\u0627\u062f \u062e\u0648\u062f\u0628\u062e\u0648\u062f \u0645\u0646\u062a\u0641\u06cc \u0627\u0633\u062a. ", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-d4868dc042f34de997b9bb183d0af01d", "input": "Premise: \u0627\u0644\u062c\u0632\u06cc\u0631\u0647 \u06a9\u0627\u0646\u0627\u0644\u200c\u0647\u0627\u06cc \u0645\u062a\u0639\u062f\u062f \u062e\u0627\u0635 \u062a\u0644\u0648\u06cc\u0632\u06cc\u0648\u0646\u06cc \u0631\u0627 \u0639\u0644\u0627\u0648\u0647 \u0628\u0631 \u06a9\u0627\u0646\u0627\u0644 \u0627\u062e\u0628\u0627\u0631 \u0628\u06a9\u0627\u0631 \u06af\u0631\u0641\u062a\u0647\u200c\u0627\u0633\u062a. <sep> Hypothesis: \u062a\u0639\u062f\u0627\u062f \u06a9\u0627\u0646\u0627\u0644\u0647\u0627\u06cc \u062a\u0644\u0648\u0632\u06cc\u0648\u0646\u06cc \u062f\u0631 \u06a9\u0634\u0648\u0631\u0647\u0627\u06cc \u0639\u0631\u0628\u06cc \u0631\u0648 \u0628\u0647 \u0627\u0641\u0632\u0627\u06cc\u0634 \u0627\u0633\u062a. ", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-2800ba4b32b04a47aad576236162e2a2", "input": "Premise: \u067e\u0633 \u0627\u0632 \u06af\u0630\u0634\u062a \u0633\u0627\u0644\u200c\u0647\u0627 \u062f\u0631 \u062c\u0627\u0645 \u0645\u0644\u062a\u200c\u0647\u0627\u06cc \u0622\u0633\u06cc\u0627 \u06f1\u06f9\u06f9\u06f3 \u0628\u0633\u06a9\u062a\u0628\u0627\u0644 \u0627\u06cc\u0631\u0627\u0646 \u0628\u0647 \u0646\u0642\u0637\u0647 \u0639\u0637\u0641 \u062e\u0648\u062f \u0631\u0633\u06cc\u062f \u0648 \u0631\u0634\u062f \u0686\u0634\u0645\u06af\u06cc\u0631\u06cc \u062f\u0627\u0634\u062a. <sep> Hypothesis: \u0628\u0633\u06a9\u062a\u0628\u0627\u0644 \u0627\u06cc\u0631\u0627\u0646 \u0647\u0645\u0647 \u0633\u0627\u0644\u0647 \u062f\u0631 \u0646\u0642\u0637\u0647 \u0639\u0637\u0641 \u062e\u0648\u062f \u0628\u0648\u062f.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-d5484353da054a149126bfb3c8ac7e1a", "input": "Premise: \"\u06cc\u0648\u062a\u06cc\u200c\u0627\u06cc\u0631 \u0627\u0648\u06cc\u06cc\u0634\u0646\"\u060c \u06cc\u06a9 \u0634\u0631\u06a9\u062a \u0647\u0648\u0627\u067e\u06cc\u0645\u0627\u06cc\u06cc \u0631\u0648\u0633\u06cc \u0627\u0633\u062a \u06a9\u0647 \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f9\u06f6\u06f7 \u062a\u0648\u0633\u0637 \u062e\u0637\u0648\u0637 \u0647\u0648\u0627\u067e\u06cc\u0645\u0627\u06cc\u06cc \u0622\u0626\u0631\u0648\u0641\u0644\u0648\u062a \u062a\u0623\u0633\u06cc\u0633 \u0634\u062f \u0648 \u062f\u0631 \u062d\u0627\u0644 \u062d\u0627\u0636\u0631 \u0631\u0648\u0632\u0627\u0646\u0647 \u0628\u0647 \u06f7\u06f2 \u0645\u0642\u0635\u062f\u060c \u062f\u0631 \u0622\u0633\u06cc\u0627\u06cc \u0645\u0631\u06a9\u0632\u06cc\u060c \u0622\u0633\u06cc\u0627\u06cc \u062c\u0646\u0648\u0628\u06cc\u060c \u0622\u0633\u06cc\u0627\u06cc \u062c\u0646\u0648\u0628 \u0634\u0631\u0642\u06cc\u060c \u063a\u0631\u0628 \u0622\u0633\u06cc\u0627 \u0648 \u0627\u0631\u0648\u067e\u0627 \u067e\u0631\u0648\u0627\u0632\u0647\u0627\u06cc \u0645\u0633\u062a\u0642\u06cc\u0645 \u062f\u0627\u0631\u062f. <sep> Hypothesis: \u0627\u06cc\u0646 \u0634\u0631\u06a9\u062a \u06cc\u06a9 \u0634\u0631\u06a9\u062a \u062f\u0648\u0644\u062a\u06cc \u0627\u0633\u062a \u06a9\u0647 \u0628\u06cc\u0634 \u0627\u0632 \u067e\u0646\u062c\u0647\u0632\u0627\u0631 \u0646\u0641\u0631 \u06a9\u0627\u0631\u0645\u0646\u062f \u062f\u0627\u0631\u062f. ", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-69eb7bc71b0243f297863dcf56573e7f", "input": "Premise: \u062f\u0627\u0646\u06cc\u0647\u200c\u0644\u0627 \u062a\u0648\u0645\u0627\u0634 (\u061b \u0632\u0627\u062f\u0647\u0654 ) \u06a9\u0627\u0631\u06af\u0631\u062f\u0627\u0646 \u0641\u06cc\u0644\u0645 \u0648 \u0641\u06cc\u0644\u0645\u200c\u0646\u0627\u0645\u0647\u200c\u0646\u0648\u06cc\u0633 \u0627\u0647\u0644 \u0628\u0631\u0632\u06cc\u0644 \u0627\u0633\u062a. <sep> Hypothesis: \u062f\u0627\u0646\u06cc\u0647 \u0644\u0627 \u062a\u0648\u0645\u0627\u0634 \u062f\u0631 \u0628\u0631\u0632\u06cc\u0644 \u0645\u062a\u0648\u0644\u062f \u0634\u062f\u0647 \u0627\u0633\u062a", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-fab26fdec6304d42aec0298d0512ebac", "input": "Premise: \u0645\u062d\u0645\u062f \u06af\u0641\u062a: \u0634\u0645\u0627 \u0648 \u062f\u0648\u0633\u062a\u0627\u0646\u062a\u0627\u0646 \u0627\u0633\u062a\u0642\u0628\u0627\u0644 \u0646\u0645\u06cc \u0634\u0648\u06cc\u062f. <sep> Hypothesis: \u0645\u062d\u0645\u062f \u06af\u0641\u062a \u0645\u0631\u062f\u0645 \u0627\u06cc\u0646\u062c\u0627 \u0627\u0633\u062a\u0642\u0628\u0627\u0644 \u0646\u0645\u06cc \u0634\u0648\u0646\u062f.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task463_parsinlu_entailment_classification_gpt3_0", "Definition": ["In this task, you will be presented with a premise sentence and a hypothesis sentence in Persian. Determine whether the hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. Classify your answers into \"Contradiction\", \"Neutral\", or \"Entailment\". Entailment:  The model should output Entailment when the hypothesis sentence entails the given premise sentence.   Contradiction:  The model should output Contradiction when the hypothesis sentence contradicts the given premise sentence.   Neutral:  The model should output Neutral when the hypothesis sentence is neutral with respect to a given premise sentence."], "Instance": {"id": "task463-97b1bd36791a482d904aa243f20f3a43", "input": "Premise: \u067e\u0631\u0686\u0645 \u0642\u0631\u0645\u0632 \u0628\u0647 \u0627\u06cc\u0646 \u0645\u0639\u0646\u06cc \u0627\u0633\u062a \u06a9\u0647 \u0634\u0646\u0627 \u062e\u0637\u0631\u0646\u0627\u06a9 \u0627\u0633\u062a \u0648 \u06cc\u06a9 \u067e\u0631\u0686\u0645 \u0633\u06cc\u0627\u0647 \u0628\u0647 \u0645\u0639\u0646\u0627\u06cc \u0622\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0634\u0646\u0627 \u0645\u0645\u0646\u0648\u0639 \u0627\u0633\u062a. <sep> Hypothesis: \u06cc\u06a9 \u067e\u0631\u0686\u0645 \u0642\u0631\u0645\u0632 \u0646\u0634\u0627\u0646 \u0645\u06cc \u062f\u0647\u062f \u06a9\u0647 \u0622\u0628 \u0628\u0631\u0627\u06cc \u0634\u0646\u0627 \u0628\u06cc\u200c\u062e\u0637\u0631 \u0627\u0633\u062a.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-5dbb5c10c90048feadf4ddbace2e4823", "input": "Premise: The fields of specialization such as Physical Chemistry, Condensed Matter Physics, Materials Chemistry, Materials Science and Energy Chemical Engineering are included in the curriculum. \n Hypothesis: Chemistry and physics are fields in physical.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-75879b434a9b4c449509a44b5d62d582", "input": "Premise: As mentioned on p. 183 Hydrogen is the most abundant element. \n Hypothesis: The element hydrogen is the most abundant in the universe.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-c13d95df224947f9b688e7430975e5f8", "input": "Premise: motile cells with a single posterior whiplash flagellum ...................................................................CHYTRIDIOMYCOTA 1. \n Hypothesis: In humans, the sperm cell is the only cell with the  flagella structure that enables motility.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-6df4ee15287d4632874460bba5903e06", "input": "Premise: NItrogen, and the other atoms in that column have 5 valence electrons. \n Hypothesis: Nitrogen has 5 valence electrons.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-94dec610c0f14f3981e6f305a2f8b685", "input": "Premise: The two types of crust also differ in thickness, with continental crust being considerably thicker than oceanic (35\u00a0km vs. 6\u00a0km). \n Hypothesis: The earth's continental crust, on average, is 35 kilometers thick.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-f5a79d312ce545b2bc9330045af95c36", "input": "Premise: Blood is composed of plasma, water and cellular components (red blood cells, white blood cells and platelets). \n Hypothesis: Blood is made up of red blood cells, white blood cells, platelets, and plasma.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-ec2624ceaf31492a999a9396b45fb9f4", "input": "Premise: The main function of the carbohydrates is eventual conversion to an energy source in the form of glucose, the primary energy source for all cells in the body. \n Hypothesis: All cells need glucose for energy.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-3facac42db2044729e4615ec3ece2f5e", "input": "Premise: THIS IS THE END OF MEIOSIS II CYTOKINESIS II-----this involves division of the cytoplasm to get two cells. \n Hypothesis: Cytokinesis divides the cytoplasm into two distinctive cells.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-cd6d722571244d62b9c8513a0757fdd3", "input": "Premise: Now good-hearted Charlie, a mentally challenged bakery worker with an IQ of 68, becomes the first human to undergo the experimental procedure. \n Hypothesis: In humans, the heart is the first organ to form and become functional.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-dcd5e169f95e41c7ac7c9b579b7c7de8", "input": "Premise: Loop Flow -- terminology indicating that electricity does not follow the traditional contract path, but rather flows over several different transmission paths in an inverse relationship to electrical resistance in each line. \n Hypothesis: Because charges must have an unbroken path to follow, electric current cannot flow through a material unless it forms a closed loop.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-61d8bf3c6d454ace9427fd3197ae8888", "input": "Premise: Gut flora produce compounds such as indole, skatole, and thiols (sulfur-containing compounds), as well as the inorganic gas hydrogen sulfide. \n Hypothesis: Hydrogen sulfide is a noxious and toxic gas produced from decaying organic matter that contains sulfur.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-c53fc902c6354fa9819559d8012f0d7f", "input": "Premise: An ORGAN is a discrete structure that performs specific functions and is composed of at least 2 tissue types. \n Hypothesis: A(n) organ is a structure that is composed of one or more types of tissues.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-54174dda81a14f778667c573a9633485", "input": "Premise: Front- The boundary or transition zone between two different air masses. \n Hypothesis: In weather terms, the boundary between two air masses is called front.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-cfcca2c5815548ef88744f5743f1f066", "input": "Premise: Experts believe that much of this increase is due to people's greater exposure to the sun's ultraviolet radiation, which can cause misspellings in DNA and, as a result, damage skin cells. \n Hypothesis: Exposure to ultraviolet radiation can increase the amount of pigment in the skin and make it appear darker.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-66028795f5ac42c79422beaaa4672536", "input": "Premise: Reptiles also have scaly skin and a three chambered heart. \n Hypothesis: There are three chambers in a reptiles heart.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-46027363aef04200bd839ca2fbae3a33", "input": "Premise: Every atom of hydrogen, for example, has one proton, and every atom of carbon has six protons. \n Hypothesis: All carbon atoms have six protons.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-36facbf633bc4838b580e22cdac7660d", "input": "Premise: The square shape of the tube also symbolically indicates material-centered consciousness. \n Hypothesis: In a pedigree chart the squares shape symbolizes males.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-e84f2923c1314cddb1fdb7e0d9c7bd98", "input": "Premise: While soft corals also grow in colonies, they do not form reefs like hard coral. \n Hypothesis: Corals build hard exoskeletons that grow to become coral reefs.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-a8be59cb76d34ce0a8b248f2329470f9", "input": "Premise: pH is the measure of hydrogen ions concentration. \n Hypothesis: The concentration of the hydrogen ion in a solution can be calculated when the ph is known.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-22ac93689dff4a08b9a04f55a6650d24", "input": "Premise: A calorie is a unit used to measure energy. \n Hypothesis: Another unit of energy, used widely in the health professions and everyday life, is calorie ( cal )?", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-8cb898ea56d44680801ca4da688afd2e", "input": "Premise: PSc.2.1.1 Classify matter as: homogeneous or heterogeneous; pure substance or mixture; element or compound; metals, nonmetals, or metalloids; solution, colloid, or suspension. \n Hypothesis: Elements are pure substances that make up all matter.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-b5dfb97dba644d32a6fde42b8d9b02d5", "input": "Premise: Organic compounds which contain both a carboxylic acid group and an amine group on the same molecule are called amino acids. \n Hypothesis: Amino acids contain both a carboxylic acid group and a(n) amine group.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-a488e3e9329d4674b94203ec9d2df17e", "input": "Premise: The diploid human genome consists of 46 chromosomes , 22 pairs of autosomes, and one pair of sex chromosomes (the X and Y chromosomes ). \n Hypothesis: There are 46 chromosomes chromosomes in a diploid human cell.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-1b487ac7129b4b97a0a6960ccb150cf1", "input": "Premise: If it is the right species of fish, the larvae stay on. \n Hypothesis: Fish hatch into larvae that are different from the adult form of species.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-f51840beda384c45a4da2c735edb7292", "input": "Premise: Within the mitochondrion two complexes exist with beta barrels serving as the pore forming subunit, Tom40 of the Translocase of the outer membrane, and Sam50 of the Sorting and assembly machinery. \n Hypothesis: Two membranes form the mitochondrion structure of a cell.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-a6afa5b5243446c4a6cd9440ef9be170", "input": "Premise: May divide time between several homes, working on hourly or daily basis. \n Hypothesis: Bacteria may divide several times an hour.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-12246d0192884cd093232122839ca26c", "input": "Premise: Index Ozone is a gaseous molecule consisting of three atoms of oxygen (O3). \n Hypothesis: Three oxygen ions make up an ozone molecule.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-61e85bd0ea7146ada6e1fb19def499da", "input": "Premise: On sugar, red, and other maples, large, irregular brownish  areas between and along veins occur with symptoms similar to physiological leaf scorch. \n Hypothesis: Leaves export sugar to roots and other nonphotosynthetic parts of the plant through the veins.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-30785659d48c4e92b503489acc9c2e90", "input": "Premise: The sun is the ultimate source of energy in most ecosystems and for almost all living things. \n Hypothesis: Most of the energy used by living things comes either directly or indirectly from the sun.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-54d976fedf88471ab29d8263747b28ef", "input": "Premise: To cut down on loss from evaporation, water in the evening or early morning. \n Hypothesis: Watering plants and grass in the early morning is a way to conserve water because smaller amounts of water evaporate in the cool morning.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-986021b2ff4f4ae8955f44868eb53a4b", "input": "Premise: The roots of the trees then intermingle with the root of the bushes, taking up more and more of the space and the soil nutrients, and the leaves of the trees catch the sunlight, leaving less and less sunlight for the lower growing bushes. \n Hypothesis: Gravitropism ensures that roots grow into the soil and that shoots grow toward sunlight.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-d1898bc6812f4ac298d52ac8e1a8c89c", "input": "Premise: He had many bone fractures and injuries in his four limbs. \n Hypothesis: Birds have four limbs.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-654d5645caf94307a79ec7e4db856e99", "input": "Premise: This reaction also may not break bonds to the chiral center. \n Hypothesis: Catabolic reactions involve breaking bonds.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-08a5413024404539a66bed9c54c74701", "input": "Premise: Animal communications; \n Hypothesis: For social animals, communication essential.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-6701123cfbc64b609313330e2eebb7f1", "input": "Premise: In each pollen grain the wall thickens and forms an inner layer (the intine) and an often highly sculptured outer layer (the exine). \n Hypothesis: Each pollen grain has two coverings: the exine (thicker, outer layer) and the intine.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-28925203152d45a3a1272bf3917a327b", "input": "Premise: The gallbladder is a hollow organ that sits just beneath the right lobe of the liver. \n Hypothesis: The gallbladder is near the right lobe of the liver.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-88023ffff8b6467a86e9b191e5cfaee6", "input": "Premise: To understand our changing seasons, follow Earth's path around the sun for one complete orbit (i.e., one year). \n Hypothesis: It takes about one year for earth to orbit the sun.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-91dafda357f8493ebd724423b2d64685", "input": "Premise: In a neutral atom the number of protons is equal to the number of electrons. \n Hypothesis: Because atoms have equal numbers of positive protons and negative electrons, they possess a neutral charge.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-e31dff8af3e9490aaa96ab1ec49b06c1", "input": "Premise: Metabolism is simply the sum of all the chemical reactions taking place in a living system. \n Hypothesis: The sum of all chemical reactions that take place within an organism is known as metabolism.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-79337747083f4522b5d5f721ec20859f", "input": "Premise: Product reviews by consumers such as you can save someone else money, time and energy and will serve as a message to equestrian products manufacturers on ways to improve their products to better serve horse enthusiasts. \n Hypothesis: Electrical energy consumed can be expressed as the product of power multiplied by time.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-aecda4d3354b430a8882cc8169264b37", "input": "Premise: A worker bee returns to the hive and signals to other workers the range and direction relative to the sun of the food source by means of a waggle dance. \n Hypothesis: A bee will sometimes do a dance to tell other bees in the hive where to find food.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-71a444963c2645aaa36932a5fc154e1f", "input": "Premise: Water in the morning  to minimize evaporation. \n Hypothesis: Watering plants and grass in the early morning is a way to conserve water because smaller amounts of water evaporate in the cool morning.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-d831ead1fece48c5928381341f037ddd", "input": "Premise: VOLATILE ORGANIC COMPOUND (VOC) is any compound of carbon, excluding carbon monoxide, carbon dioxide, carbonic acid, metallic carbides, carbonates, methane, and the exempt compounds. \n Hypothesis: Binary compounds of carbon with less electronegative elements are called carbides.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-8b38dbe1b19e471e97287504fb0d54a8", "input": "Premise: Many articles are protected by all four types of iprs. \n Hypothesis: There are four types of bosons.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-00438e99af3a4fc79a6dcc07697f6ee8", "input": "Premise: For example, one of the more common methods involves digestion of the DNA template using RNase-free DNase I, followed by gel filtration to remove unincorporated nucleotides, and then phenol extraction to remove proteins and ethanol precipitation to concentrate the RNA. \n Hypothesis: Deletions remove one or more nucleotides from the dna", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-7242603c618e41acb3d8979a94bd41a2", "input": "Premise: It is thought that chloroplasts , the bodies in plant cells that do  photosynthesis , were once small independent cells. \n Hypothesis: Photosynthesis occurs in the chloroplast.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-8ef1ce4753c4410fafb2690f0e4ee482", "input": "Premise: Have the program adjust the digits to a five digit number. \n Hypothesis: Primates have five digits on each extremity.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-cc16aebc2e454860afd5899d33c2b4d9", "input": "Premise: The hagfish has no cerebrum  or cerebellum, no jaws and no stomach, and its skeleton is made up by cartilage  instead of bones. \n Hypothesis: Hagfishes have a skull made of cartilage.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-7bd13dd3af6a45e08e19c0bb9c08f28e", "input": "Premise: Like fish and amphibians, reptiles are ectothermic animals, which is to say that they produce very little metabolic heat and their body temperature depends essentially on that of the environment. \n Hypothesis: Reptiles are described by the term ectothermic, which means their internal temperature depends on the temperature of their environment.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-3ef6bc0056654f1aa09e2ec75c988c83", "input": "Premise: To get started, develop a 4-8-week plan with your healthcare professional. \n Hypothesis: By 8 weeks, all major organs start developing.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-a69acacadc204236a0d88525c4c7ce0f", "input": "Premise: The pre-embryo may divide several times while in the incubator. \n Hypothesis: Bacteria may divide several times an hour.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-b98f8b73560a4559a252543be126f83e", "input": "Premise: Base- A substance that gives a pH &gt; 7 when added to water. \n Hypothesis: If a substance has a ph value greater than 7,that indicates that it is base.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-ab0906a940aa4e4893eefa526a247f1a", "input": "Premise: Thus a stable element such as Carbon has a nucleus with six protons and six neutrons which may be written as 12 6 C or simply 12 C. \n Hypothesis: Carbon atoms have six neutrons as well as six protons.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-eb01fa9e817b4e92be149a9a48e375c6", "input": "Premise: Again, the normal mailing cycle  for the bureau is about every four to six weeks. \n Hypothesis: There are four to six weeks are in the life cycle of ladybugs.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-d7b9f3637b304aed95126a4c8e750ae9", "input": "Premise: Others, who perhaps should know better, fail to recognize the distinction between the lovely five-leafed Virginia creeper and the three-leafed poison ivy. \n Hypothesis: Poison ivy typically has three groups of leaves.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-baa174ce2a7348748632c4bfaeb11a62", "input": "Premise: The gametophyte produces haploid gametes by mitosis cell division, which unite to form diploid zygote that develops into a sporophyte. \n Hypothesis: The haploid gametophyte produces gametes through mitosis.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-629c52fd633a427da1323c5f7bf8760d", "input": "Premise: 30 Humans have 23 pairs of chromosomes; \n Hypothesis: Humans have 23 pairs pairs of chromosomes.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-f5eec9ee73bc43bca94d61e484a453bf", "input": "Premise: Two Types of Diabetes There are two main types of diabetes, Type 1 and Type 2. \n Hypothesis: There are two different main types of diabetes.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-ffe62f42262245d6a95711076314e2cc", "input": "Premise: This organic material represents a rich food source for heterotrophic bacteria in the system. \n Hypothesis: Because all animals require an external source of food, they are called heterotrophic.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-39eb22fe817a4745806482613d7ad6dc", "input": "Premise: Samples of matter exist either as pure substances or as mixtures of pure substances. \n Hypothesis: Elements are pure substances that make up all matter.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-ad98cc6640954b1fa579e6dd101d2de6", "input": "Premise: Increase volume by fifth of maximum amount. \n Hypothesis: From observations as simple as blowing up a balloon, it is clear that increasing the amount of gas increases the volume.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-053632b1fe1445da9314d6bf7ecc80fd", "input": "Premise: Similarly, if ideal gas molecules collide, the collisions are elastic, so no kinetic energy is lost. \n Hypothesis: Because collisions are elastic, energy can be transferred between molecules during them", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-f2f5b3ecfe4a4d4ca5947f07ee6e4292", "input": "Premise: On each hand there are four clawed digits and the third clawed digit is the longest; however, the feet have five claws. \n Hypothesis: Primates have five digits on each extremity.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-5ef1035cc4c84370b78a3ee002cab76a", "input": "Premise: However, when ketones form, the blood becomes quite acidic and various organs such as kidney, heart, and brain are affected by blood acidity. \n Hypothesis: In humans, the heart is the first organ to form and become functional.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-d060fdb144cb4e22a97fc82963166937", "input": "Premise: Most carbon atoms in the world have six protons and six neutrons in their nucleus. \n Hypothesis: All carbon atoms have six protons.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-08473b4e36514235b8823604e61ffb1b", "input": "Premise: Competition is growing -- \n Hypothesis: As the population grows, competition for food grows.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-99425e8631f34bd899542daef306be49", "input": "Premise: PH is the measure of hydrogen ions in solutions. \n Hypothesis: The concentration of the hydrogen ion in a solution can be calculated when the ph is known.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-758d2e5a6e014a4f8c45e149a9048571", "input": "Premise: (Formic acid is the poison found in the > sting of fire ants.) \n Hypothesis: Formic acid is found in the secretions of stinging ants.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-5c2e2a4847df47ca8715428def18528c", "input": "Premise: there was a big fight over who discovered it first) Neptune is the eighth planet from the Sun. \n Hypothesis: The eighth planet from our sun is neptune.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-b263601770984473bf14a7cbc1285041", "input": "Premise: 40 solenoid and iron filings A solenoid is wound through a peice of plexiglass for use with iron filings on the overhead projector. \n Hypothesis: An electormagnet is a piece of iron inside a solenoid.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-bd37b7561456457f9c426ca6a9a51966", "input": "Premise: Mammal ears are relatively complex, the middle ear containing three bones, as opposed to only one bone in the middle ear of reptiles and birds. \n Hypothesis: The mammalian middle ear has three bones.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-1b86de26aca241ac84668cc33301eaa7", "input": "Premise: This oxygen is transferred from the lungs into the bloodstream and it is responsible for the transfer of heat throughout the body. \n Hypothesis: Diaphragm, lungs, and trachea take air deep into the body and provide oxygen gas to the bloodstream.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-c8fdbc3e8fb3457080d4360b8ceaaea9", "input": "Premise: Calories measure the amount of energy stored in a food. \n Hypothesis: A calorie is used to express the amount of energy in food.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-9b0dac250b1e419aaa1ca37645c2ca2a", "input": "Premise: Because CO2 absorbs energy emitted from the Earth and prevents it from going back out into space, it is called a greenhouse gas. \n Hypothesis: Gases such as co2 and methane can trap thermal energy in earth's atmosphere before radiating it into space.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-301997a212414e94b7a4f71be7e0bd59", "input": "Premise: The result was that only ten percent of the carbon dioxide was removed as compared to the expected amount for how much iron sulfate was added. \n Hypothesis: During the early paleozoic, the amount of carbon dioxide in the atmosphere was much greater compared to today.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-e7227c91e5e843919c2388ffd5acefe6", "input": "Premise: Blood first enters the heart at the right atrium, which then empties blood into the right ventricle, which pumps the blood into the lungs through the pulmonary artery to get oxygen. \n Hypothesis: Blood from the body enters right atrium of the heart before it is pumped to the right ventricle and then to the lungs.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-58da941adc644889b71714e587c02459", "input": "Premise: As threats to bird populations grow and extinctions continue, historical specimens are valuable in documenting the impacts of human activities and causes of decline for threatened species. \n Hypothesis: Around 1200 species of birds are currently at risk of extinction due to human activity.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-0e63082fc28944ac815bca61c54c19bf", "input": "Premise: Seismologists study the location and force of earthquakes and trace the behavior of earthquake waves to interpret the structure of the Earth. \n Hypothesis: Studies of earthquake waves have helped scientists determine the structure of earth's interior.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-6a9865ca2b274301bacfec98ad5d73bc", "input": "Premise: Humans may potentially transmit Avian Influenza to animal and bird species, although the risk is moderate to low. \n Hypothesis: Around 1200 species of birds are currently at risk of extinction due to human activity.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-a73756dea83c45be83febca14fe6324f", "input": "Premise: This means that the behavior is not innate. \n Hypothesis: Behaviors that are closely controlled by genes and have little to no environmental influence are called innate behaviors.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-9ef68d5234744fddb20b8109ce8bef1a", "input": "Premise: BioGeoChemical Cycles. \n Hypothesis: Chemical elements and water are recycled through the biogeochemical cycle.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-ccb43f44935a4ddbadc4a749b68e3af9", "input": "Premise: Earth represents the solid state of matter. \n Hypothesis: Water exists on earth in three matter states states.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-b8db4b3ca0df4647a7f915fb2a8f62e4", "input": "Premise: Supplemental water applications benefit the tree during periods of drought. \n Hypothesis: Because trees add water vapor to air, cutting down forests leads to longer periods of drought.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-c10b8415a7334dcd8c809860dffb6feb", "input": "Premise: The P1 radiators dispose of thermal energy into space to maintain thermal conditioning for the ISS. \n Hypothesis: Gases such as co2 and methane can trap thermal energy in earth's atmosphere before radiating it into space.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-81a5b58f6f9948adad3d36c7dbc2fe14", "input": "Premise: The six known leptons are the electron, the muon, the tau lepton, and their respective neutrinos. \n Hypothesis: There are six types of leptons.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-2d63b7fdd21d4154b77f0cb710873986", "input": "Premise: All matter is composed of all four elements but, where one element predominates, then a substance can be said to be solid, or liquid, etc. \n Hypothesis: Elements are pure substances that make up all matter.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-ba01486b13af44e48590ceb7e20073b7", "input": "Premise: There are some reptiles, such as the boa constrictor and komodo dragon that can reproduce both sexually and asexually, depending on whether a mate is available. \n Hypothesis: Reptiles typically reproduce sexually.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-8469972e0d914c92beb2690fe99beefd", "input": "Premise: In this climate zone, summers are cool, and winters are cool, but not cold, and there is little frozen precipitation at lower elevations. \n Hypothesis: Exemplified by canada and alaska, a subarctic climate has cool, short summers and long, cold winters, little precipitation, and abundant conifers.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-19708d064e0f4b9daa21087ea99df0e4", "input": "Premise: Cells propagate by repeating these four phases and this 4-phase cycle is called 'Cell Cycle'. \n Hypothesis: Cells have four cycles.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-76848e73eb3c49dbbc7d6c8dd9b00e98", "input": "Premise: Carbon's four valence electrons then half-fill each of the four orbitals. \n Hypothesis: Carbon has four valence electrons .", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-21960046fa6741c493d130dc02f0c61c", "input": "Premise: Nonvascular plants Division Bryophyta Mosses, liverworts, hornworts make up this division of plants. \n Hypothesis: Moss is best classified as a nonvascular plant.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-078bee99f5cd44ef8821d1e73ba0fae6", "input": "Premise: Fluorescence of a substance is seen when the molecule is exposed to a specific wavelength of light (excitation wavelength or spectrum) and the light it emits ( the emission wavelength or spectrum) is always of a higher wavelength. \n Hypothesis: When exposed to ultraviolet, some substances, such as minerals, glow in characteristic visible wavelengths, in a process called fluorescence.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-76332d01400048b286e3078d18c73978", "input": "Premise: Case selection was an important factor in this research. \n Hypothesis: Community interactions are important factors in natural selection.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-9f95b09d133b45ef9818c41108244300", "input": "Premise: The basic function of the cell membrane is to serve as a selective barrier that regulates the passage of certain materials in and out of the cell. \n Hypothesis: A cell's membrane provides a barrier to keep extracellular materials from mixing with its internal components.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-2e73d3a0c57749ba9afdb53eaef0f166", "input": "Premise: All cells need energy to carry out their functions, such as making proteins and transporting substances into and out of the cell. \n Hypothesis: All cells share the characteristic that they need energy.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-2568469ce6e8416c91ed5eb3cdad6176", "input": "Premise: When a silver ion receives an electron from an anion during cooling of a saturated solution, the ion becomes a silver atom. \n Hypothesis: Electrons always result in an anion that is larger than the parent atom.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-a5eb01b8511a48f58940a9aecd706f5a", "input": "Premise: Select a producer and a consumer from this food chain. \n Hypothesis: Food chains carry energy from producers to consumers.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-8c568aeaf53545f9bdad9ff75dd87e44", "input": "Premise: protein synthesis and gene regulation; \n Hypothesis: Gene expression and protein synthesis are usually considered the same molecular process.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-6f61660204c14c1b92adaff44c118d7b", "input": "Premise: Solids Solids are the only phase in which matter has a definite shape and a definite volume. \n Hypothesis: A definite shape and a definite volume are properties of the solid, only state(s) of matter.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1529_scitail1.1_classification_gpt3_0", "Definition": ["You are given two sentences. You have to find if there is entailment or agreement of the Hypothesis by the Premise. From the given pair of sentences, you should identify if there is enough information in the Premise to support the claim made in the Hypothesis. The Premise may not exactly be the same as Hypothesis. Your task is to return 'entails' if the premise supports hypothesis else return 'neutral'. (1) The model should output 'entails' when the premise sentence agrees with the hypothesis that Lyme Disease is caused by bacteria. The premise also gives additional information about Lyme disease. Therefore Premise entails Hypothesis.  (2) The model should output 'neutral' when the premise misses the context to the word 'this'. Therefore it is incomplete. The hypothesis is not supporting the premise. Therefore it is classified as neutral."], "Instance": {"id": "task1529-a1d292574ac54b469ffea0cb763b17e4", "input": "Premise: According to nuclear scientists, this can be as long as ten thousand to a hundred thousand years. \n Hypothesis: The long-lived isotopes require thousands of years to decay to a safe level in a nuclear reactor.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-0038c936156a40449c1beb6cddbb3adc", "input": "Two men stand on stairs with an assortment of chairs and a woven basket in the foreground. <sep> The men are brothers.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-1285678f667d48628ed291030657cb0e", "input": "two men are seen talking, one man wears pink and another is sporting a t-shirt for summer school 60th anniversary. <sep> Two old men talk at a family reunion.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-0718238e5bde46abaa67cb46612f1f40", "input": "Two gondola operators sit along a road in Italy. <sep> The gondola operators are in the water, pushing their boats.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-cb89358212fa495f9a4f388a88033ccb", "input": "Times Square in New York. <sep> Times Square is packed.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-2ca215bc3fb14b63b164fd4dcef4f290", "input": "A woman is carrying two children in the middle of a large crowd. <sep> a woman carries children", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-a3b92d9b4cda4c5083c7f7959929ed0b", "input": "Four kids pose on a stage. <sep> Four siblings pose for a photo on a stage.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-01dc00fe76a9435396d703552f653645", "input": "A small girl in a green shirt plays on a swing. <sep> girl plays swing", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-12bcbeceb7a74d69881737d418101fc9", "input": "A young girl in a red top is running through a grassy area with large buildings in the background. <sep> The young girl loves to run.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-b21062e724e94915abde9d8856088194", "input": "Cityscape with four men on bikes serving as the focal point of picture. <sep> Local robbers escape after stealing an otter", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-ddac9936dcc54342bbabee26fd3641e2", "input": "kid practicing karate move <sep> A kid is practicing a complicated karate move.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-773209e57f95480f9530f1f1f9fce16c", "input": "A little girl in a gray jacket is riding her bicycle. <sep> A little girl in a gray jacket is doing a wheelie on a ten speed mountain bike.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-7c89f6b6613a48b4b52d5b0b57d89d01", "input": "A group of young men in a gym take turns scoring in basketball. <sep> Guys are playing shirts vs skins.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-ff13b95356644d30ad0421ebaf444510", "input": "a woman in a black shirt looking at a bicycle. <sep> A woman sees a bicycle.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-36ddd06e79614bf8ac99534d9fcfcfbc", "input": "A man in colorful shorts is surfing under a wave. <sep> A man on vacation is at the ocean.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-f95c440d81784a8ca581278fef25139b", "input": "A man and woman are taking a picture of themselves while a woman in a scarf walks by them. <sep> A man and woman take selfies of themselves.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-fa8900f54df2461abeee448e2bc6af3c", "input": "A man, woman, and child get their picture taken in front of the mountains. <sep> People are outdoors.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-8d102ad7416c4b4bb5244d0e6b7a1d44", "input": "A red Planet Hollywood bus carries many people including a man in an orange shirt and baseball cap, one woman wearing a purple shirt and another in a red shirt with her back to the camera. <sep> The bus is going to celebrity houses.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-1bd1d69f51284778b49d820658187331", "input": "A bare chested smiling child plays in water. <sep> There is a topless child playing in the water.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-dfd1e5689d9f48ab9b5df41fb4b98c14", "input": "A man and a boy behind the wheel of a car. <sep> The little boy and the man sit behind the car's steering wheel.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-9662d0cf289042bea3b85f66b0488b64", "input": "Men wearing hats walk on the street. <sep> The men are walking inside the school.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-46f4efd6ad9f488c90285950d7e9da4e", "input": "A basketball player in a red uniform is trying to make a basket but is being blocked by the opposing team. <sep> The player is one of the best in the league.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-f31bda13dfea437aa5bc9f6f0d3cbd9c", "input": "A group of women observing an event while one in military attire takes a photograph <sep> A group of people are watching something and one takes a picture.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-0e607bd7c8d34fd88902b852977d54b0", "input": "Several people are laying on the floor sleeping covered by blankets. <sep> A group of people rest", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-b6486b1c7287469e878d4b266f90cab5", "input": "A gymnastics performer is in mid-pose as she completes her jump. <sep> A gymnast is completing her jump in the finals.", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-152cce547db84eed949a8dde2a21ebe8", "input": "Four men playing drums in very orange lighting while one of them is also drinking something out of a bottle. <sep> the men are musicians", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-f1d0cff8f6174cfcb9acbc8228ed07ac", "input": "A person wearing orange stockings and chunky boots has her legs stretched out on the grass. <sep> The boots have a hole in them.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-347d3fad411c43b585ea6353b7c6fcf4", "input": "A woman with a pink purse walks down a crowded sidewalk. <sep> A woman escapes a from a hostile enviroment", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-0d859467a13840fc851662a829e4d206", "input": "Three young women perform a dance in a crowded hall. <sep> Three young women are performing in front of a big audience.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-83241864fc7e478281c5c4c571391944", "input": "A young woman wearing a yellow sweater and black pants is ice skating outdoors. <sep> a woman is practicing for the olympics", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-c20ddb96522c41a095edc73f5e0c37e4", "input": "A man playing a piano <sep> The man's hands are on the keys of a piano.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-d460590a47cb4c8ab51d88130c5a645e", "input": "Two men and a Frisbee <sep> Two men with a toy.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-965749ccf0974cf9b679f3f19099ad3b", "input": "Two young girls show prints of a line drawing of an animal. <sep> Girls are displaying their animal drawings in a local kid's drawing competition.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-7050854f0a7d4013b4e29136938a5bc1", "input": "A man with a red helmet and numbers on his arm and leg is riding a red racing bike. <sep> The man in the red helmet is winning his bicycle race.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-5e0c3701330d4a2aa6d1ecaa22529e4d", "input": "A person attempts to rope a black cow while riding a horse. <sep> The person is riding a brown horse.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-101c738c29704bc6b363d563e1da764a", "input": "Two young girls looking very concerned. <sep> Their faces convey their feelings.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-11613bf6084d45da9859f099b3b719ac", "input": "A skateboarding youth does a trick on a rail. <sep> A young boy showing his new skateboard tricks to his friends.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-dbb4677750a6427c9f1c377b71856fa0", "input": "A man is holding a microphone in front of his mouth. <sep> The man was about to record his music album.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-8541459fd16d4710abfba0cf94a9dca8", "input": "Red-haired female answers questions while sitting at a table for craftzine. <sep> The PR rep fielded questions during the interview.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-8904cd5bc01e41eab8dc4b5662f0702a", "input": "A man walks by a building at night. <sep> A man is in the city.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-1fc4b53119ff4708b9e80919a642f2a7", "input": "One person kneels in front of a plastic bucket, while another leans toward a doorway and a third person looks on from a dilapidated building. <sep> One person kneels before zod in the oval office.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-5142df0cd8ab4d209c8f5f43e37add4e", "input": "a man walks on the icy sidewalk. <sep> The man almost slipped earlier.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-f1b932e6b989465287341a1d1772cc99", "input": "A brown dog sniffing at the fence of a brown bull. <sep> The brown dog was looking intently at the bull on the other side.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-695b165c6dcc46169df59b175a1e5841", "input": "Athletic men in matching black pants performing under the spotlight. <sep> The men are wearing black pants.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-5143abe586704147988cd01f5c7aeae3", "input": "A group of seven individuals wearing rafting gear, white water raft down a river. <sep> Seven men and women are in a yellow boat.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-979a86246c374c99bf186c1826246f49", "input": "Man wearing blue bowing on floor in front of another man in blue bowing on floor with two other men wearing blue kneeling on same floor also. <sep> A man is wearing nothing.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-ba3bb4003ac44835b92d278ff24a2d81", "input": "Topless girl riding a red bike. <sep> A woman is on a bike.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-a56e31b812dc4a12b6768057bb8499a7", "input": "A group of students are walking through the campus. <sep> There is a school tour going on", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-348e899181c849428de5ab286a205396", "input": "An accordion player with a bright colored shirt sitting outside in a chair with a young man in a blue t-shirt passing by. <sep> The accordion player is highly skilled.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-45cf0077e80b432a8cf8e2712276da13", "input": "A man in a blue jacket leans on a post and talks on the phone while an old man carries yellow bags. <sep> An old man works.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-3b1afe6fb26a42d489d5968052d1539c", "input": "A man in a purple mascot costume is standing outside of a store while a man and a woman each wearing flamboyant clothing stand off to the side. <sep> The costume is green.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-2ef6680aef7a4c2781467190ac40738b", "input": "A crowd of people standing in front of statues. <sep> The statue is actually a gargoyle and it came to life.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-820e855cdd1246968881ce069c82a514", "input": "A woman in a black leather shirt trench-coat and black leather calf-high boots and carrying a colorful bag with a shoulder strap faces away from the camera with a yellow post visible just in front of her. <sep> Some stars are walking past the paparazzis and getting into an awards building", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-7041d0fdd2b24dbbb5b0e31867796796", "input": "Six dogs swimming in a river. <sep> The puppies are setting on the couch.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-54ba79b68a88435ab2d7eb935435e2d3", "input": "An Asian woman in a hat is measuring food from barrels with a ladle into a smaller metal pan. <sep> A woman is handling food containers.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-c95a6c0db9704476958527d8640aabc7", "input": "Five girls and two guys are crossing a overpass. <sep> There are people outside.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-6e6d3a622f1a45edbec0674db1ad1c35", "input": "a skier is throwing up snow as he skis off piste. <sep> A professional skier skis down a mountain.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-8f7993e0083f4c3481480a8d61abd4d7", "input": "A man in a tank top fixing himself a hotdog. <sep> the child was happy`", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-3158216123574e05801df39c06e1de42", "input": "A woman in black is getting ready in her bathroom. <sep> The woman is wearing black", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-6a9880c602344bc18830d6b3e5acc87c", "input": "A band performing at a local bar or club. <sep> The band is playing music", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-7b7d6e47b661412dbd36f6f5eee5762d", "input": "A street performer wearing sunglasses and painted in bronze colored paint is acting like he is filming with an old-fashioned prop film camera. <sep> A mime is practicing his art.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-cac8a361ffbc43ba82c64a8f49417eac", "input": "Guy in uniform standing on the side of a boat moving through the water. <sep> A man in the Navy is sailing through the water.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-a1335a2ba2ff4c3eb14e5190efad2c70", "input": "A group of travelers pulling suitcases are making their way down a platform. <sep> Two couples are drinking a lemonade.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-17adb551766a4b60a639ea76ae7a55ce", "input": "The young lady is giving the old man a hug. <sep> The lady is giving the old man a hug.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-63c7a3258adf4356b6aa44dfe8097460", "input": "A group of people are buying fruits and vegetables from a stand located in a street market. <sep> The stand selling produce is in a street market.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-5abd7cc766f846eeb2a881da9155733a", "input": "A choir of youths are singing. <sep> they are singing in a christmas program", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-63f4777c50674bf8aaf4e3f31ccd1e22", "input": "a climber wearing a red headband is pulling himself up some gray rocks high above some green foliage. <sep> A climber pulls himself up some rocks", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-91594780a5ab47c8a2c141929d3a4f1b", "input": "A man is pushing many cartons of bread down the street. <sep> A person has food outside.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-f16bf47d51d248c3854f3dbf1f2d84b0", "input": "Three kids in a forest standing on a tree log. <sep> Children crossing stream in forest.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-dbd5e0a840ff4e38b947c5e0c1661a8d", "input": "A group of people in a room, most with computers, some raising their hands. <sep> Some people have questions.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-9e78528fdc6f49398166ae14259feed6", "input": "A man with a beard is playing an acoustic guitar on the street. <sep> A man plays guitar outside.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-a20d42a5ab9a4711920c93569d199255", "input": "Six women wait to use a port-o-john in a field. <sep> Friends are waiting together.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-50d722ee698245f189938b7879cb7de0", "input": "An African American man is posing in front of an E.S.E. Electronics advertisement billboard after purchasing items from the local liquor store. <sep> Man breaks camera in front of liquor store.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-81ca9ad6c8c3466fbed06cec30c7a12c", "input": "Two female martial artists demonstrate a kick for an audience. <sep> Two female martial artists are teaching the audience how to kick for self-defense class.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-4efb5a4ffb7f4c20bb72185fbee9ad2b", "input": "A woman with a blue hat is taking photos in an area covered in brush. <sep> The woman is photographing a wedding.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-79300b5fec8a4c5b9e3f9e665281a8f3", "input": "A blond woman in a black shirt is standing behind a counter. <sep> The woman has her hair pulled back in a bun.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-10d25abd139442f5ab9a07b1cb89da00", "input": "A man stands on a dock near several boats, while 2 other men are on one of the boats. <sep> A man is sitting on a dock.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-200387128af54940ab2dfb56f7dfe1fd", "input": "Three children and adults in the background, all pretend to sleep. <sep> The children are playing a bedtime game with their parents.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-dc80d6b683a9463aa385709d65ce2c3c", "input": "A woman with a blue shirt and colorful hair has just thrown the bowling ball. <sep> A women is sleeping.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-fa8c02f0b21f4c92b5a83ff8c402ce12", "input": "Three people sitting on a table, one woman is speaking, and people are listening to them. <sep> There are three women sitting on a table.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-aabe79b7f8214db09cd9c338263f78b2", "input": "Two young ladies walking down the street together. <sep> There are two woman in this picture, and they are both outside.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-0a2f57013fe148c482027d243745bd08", "input": "A woman stands smiling while holding a stuffed cat. <sep> A female is posing for the camera.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-f56e2bb3a7f944a78165620939393afe", "input": "A man pulling items on a cart. <sep> A man is taking things that he bought at the store home.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-59331febf52e4f758e83483dcae81e5c", "input": "A woman with her face partially covered in silver face paint sits on a plastic tote looking in a mirror. <sep> The woman is a model.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-6e80c7ce4f0a4bed95c3e55bb2b77541", "input": "The children play in the pool. <sep> The children are playing Marco Polo.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-524b9a1de3df4bafb1c043a6211c99e3", "input": "A woman in a red shirt looks at a map while with a view of a river and several boats in the background. <sep> A woman looks at a map outdoors, a river and boats are behind her.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-186bca2896e340839bacd04f04110c76", "input": "A lady wearing gloves, and a ponytail cooks something while people stand and watch. <sep> The lady cooks meat", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-4402e10b741045e3a967eb0bb5ee9911", "input": "a group of construction workers busy refinishing a subway station. <sep> A group of workers on their lunch break.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-fecaeba985074b0091bd9ebd28897b63", "input": "A group of mountain climbers rests at the summit. <sep> A group of climbers takes a break.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-85252853dd5d449e9a1c40637b9ed688", "input": "A woman lowering ballast on a boat. <sep> The woman is adjusting the boat.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-400ada6bf5c94ba892e36b807eab4b0f", "input": "Little boy in a green sweatshirt playing with his toy train. <sep> A boy is playing his xbox.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-3d4b54a75a2e4468b2305cf96078f43e", "input": "A man with a pinstriped shirt and tan slacks adjust his tie while looking at a apple laptop computer. <sep> A woman adjusts her bra", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-f0b00dd85bf14caaa2f4283571ecca6f", "input": "A group of children in African clothing. <sep> Some humans in green clothing", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-4060787af85a4222bfd83fdaaa10ffc4", "input": "One woman with jeans, gray shirt and sandals; with girl in all pink watching a white ball float in midair. <sep> The ball is on the floor.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-003cbeac3b964802a54388f58626a283", "input": "White dog high jumping over some pillows. <sep> The dog is laying down on the bed.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-075b22c74f7646cc837510372cbc30fb", "input": "Two girls jumping on a trampoline, one upright and the other landing on her back, in a backyard. <sep> There are girls on a trampoline.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-9cf489129fce47f6b2c9a72e2f21bde0", "input": "Several younger people sitting in front of a statue. <sep> several young people are sitting in an auditorium", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-665039acac8948609d9cee80269bcb23", "input": "Three men in orange suits are doing street repairs at night. <sep> Three men in orange suits escaped from prison.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-8453bfa3a4e94dbb9f52d09cbf44cb80", "input": "A woman is walking her dog along a snowy ground. <sep> A woman is with her dog outside.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-38a566e27fba4cea8ab7bc13e8719245", "input": "Two young musicians play from a stage. <sep> The two musicians are playing the trumpet", "output": ["no"]}, "Prediction": "no"}
{"Task": "task642_esnli_classification_gpt3_0", "Definition": ["Given Sentence 1 and Sentence 2, indicate your answer as yes when the two sentences clearly agree or clearly disagree with each other. If the relationship cannot be determined, answer with 'no'. (1) If two statements are about the same thing, but one is true and the other is false, the model should output yes.  (2) If two statements are about different things, the model should output no."], "Instance": {"id": "task642-b026f1729b2d4c0f87c45e0fb29ecafe", "input": "A group of people sitting around a small round table eating. <sep> The group is discussing the next project for work.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-88449be2a6b14e82888ffbc330239acc", "input": "sentence_A: A young girl with a heart tank top is raising her hands as she is playing on a slide. sentence_B: A blond child is going down a slide and throwing up his arms", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-d026942d562a49cabde0ee89e034579b", "input": "sentence_A: The man is doing floor exercises. sentence_B: A man is doing exercises", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-559024bea6a546859688b237b0a0e4b7", "input": "sentence_A: A yellow dog is drinking water from the faucet. sentence_B: A yellow dog is not drinking water from the faucet", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-628adb256dbd4cebab5a2f884e5e229f", "input": "sentence_A: A woman is riding a horse. sentence_B: A woman is riding an animal", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-8f03f50d8d8f4602b405f707ae6cf438", "input": "sentence_A: The young man is not rock climbing. sentence_B: The young man is rock climbing", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-ff9f26e84ff248fdb22c4193ca92bea4", "input": "sentence_A: Three young girls are dancing in the room. sentence_B: Some teenage girls are dancing for the camera", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-3ac976b320534efa91bb5e3f7380b947", "input": "sentence_A: The man is walking along a path through the wilderness. sentence_B: The man is not walking along a path through the wilderness", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-37de4afb11144aa8855bac493164b2c6", "input": "sentence_A: A hiker is on top of the mountain and is dancing. sentence_B: There is no hiker dancing on top of the mountain", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-143e786358f44656bd55f74e327e40c4", "input": "sentence_A: A young girl in blue is jumping in the air. sentence_B: A young girl in a blue leotard is jumping on the ground", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-ccbb8ff2848c4914a2130bbd641bc08f", "input": "sentence_A: A boy is looking at a calendar. sentence_B: There is no boy looking at a calendar", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-3abe5484578045f4b285fc64be075811", "input": "sentence_A: A person is putting meat into a skillet. sentence_B: There is no baby being put into a trash can by a woman", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-c310914992494fb6976d4d4ea21eb2b3", "input": "sentence_A: The woman is slicing an onion. sentence_B: An onion is being sliced by the woman", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-6823a1d9765f41329e0c3ef869502484", "input": "sentence_A: There is no woman riding a horse. sentence_B: A woman is riding a horse", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-d1a1d36ed934409ca2f04ac9ca82257f", "input": "sentence_A: A boy is playing guitar. sentence_B: A little girl is playing a guitar", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-07890e269af041799af4230bc444f7cf", "input": "sentence_A: Two white dogs and one brown dog are not chasing a ball. sentence_B: Two white dogs and one brown dog are chasing a ball", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-a858b54614ae4d38b05c1bd77a0c9529", "input": "sentence_A: A little boy with brown hair is jumping off of a brown chair onto the floor. sentence_B: There is no little boy with brown hair jumping off of a brown chair onto the floor", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-8c41d8f663964798922dc0f48b162c16", "input": "sentence_A: A boy is wearing a white hat and is walking on the beach. sentence_B: A little kid is wearing a hat and is walking in the wet sand", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-c0c022b68fb144eca69a275801c1a0ab", "input": "sentence_A: Someone is falling off a horse. sentence_B: A horse is falling on someone", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-735e768e8e964f63a1f8a83aec7fa543", "input": "sentence_A: A man is naked and standing still. sentence_B: A man with a hard hat is dancing", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-ab2a017954c744e0a061e20a5c1bd7a4", "input": "sentence_A: A man dressed in black is wearing inline skates and performing a trick on a rail. sentence_B: A skateboarder is jumping off a ramp", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-1d35e42a67ae48ba9fe74181f486c5fc", "input": "sentence_A: A man and two women in a darkened room are sitting at a table with candles. sentence_B: The group of people is sitting in a dim room", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-79d96f347c56410499b95b647730fe09", "input": "sentence_A: A soccer ball is not rolling into a goal net. sentence_B: A soccer ball is rolling into a goal net", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-370bc9844b9f445c9bc425f1ef925c8f", "input": "sentence_A: Someone is scratching the belly of an animal. sentence_B: Someone is stroking the belly of an animal", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-73e94ad9867e452cb3c8d664e05c13fa", "input": "sentence_A: A black person in white is joyfully running with the dog on the grass. sentence_B: One white dog and one black one are running side by side on the grass", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-6e8f9d8fdd5e4efe98c3b23ab6392b04", "input": "sentence_A: There is no man drinking orange juice and walking on a sunny day. sentence_B: A man is drinking orange juice and walking", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-89e5cf751c5948738c74da9ee67c1d75", "input": "sentence_A: A little girl is playing the piano. sentence_B: There is no little girl playing a grand piano on stage", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-02da19267f16428f9d8a982bd0b70408", "input": "sentence_A: A woman is peeling a potato. sentence_B: A man is slicing a red tomato", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-63ec9269f1bf4764b56e281287196444", "input": "sentence_A: A man is speaking on a podium. sentence_B: There is no man speaking on a podium", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-6276edeedd8b444795e51af84e4655be", "input": "sentence_A: The man is singing and playing the guitar. sentence_B: A man is playing a guitar", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-f5b6484e46de4f17a365617348b50bb1", "input": "sentence_A: The woman is stirring eggs in a bowl. sentence_B: The woman isn't stirring eggs in a bowl", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-8db1ebeb894b4471ab239343c0ebead9", "input": "sentence_A: A woman is chopping broccoli. sentence_B: The woman is not chopping garlic", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-8216f950f6214fb49d6a2fa2f9c6cd74", "input": "sentence_A: A dog with a blue blanket is running through the grass. sentence_B: A dog with a blue muzzle is running around the yard with a jacket", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-ae29cecf286940f9a2434602680002a6", "input": "sentence_A: Two children are playing on a statue. sentence_B: There are no children playing on a statue", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-33c682e633304ffc98af55461cb880b2", "input": "sentence_A: A surfer is riding the wave. sentence_B: There is no woman in a yellow shirt surfing on a pink surfboard", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-8d1da43daeec4677926e336e780955cd", "input": "sentence_A: A man is walking slowly across a rope bridge. sentence_B: A man is walking slowly across a bridge made of rope", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-061d550d74264fb9a382c7da075acf3d", "input": "sentence_A: The meat is being dropped into a pan. sentence_B: There is no woman putting meat in a pan", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-51836e9fbabd45db88aa29c370c3081b", "input": "sentence_A: Someone is beating an egg. sentence_B: The lady is stirring eggs in a bowl", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-067f618d45af4a9ba821d329b6b01a44", "input": "sentence_A: A man is riding a motorbike. sentence_B: A motorbike rider is running over a man", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-8d665fc5cb274e13b3e29a785577d6bf", "input": "sentence_A: A potato is being peeled by a person. sentence_B: A person is frying some food", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-955dfd5c518e4029859826ee13be0a13", "input": "sentence_A: The man is cleaning the drawing on the board. sentence_B: The man is erasing the drawing on the board", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-b3745d7fa197436586de0a257c761fe3", "input": "sentence_A: There is no boy filling a pitcher with water. sentence_B: A boy is filling a pitcher with water", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-f35918c74b414a49936fb44ce29be165", "input": "sentence_A: A man in a purple hat is climbing a rocky wall with bare hands. sentence_B: The young man is rock climbing", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-2256deca1f4745b887e55f098cc4e20e", "input": "sentence_A: A woman is using a sewing machine. sentence_B: There is no woman using a sewing machine", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-cde6709b9f194a64b6df833973066dce", "input": "sentence_A: A woman is frying some food. sentence_B: Some food is being fried by a woman", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-37e5fd1597354c75adffe69a998ca624", "input": "sentence_A: A man by a brick wall is wearing a mask around his mouth and a hair net. sentence_B: A man is wearing a clear plastic cap and a face mask", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-5c2859f149ae470eb6c3576ff1bd0baa", "input": "sentence_A: Two dogs of different breeds are looking at each other across a street. sentence_B: There are no dogs of different breeds looking at each other across a street", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-09c12b3692e4436c81184b60ecf1c8fc", "input": "sentence_A: A lady is cutting up some meat precisely. sentence_B: A lady is cutting up some meat", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-b1f0b50fb0a341cf888095c9e5b3a366", "input": "sentence_A: Pedestrians and cars are moving through a traffic jam in a big city. sentence_B: Pedestrians and cars are moving through a traffic jam in the big city", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-1b0fa5fe302444d9b1b511d95c8f7119", "input": "sentence_A: A man with no hat is standing outside of a green jeep. sentence_B: A man is standing on a dirt hill next to a black jeep", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-c83f6de99dbe4dbdbab11636d8d3444e", "input": "sentence_A: There is no man with a hard hat dancing. sentence_B: A man with a hard hat is dancing", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-3d14014a026d4ce28c56d3352c2a7edd", "input": "sentence_A: A man is riding a horse in a sandy land. sentence_B: A guy is riding a horse", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-7d0156c2101b470286dafd882bf7e2ae", "input": "sentence_A: Some people are in the snow, wearing clothes that provide camouflage. sentence_B: Two people are walking two dogs with golden coats in the snow", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-bede9997dc9e479b81d217bc801b3f4a", "input": "sentence_A: A large green colored ball is hitting a potato. sentence_B: A big green ball is knocking a potato", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-89a3706d55aa4859b5b4239ce5ff3035", "input": "sentence_A: A man is thinking. sentence_B: There is no man thinking", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-c7565e7ebfc14a70a420d6cf453cfeee", "input": "sentence_A: A man is squatting in brush and taking a photograph. sentence_B: There is no man squatting in brush and taking a photograph", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-0dee3e7a1b0d4a88a76255d5816b08d9", "input": "sentence_A: The man is riding a mechanical bull. sentence_B: The man is riding a bull which is mechanical", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-784ffb37b015430cbf9493c32a186d30", "input": "sentence_A: A woman is walking with a pair of dogs. sentence_B: A woman is showing a dog with very long hair at a dog show", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-10f833a98a3b483c999d6877af115237", "input": "sentence_A: There is no man on a bicycle riding on the beach. sentence_B: A person is riding a bicycle in the sand beside the ocean", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-ec685bc6789d4c98a219c02b6931d9e0", "input": "sentence_A: The young child is riding a three wheeled scooter down the sidewalk. sentence_B: A young child is riding a three wheeled scooter down the sidewalk", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-1adf6d58e352499baaa714f1a3379fd0", "input": "sentence_A: A biker is naked. sentence_B: A biker is wearing gear which is black", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-6156dd63690940869b76f8a6992771d5", "input": "sentence_A: Two men are battling. sentence_B: Two men are fighting", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-b5af051879f84dfd8335686a0566f38e", "input": "sentence_A: The woman is stirring meat in a bowl. sentence_B: A lady is mixing a mixture of meat in a bowl", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-1278b79c4fd84a8abb6ce2772ba0e685", "input": "sentence_A: Two children are playing in the surf. sentence_B: A kid is splashing in the pool", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-226715852a4b4e05890a9e8d31fd4783", "input": "sentence_A: A girl is waking up. sentence_B: A child is waking up", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-8a1ff75fb51b4ba486643458c9e8bd42", "input": "sentence_A: The cat is licking milk from a saucer. sentence_B: The cat isn't licking milk from a saucer", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-cd6414b22a524698831cc9a93d2ede9d", "input": "sentence_A: A woman is slicing an eggplant. sentence_B: There is no woman cutting a vegetable", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-e759c1f0f14b4d21a22ac2e9c9091a52", "input": "sentence_A: A dog is chasing another and is holding a stick in its mouth. sentence_B: A dog is chasing another and is holding a piece of wood in its mouth", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-9055ce29aa394e04921601a29d8374fe", "input": "sentence_A: A woman is putting on eyeshadow. sentence_B: The woman is putting make-up on", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-c790f60234b64730918ec41e78f34dc9", "input": "sentence_A: A kitten is drinking fresh milk. sentence_B: There is no milk being drunk by a cat", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-2b6adb236b83410fb0e0b39a648e60ba", "input": "sentence_A: A rabbit is playing with a toy rabbit. sentence_B: A rabbit is playing with a stuffed bunny", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-1b40566505fc40ce8425bae2e5c141ed", "input": "sentence_A: A young girl with a heart tank top is raising her hands as she is playing on a slide. sentence_B: A young girl with a heart tank top is raising her hands as she is sliding", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-40f4dc9aa7a24bd9a50a961f6495ce63", "input": "sentence_A: A group of people is sitting on both sides of a red stone structure. sentence_B: Some people are sitting on the ground outside a monument", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-15eecbd681e14808b562f30306fcdbd2", "input": "sentence_A: There is no woman using an eye pencil and applying eye liner to her eyelid. sentence_B: A woman is using an eye pencil and is applying eye liner to her eyelid", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-971ca52acf624886ada515384c4ff0df", "input": "sentence_A: The south African plane is flying in a blue sky. sentence_B: An airplane is being stationed on the ground", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-7d037d0416ea45d0bbdea23cb32c7e93", "input": "sentence_A: Two children are rolling in dirty water. sentence_B: Two children are rolling in muddy water", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-a4dd42ad0a944d5cb806b57ae4723906", "input": "sentence_A: The tan dog is watching a brown dog that is swimming in a pond. sentence_B: The tan dog is not watching a brown dog that is swimming in a pond", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-b60cda1428804fa7bf8a4ecff7a15abf", "input": "sentence_A: A boy is looking at a calendar. sentence_B: A boy is shredding a calendar", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-ef7be7a949bb40bf8c4d743bac92225c", "input": "sentence_A: There is no person kicking a soccer ball between somebody's feet. sentence_B: The soccer player is kicking the ball between somebody's legs", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-7a75eb20aaa84c34b37e14891cb65ba6", "input": "sentence_A: Two girls are not playing inside the jumper house. sentence_B: Two girls are playing inside a jumper house", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-15797acc710d423c90219fc4a6538428", "input": "sentence_A: A person is cutting a capsicum into pieces. sentence_B: A capsicum is being cut into pieces by a person", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-fbb03ff36be44b41ba68e342d50c5d06", "input": "sentence_A: The cat is hungrily drinking milk. sentence_B: Drinking milk helps a cat's hunger", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-393794765c764ad9a747fca6fa7669d9", "input": "sentence_A: The bicyclist is riding on a city street. sentence_B: The bicyclist is not riding on a city street", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-27fac74ccd974a8cab41db4de115d827", "input": "sentence_A: The man in a grey t-shirt is sitting on a rock in front of the waterfall. sentence_B: The man in a t-shirt dyed grey is sitting on a rock in front of a waterfall", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-e615183d96e14602bd2dbae6a5324d2e", "input": "sentence_A: A woman is using an eye pencil and is applying eye liner to her eyelid. sentence_B: A woman is applying cosmetics to her eyelid", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-6be2647e549d40dc98f59c181650dee5", "input": "sentence_A: A woman is beating two eggs in a bowl and using a whisk made of wire. sentence_B: There is no woman beating two eggs in a bowl and using a whisk made of wire", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-f88fbd8b6fd145edb59461282559984e", "input": "sentence_A: A man in a red uniform is swiftly making a jump in a dirt bike race. sentence_B: A man in a red uniform is making a jump in a dirt bike race", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-8420118afa4c48b692b3515f7c340239", "input": "sentence_A: A person on a bike is not in the air near a body of water. sentence_B: A person on a bike is in the air near a body of water", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-9cefa1afbc66449fac87811f1266cd40", "input": "sentence_A: A homeless man is holding up a sign and is begging for money. sentence_B: A homeless man is holding up a sign and is pitifully begging for money", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-bfeb4f7656624cc297de4d9f648155a3", "input": "sentence_A: A tan dog which is dirty is rolling in the dirt and looking right at the camera. sentence_B: A dog is rolling on the ground", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-c855decfd884495d802eb70b77382b1b", "input": "sentence_A: A boy is whacking a man with a sword. sentence_B: A man is being hit by a kid with a weapon", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-56a6a86d4f1f4436b912aa06431f105b", "input": "sentence_A: A dog is not running towards a ball. sentence_B: A dog is running towards a ball", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-b6e4e7b2b054421dbc838d29d5c1a7ad", "input": "sentence_A: There is no boy cutting grass with scissors. sentence_B: A boy is cutting grass with scissors", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-2fc42727ac0b45f5bf24099e68dd27f6", "input": "sentence_A: A yellow kayak is being ridden by a man and a young boy. sentence_B: A man and a young boy are riding in a yellow kayak", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-4d5ab84898f44e1b88ccaf3c61f58857", "input": "sentence_A: A woman is wearing an Egyptian headdress. sentence_B: A woman is wearing an Indian headdress", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-45a02e69f51a4fae88266e75d87a45fa", "input": "sentence_A: The orange rescue boat is not rushing across the water. sentence_B: The orange rescue boat is rushing across the water", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-5bc6d01daf7d4c8b8247fd360e7ec756", "input": "sentence_A: A girl is applying makeup to her face. sentence_B: A woman is putting on makeup", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-e3f26e1c9bb3492591b544fa5c80c10f", "input": "sentence_A: There is no man playing the guitar. sentence_B: The man is playing the guitar", "output": ["2"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-8e08fd4bded84b78be7cb1fd2e22d903", "input": "sentence_A: A man is flooring a sitting guitar player. sentence_B: A man is sitting on the floor and is playing a guitar", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-4986fa0684a4492d9afeeb6009140730", "input": "sentence_A: A person is shirtless and is putting down the beer. sentence_B: A person is wearing a red jacket and holding a beer", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1612_sick_label_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the numbers 0 (entailment), 1 (neutral), or 2(contradiction). The model should output 0 when the two sentences are related to each other in some way. This could be because they are both talking about the same thing, or because one sentence is entailing the other.  The model should output 1 when there is no relation between the two sentences. This could be because they are talking about two different things, or because there is no clear relation between them.  The model should output 2 when the two sentences contradict each other. This means that one sentence is saying something that the other sentence is not, or that one sentence is saying the opposite of what the other sentence is saying."], "Instance": {"id": "task1612-fa094d9d1c324d41956bb7ee5a3fe725", "input": "sentence_A: A young man on a bmx bicycle is jumping on a masonry pyramid. sentence_B: A young man on a bmx bicycle is jumping off a masonry pyramid", "output": ["0"]}, "Prediction": "1"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-89afc2c76d5d44b6a4b64f885db97a71", "input": "Premise: A very skinny Santa Claus greets young children in front of a building.\nHypothesis: A man smiles at children outside while waving\nUpdate: His hands are in his pockets.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-a3e3fb2988bb429ba7e6f5bb2fe363db", "input": "Premise: A man wearing a yellow shirt, brown pants, and a Bluetooth looks at his cellphone while seated against the exterior of an dirty white building.\nHypothesis: The man is waiting for someone who is in inside the building.\nUpdate: The workers in the building get off work in 10 minutes.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-0f74f2ff81cd4ee989bf24c9f5967a34", "input": "Premise: A man in black bathing trunks dives into water.\nHypothesis: A tall human dives.\nUpdate: The man doesn't meet the height requirment to ride a roller coaster.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-6aaf3772050d4de089010980840d1520", "input": "Premise: a group of man are sitting outside playing music.\nHypothesis: A jam session is taking place in the park.\nUpdate: The men are on a porch", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-b05021f35383426aa4e0b33049f67f48", "input": "Premise: Guy wearing sunglasses and blue shirt on skateboard in front of a bright yellow building with palm trees.\nHypothesis: A guy skateboards around with a woman.\nUpdate: The man is talking on the phone the whole time.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-66e42620316349239ab1e225477251fc", "input": "Premise: People on the street are coming to check out the women's table.\nHypothesis: People are considering buying what the woman is selling.\nUpdate: The table is full of many different items with tags on them", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-4c884113b6f343cb95ecfa4c32000fdd", "input": "Premise: A brown dog is fetching a stick in a country setting.\nHypothesis: There are other dogs fetching a stick in a country setting.\nUpdate: The dog is the only dog around as it fetches the stick.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-b7a096d1d20c460d9fc6e2e7cd593419", "input": "Premise: A man touches the snow as he snowboards downhill.\nHypothesis: The man is snowboarding a black diamond trail.\nUpdate: There is a large steep drop off to the right of the snowboarder that goes down the mountain", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-491b51392af546b6ad403125bb6c7754", "input": "Premise: A mother and her two daughters stop in a courtyard.\nHypothesis: The girls are all wearing dresses.\nUpdate: The daughters are dressed for prom.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-e947449ff52e41e68119716844d6f1b0", "input": "Premise: A man standing in a white shirt is conducting a small group of violin players.\nHypothesis: Bob is conducting a small group.\nUpdate: The man's birth certificate says Robert.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-8a1a739f62354e8f9d177dcba913594e", "input": "Premise: A woman is hugging a man, while an older man is taking a picture.\nHypothesis: The couple are crying on eachothers shoulders.\nUpdate: The couple are laughing.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-464d13a233ec4f22bb304f4bdc5c341e", "input": "Premise: A young boy runs towards a blue soccer ball in front of a goal.\nHypothesis: A young boy is trying to score a goal.\nUpdate: The boy is trying to block the other team from getting a goal.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-43dc4c659b11413d88c760093a7d09e3", "input": "Premise: A boy is going down the slide.\nHypothesis: A boy is at the park\nUpdate: The slide is 150 feet tall.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-dcb97d6063704603b839da05f65e4c6f", "input": "Premise: A man in a black jacket is admiring the merchandise from a street vendor who is wearing a brown jacket.\nHypothesis: A man is looking to purchase a knock off purse from a street vendor.\nUpdate: There are belts on the ground.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-384844149e344e4fa96abbd34e16432c", "input": "Premise: Two people jogging together near the waterside.\nHypothesis: A couple jogging down the beach.\nUpdate: The sand is soft under their feet.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-318e006fa9914cd08737e7c445fd00e6", "input": "Premise: 4 men are sitting at a table deep in thought.\nHypothesis: The men are thinking about their mother.\nUpdate: The men are comparing there parents", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-5b4707b72003427bac7c2babefcece72", "input": "Premise: A lady is visiting a place important to her.\nHypothesis: a lady is visting a grave\nUpdate: There are balloons and music playing.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-8f8f91f714dd49f18e111e67a8623b8f", "input": "Premise: Several hikers rest with their gear in front of a mountain.\nHypothesis: The mountain will fall on top of them.\nUpdate: The mountain has stood for millions of years.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-f3a8229114ee4fbca2c080fd761a36b1", "input": "Premise: A little girl with a hat playing ball with her mom.\nHypothesis: The girl is happy.\nUpdate: The girl is smiling", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-980d908844fa40e483c4f9b2b688a232", "input": "Premise: A girl in a mostly navy blue uniform is playing baseball.\nHypothesis: A girl is playing for her team.\nUpdate: She has a brace on her arm.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-57cabafa08a142b7a2b12ad2642f4716", "input": "Premise: A person wearing a blue jacket and fur lined hat is sitting on the street holding something that looks like a sandwich in his hand.\nHypothesis: The man is on his lunch break.\nUpdate: The man occasionally checks his watch.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-8a4986ea63e3491b87b786483d9f5192", "input": "Premise: A young boy wearing a green and red shirt kneels down on a sidewalk in Paris.\nHypothesis: The boy is from Paris.\nUpdate: The boy knows his way around the city.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-e713c752a33a483683ce3dfdb505eb00", "input": "Premise: A man is sitting down pulling down his red long-sleeve sweater.\nHypothesis: The man's favorite color is red.\nUpdate: The man does not like this sweater.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-31c4da55534f4ef6a0ea7a1ee0d897df", "input": "Premise: Four adults and one child visit on a backyard patio.\nHypothesis: people are sitting and talking on their vacation\nUpdate: The people look around like they haven't seen it before.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-34a4db4598e44ff0bfb4e6da88763ecc", "input": "Premise: Two men playing stringed instruments.\nHypothesis: Two guys are preparing for a concert.\nUpdate: An audience watches the men.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-3a641b249b5840d1928863bdc679d367", "input": "Premise: A couple sits alone in front of a large statue late at night.\nHypothesis: The couple is in front of an Abraham Lincoln statue.\nUpdate: The couple are in Paris.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-634ed6a3b17d40389719a9e71cb4c0bf", "input": "Premise: The man has a blue shirt on and is standing in front of some snowy mountains.\nHypothesis: The man is currently in Alaska.\nUpdate: He is visiting his daughter in Nome.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-06dfed5d966d421a961fff7604eb69e2", "input": "Premise: A brown dog catching a ball in silhouette.\nHypothesis: The dog is playing catch with his master.\nUpdate: The owner just threw the ball.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-9f8265f4a6474085a51e2ccf871cd45f", "input": "Premise: There are people standing and setting beside white tents with sad and worried faces as they look around at boards and trash scattered around the area.\nHypothesis: the people look worried because of the trash\nUpdate: They begin to pick up the trash.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-76dd2852a5154e2093c55f0b52ce584d", "input": "Premise: Food prepares are serving their customers with pride.\nHypothesis: The food prepares are serving a party.\nUpdate: It is a normal Sunday night at the restaurant", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-074c18db16f2441c922b874f6d228c9c", "input": "Premise: The boy pours water on the baby.\nHypothesis: The boy is watching the baby.\nUpdate: He is helping his  mother give the baby a bath.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-16f326d6374b47bb82db6b090ca51959", "input": "Premise: Two men in football uniforms sit on the grass, looking unhappy.\nHypothesis: Two men unhappy after losing a game.\nUpdate: They are sweaty.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-de9383c5163149d9b7363e80fb1b4cc4", "input": "Premise: A older woman wearing a black dress holding a loaf of bread by a doorway.\nHypothesis: An older woman comes home from the local bakery\nUpdate: The bread is still warm from the oven.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-898c57b966f8488593fa3b9c4ce4be7c", "input": "Premise: The girl with the blue bucket splashes beneath the pier.\nHypothesis: A girl has sand in her bucket.\nUpdate: The girl has been trying to build a sand castle.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-1c1cca7c95a749c28dc739ccb79698b4", "input": "Premise: A boy with his soccer team wearing black and gold uniforms leaps to hug his coach on the soccer field.\nHypothesis: A boy hugs his coach after the team won the game.\nUpdate: The boy is holding a trophy.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-2c6564f7258347e8afa55cb41ec022d2", "input": "Premise: Two men at a rodeo attempting to rope a calf.\nHypothesis: Two rodeo clowns at a rodeo are attempting to rope a calf while a crowd watches.\nUpdate: The men are dressed in many outlandish clashing colors.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-419a8f7eee2a42b2a57cb16b20952962", "input": "Premise: Five students are reading off a piece of paper.\nHypothesis: the students are practicing for  a test\nUpdate: The test will account for 20% of their final grade.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-4e2a3caf6cf64af2888544c0eb3dadaf", "input": "Premise: An ice cream truck with an open door is driving through a residential neighborhood.\nHypothesis: An ice cream truck with an open door is driving through a big neighborhood.\nUpdate: The ice cream truck is surrounded by several dozen children.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-17fa0672a978404a9a35bf9bf995c3b8", "input": "Premise: A man in a black suit and a woman wearing a white dress and holding flowers getting married\nHypothesis: the man is giving flowers to the woman.\nUpdate: Rice is being thrown.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-560904e24dc34b9bb1af8675267509b6", "input": "Premise: Two people standing in tree on a sunny day\nHypothesis: two boys have climbed a tree\nUpdate: The boys can see very far ahead.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-f48832c9b2a34f3087aacc4607309f1d", "input": "Premise: A black and white dog walks on a beach.\nHypothesis: The dog is walking with its owner.\nUpdate: The man is getting some exercise with pet on the beach", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-18065bc8ba0847f39835ba4152273230", "input": "Premise: Two men are standing outdoors on a sunny day holding pieces of a new item, possibly a small grill, while one of the men studies the assembly instructions.\nHypothesis: A man stands beside a new box of grill machine and tries to figure how to assemble it by reading through the manual\nUpdate: A man stands beside a new box of grill machine, with a tray of raw meats, and tries to figure how to assemble it by reading through the manual.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-a4f18fe449c64fdcab921f0a11e1d2db", "input": "Premise: A man in a striped blue shirt holds a large bouquet of brightly colored Mylar balloons in a crowded market area.\nHypothesis: The man is waiting to receive somebody.\nUpdate: The man keeps looking around and at his watch.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-a67e27d58eb94b4da6ed162f2a2812fe", "input": "Premise: A large crowd of people are walking down the street.\nHypothesis: A group is walking to a festival.\nUpdate: It's raining and thundering.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-08ccdf2b876b4db1b3a8dd31b6000e13", "input": "Premise: Amateur chef wearing a white cooking apron is about to chop a chicken with a butcher knife.\nHypothesis: The chef is holding a knife.\nUpdate: Several parts of the chicken are already cut off, and he is preparing to cut off the drumsticks.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-382eb3b36be249c6ae67900783a55364", "input": "Premise: A mix of kids and adults sitting by a tree that has different colored flags hanging around it.\nHypothesis: A group of people are sitting by a tree at night time.\nUpdate: There are people finishing up dinner near the tree.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-79ad1df6ad4347a290c232b20d8c7a5a", "input": "Premise: A young boy with an older man using chalk to draw on the sidewalk.\nHypothesis: A young boy with an older sad man using chalk to draw on the sidewalk.\nUpdate: The man is laughing.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-990528f469324c3e9139f7d5215ed96b", "input": "Premise: The tattooed woman, who is wearing the black dress, is hula hooping.\nHypothesis: A woman plays with a hula hoop at an outdoor concert in the park.\nUpdate: The woman is hula hooping by a stage.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-7730f55d6b7f4289baa9acb5ced14a43", "input": "Premise: A lady in a fold up chair eats while a man looks inside a car door that is parked on a curb.\nHypothesis: A man is looking at the car belonging to the door to door salesman he just killed and fed to his wife.\nUpdate: The man says 'Honey I can't find your purse anywhere'", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-e0ffc602eae34ac1ba4ce0007aedbb6a", "input": "Premise: A man with brown hair and glasses wearing a dark overcoat, suit and tie reading a newspaper on the subway or train.\nHypothesis: A man is reading a news article.\nUpdate: The man is learning about the situation in Syria.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-6667d7b4f51f4602bbb3fc1e252cc7f8", "input": "Premise: Police officers in Madrid talking.\nHypothesis: Police officers are speaking spanish to one another.\nUpdate: The police officers are giving a speech to the crowd.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-fa5f3a1b27f44adab4effbfa0bebe628", "input": "Premise: Beach volleyball player Dalhausser just blocked a spike from a Brazilian beach volleyball player.\nHypothesis: A person blocks a volleyball on the beach in summer.\nUpdate: They are practicing indoors.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-4326ecda5e56411f85948faf44e7691a", "input": "Premise: One man is jumping into the water, while the other is watching.\nHypothesis: Brothers are by the water\nUpdate: The two men are roommates.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-fe4fe9abe4ae466f9070b38ede4e7853", "input": "Premise: Trendy girl walking down the street.\nHypothesis: A girl is modelling for a photographer.\nUpdate: She was breaking in her new shoes.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-cedc53fafb6d44b0a2754db5b318c459", "input": "Premise: A girl jumps rope on a sidewalk.\nHypothesis: A young girl is jumping rope on a sidewalk near school.\nUpdate: Her mother calls her inside to have supper.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-5f4a0ccdefe64e16a513aa79463dbd88", "input": "Premise: an asian girl wearing a red hat along side several others with red hats as well\nHypothesis: The woman is part of a red hat fan club.\nUpdate: There are also men in the group.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-3d495e5ae3c24147afc2d6d1ddc75e26", "input": "Premise: A group of people are sitting in some rows of wooden seats.\nHypothesis: Ten people are in seats.\nUpdate: A dozen were seated but two got up.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-cf4918cde5b145beaaccfdddea3fae74", "input": "Premise: Man in black prepares to celebrate his birthday by blowing out the candles on his cake.\nHypothesis: A man is getting ready to eat some cake.\nUpdate: He is allergic to gluten but did it for the occasion.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-1f4a3f802c3443b2a0597227e112920d", "input": "Premise: A little girl with a bindi laughs as she stirs a pot in the kitchen.\nHypothesis: The girl is mixing mud pies in the pot..\nUpdate: The pot is only filled with water.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-2bf0043a9e3f47fc833045124ad3f7df", "input": "Premise: A man plays electric guitar on his knees.\nHypothesis: Jimi Hendrix wowed the crowd yet again, dropping to his knees before finally setting his guitar on fire.\nUpdate: A concert in the 1990's.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-e2c5873996864f5380ec314411394a25", "input": "Premise: A small black and white dog on a leash stands next to a gray and white cat on the sidewalk.\nHypothesis: The dog fights with the cat.\nUpdate: The dog is growling at the cat.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-7cb5aaf8e65b4fbeb4f0a115a4df3071", "input": "Premise: Black man working on a plywood stage.\nHypothesis: A man is cleaning the theater\nUpdate: The stage is outdoors in an park.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-57985aa5ee22454cb79a348eb081a805", "input": "Premise: Black bird flying with a leafy branch in its mouth.\nHypothesis: The bird flies low to the ground.\nUpdate: The bird is landing near it's nest.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-4e27098ccc60422e99b1d852d9edc3a0", "input": "Premise: Swimmer in the water takes time to contemplate the race.\nHypothesis: The person is nervous about the race.\nUpdate: This is only the swimmer's second competition.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-906051b8b2034128aa09fdf62150b126", "input": "Premise: Trees obscure a building to the right.\nHypothesis: There are trees near that building.\nUpdate: The shadow of the trees doesn't reach the building.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-ccd8729fcd0b41e0aeee2bf4094c3f99", "input": "Premise: A view from the ground of a footbridge, with several pedestrians on it, and the view of one man's feet in the center foreground.\nHypothesis: The people are crossing the footbridge.\nUpdate: There is a parade on the bridge.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-5940ef4589254be9afa832776a7b43fe", "input": "Premise: A man is sleeping on the ground.\nHypothesis: A man stays comfortable in a sleeping bag\nUpdate: The man is camping.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-daed61d228de4918b5fab789a7df6b23", "input": "Premise: Male walking by cement wall and passing a tree.\nHypothesis: The man passed the tree on the way to the store.\nUpdate: The man walks by the tree and there is a store behind him.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-843b6da5b4874837b5fea76a91ec0039", "input": "Premise: Several people, including a man in a blue shirt and two women wearing black, acquire food from a buffet table.\nHypothesis: Several people are overloading their plates with food.\nUpdate: They are in an eating disorders inpatient center", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-dd04042c543846fe93f74cfe4d1dc609", "input": "Premise: A girl in a polka dotted blue jean dress walks barefoot on a balance beam.\nHypothesis: A girl is walking on the beam.\nUpdate: The girl forgot her leotard but the coach made her practice anyway.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-70b55f80690546319b80f5abd52868e6", "input": "Premise: A young boy hanging on a pole smiling at the camera.\nHypothesis: The young boy is hispanic.\nUpdate: The young boy is speaking Spanish.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-dbae68007f1c48e6b6ed04a9eb8bf5d1", "input": "Premise: A man in a cape is near a red building.\nHypothesis: The man is wearing a red cape.\nUpdate: He is dressed as batman.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-d3f87be530fd4f04b34d462abdb60704", "input": "Premise: This is a young girl in the grass at a park posing for the camera.\nHypothesis: A model is having a photo shoot in the park.\nUpdate: She has her graduation cap and gown on.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-46ab2ae5999e48a4a0d75cc2e1743a43", "input": "Premise: Two women and a man in a studio looking at a large portrait of Cher.\nHypothesis: Two women and a man are thinking about purchasing the large portrait of Cher.\nUpdate: They are being shown around a friend's home.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-f28248bae6754898aed5d2135331411b", "input": "Premise: In front of palm trees, figures ride bicycles while a couple walk and a child wears rollerskates near an older person.\nHypothesis: People at a Los Angeles park.\nUpdate: The population density nearby is very low.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-90f7f7f423784d889e22ca74b74f671e", "input": "Premise: A woman in a white hat sings into a microphone.\nHypothesis: The woman is singing to an audience.\nUpdate: They applaud her lovely voice.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-ea661dabad0e4feebe8c23f16c56fb52", "input": "Premise: two dogs wrestle.\nHypothesis: Two dogs playing together.\nUpdate: The dogs are growling and biting each other.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-9e42d609dfe4403cb6ed66bc10c6e32c", "input": "Premise: A young woman wearing a black and white striped shirt looks at a necklace that another woman is holding up.\nHypothesis: The young women is at jewelry shop.\nUpdate: There are rings for sale nearby", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-62fd23823c2845ec821d9a30678729f6", "input": "Premise: A biker in spandex riding on a busy street.\nHypothesis: A biker is coming home from work.\nUpdate: The biker is in formation with dozens of others.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-5b45aeb23b824a1f8bbef69201f51976", "input": "Premise: Women sit at a bar that has dark cabinets, menus written on the walls, and a light hanging above the bar.\nHypothesis: Woman goes to bar for the first time\nUpdate: The woman knows exactly what drink she wants to order.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-b54aa5a654f948aa8965cc8af4c99f24", "input": "Premise: A man waiting for the subway while looking at a newspaper.\nHypothesis: A man reads on his way to work.\nUpdate: He is entertaining himself to pass time.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-0013dce0ea814b14a2b42781d7dc6d09", "input": "Premise: three pairs of underpants are hanging from a line under a red shelter.\nHypothesis: The drier was broken and the backup was used.\nUpdate: The house does not have electricity", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-4b7c38f71b1142aa88d8fcb05e019c99", "input": "Premise: woman with dark glasses and ball cap talking on a cellphone\nHypothesis: A person is talking long distance on the phone.\nUpdate: She is using the phone's voice recorder.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-f8bd1d4a00ec4002b06717e7c37b68ab", "input": "Premise: children sit on top of somebody in a banana suit.\nHypothesis: Children are hurting others.\nUpdate: The children are bouncing up and down", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-1e7e45f2bad64f6baa1ce6e73fe0eaf7", "input": "Premise: A man wearing a cap stands behind the counter of a shop where sausages and peperoni hang.\nHypothesis: The cap is blue\nUpdate: The man's cap matches the grass.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-21e29b00427542f6b51a3f2a05680789", "input": "Premise: Three adults take shots by a bar.\nHypothesis: There are three adult friends.\nUpdate: The people are sitting seperately.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-dd55ba1e9dca4e228064bbea82e314e0", "input": "Premise: A child doing a handstand on the beach.\nHypothesis: A child doing a handstand on the beach alone.\nUpdate: The beach is silent aside from the waves.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-e612907acf354183bbbc2aa065a5c712", "input": "Premise: A group of people sit on benches at a park outside a building.\nHypothesis: The people wait for the bus to come.\nUpdate: They have money for the fare.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-7a4c2ccbc4eb4e27a1b6b02284194898", "input": "Premise: Workers in reflective clothing with shovels on a train track.\nHypothesis: Workers are working at night.\nUpdate: Crickets are chirping loudly in the woods", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-8386dafe2bc4458c9a9084408da67576", "input": "Premise: A young boy plays a video game in a McDonald's restaurant.\nHypothesis: A child just finished eating.\nUpdate: Empty trays with burger wrappers and fry tins are present on the child's table.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-89ce71af8be546489f4fc323d88d49ae", "input": "Premise: A woman walks in front of a movie advertisement.\nHypothesis: The woman is at a movie theater.\nUpdate: The advertisement is on a billboard.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-fc3201d1315a4acf984e57a9c5adcf43", "input": "Premise: Some middle eastern people have set an Israeli flag on fire.\nHypothesis: Middle eastern people are protesting the Israeli occupation\nUpdate: They are shouting as it burns.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-5f9ccce50e0e40cc9658ac38318386b4", "input": "Premise: The mother is helping her baby brush his teeth with his big boy green toothbrush.\nHypothesis: The mother and baby are at the bathroom sink\nUpdate: The bathroom mirror is large.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-023653d33ef34f9db4f387481c3a931e", "input": "Premise: A woman taking pictures with her phone.\nHypothesis: The lady is taking pictures of everything with her phone.\nUpdate: The woman only clicks on the camera twice.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-fcd85005e6f04e4b8face6e4f250c972", "input": "Premise: A toddler boy in a racing jacket tries out the green hula hoop.\nHypothesis: The toddler boy is trying out the hula hoop outside.\nUpdate: The boy's shoes become grass stained.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-068664935700487795d368ad4efd3dd9", "input": "Premise: A dog, jumping over a trace obstacle, a woman watching in the back.\nHypothesis: A dog jumps over an obstacle to first place.\nUpdate: They practice alone in a park", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-92660d8c162a465084230197069a5b15", "input": "Premise: A teenage boy hits a tennis ball with a racket.\nHypothesis: The boy is on a tennis court.\nUpdate: The balls bounces off a net.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-7470653f15cb4a0a929a94171a7ea28b", "input": "Premise: The skateboarder rides near a small cone.\nHypothesis: The skateboarder rides his skateboard on the concrete.\nUpdate: The skateboarder's town is known for its wooden sidewalks.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-614372595e4c41a88db049fb7695a3b7", "input": "Premise: A bunch of people are standing or sitting in a snow valley.\nHypothesis: They are all friends, talking with one another.\nUpdate: They are looking away from each other.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task936_defeasible_nli_snli_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis, that is, it makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis, that is, it makes you much more likely to believe the hypothesis is true. Your task is to answer with 'strengthener' or 'weakener' if the update strengthens or weakens the hypothesis, respectively. 1. The model should output a strengthener when the premise and hypothesis are both true and the update supports the hypothesis. 2. The model should output a weakener when the premise and hypothesis are both true and the update contradicts the hypothesis."], "Instance": {"id": "task936-ef7b2ada561a4440b6b031097a96a534", "input": "Premise: A young boy in a baseball cap jumps into the arms of a man wearing a blue shirt.\nHypothesis: The boy jumps into his father's arms.\nUpdate: The man is a little league coach.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-2bd0cdc83db04662a47cd28285870eb1", "input": "Last month is the third-hottest June on record globally.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-0b332ed43941431cb5d3c90050a65813", "input": "By burning fossil fuels at a prodigious pace and pouring heat-trapping gases into the atmosphere, humanity is about to provoke an abrupt climate shift.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-c9d739655fe94bd78ced76d9f1f6f1fa", "input": "Today 's [ Green New Deal ] vote is a partisan stunt to side-step needed debate on climate action, and give Republicans cover to put oil lobby checks over our kids.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-a2ee7b6374034ab1b7efa6c8fd9ff44d", "input": "While many scientists are wary of drawing firm links between any particular storm and climate change, a rising sea level adds to the destructiveness of storm surges, and a warming atmosphere holds more moisture, leading to more rain.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-f5a3fe7f812344ea872fcd412ffaa18a", "input": "There has been no increase in global temperature for 18 years.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-4de4e5e257fa47dbafd207cff26040be", "input": "Greenhouse gas emissions decreased during Trump's first year in office.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-addc51efc01448e9a08487943a59ba20", "input": "The research is the first to quantify how air pollution in the United States is affected by China\u00e2\u0080\u0099s production of goods for export and by global consumer demand for those goods.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-1c1839419df84fd18bfc0b97675faf51", "input": "Some people believe that the global elite go to Davos and plan for world domination, but it's much scarier than that.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-c2d328cbf0f041749862d539fbed5a5c", "input": "Flooding has been going on forever.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-34fa73f21fc74be48a6ab782568dbff0", "input": "Beating climate change won't require a miracle.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-07483c86bbc64aea964c9836a8e194ab", "input": "Climate scientists centuries in the future won&apost be able to see any hints of the Medieval Warm Period or the Little Ice Age in Pacific data.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-083170c6adfc418ba624cd23e8b590bc", "input": "Global warming is a myth the greenies\u2019 heads exploded.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-c37476ea4cbf4a13ba8e1e6e6c6cab4c", "input": "These scientific events are not linked to climate change.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-b9576d9aec664042942fddc01b474c0b", "input": "A changing climate means that weather-related disasters like droughts, wildfires, storms, floods are potentially going to be costlier and they\u00e2\u0080\u0099re going to be harsher.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-bfcf578809d24960830aa4e6da4f728a", "input": "Global temperatures last year ranked as the second warmest since record keeping began in 1888.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-f899a524865e40c39bfbb7c443b0d262", "input": "All that our world leaders need is a little more common sense, in order to avoid the nonsense of seeking a globally-binding treaty to reduce CO2 emissions.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-ae21e3f026e347e2b91479b6fdd5ed37", "input": "The measure of introducing a carbon tax should be adopted soon.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-d048cb495f154814904ace140693d356", "input": "Global warming may be occurring more slowly than earlier thought, and that previous climate models may have been on the hot side.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-fa9df8ff200540fe9141e46c22769cde", "input": "But only half of the carbon dioxide stays up there.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-f40af1d2e03a4c67934e54d3e40bf76b", "input": "Whatever environmentalists may hope, the Obama White House and congressional Democrats are unlikely to make global warming a top issue in 2013 or 2014.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-91e33c66e7084698b3eb0fa9de4e9586", "input": "Sea temperatures are rising.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-9f375dd2d5b341d8ad6a8a1a91b0ca09", "input": "They are on the verge of passing climate legislation at home and a global carbon accord at the Copenhagen talks.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-41d27464886148239bd784cf94963f21", "input": "The long-term trajectory is toward low-and zero-carbon transportation.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-67ded18f776341a69d82796045cbd912", "input": "The corruption of climate science has occurred because some of our most important institutions have let us down.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-adbf7eef414245adbd979195f2c3fd75", "input": "Temperature readings from the Arctic and Antarctic used to estimate the effects of global warming are nothing more than guesswork.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-5694647a4f1542129f529116107d0fa5", "input": "Antibiotics are losing their effectiveness at a rate that is both alarming and irreversible \u2014 similar to global warming.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-c5de57ce8fe34870823490bcf4b87f93", "input": "Climate change is a likely threat to national security \u2013 though scientists can not yet predict particular climate effects of anticipated global warming with any degree of certainty.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-2fe4e3960a3e4f71881cef2c88ce161c", "input": "A warning sign that some scientists worry could mean global warming has passed an ominous tipping point.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-6869b5617a8a4421bbdba215086defc9", "input": "Addiction to fossil fuels has reached a point at which we should expect the judgment of senior leaders to become impaired, as seems to be happening.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-1f3489688954440db5aabff68f1de6f8", "input": "The ramifications of vanishing ice will also be felt far from the poles.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-64fd7426bea5493b9c04862d1b890932", "input": "We can\u00e2\u0080\u0099t retreat from the rising sea.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-a4501425226647f0a8a9bdb1fabc5b8f", "input": "Climate alarmists\u2019ve got it wrong on global warming.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-f6da3c37394e462d8b3e70bf3a5f38cd", "input": "An ice-free Arctic Ocean would not freeze again.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-1eb89ba900c742539c7ca06006b99a9e", "input": "You could have two people in the same room who agree about the details of climate change investing, but then they start fighting over the nuance.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-f8386c7cbaf3473cb8a17772c9a26cf9", "input": "Thousands more homes are damaged by Florence because of rising seas.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-9c8cd9a925884d1cbc18b9304e7289d7", "input": "That level of warming, while potentially producing dire effects on agriculture, sea level and the natural world, might at least be tolerable.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-c2493e7bfd4c4a5fad8679fbbd40de94", "input": "Caring about the climate is elitist.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-b06eaa45a72547dba0477a11327cf54c", "input": "A group whose journey is meant to highlight the effects of global warming is trapped by a substance that is supposed to be melting.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-5b616d7e45e84bbd9bc7b4238c4f5bd7", "input": "Global warming is an election-winning issue.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-cced117ab70d434f8536cda4d1321c31", "input": "Kauppinen is the author of a separate submission to Nature in 2010 that also contests the UN Climate Panel\u2019s consensus view on the degree to which human activity contributes to global climate change.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-c76772d79382462d9c15c4b40e70bbd0", "input": "Global temperatures drop further still.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-6b4f755b8978431fba6eaadc013291d3", "input": "We have a global agreement on how we are going to limit the emissions of carbon dioxide and other greenhouse gases, going forward, and an agreement that will include the tropical forest, that will include ways to transfer some of the revenues from carbon taxes or carbon emission permits in the north to pay for reduced deforestation in the south.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-aed60e586c3a4fc2a81541adb580a524", "input": "The earth\u2019s cattle population actually produces more carbon dioxide than automobiles, planes, and all other forms of transport combined.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-8f470352625b4855ba6eb8cd16930425", "input": "The dangers of a warming planet are being wildly exaggerated and question the impact that fossil fuels have had on climate change.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-5c94d752fbfc4d72a852fb224309bb7b", "input": "Global warming is caused by human greenhouse gases.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-d12710735bd3471b98a5b027cb365cb2", "input": "Developing countries are paying the price for the carbon-intensive practices of a few countries.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-f88e457cf6df44b99f6e3d20d49cc0dc", "input": "These are the effects of climate change.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-22468310eaff462c848a82d2fa876478", "input": "A mammoth effort is needed, beginning now and carrying through the century, to decarbonize global energy systems.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-4400e0e8821b482b92d16c91d41a5b27", "input": "Through the 1980s, Exxon researched the emerging science of man-made climate change by, among other things, modeling increases in global temperatures due to carbon dioxide emissions.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-3475f733d6f84bceb6067ee76a205326", "input": "Liberated carbon makes our society possible.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-ba429df1052740978b3a1109d4e7297a", "input": "Climate change means the end of shopping.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-71479be924e24326b8cb0e98cc93d950", "input": "A rapid shift away from those fuels over coming decades would preserve much of the ice, or at least slow the melting drastically.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-4398e7696c1d419eae1fcc64ca0c9b1f", "input": "The theories of man-made climate change are no longer credible in light of the so-called hiatus in rising temperatures, not to mention that polar ice is increasing, not melting away.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-65c4a1760fbf42dfb38b39b7fa627556", "input": "Tending to the needs of the poor constitutes a greater priority than curbing global warming.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-45bd050adcf44c39bbb993bd19012473", "input": "The climate scare will soon lose credibility as global warming.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-579d460c208d487c9be9026b22b608ee", "input": "Such problems will be vastly worse if global temperatures continue to rise.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-cadc886a1cbc42ab9e819eb83165da20", "input": "Climate policy is good for humans.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-55cc939cc4b345dab275dc5428b643d2", "input": "While scientists say man-made climate change isn't solely to blame for tropical storms, studies have shown that higher temperatures can make them wetter and more damaging.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-663ea1a6da2b4c6894c96cfcbd2dbed6", "input": "Global trade merely outsourced U.S. emissions.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-222ea4afd67842238faade5d5bdfe488", "input": "Global warming can increase snowfall by boosting the amount of moisture in the air.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-e585dcb97df949dbb5904e9e574c093e", "input": "Greenland is not only melting.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-ed4b0ed530ce48d8943cb089ffd22310", "input": "Two of climate alarmists favorite bellwethers of global warming doom Greenland and the South Pole, are cooling not warming.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-37efbe4a9c3d4bca87bd28259c4af55a", "input": "The most important outcome of the international agreement in Paris is the pressure that 200 countries agreeing to environmentally conscious practices put on global markets.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-d83db51f22fc44d2be23834baf06c6fc", "input": "Not one of 928 papers on \u201cglobal climate change\u201d in a database of scientific journals questioned whether the event is human-induced or natural.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-56dd2048dc9047fba552a9d5cb35e1fe", "input": "Major glaciers that are part of the West Antarctic Ice Sheet appear to have become irrevocably destabilized.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-3027e6af64d543ffa56f9427132b1c68", "input": "Mr. Wall is exaggerating the impact of carbon taxes on investment decisions.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-3598acc5afc541b982970e739dc21c27", "input": "Climate change is not primarily caused by man.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-f8385ad84c1846baac4f0d4b7c70d73c", "input": "Antarctica was once a lush, green continent, icing over only in the past 35 million years, amid a general cooling of the world\u00e2\u0080\u0099s climate.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-a818d012e4434637a5d425cf3f1e081a", "input": "Extracting energy from wind power on a huge scale can cause its own global climate consequences.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-33b55d9d98784f82b40a2be5cb5a9c18", "input": "We need to more or less immediately stop using or drastically curtail fossil fuels.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-7c2e3b3489454614aeeec956eb98367b", "input": "The standard global warming narrative is stale and alienating \u2014 and perhaps worst of all, stuck in the technical weeds.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-8ff57c008c224ddb84bfa1bb3fabea5b", "input": "The Arctic environment is changing extremely rapidly and it is time for the rest of the world to take notice and also to take action to address the root causes of climate change.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-634b50b712704090bc74efb20a23db3f", "input": "We need to get rid of fossil fuel subsidies now.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-188fa774087e49f8bab83450a645d489", "input": "Roughly 75 percent of the carbon dioxide emissions from the natural world come not from above-ground biomass, but from the soil.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-b0b63d3dbb8643acb22fc1656cd9101e", "input": "When the media the media speak of unusually hot weather as a sign of global warming, the media never seem to look for places where it is unusually cold to show nature\u00e2\u0080\u0099s balance.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-2a575258008e4d54905e7f4824ae328a", "input": "These phenomena are consistent with the ongoing changes in global climate, which we know with very high confidence are being caused mainly by the increase of atmospheric carbon dioxide and other heat-trapping gasses released by human activities.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-c074e58fdb9941d2b90a587bf5b1f341", "input": "And ocean acidification, which comes from the added carbon absorbed by oceans, will harm marine life.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-3c3bebe2252d4cb387e9d00ff9670253", "input": "The hiatus in measured global warming could persist.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-78f5b574edad491f9cbbca6ddbfce704", "input": "Concerns about Arctic oil leading to increased global warming are overblown because the stuff will be so expensive to drill.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-9f3ceaaafe314edc8946a8ab92b75fdd", "input": "A NASA climate scientist is reported as having faked global warming data.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-aee141f6b0bb415d862212dab9c9dc32", "input": "Global warming is going to cause more wars.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-d72ac8b7017f49879e008f1ec08d5039", "input": "The global warming of the 1900s is caused by a rise in solar output.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-9f714e549a754ed4b217564125b46cc9", "input": "Global warming is already making it worse.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-e17321bea740459ea10fef58b218324a", "input": "Anthropogenic warming theory just didn't stand up.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-469dc422fb50410fa8c8cc10a99b5008", "input": "The CO2 emitted by burning fossil fuel is the greenhouse gas that causes global warming.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-f02ec9d151d44bc4bb0106cc6e50edd5", "input": "Australia could become so hot and dry that its residents could join the ranks of the world's climate refugees.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-cf679c77b3864cbf8813509397e8485e", "input": "But reducing greenhouse gas emissions to fight climate change will require drastic measures.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-eb9675cca5c349c2a44a8d7441d200a7", "input": "Global temperature had dropped in the last 10 years.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-22fbd6e2f5284d3d8900a88ca9dda10e", "input": "Global warming will never hurt anyone.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-df8fd577637c450aa09b0081c321f85e", "input": "2 degrees is not good enough to avoid global catastrophe, and so we would have to cut carbon emissions enough to prevent world temperatures from rising more than 1.5 degrees Centigrade.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-f774af57eb0b4e97a8068d7adfd3225b", "input": "The environmental movement is now saying \u201c climate change \u201d because it can explain anything, including \u201c decades of global cooling, \u201d as one Fox News host claimed.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-09be46691bb544dd8795095cba723af0", "input": "The non-climatic effects of carbon dioxide as a sustainer of wildlife and crop plants are enormously beneficial, that the possibly harmful climatic effects of carbon dioxide have been greatly exaggerated, and that the benefits clearly outweigh the possible damage.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-5ca8b794944f45ddaf5dbaf4a36a1d57", "input": "The likely consequences would include killer storms stronger than any in modern times, the disintegration of large parts of the polar ice sheets and a rise of the sea sufficient to begin drowning the world\u00e2\u0080\u0099s coastal cities before the end of this century.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-1f95eaaa45cb4fefb48c47117600083b", "input": "We had just lived through the third consecutive year of the highest global temperatures on record and the lowest levels of Arctic ice.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-07edc1b170394da4a8df1f5ce1121f59", "input": "Women are more likely to be harmed in the kinds of natural disasters made more likely by global warming, bear greater responsibility for getting access to water, energy, and other basics of domestic life, and often are shut out of opportunities when resources decline.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-c22e3522ee514215b5b3dce05ede2cef", "input": "224 of the 386 \"climate change contrarians\" quoted by the media have at least one publication in peer-reviewed scientific journals.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-a3267aacd2914442a047bb8fdf23b6c4", "input": "In the long run, the costs from raising the price of fossil-fueled electricity and other sources of energy could be modest.", "output": ["neutral"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-fa886a0f98e14788af95170c15fe07cc", "input": "If human-driven climate change continues on the present course, the ice covering the site could begin to melt in about 75 years.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-61f233ced59b464ba6063bd9d19970ec", "input": "Man-made global warming may further lessen the likelihood of the freak atmospheric steering currents that last year shoved Superstorm Sandy due west into New Jersey.", "output": ["disagrees"]}, "Prediction": "agrees"}
{"Task": "task890_gcwd_classification_gpt3_0", "Definition": ["Read the passage and find if the passage agrees, disagrees, or has a neutral stance on whether Global warming is caused by human activities. Answer only with keyword (a) agrees - if passage agrees with the target (b) disagrees - if passage disagrees with the target (c) neutral - if the given passage neither agrees nor disagrees with the target. You don't need to use external knowledge in this task, and you have to answer based on the given passage. -If the sentence explicitly states that global warming is natural, it should output \"disagrees\". -If the sentence states that with the reduction of fossil fuels, we can reduce global warming, it should output \"agrees\". -If the sentence puts equal weight on both human and natural causes for global warming, it should output \"neutral\"."], "Instance": {"id": "task890-c9f16a0056564737875d15874fce0e1f", "input": "The added burden of climate change, with climate change potentially negative effects on sea life, makes the establishment of refuges even more urgent.", "output": ["agrees"]}, "Prediction": "agrees"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-0d56fbad415c42aaa8b01834301d4a40", "input": "3 young man in hoods standing in the middle of a quiet street facing the camera. <sep> Three people sit by a busy street bareheaded.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-444d7e3515c94284aca76960c260cf19", "input": "A snowboarder on a wide plain of snow <sep> A snow field with a snowboarder on it", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-05d2f029284f4bd7815e05dee9709230", "input": "A land rover is being driven across a river. <sep> A vehicle is crossing a river.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-0797bb59ee24441cb4907daa0d185c49", "input": "An older women tending to a garden. <sep> The lady has a garden", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-c1014cfbab8643539f9c901f0790ae42", "input": "A person wearing a straw hat, standing outside working a steel apparatus with a pile of coconuts on the ground. <sep> A person is burning a straw hat.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-a66ad92ee871480f956ae2199cc35fee", "input": "Three men, one holding pipes, another holding a large object above his head, and one resting against the pipe bed on the truck, are looking at the camera. <sep> three men going to work", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-2d92f8fe23184b3d9285de31ea26ff5a", "input": "A blond-haired doctor and her African american assistant looking threw new medical manuals. <sep> A doctor is looking at a book", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-08d9eb2169f946a7b7fae1735f6c571e", "input": "3 young man in hoods standing in the middle of a quiet street facing the camera. <sep> Three hood wearing people pose for a picture.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-7ef5524b2ffb45ea94af6c8753edcbc8", "input": "Three firefighter come out of subway station. <sep> Three firefighters putting out a fire inside of a subway station.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-af189f4302a846b2bf6172c9b4620b70", "input": "Two children re laying on a rug with some wooden bricks laid out in a square between them. <sep> Two children are on a rug.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-15f1b603b7ed48649f0f6be432782ae6", "input": "A man looking over a bicycle's rear wheel in the maintenance garage with various tools visible in the background. <sep> A person is in a garage.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-5baff45edbda49ef9ae38ed62edc78ff", "input": "A woman with a green headscarf, blue shirt and a very big grin. <sep> The woman is very happy.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-648cfef5a0824d258b7cab4b035fd5e8", "input": "A man reads the paper in a bar with green lighting. <sep> The man is inside.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-10c8353f03a94977a1acce28c56382d5", "input": "An older women tending to a garden. <sep> The lady is weeding her garden", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-55a15a77e7d340f1b80829400beaa121", "input": "A man standing in front of a building on the phone as two men to the side pain on the side. <sep> a busy man stands with bodyguards", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-34b9fd84afba47858ef9ccf33537e01a", "input": "Three firefighter come out of subway station. <sep> Three firefighters coming up from a subway station.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-28881b23b539486da1fe3382d2f09f08", "input": "Three men, one holding pipes, another holding a large object above his head, and one resting against the pipe bed on the truck, are looking at the camera. <sep> three men look at the camera", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-1f4e139a0a4e401c9ce803a190897d69", "input": "Male in a blue jacket decides to lay in the grass. <sep> The guy wearing a blue jacket is laying on the green grass", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-149ddceb339f4c70b3ef514b1c6bf0a0", "input": "People jump over a mountain crevasse on a rope. <sep> People slide over a mountain crevasse on a slide.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-962d6893ac8c4184b3b06d05986ce08a", "input": "Male in a blue jacket decides to lay in the grass. <sep> The guy wearing a blue jacket is laying on the green grass taking a nap.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-2878108ef91d4d3fa2a6f422390cd281", "input": "A man reads the paper in a bar with green lighting. <sep> The man is reading the sportspage.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-618965a881724652ab77dc3ef9bf0691", "input": "A woman wearing a ball cap squats down to touch the cracked earth. <sep> A squatting woman wearing a hat touching the ground.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-03ff9577c16b4f80a62d587bd0714ea8", "input": "Two children re laying on a rug with some wooden bricks laid out in a square between them. <sep> Two children are playing catch at a park.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-498d9d6e563641c8990560f311ef4516", "input": "Three people sit on a bench at a station, the man looks oddly at the two women, the redheaded women looks up and forward in an awkward position, and the yellow blond girl twiddles with her hair. <sep> People run together.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-2b1057745fe546ebb6baa13f012d92ea", "input": "A person wearing a straw hat, standing outside working a steel apparatus with a pile of coconuts on the ground. <sep> A person is near a pile of coconuts.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-c7037f0713b340d5aef13daa1a79bbea", "input": "A Ford car is making a right turn as 3 males are walking across the street behind the car. <sep> A car making a right turn had three pedestrians cross behind it.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-2102a855f5b9474db1de950effb65116", "input": "One tan girl with a wool hat is running and leaning over an object, while another person in a wool hat is sitting on the ground. <sep> A boy runs into a wall", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-e59cc9028e9c4eae9879d5f544442c3e", "input": "A dog jumping for a Frisbee in the snow. <sep> A cat washes his face and whiskers with his front paw.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-e0082838943f45b3b7ad26b96291ce5f", "input": "A woman wearing a ball cap squats down to touch the cracked earth. <sep> An archeologist wearing a hat squats to examine the site for a dig", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-f3c15563924441b8b94a32f16e0ee668", "input": "A statue at a museum that no seems to be looking at. <sep> There is a statue that not many people seem to be interested in.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-f784f9bf18c84fb2b710ace2db417a02", "input": "A Ford car is making a right turn as 3 males are walking across the street behind the car. <sep> A sedan was turning a corner as walkers were crossing.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-42c40110c188424cabf5c5d4d323995e", "input": "A young family enjoys feeling ocean waves lap at their feet. <sep> A young man and woman take their child to the beach for the first time.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-89de9d62bd8a4d8996ea3f394cbbc054", "input": "A man reads the paper in a bar with green lighting. <sep> The man is climbing a mountain.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-a662ae1343d94f6dba91bfd610071736", "input": "A couple walk hand in hand down a street. <sep> A couple is sitting on a bench.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-f523accc305046489555c1d32ddf4ec9", "input": "A land rover is being driven across a river. <sep> A Land Rover is splashing water as it crosses a river.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-c4594e7eb4804e6a98877f2376fc6c58", "input": "An old man with a package poses in front of an advertisement. <sep> A man walks by an ad.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-a7e3efbecd40439ba25698fa6d8f7d2a", "input": "A snowboarder on a wide plain of snow <sep> A snowmobile in a blizzard", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-854cb9b96d07488eb92b125be99f8358", "input": "A woman within an orchestra is playing a violin. <sep> A woman is playing a concert.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-0dedff4bc1b94fb0be098be51d8a220f", "input": "A woman within an orchestra is playing a violin. <sep> A woman is playing the violin.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-90183ba36be74ddfbd242db1ad9c25e6", "input": "People jump over a mountain crevasse on a rope. <sep> Some people look visually afraid to jump.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-25e1c4ff574c4afbb1c90a46cb8814e0", "input": "During calf roping a cowboy calls off his horse. <sep> A man ropes a calf successfully.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-91d010a5349947aabce029493242c53a", "input": "A child wearing a red top is standing behind a blond headed child sitting in a wheelbarrow. <sep> A child wearing a red top is standing behind a blond headed child", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-481002d07f094e54ab7d23296b0bb977", "input": "A little boy in a gray and white striped sweater and tan pants is playing on a piece of playground equipment. <sep> The boy is sitting on the school bus on his way home.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-ae940f0189224ff6809bbb3943ffcd0d", "input": "A man in a black shirt is looking at a bike in a workshop. <sep> A man is wearing a red shirt", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-d49dd2a3b0ee466bb389d3f31cfefb25", "input": "A dog jumping for a Frisbee in the snow. <sep> A pet is enjoying a game of fetch with his owner.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-ff60d59141324b04a81053b1297018b7", "input": "Three people sit on a bench at a station, the man looks oddly at the two women, the redheaded women looks up and forward in an awkward position, and the yellow blond girl twiddles with her hair. <sep> People wait at a station.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-76059b1840f440cb83317498c73db026", "input": "The two young girls are dressed as fairies, and are playing in the leaves outdoors. <sep> Two girls play dress up indoors.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-b62b70caa746472b8bbfb8126641856a", "input": "A woman with a green headscarf, blue shirt and a very big grin. <sep> The woman has been shot.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-df0fec5bb6c046a9b71a4e787c88abf2", "input": "A little boy in a gray and white striped sweater and tan pants is playing on a piece of playground equipment. <sep> A boy is on a playground.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-069f4512a32a4a9694aa6e965c68d06f", "input": "During calf roping a cowboy calls off his horse. <sep> A first time roper falls off his horse.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-8975bc38702e440ca6b5a6f37e7b1922", "input": "A man in a black shirt is looking at a bike in a workshop. <sep> A man is deciding which bike to buy", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-644f2a71e43d4a6dbd20b6ea71b32d07", "input": "People are conversing at a dining table under a canopy. <sep> People are talking underneath a covering.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-25731f96b846400ab3bf4d74ca3245e6", "input": "A man in a black shirt overlooking bike maintenance. <sep> A man learns bike maintenance.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-24946d3f192d474d92d557f22017f411", "input": "A man looking over a bicycle's rear wheel in the maintenance garage with various tools visible in the background. <sep> A man repairs bicycles.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-fb167fbfa79f450f858daaa8e1771a45", "input": "An older women tending to a garden. <sep> The lady is cooking dinner", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-3b5b1f6dda0d4d55a2e83190107e8b21", "input": "A blond-haired doctor and her African american assistant looking threw new medical manuals. <sep> A doctor is studying", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-37e72ee9c82e4d6da57e00c62dba433d", "input": "A man standing in front of a building on the phone as two men to the side pain on the side. <sep> two girls walk through a hall", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-578665366ee2422492d556f6b4c65846", "input": "A couple walk hand in hand down a street. <sep> A couple is walking together.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-17bd9d44604e4c14a6d89678f5aec89f", "input": "A woman wearing a ball cap squats down to touch the cracked earth. <sep> A woman wearing a sun bonnet planting a garden.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-781c8b74a0cf4e53a728b4928e8db744", "input": "An old man with a package poses in front of an advertisement. <sep> A man poses in front of an ad.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-52df45cd7213485b96ac4afed2fcfb02", "input": "Three people sit on a bench at a station, the man looks oddly at the two women, the redheaded women looks up and forward in an awkward position, and the yellow blond girl twiddles with her hair. <sep> Some people stand around.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-0094066e49e64971a69080be4d61c4d3", "input": "A person dressed in a dress with flowers and a stuffed bee attached to it, is pushing a baby stroller down the street. <sep> An old lady pushing a stroller down a busy street.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-a35d8c0259cc40c99c6badffdcc9ca01", "input": "A statue at a museum that no seems to be looking at. <sep> Tons of people are gathered around the statue.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-07f98115a18d42c0b583ac805e177ecf", "input": "3 young man in hoods standing in the middle of a quiet street facing the camera. <sep> Three hood wearing people stand in a street.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-eafe5fc9e10b4d8a94ec1951b301ea94", "input": "Two children re laying on a rug with some wooden bricks laid out in a square between them. <sep> Two children are building a brick furnace.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-0b83b46cd74741e5a969fb5890f747a4", "input": "Three men, one holding pipes, another holding a large object above his head, and one resting against the pipe bed on the truck, are looking at the camera. <sep> three men sleeping in a tent", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-4af9ec5b3fc44ad1bd57ddde3bb1690c", "input": "A little boy in a gray and white striped sweater and tan pants is playing on a piece of playground equipment. <sep> The boy is playing on the swings after school.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-1c7ed2696103459f95fbec0166a67935", "input": "The two young girls are dressed as fairies, and are playing in the leaves outdoors. <sep> The two girls play in the Autumn.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-4bb956072c72435fb3f7a34d202f41bd", "input": "A child wearing a red top is standing behind a blond headed child sitting in a wheelbarrow. <sep> A child wearing a red top is standing behind a pretty blond headed child", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-45937fb468db4fb58d42df6e6aaed1e9", "input": "Male in a blue jacket decides to lay in the grass. <sep> The guy in yellow is rolling on the grass", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-ece96c15750d4443b03cc07eaed84617", "input": "Three firefighter come out of subway station. <sep> Three firefighters playing cards inside a fire station.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-020b0e31ebf14d50a3c4d26ac2896b5e", "input": "People are conversing at a dining table under a canopy. <sep> People at a party are seated for dinner on the lawn.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-c987b38a07a8406b8d8537b410f696de", "input": "A man in a black shirt is looking at a bike in a workshop. <sep> A man is in a black shirt", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-e8deef24fe8047de82d9aa33ef6a0d52", "input": "One tan girl with a wool hat is running and leaning over an object, while another person in a wool hat is sitting on the ground. <sep> A tan girl runs leans over an object", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-b42733b36bdc42a18675574a4d528df6", "input": "A dog jumping for a Frisbee in the snow. <sep> An animal is outside in the cold weather, playing with a plastic toy.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-37b00b1858ad4cc5b831771c8d63d4da", "input": "A person dressed in a dress with flowers and a stuffed bee attached to it, is pushing a baby stroller down the street. <sep> A lady sitting on a bench in the park.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-312a2792823e479fb32562a52951b145", "input": "A girl playing a violin along with a group of people <sep> A girl is washing a load of laundry.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-e24e93374b7d453993b16ec78a55aa0f", "input": "A man playing an electric guitar on stage. <sep> A man playing banjo on the floor.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-765a3777e6fb4884820a3cf87d0624ae", "input": "A woman with a green headscarf, blue shirt and a very big grin. <sep> The woman is young.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-3e846752a1a24b8fb0ea36d25008fd38", "input": "A person dressed in a dress with flowers and a stuffed bee attached to it, is pushing a baby stroller down the street. <sep> A person outside pushing a stroller.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-c923dde3eb084517994371983a1c879c", "input": "A young family enjoys feeling ocean waves lap at their feet. <sep> A family is at the beach.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-1cc2f3e778e644f68aa1ce855ee39c30", "input": "A couple walk hand in hand down a street. <sep> The couple is married.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-08032afc2d0b44ad8b8e2eeab22f842d", "input": "An old man with a package poses in front of an advertisement. <sep> A man poses in front of an ad for beer.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-1c9327c19e8244019e408ce8c7ec800e", "input": "A statue at a museum that no seems to be looking at. <sep> The statue is offensive and people are mad that it is on display.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-5aac6ad189b942c6a2fced0707da5746", "input": "A man in a black shirt overlooking bike maintenance. <sep> A man watches bike repairs.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-b3fa17d801f14f71b27b1946afeaa068", "input": "A man in a black shirt overlooking bike maintenance. <sep> A man destroys a bike.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-b03c74254bfa4aea96383c1902db407f", "input": "A girl playing a violin along with a group of people <sep> A group of people are playing in a symphony.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-294439d88c214b82818cdaa7de208c24", "input": "A person wearing a straw hat, standing outside working a steel apparatus with a pile of coconuts on the ground. <sep> A person is selling coconuts.", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-569a669bfbde4e8799f1c30961b47442", "input": "A snowboarder on a wide plain of snow <sep> A snowboarder gliding over a field of snow", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-cc8ce0de229141c28b88f0e08ddffd17", "input": "A child wearing a red top is standing behind a blond headed child sitting in a wheelbarrow. <sep> A child wearing a red top is standing on top of a blond headed child", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-15c0602462a0479ca90d498e1ce98a92", "input": "One tan girl with a wool hat is running and leaning over an object, while another person in a wool hat is sitting on the ground. <sep> A man watches his daughter leap", "output": ["neutral"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-6ff31c5590964b83af68c9e542901319", "input": "A woman within an orchestra is playing a violin. <sep> A man is looking in a telescope.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-156bcaf9dbe549579ea877f7990128f8", "input": "A young family enjoys feeling ocean waves lap at their feet. <sep> A family is out at a restaurant.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-9fba45e6812245ffb665be47fe96ed7f", "input": "A man looking over a bicycle's rear wheel in the maintenance garage with various tools visible in the background. <sep> A man waits outside a garage.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-54138892f933416797217ad09cfac22f", "input": "People jump over a mountain crevasse on a rope. <sep> People are jumping outside.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-db0503822e384e1f8c1ebdfe6ffaebe2", "input": "People are conversing at a dining table under a canopy. <sep> People are screaming at a boxing match.", "output": ["contradiction"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-932185afb49543b3ba84a9482dc3a8e6", "input": "A man standing in front of a building on the phone as two men to the side pain on the side. <sep> a guy near a building stands by two other men", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-39258d40909b4b06a967361fe7f3df26", "input": "The two young girls are dressed as fairies, and are playing in the leaves outdoors. <sep> Girls are playing outdoors.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-cbb156fff7ec470baa84b38faf10ddb9", "input": "A girl playing a violin along with a group of people <sep> A girl is playing an instrument.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task640_esnli_classification_gpt3_0", "Definition": ["Given a premise and a hypothesis, determine if the hypothesis (second sentence) can be concluded from the premise and assigning it a label among entailment, neutral, or contradiction. Entailment means thats the hypothesis makes sense/follows after the premise. Neutral means that the hypothesis does not follow the premise but also does not contradict the premise. Contradiction means that the hypothesis clearly contradicts the premise. (1)  The model should output neutral when the two sentences are not logically related. For example, if the first sentence is \"The sky is blue,\" and the second sentence is \"The sun is shining,\" then the model should output neutral, since the two sentences are not logically related.  (2)  The model should output entailment when the second sentence logically follows from the first sentence. For example, if the first sentence is \"All dogs are animals,\" and the second sentence is \"All dogs are mammals,\" then the model should output entailment, since the second sentence logically follows from the first sentence.  (3)  The"], "Instance": {"id": "task640-765f6be6330d4274b5fbe245c05c8fde", "input": "A man playing an electric guitar on stage. <sep> A man playing guitar on stage.", "output": ["entailment"]}, "Prediction": "neutral"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-4a4b59b051314b0fa76ddb45df014ff1", "input": "Sentence 1: People in traditional military fare and two people riding elephants somewhere in Southeast Asia. Sentence 2: The men are patrol.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-c2c9fc1c84a84941a41dbcd7b068852b", "input": "Sentence 1: A family of five is watching a performer standing on a stepstool. Sentence 2: The performer is on a ladder.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-5f4d9aa1191443319ceec09bccaff22f", "input": "Sentence 1: A young girl and a woman stand in white dresses stand against a wall. Sentence 2: Two women pose for a photo shoot.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-401f319d20134c70b591fb545e1d4504", "input": "Sentence 1: Four males in a string quartet perform on an indoor stage. Sentence 2: The pianists put on shows in enormous outdoor arenas.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-a498024db206408385f8dbd10ee61d41", "input": "Sentence 1: A little brown dog on the end of a leash who's owner is wearing a blue skirt and black flats. Sentence 2: the dog is quite happy", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-5296361fcb314f19933b1d6653174958", "input": "Sentence 1: Several women and children are walking along a graffiti covered wall. Sentence 2: A group of women and children are in motion.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-b8595502185547fd9525ab7abc60b6fc", "input": "Sentence 1: A woman sporting a freshly baked pie on her head. Sentence 2: A woman is practicing to be a circus clown.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-6a487d0dd3ca44eaaca550587c252c31", "input": "Sentence 1: An Asian boy is leaning against a pole. Sentence 2: The child is leaning against the pole", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-19d5aff139304581b53b5c065bb184fd", "input": "Sentence 1: A soccer player dressed in a red uniform goes up for a header. Sentence 2: a soccer player is trying to score a point", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-5b1d1dd6efd2482dae124318af4a981f", "input": "Sentence 1: A group of people stands on the field of a soccer stadium. Sentence 2: There are preparing for a soccer game.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-abd67d8af15a4aea81b943e3e055e2c1", "input": "Sentence 1: A young male is performing stunts on a blue BMX bike. Sentence 2: A man is in a bmx race.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-08b9f88495b042be9e73df8fdfb64600", "input": "Sentence 1: Person wearing a black hat lets a cat sit on their shoulder. Sentence 2: A witch wearing a black hat lets a cat sit on her shoulder.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-67fa69a4efd74c02b60775db4ded28f9", "input": "Sentence 1: Two men, one in a yellow jersey, the other red, jogging on a fall day. Sentence 2: two men are skydiving", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-a5ad3cd192e840f28b2de287229b23f9", "input": "Sentence 1: White dog with leash running through water Sentence 2: The white dog is dry.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-17e50cf9e8794efba9479eb6bd1fbd0e", "input": "Sentence 1: A man wearing all white (including a bandanna) cooking something and making a huge flame. Sentence 2: A man who loves white cooks some good food", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-0135b24169db41599cf0114e52b47603", "input": "Sentence 1: A man in a gray shirt is giving a speech. Sentence 2: The man is a motivational speaker", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-2722ce9ffe214cb0b359d3306cf8a792", "input": "Sentence 1: A young black man is skateboarding on a smooth concrete surface. Sentence 2: A black man is sleeping on the skateboard.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-43978298111a4f25afe810ce15fe929e", "input": "Sentence 1: A group of men, women, and children is clustered in a sunny area with benches and a statue. Sentence 2: A family are enjoying a picnic in the sunshine.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-5390a9e21f3947349114f38406b90252", "input": "Sentence 1: A shirtless man is sitting on the ground holding fruit. Sentence 2: A homeless man with no shirt is sitting on the holding fruit.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-e63f1d62dcdb4e2783dba19777c008aa", "input": "Sentence 1: A man sitting at a table playing a an acoustic guitar. Sentence 2: A man is playing guitar.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-89faefabad934dd39a6026e9ed6faf98", "input": "Sentence 1: Woman giving a presentation at a Wikimedia event. Sentence 2: A woman delivering a sermon in a church.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-11945bf2f4774ad5a620419f6317431e", "input": "Sentence 1: Two young ladies affectionately hugging each other with their faces touching, as they smile at each other. Sentence 2: The women are lesbians", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-a37e9c0b87994447a7960560abcab26f", "input": "Sentence 1: A boy wearing a hockey sweatshirt is raking the yard. Sentence 2: A boy is doing outdoor chores before going to a hockey game.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-93dbb46c677b49a9985bdf8a63e9fc5c", "input": "Sentence 1: A black man and woman, and an Indian woman in a blue-painted room. Sentence 2: People enjoying a room painted their favorite color.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-ffef5c37fd37460e8e4a60fd53758299", "input": "Sentence 1: An orchestra practicing their composition. Sentence 2: The orchestra is practicing a very difficult composition.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-045b0ea239654e99b7c225b659d415d4", "input": "Sentence 1: A motocross rider is traveling along a dirt path with people watching. Sentence 2: A motocross person riding.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-9ed78900ad5d43cf9ff3ae1fb89aa4f0", "input": "Sentence 1: A pedestrian with a british bag, walking near an art shop. Sentence 2: A person is interested in art.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-4242c6f1992b43d7845f4858a5e32db8", "input": "Sentence 1: A group of males sitting outdoors. Sentence 2: Some guys are sitting on a bench.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-43a91ab657d34d3c9d6924fabe0d5dfd", "input": "Sentence 1: A man in a blue shirt and black pants relaxes with his glasses resting on his forehead. Sentence 2: a young boy runs", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-a1a58f16fae54d93adebdfd6b7992278", "input": "Sentence 1: A dog is digging a hole in the sand. Sentence 2: A dog digs in the sand at a beach.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-419305c0cb03481fb80691c3c8b33296", "input": "Sentence 1: A woman wearing a fur coat enters through a doorway Sentence 2: The woman enters a club.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-031b1fa2268246b5bbcf395b76ca7d84", "input": "Sentence 1: The view from a overlook at the public beach. Sentence 2: This is a grassy field.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-37984da3b854409ebadaf34e0bfb5775", "input": "Sentence 1: A spray painted car carrying a container strapped to the top. Sentence 2: the child was happy`", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-9e998371d7884963a2a6c83ec271d18e", "input": "Sentence 1: A boy is hugging a smaller boy from behind. Sentence 2: girls are swimming", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-fa21cb7587884873a8ed383053d526c1", "input": "Sentence 1: A person is working in the garden. Sentence 2: gardener is working", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-d65d59b50d28483588966408eea33c06", "input": "Sentence 1: A woman in a tank top and capri pants costume taking a bow in the street. Sentence 2: A woman is happy for the applause after her street performance.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-581759f5559a4b9bbdc86dd881fb56e6", "input": "Sentence 1: A family stands in the snowy woods. Sentence 2: The family is playing catch with a football in their backyard.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-f73da7b228a34395a34c7fed7fae98a4", "input": "Sentence 1: A woman is laughing in a pool while wearing scuba gear. Sentence 2: The woman is wearing scuba gear in the pool.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-94cc30ae10bf4a928a761baa5ac7cc60", "input": "Sentence 1: A group of people waiting outside a fenced in area. Sentence 2: A group of people are waiting for the fair to open.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-651d557b4f594c6c86ed3a8ae366fac8", "input": "Sentence 1: Two people are on a stage playing stringed instruments for a small crowd. Sentence 2: Two people are playing the piano for a small crowd.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-b13bfc76b27440e2a0e94b758d26c299", "input": "Sentence 1: A male tennis player runs for a shot. Sentence 2: A boy is running after a tennis shot his friend made.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-370fe3cae74c4716827373cb1ff098f8", "input": "Sentence 1: A man is carrying a bag of yellow balls. Sentence 2: A man is holding a bag.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-29677cfc649142dfa195cd4afcf4067c", "input": "Sentence 1: A woman in a knit cap and green coat its on a stone block, looking out. Sentence 2: A woman in a coat is looking at something.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-96e1d8fd3942478a93f9a2c68c853ad8", "input": "Sentence 1: There are people who have dogs at a judging contest. Sentence 2: A contest is taking place near the animals.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-8adf5cd4bb0a4593882efa856d323850", "input": "Sentence 1: A blond woman and bald man sitting together. Sentence 2: A pair of people are beside each other.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-64f3a0c2b9674623a227a756fd77701a", "input": "Sentence 1: A person is abseiling down a rock face attached to a rope. Sentence 2: A person lowers themselves down the rock face while their spotter watches carefully from below", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-7d059d03c2be4baa8a20fe73480984b7", "input": "Sentence 1: A man, a woman, and a child are relaxing outside. Sentence 2: A couple sits and enjoys the fireplace.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-60939abdb55e430a9612559330cb606b", "input": "Sentence 1: A young girl with blond-hair and blue eyes is eating a cookie with one hand while holding another cookie in the other. Sentence 2: The young girl is trying to multi-task", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-9c0335ea98554dacac2dd43ce799a52e", "input": "Sentence 1: A graceful basketball player stands at the two point line as she throws the ball. Sentence 2: A basketball player takes a shot", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-f9c7361532594ffea2feaa0787ea6ed8", "input": "Sentence 1: A girl is serving food and a man is staring at her. Sentence 2: A girl is serving food and notices a man is staring at her.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-748a66c58ad24032944422da8eb22161", "input": "Sentence 1: A woman behind a glass smiling and holding the peace sign. Sentence 2: A woman with long hair is smiling and holding a peace sign.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-43658f912ab2463fa3185d33f1218296", "input": "Sentence 1: A young man sitting at a table in a long room with food counters and customers. Sentence 2: A young man is eating his lunch at a table.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-5fe87ea82f0f4caf92faa53f1a515f8b", "input": "Sentence 1: People dressed as angels are walking on a street near Pike's Market in Seattle, Washington (the sign in the background). Sentence 2: Real angels walk through the streets of Seattle", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-473180905d9b4b0a87e677df1843c38c", "input": "Sentence 1: A group of friends discussing what to do at the event. Sentence 2: The group of friends were eating on a grassy knoll.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-362552b8d33e48bf97d19a8aebf4be33", "input": "Sentence 1: A man in a green floppy hat is selling merchandise, including star-spangled inflatable baseball bats. Sentence 2: A man is selling inflatable baseball bats and mitts to the crowd.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-d2675363a17f4e1392a43eb904996ee8", "input": "Sentence 1: A tan woman with a black scarf and a long floral-print dress in sitting on a stone and smiling with her hands in her lap. Sentence 2: A woman poses for a technology magazine's photographer.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-0a29fa1189584e609d35b42c075cae05", "input": "Sentence 1: Man in gray shirt throws a football into the air. Sentence 2: A man is playing a football", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-a78a6cc721f14436be5031426bb27f91", "input": "Sentence 1: Two soccer players colliding as one tries to get the ball in front of the other player. Sentence 2: The men are playing tennis.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-e8b8c85ff9a24c3a838230b9f9b0063c", "input": "Sentence 1: Several menu boards are showing items for sale along with prices. Sentence 2: There are several graphics of the food and associated prices.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-b30793af78d44561a1ffed54813ad581", "input": "Sentence 1: An old man standing behind a basket full of green stalks. Sentence 2: The green stalks are vegetables.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-8f2b6586b7c0482d8759edc41b2c356e", "input": "Sentence 1: The Baltimore Orioles are excited after winning a big game. Sentence 2: They have just won the World Series.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-3ea03620dda943fbb5a33674c3bb8d5d", "input": "Sentence 1: Two white women, one wearing white and the other black, are laughing and wearing blue pins. Sentence 2: Two ladies,one in white and other in black are wearing blue pins and giggling.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-cb6e1ab695294b168fd1f31f847faa55", "input": "Sentence 1: A young girl plays on a colorful toy outside. Sentence 2: A girl plays on a toy at the park", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-953805c2d9024ec68a515a6ff5c88422", "input": "Sentence 1: A homeless man has a shopping cart full of junk. Sentence 2: The man is homeless.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-3dce48e41d44461d9539c8fd251d6921", "input": "Sentence 1: The sky appears clear. Sentence 2: The sky has very little to no clouds.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-edf34ec283554cedb728655219edd699", "input": "Sentence 1: Bicyclist dressed in black and white with white sunglasses on points at something. Sentence 2: The woman was riding the bike.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-3b261a7890804718834fc0bd60ebecb9", "input": "Sentence 1: A group of people are sitting on a rocky beach. Sentence 2: A group of people are eating in a mall food court.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-b3240038110c4b8fa39545d01cc25c9f", "input": "Sentence 1: A group of adults and children with a white elephant statue at a festival. Sentence 2: dog swims", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-73887e6d19754bf28c813d9472a3e58d", "input": "Sentence 1: Man in hat waves to the camera, surrounded by other people. Sentence 2: The man in the hat was watching tv", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-a50af88137fb4f2c80e47b464fde94be", "input": "Sentence 1: A toddler sits beside a shower in a hooded white robe with its hands in the air. Sentence 2: The toddler just took a bath.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-213105a8a3a04fd4bae412d23849d411", "input": "Sentence 1: A man crossing a natural stone bridge jumps while in the middle of it. Sentence 2: A Girl was running in the bridge.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-3197d39a439d4753bb3e1a7427b3c79f", "input": "Sentence 1: A hostess in a restaurant, wearing a uniform and a black hat is cleaning one of the tables. Sentence 2: One of the waitresses did not show up so the restaurant hostess is bussing tables.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-84bb9fba9cb849fb9a0209b137adfb9b", "input": "Sentence 1: A young child, who has a cast on her arm, is diving into a pool. Sentence 2: Someone has a cast on their arm.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-6885875f10e74123a40bb72489eb3df3", "input": "Sentence 1: A black dog running with a black and white toy in its mouth. Sentence 2: A black dog is playing.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-e68adff323a5472783b2195aefc22506", "input": "Sentence 1: A blond dog runs down a flight of stairs to the backyard. Sentence 2: The dog is chasing a tennis ball.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-1bd079ecf7274e21b70441baf2290fec", "input": "Sentence 1: Four women are doing handstands on a basketball court, wearing blue and white shorts and a white tank top. Sentence 2: The women have black eyebrows.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-ecc58f60dae34e87bb768feecc823fa2", "input": "Sentence 1: An older man is sitting in a lawn chair with a newspaper in his hand and selling paint cans, lawn chairs, and other items. Sentence 2: An older woman is selling newspapers.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-6809ac9300484fe1b619d711562e2799", "input": "Sentence 1: A little boy sleeps in his blue stroller. Sentence 2: A boy sleeps in a stroller.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-05c3037a68bb4a1992ba711b50e474d8", "input": "Sentence 1: A woman is pushing a child in a stroller of some sort while many people ride bikes behind her. Sentence 2: the woman pushes her baby", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-4093dc132575426cb3986b297c867558", "input": "Sentence 1: Two men Nordic ski racing while others watch from behind. Sentence 2: Two guys have on skis.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-63257a21399a4cbdab1bf6d081ab2062", "input": "Sentence 1: A child in a white shirt is stirring a pot. Sentence 2: A child is making dinner", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-cf9ed2fb8eb54afb98e5831c7dc628dd", "input": "Sentence 1: Construction workers are working together to carry a piece of equipment. Sentence 2: The construction workers are building something large.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-15db72a10c484dad97f6bf06ab4d3280", "input": "Sentence 1: People are watching a race on city streets. Sentence 2: the people were watching a race that was on the city streets", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-67a32bdbd2a243e0af3e7795efa0097b", "input": "Sentence 1: Two middle-aged people stand by a golf hole. Sentence 2: A couple riding in a golf cart.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-5ea4f8d200884735b7fd1b1495a00300", "input": "Sentence 1: Baseball field staff washing the clay that rings the outside of a baseball field. Sentence 2: People are working", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-33d0e668e497470a98c68a8fe08bbac4", "input": "Sentence 1: a female holding a blanket. Sentence 2: A cold woman holds a blanket.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-fa9a276bf4fb4c6abf40a723c5edac80", "input": "Sentence 1: A crowd of people views newspaper covers in Washington D.C. Sentence 2: The crowd is not looking at anything.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-d8c5cce3f8924a2f946ca44bcc875d96", "input": "Sentence 1: A young woman in an \"I Heart Bill Clinton\" T-Shirt cooks meat on a grill in a public picnic area, while two young men converse behind her and a bicyclist and motorcyclist ride by on a nearby road in the background. Sentence 2: a woman heats up a frozen dinner in a microwave", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-6eaafb90f9f740b982c70f32afe1a3e1", "input": "Sentence 1: A baseball pitcher wearing a white and red uniform caught in midpitch of the ball. Sentence 2: People are walking along the beach.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-b3a01e3abf2f4f68892173d3b0d1a622", "input": "Sentence 1: A man running in a marathon runs past 3 bagpipe players, and a drummer, all wearing a uniform Sentence 2: The man is wearing shorts.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-4d4eb9169bf448549b8683f7e07559bd", "input": "Sentence 1: a man wearing a yellow shirt with a dramatic look on his face Sentence 2: A man poses for the camera emotively.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-ebc37bdd89774fc89d4b6eb837a6806b", "input": "Sentence 1: Kids washing and playing in the sink with water sprayer. Sentence 2: Siblings spraying each other with the water sprayer at the kitchen sink while washing up for dinner.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-766a3208847b40da95ad336735de9a57", "input": "Sentence 1: A family sits outside in the sunset, drinking wine. Sentence 2: A family is drinking coffee at sunrise.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-b8ba93d4960e430f89df6488fc18b40d", "input": "Sentence 1: Two small boys sit on a bench near a carnival ride. Sentence 2: Two boys are waiting for their parents.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-27757adf7151493781c0a53c9e2e5a59", "input": "Sentence 1: Two blond women serve themselves from a platter while sitting at a banquet table with glasses of red wine. Sentence 2: Women dancing at the club.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-3d4e0e4af0b84ffaa72b6046f6a06d6c", "input": "Sentence 1: Man with a musical instrument riding on a subway. Sentence 2: A man is on a mode of transportation.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-af92249823164197b3e6a38124a7d7a9", "input": "Sentence 1: An older woman sits next to a small girl who is wearing a striped dress. Sentence 2: People on the train can't help but stare-down an homeless man at the end of the coach of the train", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-f9f0db3342be431b8e39ffaaaa341a38", "input": "Sentence 1: Big brother shows his sister how to play a game in the backyard in the afternoon. Sentence 2: The brother plays with the sister", "output": ["N"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-3884c3f3eefc433298bbad1e7aeabc5b", "input": "Sentence 1: A woman is running a marathon while people dressed up in roman costumes follow her. Sentence 2: A man is running in a race.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task190_snli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to choose whether the two sentences clearly agree (entailment)/disagree (contradiction) with each other, or if this cannot be determined (neutral). Your answer must be in the form of the letters E, C, and N respectively. The model should output N when it cannot find any evidence to support either E or C. The model should output E when it finds evidence that supports E but not C. The model should output C when it finds evidence that supports C but not E."], "Instance": {"id": "task190-0a4087da20634e38a518b6419e8f9bf2", "input": "Sentence 1: A brown dog slurps water from a sprinkler on the grass. Sentence 2: A dog plays in the water.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-9f24a64c62d14269ab003b6a7ea171f9", "input": "Statement: I forgot. Choices:  1. It was forgotten.  2. The person remembered.  3. An answer was forgotten. ", "output": ["2"]}, "Prediction": "1"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-9ffa89249d3e41ce8df288e7dc60d5e8", "input": "Statement: It will be because they hope it may mean a happier, more secure week for their kid and a less anxious one for themselves. Choices:  1. The week will be more secure 2. The kid might enjoy it 3. It won't be helpful for anyone", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-ac8a7c75e9f842888651121c0302fdc9", "input": "Statement: In many circles, The Biological Differences Between Men and Women are fighting words. Choices:  1. The Biological Differences Between Men and Women do not cause hostility 2. The Biological Differences Between Men and Women can be fighting words. 3. In a lot of circles the Biological Differences Between Men and Women have no effect.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-67417f5814134c3d9270fa01c7a090f9", "input": "Statement: It has Gothic arches, a splendid inlaid cedar ceiling of Moorish design, beautifully carved blue-and-gold choir stalls, gilded altars, and a sprinkling of nice azuleJoseblue-and-white ceramic tiles). Choices:  1. It has blue and white ceramic tiles and Gothic arches. 2. The altars are not gilded. 3. The architecture is appealing.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-2496e3bcca534c93b0ed326a1d92491a", "input": "Statement: During his reign Palestine flourished, but his successors proved less able, and over the next four centuries the country continuously declined to become a virtual backwater. Choices:  1. It took four centuries for Palestine to decline after his reign. 2. His reign allowed his successors to make Palestine a flourishing city. 3. His reign was the last time Palestine flourished, as his successors were less able and the country continued to decline.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-5f984716cdce423480ccae087c92d1ac", "input": "Statement: These sorts of perks are potentially illegal for two reasons. Choices:  1. There are a couple of reasons why these perks might not be legal.  2. The perks this company is offering its employees just may be illegal.  3. Rest assured, these perks are 100% legal.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-f1938e764e3e47f5907a4ab6fcee2b9d", "input": "Statement: Look for the Galerie des Rois across the top of the three doorways. Choices:  1. The Galerie des Rois is located on the floor of the doorways. 2. The Galerie des Rois spans three doorways. 3. The span is symbolic of the Holy Trinity.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-c7313d8679f844488a03bd25e5e99911", "input": "Statement: At the east end of the galleries, two small columns and a circle of green marble mark the spot where the empress sat during services; on the floor of the nave below, a circle of coloured stone to the right of centre is the Opus Alexandrinum, the place where the Byzantine emperors were crowned. Choices:  1. Byzantine emperors ascending the throne were crowned at the Opus Alexandrinum. 2. The Opus Alexandrinum marks the spot where the bishop would stand during church services. 3. The Opus Alexandrinum has been in place for over twelve hundred years.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-20d562914fc2433cb314fcd2a322fddd", "input": "Statement: The acropolis was built on a set of terraces. Choices:  1. The set of terraces have never been built on before. 2. The acropolis had been built on some terraces. 3. The acropolis was not always built on the terraces.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-8d1c965d3d2544bfad564b51058e332a", "input": "Statement: If they would, medical journals might need to be educated to accept articles from non-MDs. Choices:  1. Medical journals could be educated to accept articles from non-MDs. 2. Non-MDs can offer valuable input. 3. Medical journals have no bias.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-b2ca43a7342448e8b533d6ee12b635a8", "input": "Statement: For example, whether or not there are active opposition parties may be a more valid measure of whether a country is a democracy than how many people vote in an election. Choices:  1. There needs to be opposition in a democracy. 2. The opposition parties pose no threat to them. 3. The country is a democratic state.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-35940f540673458480a7e4edbb4e55ed", "input": "Statement: Thus, IRCA deemed H-2As to be permanent resident aliens -a category eligible for LSC legal assistance -- for the purposes of receiving legal assistance from the Corporation. Choices:  1. H-2As are considered permanent resident aliens by IRCA. 2. Most other resident aliens are not considered to be permanent. 3. The IRCA do not give legal assistance to the H-2A holders.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-6d258dd74a7241c6975a27cada8f7928", "input": "Statement: A statutory term is to be interpreted based on its plain and ordinary meaning, in light of its context and the purpose and design of the statute as a whole.  Choices:  1. The ordinary and simple understanding of a statutory term is what it is to be interpreted on.  2. The interpretation of a statutory term is meant to be by its most complex definition.  3. The individual in charge of the actual interpretation is usually a justice of the Supreme Court.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-fdf9392f6b23487289c88cf9b4607cca", "input": "Statement: There are many personal pieces and family portraits in the house, along with original Wordsworth manuscripts. Choices:  1. The house is devoid of any personal pieces and there are no family portraits to be found anywhere inside.  2. The house is filled with numerous portraits of the family and personal items.  3. There are eight family portraits hung on the walls of the house. ", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-47fef44682b6443cb7161f89c0fa8f96", "input": "Statement: Art History Choices:  1. History of Art 2. Science History 3. 1900's Art History", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-9def690299ac4dcb91c3c27a1353a8de", "input": "Statement: With forests and fells, a valley of breathtaking beauty, and the most spectacular lake setting in the National Park, this area has a greater variety of views than any other in the Lake District. Choices:  1. Many other places in the Lake District have plenty of views.  2. Very little of the nature is preserved here. 3. There's a lot to see in this location. ", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-138bc2afd5644f59b609f6b75c981986", "input": "Statement: retirement contributions for low- and moderate-income families. Choices:  1. low-income families contribute to retirement 2. Low- and moderate-income families need help with retirement contributions. 3. Low- and moderate-income people do not contribute to their own retirement.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-c5609eb0b7ed4a66b77929b56f8056e4", "input": "Statement: Auditors should use a cost model to provide general estimates and not precise figures. Choices:  1. General estimates are preferred over precise figures.  2. Auditors who give precise figures find much of the information they offer is useless.  3. Auditors do not use a cost model for providing estimates.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-18f9ff80d9dd41c5aa5f3283f72b200a", "input": "Statement: Bitterly, I toted three pairs of Slates to the dressing room, vowing never again to subscribe to an online magazine, even one that doesn't charge. Choices:  1. I have decided to subscribe to every online magazine. 2. I decided not to subscribe to online magazines anymore. 3. I decided after making too many purchases from ads in online magazines not to subscribe anymore.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-aa12486d5d9b469a9ccdc551970eb74c", "input": "Statement: but uh we stripped and then had somebody else come in and do the actually put the paper up next time i think i'll do it the other way around let them strip and i'll hang the paper Choices:  1. Hanging the paper doesn't take any expertise. 2. I did it the wrong way this time because I should've let them strip. 3. This time they stripped the paper and we hung out and drank beer, but next time we should do the opposite.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-6ff263a514f14daa870e3c33926b5376", "input": "Statement: The reporting and recordkeeping burden associated with the application, certification and continued eligibility of food stamp applicants was approved by OMB in 1995 under   Choices:  1. The OMB disputed all attempts to keep records associated with these applications. 2. The OMB approved the reporting burden in 1995. 3. Reporting standards for this service are very lax.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-c61d7aa252de4c2f8459ca527cf3aefc", "input": "Statement: The female's nose is an unremarkable little snub, but zoologists say that she appreciates, and is even aroused by, the male's proboscis. Choices:  1. The female's nose is tiny but highly sensitive.  2. The females have large and fat noses.  3. The female has a small, insignificant nose. ", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-f2773a8cb01d4b1abf7adaf1134ba770", "input": "Statement: i don't know the city Choices:  1. I went to that city last year. 2. I plan on visiting the city next year. 3. The city is unfamiliar to me.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-35b5a86646e24c1fadadd7c54b44f656", "input": "Statement: Home to the Sultans of Perakiaor the past 500 years, Kuala Kangsar is built on a sweep of the Perakiaiver (Sungei Perakia50 km (32 miles) from Ipoh on a newer highway. Choices:  1. The newer highway was built in 1997. 2. Kuala Kangsar, a home to the Sultans of Perakiaor the past 500 years, is built on a sweep of the Perakiaiver. 3. Home to the Sultans of Perakiaor for the past 1000 years, Kuala Lumpur is built on water.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-32202e337a03420cafa0accdac09fb5d", "input": "Statement: and and if we take my car in to be fixed he'll he'll tell them what he wants and then he'll say well well call my wife if there's anything else that needs to be done  and then they call me at work because he he doesn't work near uh uh uh doesn't Choices:  1. He isn't able to deal with it after that because he works far away. 2. He'll take my car in to be fixed but tell them to call me. 3. He deals with the entire process. ", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-33522755e5fe44959d25975a21c85352", "input": "Statement: And Chatterbox cites Lapham's mention of the Roman mob familiar with the expensive claques traipsing after the magnificence of the Emperor Nero. Choices:  1. Chatterbox cites Lapham's mention of sycophantic Romans who followed Emperor Nero and absorbed his opulence. 2. Chatterbox cites Lapham's mention of the Emperor Nero of Rome. 3. Chatterbox cites Lapham's mention of Roman sycophants that followed Emperor Nero.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-4ec58f4a37ad42d9b1c28aa2a551dd4c", "input": "Statement: Chronic Illness Choices:  1. The illness was chronic. 2. It is not possible for ilnesses to be chronic. 3. There are a lot of chronic illnesses.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-0349da7934774d1c9bc79b0c6095b1a3", "input": "Statement: Moreover, wood supply increases by about 10 percent and the capacity factor of wind energy systems increases by about 15-20 percent compared to the reference case assumptions. Choices:  1. The wood supply of the national parks increases by 10 percent per year. 2. The increase of wood supply is around 10 percent and capacity factor of clean energy (wind) systems increased to around 15-20 percent. 3. Wood supply decreased by 80 percent and the capacity factor of wind energy systems also decreased by about 10 percent.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-94ac5c560bc44eaf834d12e11ff101ee", "input": "Statement: Many Indians remained and established small farms in the FWI, their descendants becoming an important and colorful segment of the population (see box, page 42). Choices:  1. Indians never felt the need to leave FWI as they have already raised a family there.  2. A lot of Indians stayed and took up farming in the FWI.  3. There are no more Indians in FWI. ", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-3fd1c9ad36714167978f2dd84e135485", "input": "Statement: For the purposes of this discussion, though, Chatterbox will accept Reed's premise that Texans are southerners. Choices:  1. Chatterbox will accept what Reed says about Texans though he doesn't like it. 2. Chatterbox will accept what Reed says about Texans. 3. Chatterbox will not accept what Reed says about Texans.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-1969c8a7b5fe427dbb8e7e5e7a1b0088", "input": "Statement: Qualitative Data Choices:  1. They wanted quality for quantity.  2. Quality data. 3. Quantitative Data", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-8813fb99ab3f4eceb2dfb800655f3a1d", "input": "Statement: Not so the New York Times , which editorially called for legislation to overturn the ruling. Choices:  1. The New York Times does not agree with the ruling.  2. The ruling was in agreement with what the New York Times thought. 3. The New York Times editor is personally involved in the situation.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-f6e0681180324f59a9ba2b4b7d03a895", "input": "Statement: Malcontents and loners. Choices:  1. Sad and misunderstood folks. 2. Rebels and introverts. 3. Happy people.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-54cd52790c8449039ccb2b301a13985b", "input": "Statement: This is because automated systems and records are fast replacing manual procedures and paper documents, which in many cases are no longer available as backup if automated systems should fail. Choices:  1. Manual procedures are being replaced by automated systems. 2. Automated systems are replacing paper records but not manual procedures. 3. Management has been talking about having staffed trained in manual procedures as a back-up plan.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-002a8e6499b5451e913b117c6bdffe96", "input": "Statement: An on-line version of this guidance, which will include tools that may help you in assessing reliability, is currently being developed. Choices:  1. A paper version of the guidance will include tools that help assess reliability. 2. An online version of the guidance will include tools that help assess reliability.  3. An online version of the guidance will include tools that help assess reliability of new programs.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-8e5ec923517442cb9e73c7ab2b64d237", "input": "Statement: and of course the younger one was in day care but you find even working six hours a day and not eight hours or whatever that it cuts into your time so much and what happens really is that even though i had the time with them in the evenings all the things that you you you know normally you can get done during the week um you save up for the weekend so your whole weekend that your kids really want your attention but you're saying oh can you go play now or whatever because you have so many things to catch up on Choices:  1. I had time to spend with them in the evenings. 2. The weekends are a busy time with kids. 3. The younger one was not in daycare.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-16231b335ff441baa15aafb36b799132", "input": "Statement: What are you doing this afternoon?\" Choices:  1. What are your plans this afternoon? 2. Do you have plans for the morning? 3. Can we get together this afternoon?", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-1175fc1d007a405f866a68c8f351b1f3", "input": "Statement: Many of these people don't seek a lawyer's help because they think they cannot afford it, think the problem is not important enough or think nothing can be done about the problem. Choices:  1. People often seek legal help even while knowing that they can't afford to hire a lawyer. 2. Lawyers must do more to change people's perceptions about the seriousness of their legal problems. 3. More often than not, lawyers aren't sought after because people don't believe they're able to afford lawyers.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-77f6868a8e2242ad948715a46b25350f", "input": "Statement: For example, what type of assurances are needed for nonfinanical information and can auditors provide such assurances? Choices:  1. Auditors are prohibited from sharing nonfinancial information. 2. Someone wants to know what information is needed for auditors. 3. Auditors have many different sources from which they obtain information.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-1daaa0a509d14089be3cca453725e8e5", "input": "Statement: I knew it was him, because his arms were crossed and he had a Wasn't that funny? expression firmly on his face. Choices:  1. I realized he was the one. 2. He played a joke on me. 3. I had no idea who it was.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-5c7c0bbeb6074495aceaf8009d922478", "input": "Statement: The operating permit modification process consists of preparation and submission of the application to the applicable State or local regulatory agency. Choices:  1. If you want to modify your operating permit, you can just call your State or local regulatory agency and make a verbal request. 2. You must prepare and submit your application to a regulatory agency in order to modify your operating permit. 3. There are other steps in the operating permit modification process in addition to preparing and submitting an application.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-d897c4edf9ae40b196f32f22f7cf7838", "input": "Statement: The Emission Banking and Trading of Allowances Program is expected to achieve substantial reductions when it is fully phased in by 2003. Choices:  1. The Emission Banking and Trading of Allowances Program was fully implemented in October 2003. 2. The Emission Banking and Trading of Allowances Program was fully implemented in 2003. 3. The Emission Banking and Trading of Allowances Program was fully implemented in 2002.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-22a562a248354fc59526527d3414ba3a", "input": "Statement: Mr. Hersheimmer, I think, you already know.\" A quizzical gleam came into the doctor's eye as he shook hands with Julius. Choices:  1. The doctor was quite sure that Mr. Hersheimmer already knew. 2. The doctor casually suggested that Mr. Hersheimmer knew nothing at all. 3. The Doctor was merely guessing that Mr. Hersheimmer knew about all of it.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-59e69db7c4464aa4ade00666adb850a2", "input": "Statement: Our goal is to better serve our client by making GAO more responsive, more flexible - and more focused on our client. Choices:  1. We want to make GAO more focused on its clients. 2. Until now, GAO has completely ignored its clients. 3. We are trying to make GAO less flexible.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-04c3cbe19ef24505a8baa7bf6a455ca4", "input": "Statement: The valuation of Work Loss Days presented in our national benefits summaries, however, incorporates county-specific adjustment factors to account for variations in regional income. Choices:  1. The valuation of Work Loss Days incorporates adjustment factors. 2. The Work Loss Days will appear to be inflated at first glance. 3. The valuation of Work Loss days is consistent across counties.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-edca54d2357b4981875d0b18e0723654", "input": "Statement: Don't ask me to explain it; it was long ago, and all I know for sure is that it happened. Choices:  1. Please don't ask me to explain; it's all in the past, I know for certain what happened 2. I would love to try explain; it was only yesterday, I have no idea what heppened 3. Don't ask me to explain, it will take me a very long time", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-82ef54d4f941401fa0ecf3c88c1dc0ce", "input": "Statement: I do love women. Choices:  1. I have always loved women. 2. I adore women. 3. I really hate women.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-7d0a46f541844c7dbfb63c9d686aa922", "input": "Statement: The dark skinned man growled low and deep in his throat. Choices:  1. The dark-skinned man growled. 2. The dark-skinned man smiled pleasantly. 3. The growl was emitted out of anger and fear.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-e4c567bb208a4eff9b15f3b3c41b4ce9", "input": "Statement: Perfectly located right on the central Plaza Mayor, this small 19th-century hotel is charming. Choices:  1. Located perfectly on central Plaza Mayor, this is a charming small hotel. 2. Located imperfectly on central Plaza Mayor, this is a terrible small hotel. 3. Located perfectly on central Plaza Mayor, this is a charming small hotel in Boston.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-c3867388c7ad4d90a74257000a1e4273", "input": "Statement: oh i guess i i just you know i always i have always tried to sew and uh i didn't like the way it looked so i'd never wear anything but now i i really have bought some uh new sewing equipment i bought the Serger machine Choices:  1. I have never attempted to sew. 2. I tried to sew a dress. 3. I have tried to sew before.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-7dbee882cf2845378d30bd55ff4c3430", "input": "Statement: Congressional reforms passed in 1996 necessitated a fundamental shift in how LSC apportions federal dollars to legal services providers across the country. Choices:  1. The congressional reforms in 1996 was considered successful by economists. 2. The congressional reforms of 1996 necessitate a fundamental shift in the way the LSC apportions federal dollars. 3. The way the LSC apportions federal dollars to legal services has never changes in their history.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-62921ebb122640369e408eab06ca8369", "input": "Statement: Dumbness doesn't. Choices:  1. In fact, dumbness does. 2. Dumbness doesn't mean it's okay to kill someone. 3. Being dumb does not.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-7432a696210b4e62a70782edce673e5c", "input": "Statement: The island's most important achievement and only significant remnant from this period is the law code of Gertis (see page 36). Choices:  1. The law code of Gertis closely follows the principle of \"an eye for an eye.\" 2. The island has not had any lasting contribution. 3. The law code of Gertis is explained on page 36.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-b8bc11a2ed0a4af398621ad78503ae8d", "input": "Statement: Prehistoric cultures flourished first in the north and in today's Alentejo region of south-central Portugal. Choices:  1. North is one of the regions where prehistoric cultures failed to grow. 2. Today's Alentejo region of south-central Portugal and the north is where the prehistoric cultures flourished. 3. Prehistoric cultures flourished in many territories of today's countries, not only Portugal.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-f7955c9933e84b58a685d649a665e937", "input": "Statement: The whole peninsula is a memorial, with plaques describing the campaign's progress, and monuments to the soldiers of the Allied and Turkish armies. Choices:  1. The peninsula has only one memorial - for the soldiers of the Turkish army. 2. The peninsula is home to monuments to the soldiers of the Allied and Turkish armies. 3. There are several restaurants tucked behind the memorials.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-a0760db2bfa745aba2c86c75ff7c5d6e", "input": "Statement: care provider right she goes to seminars and uh she gets home visitations by this state uh uh i don't know the state boards i guess some of them and then some by the association and they Choices:  1. There are seminars held for people like her. 2. She sometimes goes to seminars and gets home visitation by the state. 3. She doesn't bother to go to any of the seminars.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-0f3edc17fc9b4a4eaf4d439aed628387", "input": "Statement: The rest of the building and an adjoining college were destroyed in a typhoon-fanned fire in 1835. Choices:  1. The building survived the 1835 fire, remaining completely intact. 2. The 1835 fire that destroyed the rest of the building, was started by an unattended candle. 3. The rest of the building was destroyed by fire in 1835.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-69c04637861f4553855a230bbcb9d13b", "input": "Statement: Most of the graves are recent, barely a century old, but the cone-roofed, timeworn monument seen down the valley dates from the Second Temple period over 2,000 years ago. Choices:  1. The monument was constructed in the past 20 years. 2. The monument was there long before the graves. 3. Most of the graves were all placed there in the past century.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-f78a34f731574b31a14519b66347beda", "input": "Statement: oh yeah we  we have one down here in the summertime uh it runs from like five o'clock to seven thirty or eight o'clock you know because it doesn't get dark until nine thirty or ten Choices:  1. We only have one during the wintertime. 2. It doesn't get dark until very late here. 3. The one we have in the summertime is very popular.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-c0c32cc65a1f4240bc0646c1536d0ae7", "input": "Statement: Some conservatives, including reporters at the New York Post and Washington Times , blame Clinton's philandering on the '60s free-love attitudes he adopted as an anti-war radical and never jettisoned. Choices:  1. Clinton has never cheated on his wife. 2. People blame Clinton's philandering on his 60's attitudes. 3. Clinton cheats on his wife because he still thinks he's living in the 60s.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-1c1139337bfc4e5c83189f501add33da", "input": "Statement: Begun in 1163, the main part of Notre-Dame took 167 years to finish. Choices:  1. The Notre Dame project began in 1163. 2. Notre Dame took 167 years to complete. 3. The Notre Dame project took 1163 months to complete.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-11d192efd55141d9bf6e31bd36158e51", "input": "Statement: We're not all cowards like you! Choices:  1. You are a coward but we are not all like that. 2. You are so brave that we cannot remain with you. 3. You are a coward because you are without honor.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-1fb8eca84dcb42feae7ec30f217feb57", "input": "Statement: a um college fund for them because it was just so important i said i don't want them to go through what i went through Choices:  1. I think it's important that my kids experience struggling like I did. 2. It was very important to us to set up a college fund. 3. We have about half of their education saved for right now.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-1861bf0624f24fba8fd491db2f3c793b", "input": "Statement: First, the CEF analysis was benchmarked to a 1999 reference case. Choices:  1. The CEF analysis was benchmarked to a 1999 reference case. 2. The CEF analysis was not compared to any other case. 3. The 1999 case showed better performance in comparison.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-c328caaabc764d07afe550829fe458d6", "input": "Statement: For smaller cases, the judge suggested trying alternative dispute resolution, a service offered by the Coconino County Superior Court and most courts. Choices:  1. The judge suggested trying alternative dispute resolution, a service offered by the Coconino County Superior Court and most courts, for smaller cases. 2. The judge did not suggest trying alternative dispute resolution. 3. Alternative dispute resolution will be tried.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-850b360fb2f1491b830b0b8216ede2b8", "input": "Statement: Selenastrum capricornutum (without EDTA) Growth, IC25 21 58. Choices:  1. Selenastrum capricornutum Growth, IC25 21 58. 2. Selenium capricorn (without DEHA) Tumor, OX24 20 56 3. IC25 21 58, Selenastrum capricornutum (without EDTA) Growth.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-fb2a23f985ea444ea15ad66b49a522a8", "input": "Statement: One of the revolting little creatures in the cage lifted a metal object and there was a sudden hole in the top of the cage and another in the roof of the barn, each hole rimmed with charred wood. Choices:  1. The cage was outside in the middle of a field. 2. There was a monkey in the cage and it was pissed. 3. The being in the cage threw things into the air.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-b6d4341d2fa74774ae577a3e2bf5809e", "input": "Statement: This wetland area covers a vast amount of mangrove swamp and has been turned into a nature theme park. Choices:  1. The wetland area is being used as a nature theme park. 2. The effort to create a nature theme park received great support from within the government. 3. The mangrove swamp was destroyed to put in a parking lot.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-4c915817eadf4dbf86f7d71478d63648", "input": "Statement: However, the university had established an information security policy committee that included top university officials, legal counsel, and representatives from student affairs, faculty affairs, and internal audit to assist in the development and review of policies. Choices:  1. the information technology committee is not linked to the university. 2. There is an information technology committee at the university. 3. the information technology committee includes legal and faculty affairs personnel.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-326a9f90d15a4a378201f4ce10c5d5e1", "input": "Statement: yeah well i know some people that i suspect are casual users of uh marijuana as well and i expect that they probably uh mended their ways uh in uh Choices:  1. I know some friends that smoke marijuana everyday. 2. I know some people that smoke marijuana casually. 3. I do not know anyone that smokes at all.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-f09f8ef6e07b4c0aa1f38d09616a6b30", "input": "Statement: te morituri salutant,'   Choices:  1. This is english 2. Te morte 3. Morituti", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-aac3c0c8e5d64ddbb163c9f2df4a8887", "input": "Statement: Since Yugoslavia's disintegration, Franjo Tudjman, a right-wing dictator, has exploited Croatian nationalist sentiments. Choices:  1. Franjo Tudjman, a left-wing king, did not abuse Croatian nationalist sentiments. 2. Franjo exploited Croatian nationalist sentiments because he's a greedy person. 3. Franjo Tudjman is considered a right-wing dictator.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-5e72c84442d4480093e66d916f8196f8", "input": "Statement: One of best ways to obtain uniformly high quality services is to ensure that grantees' legal work management and supervision is rigorous and effective. Choices:  1. Legal work management is vital to operations success. 2. Rigorous supervision is one of the best ways to ensure high quality service. 3. Rigorous and effective intimidation tactics are crucial to high quality services.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-bf30dc767ce04e4f9746b70d88afe840", "input": "Statement: As the tankards filled, they brought it to their lips and drank, letting it pour down their chins and chests. Choices:  1. The tankards were full of mead. 2. They drank from the tankards without spilling. 3. They drank from tankards.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-95ed183bd0f146cba3bbc56f9a03943e", "input": "Statement: yes that's interesting are there are there any other specific things that that you feel like where where you feel your privacy to be invaded on a day-to-day basis or either growing on a growing frequency Choices:  1. Do you believe that your privacy is being invaded every day? 2. What other specific things make you feel that your privacy is being invaded? 3. You don't care about privacy, do you?", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-b698ff3adc6242df8afe22f78bf2e4eb", "input": "Statement: a 300gg-92) provides that the Secretary of HHS may promulgate any interim final rules determined to be appropriate to carry out the provisions of Part B of the act. Choices:  1. The Secretary will not promulgate interim final rules. 2. Secretary of HHS may promulgate interim final rules as appropriate. 3. The Secretary will promulgate interim final rules.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-9a68b13d61fa4eff916b666f52769a1b", "input": "Statement: and the coverage and so after a while i just turned it off i said i can't take it any more i just can't Choices:  1. After a while I turned off the coverage and said \"I can't take it anymore, I just can't\" 2. I said \"I can't take it anymore\" and turned the coverage off.  3. I watched the coverage and thought \"I can take this\".", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-d8331c9f632e4bf89dfb7ed4e93d9c4c", "input": "Statement: disappointed because i was you know so hyped up on Honda so yeah Choices:  1. I was really excited to drive a Honda. 2. I was excited about Honda. 3. I was dreading it because I really hate Hondas", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-d3777d49489646b895f0b7b423d94ae0", "input": "Statement:  S\u00ed a real diablo , that one!\" Choices:  1. See the fake diablo! 2. That one is a real diablo. 3. That is a rare sight.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-2b0a5b8402e64acab036fc831f59dd75", "input": "Statement: In 1098, the Byzantine Emperor ceded land on the island to a monk, Christodoulos, who founded a monastery here in honor of the saint. Choices:  1. The monk Christodoulos founded the monastery in honor of the saint. 2. The Byzantine Emperor was known to be a ruthless killer. 3. In 1888, the Byzantine Emperor ceded land on the island to his mistress.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-8f63443c068b4b63a528fca6be05b447", "input": "Statement: Below is a list of the hubs and the islands that can be reached by ferry from them within two hours. Choices:  1. There is a list of hubs that can be reached by the ferry.   2. The list of hubs that the ferry visits is a short list.   3. There is no list that contains information on where the ferry visits.  ", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-d4143da0995a4344a34d0676fc29b040", "input": "Statement: EPA responded with a discussion of the overall costs and benefits of controlling pollution. Choices:  1. The EPA felt that people needed to hear the pros and cons of the pollution-control approaches that were on the table. 2. When questions about pollution-control came up, the EPA immediately shut it down. 3. A conversation about the benefits and expenses associated with pollution-control was how the EPA responded.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-b6de5c67429649cba2a9394fb57f9a5c", "input": "Statement: and and sort of made a decision as we were walking me and a friend of mine were walking over to campus uh to to sign up for our majors it was just sort of an off the wall decision Choices:  1. We never walked anywhere.  2. My friend and I were walking over to sign up for our majors when we made a sudden decision.  3. We decided our majors right then and there.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-d790abb252cf4837a3dc9663814cc91a", "input": "Statement: (Bennett himself appears to share this view, terming gays, as a group, wealthy and well educated. Choices:  1. In general, Bennet classifies gays as tending to be poor and uneducated. 2. Bennett believes that only gay people are well educated. 3. One person thinks that gay people have lots of money.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-c77ee7df885b4c0883ab1be0b6e91475", "input": "Statement: You're not much to look at, but you're the best we could find in the Ways we can reach. Choices:  1. You are more than what we would have hoped for. 2. You're not what we would have wished for, but you will do. 3. You don't have much, but you're the best we could find.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-fbe2e123612843f8a07d88aaf6775c3d", "input": "Statement: Maybe we shouldn't save every premature baby regardless of the cost. Choices:  1. Let's save every baby. 2. Maybe premature babies shouldn't be saved every time. 3. Maybe premature babies cost too much to save every time.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-b4a3c19036a748fca06f93a4df246360", "input": "Statement: well it's in terms of guaranteed return on investment and maybe you don't start looking for that word guaranteed until later Choices:  1. The return on investment isn't necessarily guaranteed until later down the road. 2. You are guaranteed to have a return on investment as soon as you get started. 3. The return on investment will be disappointing at first.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-019b984dc1814be5b98ed0e60c6619c1", "input": "Statement: well actually if your check bounces i guess they could legally take it off your credit card if that's why they're taking it i mean i don't know how fair that is Choices:  1. They can't legally take it off your credit card.  2. They can take it off of your credit card if your check bounces.  3. If your check bounces you still have to pay it somehow, usually with your credit card. ", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-15937b7dce704046aacbb0b0d39772c5", "input": "Statement: Say, then. Choices:  1. You can tell me later.  2. Speak up.  3. Keep quiet. ", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-3dcc380dc28a4b579f6067985e9db0a0", "input": "Statement: You aim to stay on in Tubacca?\"  Choices:  1. Do you want to stay in Tubacca for the rest of the year? 2. You want to leave Tubacca right away? 3. Do you want to stay in Tubacca?", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-641277f9597b4e2ab6026a7bf9361054", "input": "Statement: Times when I was in that Yankee stockade eatin' th' swill they called rations I used to dream 'bout them pickles an' canned peaches an' crackers with long sweetin' poured on 'em!\" Choices:  1. Those dreams about delicious food kept me sane. 2. The food they serve as rations in the Yankee stockade is swill. 3. The Yankee stockade had some of the absolute best food I've ever eaten, I didn't dream about anything else while I was there.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-3ab1bbac399540b78e1781b273b62ae4", "input": "Statement: Before that there were few cars in Nepal. Choices:  1. Today, everyone in Nepal owns at least one car. 2. There was a time when there were not many cars in Nepal. 3. There have always been lots of cars in Nepal.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-021bf6cbf7fb4de7bafca533f6ad4c95", "input": "Statement: uh-huh well that turned out to be a good game Choices:  1. It ended up being a decent team. 2. They ended up being the worst team. 3. I predicted that they would do well.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-9b44a2133c3149d690a12650f5e5f684", "input": "Statement: Coffee without caffeine is descafeinado. Choices:  1. \"Descafeinado\" is the name of decaffeinated coffee. 2. Coffee with extra caffeine is called \"descafeinado\". 3. Caffeinated coffee is called de-descafeinado.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-f6b1fd5dce1f40c28897a7c0ecc58330", "input": "Statement: And, actually, Goodall's own data, as synthesized in her magnum opus The Chimpanzees of Gombe , also support the idea that males fight over access to fertile females. Choices:  1. There are male and female chimpanzees in Gombe. 2. Males chimpanzees do not fight over fertile females.  3. Goodall also studied birds in Gombe.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-e33787657c47400695eb9a22aeb30927", "input": "Statement: This pattern of installations exhibits that the catalyst market demonstrated the ability to respond to the surge in demand resulting from a dramatic increase in SCR installations. Choices:  1. The catalyst market demonstrated the ability to respond to the surge in demand. 2. The catalyst market demonstrated the inability to respond to the surge in demand. 3. The catalyst market demonstrated the ability to respond to the surge in demand in pollution control.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-df230bac24404c49b198f0933bb675e1", "input": "Statement: If Social Security reform reduces anticipated retirement income, many analysts expect that workers might, to some degree, want to offset this effect by increasing their saving outside the Social Security system. Choices:  1. If retirement income decreases, workers are expected to decrease their savings. 2. If retirement income decreases, workers are expected to increase their savings. 3. If retirement income decreases, workers will spend less.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-5474a1d36ec14250a257edc754443153", "input": "Statement: yeah Malaysia but of course uh it's also true in Great Britain Choices:  1. Its true in great Britain and Malaysia.  2. Its not true for brituaun or Malaysia.  3. Britain and Malaysia outlaw guns. ", "output": ["2"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-11184e8bf944447297646c5ceb46f05a", "input": "Statement: well i know there there's got to be a lot of uses but it's just you you have to have a need Choices:  1. There are no uses and no needs for that. 2. There are a lot of uses for vapor rub but you need to have the need. 3. There has to be a lot of uses but you have to have a need.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task202_mnli_contradiction_classification_gpt3_0", "Definition": ["In this task, you're given a statement, and three sentences as choices. Your job is to determine which sentence clearly disagrees with the statement. Indicate your answer as '1', '2', or '3' corresponding to the choice number of the selected sentence. The model should output 3 when it is given a statement that contradicts what is said in choice 3.  The model should output 1 when it is given a statement that contradicts what is said in choice 1."], "Instance": {"id": "task202-124be085f19949bdacd86be2a5166cb0", "input": "Statement: Really, I can't tell you.  Choices:  1. They won't let me tell you, there's something I need to keep secret from absolutely everybody under ever circumstance. 2. I could tell you if you want.  3. I'm not allowed to tell you, honestly.", "output": ["2"]}, "Prediction": "2"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-519caeb9e98f492abbe94193bb456efb", "input": "Premise: Most of them young, about his age, stood and talked and drank and laughed. The two girls he had noticed earlier were standing talking to some other girls. Graham hoped they all realised that just because he was standing talking to Slater that didn't mean he was gay too. <sep> Hypothesis: Graham was gay too", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-a5343f5f9b424ffcab5d0e454c88de66", "input": "Premise: A: The one thing I sometimes wonder about, um, in civil cases is, uh, whether, especially sort of in, uh, maybe like product liability, or medical malpractice, where there's, um, sort of a very technical decision to be made sometimes B: Yes. A: you know, it's not just a matter um, of, you know, did this guy rip off this guy, and it's just a matter of interpreting a contract, it's sort of a matter of, um, you know, sometimes getting into very technical issues, and I wonder um, if the system works adequately in educating the jurors about, uh, whatever, um, you know, issue is under discussion. B: I don't think that they educate them enough to really know what's going on. <sep> Hypothesis: they educate the jurors enough to really know what's going on", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-53f931a6ee41415785df396207630f54", "input": "Premise: A: Yeah. The radio doesn't really have much news sometimes. The stations I listen to are just mainly music. B: Yeah, I think you pretty much have to listen to all news station to get any news at all. A: Yeah. Do you think that TV is, uh, pretty accurate. <sep> Hypothesis: TV is pretty accurate", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-3ffeb8e32c794e8ba9adcd52fc73c53f", "input": "Premise: B: how'd you like to own a piece of property where your lake is going sour because of acid rain. A: Right.  Right. B: It's, uh, really a serious issue for those of us up in this, uh, sector up here. A: um, or do you hypothesize that most of the, uh, smog or air pollution comes from vehicles <sep> Hypothesis: most of the smog or air pollution comes from vehicles", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-43f985c4c42e424ebab4e4ac4548b67d", "input": "Premise: A: Yes, um, I think that Plano has really done a fantastic job. I mean, at least their plans are good. Um, however, I was, maybe you saw in the paper this morning that, um, they've had some problems with, the recycling on plastic, <sep> Hypothesis: they've had some problem with the recycling on plastic", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-dde0a4780f774cb1ab420ff1eeb74108", "input": "Premise: A: And I haven't quite figured that out, if they figure they have got it won or if there's no real hurry because the first three quarters or, uh, uh, if something happens that that adrenalin starts flowing. They say, hey, we got to do something now. And then start playing the game the way the game should be played toward the last few minutes. B: Yeah. A: So, I don't know I'm looking for a good year. I guess we're always looking for a good year. B: So, obviously though, do you think they're going to do anything in the playoffs to make it to the Super Bowl this year <sep> Hypothesis: they're going to do anything in the playoffs to make it to the Super Bowl this year", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-ea64866f3bf64d2f8a1ae4d5173f6397", "input": "Premise: It's where the bands practise. I can't remember what band Petra's in, but I seen them practise once. They were OK but I didn't think they was brilliant. <sep> Hypothesis: Petra's band was brilliant", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-488af08a6e5d41f18ddf7140a9e85f75", "input": "Premise: B: you know, sometimes I would go over, but you know, it wouldn't hit me in a big way because I knew that, uh, I would have it covered in that respect. A: Right.  Right. That's good. I don't think we've gone that far, to pay it you know, in advance before we spend it, <sep> Hypothesis: they've gone that far", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-958545c4f6b9481fbb9f9b058c709e68", "input": "Premise: He also liked swimming and cycling. He said that he wrote stories, though he had to admit that he had never got further than the first two pages. Willie meanwhile not only remained silent during these conversations but picked his berries slowly so that they might forget that he was there but he reckoned without Zach. <sep> Hypothesis: Willie was there", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-0fbc3fb2def742c8817056599623a14c", "input": "Premise: B: uh, but it's worked out for my family, to have my cake and eat it too, kind of thing. A: Yeah.  Yeah, that's a good deal. Where do you think this is going in the future, I mean, do you think things are going to change, <sep> Hypothesis: things are going to change", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-e54c3eb1442e456b99d8a76e98a9d140", "input": "Premise: A: Well I, uh, when is your next one, uh, scheduled now. B: Well it's like, the last one was my high school graduation the next one was when I graduated from college, so I guess about two more years. A: Yes, well, and do you think you'll have a baby to take back with you. <sep> Hypothesis: speaker B will have a baby to take back with her", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-84f477cf7857413999e2ce1f46e382cf", "input": "Premise: B: And other than that I do not think it should be allowable. I think it should be illegal for them to want to do that. it's kind of the big brother syndrome, I mean, I just, anything like that just kind of scares me. A: I tend to view it, even though I don't think I'd work for a company that did that, I sort of want to defend an employer's rights uh, in addition to an individual's rights, <sep> Hypothesis: she would work for a company that did that", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-db49298fb4bd4c12aaf6f16c8ff6ba0e", "input": "Premise: A: Okay. So Frank, what, uh, type of, uh, budget do you or your family have? B: Well, uh I don't know that we really have a budget. <sep> Hypothesis: he and his family really have a budget", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-4cfa750e91ae40549c3c4f66f5dd60a1", "input": "Premise: She said good morning to Alice and Alice said hallo. She was thin and rather tall with a very lined gentle face and hair that was white but which Alice could see had once been blonde. She could also have told this was Tina's mother before Mrs Darne went off down the passage that led to the Headmaster's Flat. <sep> Hypothesis: this was Tina's mother", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-dcfe0bebfed841299afb205238cba7e8", "input": "Premise: ``And you're not having this dress,'' Nora said, bending down to look at the price tag. ``It's two and a half guineas!'' she hissed at Louise who could tell that she was genuinely appalled. <sep> Hypothesis: Nora was genuinely appalled", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-409f6d10212e4217b479a030edfff922", "input": "Premise: ``Molly likes having an audience for her tales and it passes the hours for them.'' When Miss Louisa had a second more severe stroke at the end of August, and Miss Ellen another heart attack, both old ladies died within a few days of each other. Their friends could only feel that death was merciful in the circumstances especially with war imminent and that Molly had made the closing months of their lives very happy. <sep> Hypothesis: death was merciful in the circumstances", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-6d8d60da400744f797a797124402eec9", "input": "Premise: A: Yeah, they did. They put a lot of pressure on him from the outside and from the inside. Uh, it's funny watching them play, he's probably like a lot of quarterbacks, uh, when the pressure is really on when it's down to the last few minutes of the game for the season is when the guys seem to really do their best. B: Uh-huh. A: And I haven't quite figured that out, if they figure they have got it won or if there's no real hurry because the first three quarters or, uh, uh, if something happens that that adrenalin starts flowing. <sep> Hypothesis: they have got it won", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-b933bc7da1864f7f8f03da1577b7d999", "input": "Premise: Richard Breeden had n't noticed that his new desk had just four telephone lines and one phone . <sep> Hypothesis: Richard Breeden's new desk had just four telephone lines and one phone", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-6f2fc70fd0144b36821bbdbf907af116", "input": "Premise: B: Right, you know, like In packaging A: Yeah. B: and, uh, you know, just goodness. A: Yeah, I don't think they do the packaging at this plant, <sep> Hypothesis: they do the packaging at this plant", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-30007a98f4f24fc4ae23e53ab89dc7a5", "input": "Premise: He 'd gone. Philip had to get them back. His Dad would kill him if he found that he 'd taken them. <sep> Hypothesis: Philip had taken them", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-45a58a70cc3048f6bf6bb7dd42a2d4db", "input": "Premise: She hated to think of his sister lying in hospital waiting for her husband to come to her while all the time he was with Dana. She gripped her hands tightly together. Dana didn't know Berenice was in danger of losing her child. <sep> Hypothesis: Berenice was in danger of losing her child", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-3840236d651a48ef887228ecef2e68e7", "input": "Premise: After the twelfth dot, two thirds of the way down the page, the transcript of this long session tails away into blank paper. I suppose what's happened is this. He has gone on staring out of the window thinking and she has gone on staring at him waiting with such absorption that neither of them noticed the tape had run out. <sep> Hypothesis: the tape had run out", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-cb94d80662914bacb966f8a141cb96f0", "input": "Premise: A: Uh, well, it would depend on when you go it's not excessively crowded on the weekends. B: See I'd want to be there in the mornings like from nine thirty to ten thirty. A: Oh, I don't think that would be bad at all. <sep> Hypothesis: that would be bad", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-c6b82a4c9feb45dbad6793815a2e8b57", "input": "Premise: A: and that rolling kind of, uh, B: Terrain. A: Yeah. is fairly famili-,. The thing that I thought was interesting was that the critics, apparently it's going to win everything. B: Really? A: Uh, and I had been told, you know, you wouldn't notice that it was three hours long, and all this, kind of, <sep> Hypothesis: it was three hours long", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-0580797d39f341958898cf8207bfa889", "input": "Premise: ``Look, lady, give me a break. I just deliver the stuff, I don't interview it for the Sunday papers.'' He waved the paper at her and even at a distance she could see that it said very little. <sep> Hypothesis: the paper said very little", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-98ca26378cd44c4886ac5702e27340f2", "input": "Premise: B: Yeah. Those are pretty. A: Number one turned out just great, and the lady said she couldn't believe that they know that I had done it in the color that they had decorated the nursery <sep> Hypothesis: they know that she had done it in the colors that they had decorated the nursery", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-99a407500a8a46edb38f7d2cceabafbf", "input": "Premise: B: Uh-huh. So, yeah, that's the thing is just to look at the school system in the area that you move into before you. A: Uh-huh. Of course we have a slight problem in that, uh, the number of the illiterate in America is mushrooming at this point, and, uh, you know, where our kids might be in a great school, we're still paying an awful lot of taxes for people who are on welfare and unemployment because they can't read, you know. B: Uh-huh. A: So. B: But do you think that there should be, um, nationwide, um, curriculum? <sep> Hypothesis: there should be a nationwide curriculum", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-3049397569aa43939f859997adf45511", "input": "Premise: It seemed impossible that anyone could endure such pain for so long, but at last the doors of the Renault slammed and there was comparative silence. The engine was started up, revving violently as the car was turned round on the narrow road. John could tell that it was being driven back up the hill towards Putna. <sep> Hypothesis: the car was being driven back up the hill towards Putna", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-4d6c3f1d841a40e7b665eec6545a3939", "input": "Premise: A: Well, how do you feel about the immigration laws? B: At, currently, I think they are a little restrictive. Uh, particularly for, uh, certain ethnic groups or from certain countries. Um, I think we should permit, uh, more immigration from eastern Europe, for example, uh, particularly uh, the Jewish, uh, uh, people from Russia. I think we could permit more of them in than we have permitted in the last, uh, several years. And, I think we have, uh, uh, too much restriction uh, on the Orientals also, but, of course, that's just my opinion. A: Yeah, well, I'm not real sure why I got this topic, because I don't think I checked it off on the list because I know very little about the current immigration laws. <sep> Hypothesis: he checked the topic off on the list", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-760d3d64b887435286c3bbb192e30516", "input": "Premise: B: That was kind of a funny movie with, uh, Richard Dreyfuss and Bill Murray. A: Uh-huh. B: That was fun. A: Golly, I don't think that I've ever heard of that movie. <sep> Hypothesis: he has heard of that movie", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-e2e8aef99fb840d481f478f4a57715e4", "input": "Premise: Why should this topic matter? You talked about everything else as you usually do. Why should I feel Maelmuire is important? <sep> Hypothesis: Maelmuire is important", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-4bf0507e59e34d4a82304a4a607bbb76", "input": "Premise: That evening Shannon steered well clear of Dane, all but tiptoeing around him, determined not to land in any more confrontations. From now till this snow siege ended, she would simply live under the same roof, but keep to her own side of an invisible barrier, she decided. She could only hope he 'd do the same. <sep> Hypothesis: Dane would do the same", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-3b098b849ff743278dc0514bf076c878", "input": "Premise: B: So again, it never really penalizes, the company doing the wrong. A: Right. That will, B: They can go right on doing the same old thing they always used to. A: Huh. B: And if they know some practice is wrong, you know, <sep> Hypothesis: some practice is wrong", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-a4d5ee5599f94f41a5411d4ef4885b4c", "input": "Premise: B: um, they try to encourage you to follow a specific curriculum, although you don't have to. A: Uh-huh. B: And then if you have particular religious beliefs they're kind of monitored. You know, they will allow you to, I can't think of any examples but certain religious groups don't want their children in public schools because the influence. And maybe they were a group of Mennonites or something like that. A: Uh-huh. B: I don't think they're were in this area <sep> Hypothesis: they were in this area", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-0474e7b88f754b53a162d87bbfd7d7b5", "input": "Premise: Part of it was to be compulsorily purchased. You could say that Gustave was shepherded into creative retreat at Croisset by epilepsy. You could also say he was driven there by the railway. <sep> Hypothesis: Gustave was driven to creative retreat in Croisset by the railway", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-4ad844a79abc4abcbc2e4d74e685b866", "input": "Premise: L. Underneath, in purple ink, had been added. ``And love, Fenella'', with a capital X as a kiss. I might have known Lisabeth wouldn't have walked up the stairs herself to leave the note. <sep> Hypothesis: Lisabeth wouldn't have walked up the stairs herself to leave a note", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-b242d3b1bc4d48a49cfde235426f0896", "input": "Premise: B: I think the, uh, I think a lot of the commentators on, like the major networks, like right, it's kind of appropriate right now because of the election stuff going on, but, um, it seems that, um, they kind of get to throw their opinions into how they, you know, report on the news. A: Right. And I think even in the elections, they choose who they're going to follow and who they're not, and basically you know, if a candidate can get them to follow, then the news will, you know, kind of publicize his name. B: Yeah.  Yeah, exactly. A: I don't think that the way I get the news is the right way to get it. <sep> Hypothesis: the way she gets the news is the right way to get it", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-197a249f9e1f4117bc3da2c09f040f5a", "input": "Premise: B: I do not know. I wonder where he gets it? You know, you must, I think TV is bad. Because they, uh, show all sorts of violence on, A: That and I do not think a lot of parents, I mean, I do not know how it is in the Air Force base. But, uh, I just do not think a lot of people, because of the economy, both need to work, you know. I just do not think a lot of parents are that involved any more. <sep> Hypothesis: a lot of parents are that involved", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-9ed9b6e5f4a4445c8306637141ae249a", "input": "Premise: B: but I found that, uh, it was made of some material which actually ended up rusting uh, after, A: Oh. B: even, despite, you know, diligent washing, it got rusty after about, uh, three weeks of use. And I don't think it was my fault because you know, I had made a point of like drying it off and cleaning it <sep> Hypothesis: it was his fault", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-c3222b4d56794727b4d7d4ecc6a18976", "input": "Premise: Matthew rode on feeling a little more at peace with himself. He skirted the spruce plantation and supposed that at some point he should tell Sara about it. He could imagine that she might be interested in its money-making propensity at the end of the year. <sep> Hypothesis: Sara might be interested in its money-making propensity at the end of the year", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-babcadff18924c6aa0f0872bf3417c06", "input": "Premise: But the damage was done as far as my faith was concerned, which is probably why I went mad. So anyway, that Christmas Eve night confirmed my worst fears, it was like a kind of ``royal flush'' for the infant Jimbo. All three kings - Pa Santa and the King of Kings - all down the pan together... And to be honest I don't believe any of them stands a chance of ever making a comeback with me. <sep> Hypothesis: any of the three kings stands a chance of ever making a comeback with him", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-696f54ee2330497e8fba3b1cad690a9b", "input": "Premise: ``But my father always taught me never to be afraid of pointing out the obvious. I'm sure you have noticed the implication of the letter, that the writer has in fact observed Jenny undressing for bed?'' I just wondered if you also knew as I'm sure you do that her bedroom's at the rear of the house? <sep> Hypothesis: Jenny's bedroom's at the rear of the house", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-7c01549d0af64fa5a888b7ae2247422f", "input": "Premise: But what we may not know is just what makes somebody a sucker.  What makes people blurt out their credit-card numbers to a caller they 've never heard of? Do they really believe that the number is just for verification and is simply a formality on the road to being a grand-prize winner? <sep> Hypothesis: the number is just for verification and is simply a formality on the road to being a grand-prize winner", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-3aa2ffad1e314cde908ea4e51f108e09", "input": "Premise: B: Yeah, and the ground will filter some of it but not all of it. A: No, not when you figure, I didn't realize one cow produces that much manure <sep> Hypothesis: one cow produces that much manure", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-618af3c2260842e99468c59f422ca830", "input": "Premise: A: I got a friend who goes there, by the way. I want to talk to you about that afterward, okay. B: Okay. Uh, I've, the high school I went to uh, was a good one also. And well, I guess you could say one of the problems with the public education system is the disparity between different schools. <sep> Hypothesis: one of the problems with the public education system is the disparity between different schools", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-bb302c034f304051ba1d21433809ed8b", "input": "Premise: Like now. The Community in Knockglen would defend Eve vociferously. Even some of the Sisters here in Dublin might see that the girl had a point. <sep> Hypothesis: the girl had a point", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-aca02a2f6feb4c53828fbd561ac046d7", "input": "Premise: A: I'm like, I'll get a job some day and my boss will pay for it, I'll be needed. B: Yeah. A: Because, um, I didn't want to go do it myself because I didn't think I was really going to use it. <sep> Hypothesis: he was really going to use it", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-a1f747caa68449c583b0b53728791baa", "input": "Premise: B: and both of those seem very easy to use compared to D Base. A: Uh-huh. Do you think D Base is more flexible or allows you to do more. Or do you think the others are pretty much compatible these days? <sep> Hypothesis: the others are pretty much compatible these days", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-7e5cf952235f4720975749762a371b0a", "input": "Premise: A: Yeah, that's crazy. B: and then you come here in the Dallas area, um, I don't believe that people should be allowed to carry guns in their vehicles. <sep> Hypothesis: people should be allowed to carry guns in their vehicles", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-5f17ad50c9c64652a3aadde5af93ef0e", "input": "Premise: And I resent what happened to my flat. A couple of guys think they can stake it out and wait for me, rub their filthy fingers on my clothes, piss in my bathroom, and I'm supposed to ignore it. I know what I said about possessions being like leeches but that don't mean I 'll surrender them to a pair of punks. <sep> Hypothesis: he will surrender his possessions to a pair of punks", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-0c9b9aadeffe4c1fb3752e6eb82c5f77", "input": "Premise: B: She says that when her husband died oh, that my uncle had said that he would never put her in a rest home. So it's kind of, uh, I don't know. I mean, I don't think my parents would but she is getting pretty bad like she has to have like a little toilet right by her bed and, it's, A: Uh-huh. B: and my mom has to take care of her pretty much so it gets, I don't know. it's a hard decision, but I don't think I would do it to my parents personally. <sep> Hypothesis: she would do it to her parents", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-67bc97a4bf224730af09efb544543691", "input": "Premise: B: And they go down the line ten years and then on some little technicality they get out and on the streets again doing the same they did before. A: Uh-huh. B: And, you know, that's about the only thing. Like for theft and stuff like that or manslaughter, you know, I don't think they should do that. <sep> Hypothesis: they should do that", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-57dd37c990cf4030a90c8e001f6011eb", "input": "Premise: The assassin's tone and bearing were completely confident. If he noticed that Zukov was now edging further to the side widening the arc of fire he did not appear to be troubled. <sep> Hypothesis: Zukov was edging further to the side", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-a73caada952643328477f2fa7b47473d", "input": "Premise: Did he intend everyone in the castle to know he did not want the wife he had married in such a hurry? Did he intend to ignore her completely? Then Isabel saw Ellen's stunned face and realised that her maid at least did not know she had spent the night alone. <sep> Hypothesis: Isabel had spent the night alone", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-401a364e73734184b2c4fcef9a6ced9b", "input": "Premise: B: So am I. A: Are you, B: You know, I think it's kind of coming back around to that, don't you, <sep> Hypothesis: it's kind of coming back around to that", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-7d91bfea64fa4b7790fbb5cac9ce737f", "input": "Premise: Nicky approached her with the assumption that men are naturally right and it is the role of women to follow their lead. Constance, whose confidence was growing daily, was not prepared to give in to Nicky's wishes merely because of his sex. If she felt he was right then she agreed with him. <sep> Hypothesis: Nicky was right", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-e6a9dbf50f8043aa9edbc1950413c638", "input": "Premise: Look, my dear, I'm not in my dotage yet, and I know I'm a grumbler and a complainer. You could say the only form of comfort I 've got are my complaints. <sep> Hypothesis: the only form of comfort he has are his complaints", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-751b500cd68540afac2f439214e09f47", "input": "Premise: A: Oh, yes. Animals have a way of talking. B: Alfie did. I tell you if I could have gotten a hold of that cat that day. A: I don't know uh, that I'd trade my dog in for the world. <sep> Hypothesis: he would trade his dog in for the world", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-5e902ab797344c2294fc27884d504d86", "input": "Premise: A: Sometimes you hear things on the radio that, you know, could be true or couldn't be. B: Uh-huh. A: Uh, do you feel like this is, I guess they're spending a billion or so a year on this AIDS research. B: Uh-huh. A: Do you think they should spend more? <sep> Hypothesis: they should spend more", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-1403787bd69c4ece89ad2b641892fb20", "input": "Premise: It is all very well, in these changing times, to adapt one's work to take in duties not traditionally within one's realm. But bantering is of another dimension altogether. For one thing how would one know for sure that at any given moment a response of the bantering sort is truly what is expected? <sep> Hypothesis: at any given moment a response of the bantering sort is truly what is expected", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-acfaf5f755514768ad8fb8fafe03d3fe", "input": "Premise: Anna looked at Peter again and said to herself in a guilty whisper, ``Will he become even more difficult?'' She wondered if a stranger could tell that he was difficult, just by looking at him. Would such a person watching Peter now reading the prayers of Rite B in his level pleasant voice notice that resentment lay like his blood just under his skin because the life he had chosen had not turned out as he had expected it to? <sep> Hypothesis: resentment lay just under Peter's skin", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-88b70dd162f34032ad50d55bf1ac319a", "input": "Premise: B: I think that not only applies inside the public school system, but in society itself. there's been too much negative reinforcement. How much, like, the caught being good slips. How about, just the John Q citizen out there on the street? A: Yeah, well that's true. I think, really though, I mean, that's one thing that, I mean, my kids definitely get spanked when they need to be spanked. But I really do try to use positive, uh, reinforcement with them at home, also. And it really helps. And I mean, they don't get spanked very often, but they do when they deserve it, you know. But, uh, I don't think any kid should be exempt from being spanked. I mean, I think I wouldn't mind if a teacher spanked my child. But, you know, that's just my personal opinion, and that's not going to, I mean, I don't think that law will ever change. <sep> Hypothesis: the law will change", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-54093d0c6d144587a448bb31cc5ed4e9", "input": "Premise: A: I, that would have been stupid, B: Yeah. A: and I don't think we did it. Everything else we handled in this seemed to be perfectly right. I don't think they would have done that. <sep> Hypothesis: they would have done that", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-d18a9573c5e344398875ad8b80a95e79", "input": "Premise: A: Do you go to museums in Europe? B: Uh, actually, no, I don't think I went to any of them. <sep> Hypothesis: she went to some of them", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-cefd239afd244203b611ddea5664fe96", "input": "Premise: A: I suppose so. Let me push the button. B: All right. A: Okay, uh, I guess I'm supposed to be all for switching to the metric system, but, uh, I sense that it's not going to happen anytime soon. B: Yeah, I don't think it's going to happen either, <sep> Hypothesis: it's going to happen", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-a137d9e481b84ff8934c6c541ec47aa3", "input": "Premise: B: if you get it on sale, A: Yeah, yeah, so we bought that or we bought the filets, and then the chicken, or turkey nuggets, and I don't think anybody in my house knows the difference, unless you tell them. <sep> Hypothesis: someone in his house knows the difference", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-780616a33f9346b4b00822dd6ca0659e", "input": "Premise: ``Clever''. Klug means ``clever''. Would you say that Abie was clever? <sep> Hypothesis: Abie was clever", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-1708318d329846a5b3eeb8c54e19bc0f", "input": "Premise: ``You 've heard something like that before. Haven't you, Jimmy?'' Jimmy had been shaken by those sounds more shaken than the others for good reason but Cardiff could see that he was unprepared to show it as he pushed himself away from the reception counter. <sep> Hypothesis: Jimmy was unprepared to show he had been shaken", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-367a930b9bd346eb962836d424e13c4a", "input": "Premise: B: And, uh, I think they've all developed kind of an interest in reading also. A: That's re-, yeah. B: I'm not saying they read all the right things <sep> Hypothesis: they read all the right things", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-52129d1ca0504393981ddcad2b2af6b5", "input": "Premise: A: How do you feel about gun control? B: Well, uh, I mean I don't think that guns should be outlawed <sep> Hypothesis: guns should be outlawed", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-c89d75eef4744cf4aa9d4fbf7bc8649b", "input": "Premise: A: for the moment, and that's what really is getting me about what George Bush's stand on the budget is right now is that he is saying, I am going to give you this ludicrous little tax cut so that you'll be happy come November, and you'll elect me again B: Uh-huh.  Uh-huh. A: and then I'm going to go on and just forget everything that I said B: Uh-huh. A: or you know, it doesn't seem that it's going to make much of a difference. <sep> Hypothesis: it's going to make much of a difference", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-0b43d96b5b684bea9374cc304004d30f", "input": "Premise: How did Selden know that the hound was following him? We know he ran a long way. He was screaming for a long time before he fell and we could hear that he was running as he screamed. <sep> Hypothesis: Selden was running as he screamed", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-2e3c2e025c4d4779b508979ca23e50fb", "input": "Premise: Under the Racketeer Influenced and Corrupt Organizations law, or RICO, the government has the authority to seek to freeze or seize a defendant's assets before trial.  According to individuals familiar with Mr. Antar's case, prosecutors issued their warning this week after one of Mr. Antar's attorneys asked whether legal fees might be subject to seizure. In a letter, prosecutors told Mr. Antar's lawyers that because of the recent Supreme Court rulings, they could expect that any fees collected from Mr. Antar may be seized. <sep> Hypothesis: any fees collected from Mr. Antar may be seized", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-ab416cae93e24ebcb7b1927b3928a8e1", "input": "Premise: A: Really. If they were to take half of what they spend on that and put it on some economic, you know, intergovernmental or inter United States like programs that one really might. B: Yeah. A: I believe in paying my share, and I don't mind, uh, paying for some of these fringe benefits that people are entitled to. But I just sometimes feel like I'm being used. But, uh, again I don't think we'll be able to do anything about it, <sep> Hypothesis: they'll be able to do anything about it", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-7b5bcc47d2814617a06317b162a9ccfb", "input": "Premise: B: Right. And I'm sure that would make a big difference, too. You know, you've got, A: Yeah. Well, what about a voluntary program? Do you think that would be a good idea? <sep> Hypothesis: a voluntary program would be a good idea", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-b052ae3486ae453abd2156dbc59561bc", "input": "Premise: Robert Erwin, president of Biosource, called Plant Genetic's approach ``interesting'' and ``novel,'' and ``complementary rather than competitive.'' ``There is a large market out there hungry for hybrid seeds,'' he said. Mr. Robinson of Delta & Pine, the seed producer in Scott, Miss., said Plant Genetic's success in creating genetically engineered male steriles doesn't automatically mean it would be simple to create hybrids in all crops. <sep> Hypothesis: it would be simple to create hybrids in all crops", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-8411b25f1f8a42aa8104b40717078218", "input": "Premise: B: Yeah. I understood that. you know, I work full time and I have two kids so my spare time usually involves something with the kids. A: Yeah. B: You know, hobbies, I can't really say that we have hobbies. <sep> Hypothesis: they have hobbies", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-d4cefba7e8044d7b8e8877ffed28bef9", "input": "Premise: Jane ate without pausing. Hunger was an unknown experience. She had never imagined it could actually hurt. <sep> Hypothesis: hunger could actually hurt", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-b6bd9263505749e89fcd71c91465fe0d", "input": "Premise: ``I hope you are settling down and the cat is well.'' This was a lie. She did not hope the cat was well. <sep> Hypothesis: the cat was well", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-afe01bfbc68b40e7a04364ed3cd271ff", "input": "Premise: The Deputy Under Secretary could talk of his host's prospects and disappointments, he could learn of the problems of digging out foreign exchange and hard currency in the Third World, the tribulations over the renewal of Residence Permits, the difficulties of keeping reliable servants, but of his own world he must remain silent. The Deputy Under Secretary headed the Secret Intelligence Service of the United Kingdom, and that was not a subject matter for gossip and conversation on a bougainvillaea-fringed veranda as the lights of the fishermen's dug-outs floated inside the coral reef... No bloody way. He was a man who could be honest with himself and in honesty he could say that he was both pleased and relieved to be back at his desk on a grey Monday morning in London. <sep> Hypothesis: the Deputy Under Secretary was both pleased and relieved to be back at his desk on a grey Monday morning in London", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-04b55d6cee434195a20f6a7b570d9090", "input": "Premise: Meh ' Lindi did not develop the lower set of arms nor the bony, sinuous tail. Too much to expect a new pair of arms to grow out of her ribs, or her coccyx to elongate so enormously. Nor could Jaq imagine that she could attain the full strength of a purestrain Stealer - though her own strength was formidable even when unenhanced. <sep> Hypothesis: Meh ' Lindi could attain the full strength of a purestrain Stealer", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-9bfadc1ac3e645d19544063f5e38cae4", "input": "Premise: B: I don't know how my parents did it. A: Yeah. B: I mean, there were five of us and I don't recall, you know, wanting anything in particular. Uh, but I don't know how my father did it. He worked at a truck line and he just didn't make that kind of money with five children. But we did okay. We had a house and a home and, but now, my wife and I both work and I don't believe we have as much as my parents did. <sep> Hypothesis: he and his wife have as much as his parents did", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-b8be66de79074c68badc0dd0699e708b", "input": "Premise: A: Oh, wow! But maybe you shouldn't be held responsible for something you did several years ago. B: So,  I know. A: That's the other thing. I mean a lot of people as kids or, you know, young people get into some things that they get out of later on and I don't think they should really have to pay for that forever. <sep> Hypothesis: they should really have to pay for that forever", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-3de4ce939b5444db845039662ba938a7", "input": "Premise: A: I thought Carter was good too, and that was, yeah, B: Did you? I always liked him, I thought he was great at the time and I just couldn't get over the fact that Reagan beat him. you know, that I just couldn't believe that he got voted out. <sep> Hypothesis: Carter got voted out", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-87745458acf748e7ad7ec9ec8aac179f", "input": "Premise: A: I am right outside Baltimore. I am less than a mile from the Baltimore line. B: Um. A: And I go to a campus of the University of Maryland that is just, less than a mile from my house. So I'm actually in Baltimore, yeah, you could say I'm in Baltimore. <sep> Hypothesis: he is in Baltimore", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-d2805433eb3c410a880d8eab42553faa", "input": "Premise: Yet what good came from knowing that a woman had killed herself? The children who had suffered a trauma would survive the experience, scarred by it and a little flawed by it. They would never forget that for a week they had imagined the act of murder had been committed. <sep> Hypothesis: for a week the children had imagined the act of murder had been committed", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-a40698bc75fe4f20af050212a1895686", "input": "Premise: A: So, we're comparable. B: Yeah. A: As a matter of fact, I just paid my Richardson taxes because I live in Richardson and supplemented the Robin Hoods very thoroughly, I think. B: Yeah, I think Yeah, we have got it on the line, don't we. <sep> Hypothesis: they have got it on the line", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-84501df581bd4f4ba53a449b897221da", "input": "Premise: I can't afford to get bogged down in the weeds. But at least you know she did leave. Maybe a coincidence maybe the two girls talked on the phone decided they 'd both had enough. <sep> Hypothesis: the two girls had both had enough", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-e84104b69b7b4a7d940749565e391508", "input": "Premise: B: I look at our big green containers, and I say, well, they work fine and I keep mine outside the garage so that I don't have any odors but it's clearly a place where, uh, uh, A: Oh, right. B: it will be interesting to see how well that works and I'm glad the community is doing it. Uh, it's one of those things that kind of has to be forced on people. Uh, I don't know what you saw back, uh, years ago, but for me the thing that strikes me is uh, growing up in rural South Dakota where, hey the farmers brought their eggs to town and the local hatchery would candle them and package them is that, uh, in the fifties, uh, you could say we had the recycling going on then that we should have now. Which was all the milk bottles were glass <sep> Hypothesis: they had the recycling going on then that they should have now", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-038deea895bd4586acc0c6aca29fd69f", "input": "Premise: It - the tractor, the boys and the bulbs in the earth - knew she had chosen for them and was coming back to them. Of course there was still love, there was healthy, growing love and its name was called Work. She had fallen in love with it so slowly and gently and sweetly that she had never noticed it had happened. <sep> Hypothesis: falling in love had happened", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-d1cdc86684004c7f9f18b2cab3b3ffe8", "input": "Premise: ``Who knows? The point is, do we go with it or not?'' Do we assume there is a shipment? <sep> Hypothesis: there is a shipment", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-e428ffdaf8ad4e27b852dcb78c4157c6", "input": "Premise: Jean was tough and liked to drink. She would endure for a long while yet. But what would she do when she realized that with things as they were she was on a life sentence not just a temporary suspension of essential pleasure? <sep> Hypothesis: Jean was on a life sentence", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-6492c6abc30a4dc68efe4272590fa85d", "input": "Premise: But don't dilly-dally for too long. Once it's published we are all going to look a little risible if we have made no adjustments to what is after all known as being predominantly my own design of gallery. Also I am a bit older than the rest of you but you can perhaps understand that I don't want to drop dead without a proper and public recantation. <sep> Hypothesis: he doesn't want to drop dead without a proper and public recantation", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-c8d8640d79884bb885882b7fe1ac445f", "input": "Premise: B: And yet, uh, I we-, I hope to see employer based, you know, helping out. You know, child, uh, care centers at the place of employment and things like that, that will help out. A: Uh-huh. B: What do you think, do you think we are, setting a trend? <sep> Hypothesis: they are setting a trend", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-68bddaa1608c4d07ace7e362d0ad440c", "input": "Premise: B: Now see I. A: I'm intrigued by it, but I'm not sure I want to go see it yet. B: Yeah, I don't think I want to see that either. <sep> Hypothesis: she wants to see that", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-5da570cab1674fe2b143172f5487a4ac", "input": "Premise: Whether the relationship had gone beyond friendship Dalgliesh would now never know. She had, apparently, spent little of the money on herself, had been a dependable benefactress of the few eccentric charities of which she approved, had remembered them in her will, but without egregious generosity, and had left the residue of her estate to him without explanation, admonition or peculiar protestations of affection, although he had no doubt that the words ``my dearly beloved nephew'' meant exactly what they said. He had liked her respected her had always been at ease in her company but he had never thought that he really knew her and now he never would. <sep> Hypothesis: Dalgliesh really knew his aunt", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-deb05bc495364454afaeb63ef1b36789", "input": "Premise: B: I wouldn't be surprised. A: You know, because they don't want to send them to daycare. B: I doubt if they would say it was too long. <sep> Hypothesis: it was too long", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-d7f9a1040b3141c6b7f52076f8f58df1", "input": "Premise: Then it cried. It was another girl. I was a little disappointed but I could only hope that Celia was still a bit hazy from the drugs. <sep> Hypothesis: Celia was still a bit hazy from the drugs", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-8bd90a568cbc4c8c8d54cffb91bdffd4", "input": "Premise: ``Yes?'' ``Nathan?'' He could tell it was long-distance the line was so gravelly and hollow but he didn't recognise the voice. <sep> Hypothesis: the call was long-distance", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1388_cb_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". (1) The model should output Entailment when the hypothesis sentence entails the given premise.  (2) The model should output Contradiction when the hypothesis sentence contradicts the given premise.  (3) The model should output Neutral when the hypothesis sentence is neutral with respect to the given premise."], "Instance": {"id": "task1388-ae5164fe205a423b8bbd7c650dbc5cd0", "input": "Premise: B: when you've lost something or uh, uh, don't have what other people have that's when you tend to realize, you know, what's out there and you know, what you have and what you don't have. A: Yeah I agree. B: So the original question, do we think they're you know, a security threat? <sep> Hypothesis: they're a security threat", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-9fa6c37885064aa8a0aa5242365cd140", "input": "claim: Forced marriage should be banned.\n perspective: The state should not be allowed to intrude in such personal matters", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-586ab9c6acf94199b747b6eb4cee79ac", "input": "claim: Wind power should be a primary focus of future energy supply.\n perspective: Animal habitats are threatened by the turbines used in wind power.", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-9c72c59698de42b28e2eb660e71704d9", "input": "claim: Should Turkey Be Accepted In The EU.\n perspective: As a matter of precedent, Turkey should be allowed into the EU.", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-c9c33d62d9a44563a6cafd4e6d9ec67b", "input": "claim: Children should not be allowed to inherit vast wealth as this damages them and society.\n perspective: Inherited wealth demotivates the recipients so that they put less effort into training, education and social skills.", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-db022e2e115a4ecebf642f55707d8981", "input": "claim: Sikh school pupils should be allowed to carry ceremonial daggers.\n perspective: It is a potential weapon.", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-7d8a122c587e45d195eed1e6ac88bc7f", "input": "claim: Ban junk food from schools.\n perspective: Unhealthy foods lead to a higher risk of diabetes.", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-8b6967f37cee425d9c4aca8a059f691e", "input": "claim: All Americans should have the right (be entitled) to health care.\n perspective: Health care for all might cost more in taxes.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-9dc7bf57897e4d5b8c6ac05fa26761df", "input": "claim: We have to teach creationism in schools.\n perspective: Freedom of speech should apply to teachers as much as anyone else", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-620ee84c8f394eb49d695bcc72385c9d", "input": "claim: We should be investing in public transport.\n perspective: it is the only way to stop our lazy nation from driving", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-37f8c978742e48abb7f8b4e92a6eff5b", "input": "claim: Violent video games cause violent crime.\n perspective: Violent video games have been shown to have positive effect on kindness and cooperative behavior.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-320ed56728344d58b3f599f3f0bbd2fd", "input": "claim: The U.S. Should Ban The Use of Cluster Bombs.\n perspective: This House Believes That the U.S. Should Ban The Use of Cluster Bombs", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-defbbb3239944dd3a851e36533befbde", "input": "claim: The UN should be reformed or replaced.\n perspective: The UN has performed a valuable service in preventing wars and in peacekeeping. ", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-a66a3cbb55f2489a842f916f4e119def", "input": "claim: Democracy Is the Best Form of Government.\n perspective: Promoting democracy promotes peace.", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-8327d6a5a2634f8cb9f56596252d962f", "input": "claim: Social networking sites are good for our society.\n perspective: Social media facilitates political change.", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-18d8930c48584a49807e7e698e7f654b", "input": "claim: Social networking sites are good for our society.\n perspective: Social media has been found to be used for criminal activity.", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-d1cdd6aa9f8d4936b12ccc9eb16f9fb0", "input": "claim: Voting should be compulsory in the UK.\n perspective: People forced to vote are unlikely to vote intelligently.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-65070959bd7b4a2c8a3a3fc4e770b222", "input": "claim: Drones Should Be Used to Take Out Enemy Combatants.\n perspective: Drone strikes are often not targeting high value targets.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-93b97a2473ae4f9a9582d5df6d2ded18", "input": "claim: Violent video games cause violent crime.\n perspective: Restricting violent video games will have no correlation to a reduction in societal crime.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-f368a544b70247448392779901f55b01", "input": "claim: Wire-tapped and \u2018intercepted\u2019 evidence must be allowed as admissible in court.\n perspective: Intercepted evidence is a strong tool against widespread criminal networks.", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-bc3936552f8d489baf6b2f18ceb6ab5c", "input": "claim: Homework is a waste of time.\n perspective: Too much homework can be harmful", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-d77f2f2a96654f798be20d3350971adf", "input": "claim: Fast Food Advertising Should Be Banned.\n perspective: Marketing aimed at children should be subject to strict regulations.", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-4c4ceb9d79f24e95914a5c069da81a46", "input": "claim: Junk Food Should Be Banned.\n perspective: The sale of \"junk food\" items provide vital financial assistance to schools.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-91202058cd8c47bfb117ef2dc8ac0305", "input": "claim: Prostitution Should Be Legal.\n perspective: Legalization has benefits for society", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-bf920893ba3b4d0fbd6226951697a40e", "input": "claim: Golf is a Sport.\n perspective: If you can compete in golf with a handicap, then it is not a sport.", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-512d68c894d14aa9908553bf00c1a5db", "input": "claim: People should have a right to private education.\n perspective: Private schools are financially good for the state", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-7bde66d008f6449f90b430dac8a78257", "input": "claim: Domestic intelligence agencies have a legitimate role to play in democracy.\n perspective: The government does not have the right to spy on its citizens", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-e83bc9af41254d1daf2c78a9b4ff086f", "input": "claim: The age of consent laws should be lowered.\n perspective: Lowering the age of consent will open the door to more criminal problems", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-79647babaff448b981c48541ef97997e", "input": "claim: Voting should become compulsory.\n perspective: What's the point of voting as politicians don't listen to the public anyways", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-c311369b659640fd848640a4ff4cc22f", "input": "claim: All drugs should be decriminalised.\n perspective: Why is it legitimate for the government to ban drugs", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-8458867be1e74f268e092de458d9a6b8", "input": "claim: Raise The School Leaving Age To 18.\n perspective: Society should make it easier for all young people to receive an education.", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-610044dedbea4185b1474d3b920f6271", "input": "claim: Ghana\u2019s ban on smoking in public places is a model for Africa.\n perspective: It isn't necessary to ban smoking.", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-f7820de660d7440ebe760224c2c8cbd6", "input": "claim: Same sex relationships should have the same legal status as heterosexual relationships under EU law.\n perspective: Legalizing gay marriage will not harm the institution of marriage, and same-sex marriages may even be more stable than heterosexual marriages. ", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-b0738990de004d2d88cd4c5487749247", "input": "claim: social networking sites should be banned at the workplaces.\n perspective: The public has a reliable source of essential public health and safety information through their social media accounts.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-c2d3521d4941414a99831c41c11a60a7", "input": "claim: Global Warming is not an issue.\n perspective: There are other things that cause the global warming situation.", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-9973794d3d034a9daaf82b163af3cb07", "input": "claim: Speed limits should be reduced.\n perspective: Government have illegitimate reasons behind lowering the speed limit ", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-20eaebedb5654f71aa910ddc7a0803e8", "input": "claim: Religion In Itself Is A Purely Positive Force In The World.\n perspective: Religion's Net Impact On The World Is A Positive One", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-affaf75d1262445cba93972723746cb2", "input": "claim: Religious freedom abroad should be one of the primary foreign policy concerns for any country.\n perspective: Religion does not motivate foreign policy", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-cc96b45839494270b61fdeaccea6751f", "input": "claim: More gun control laws should be enacted.\n perspective: More gun control laws are needed in protecting women from domestic abusers and stalkers.", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-1065a762399042698dbe5a037f8d99b2", "input": "claim: The EU should significantly reduce the amount it spends on agricultural production subsidies.\n perspective: The market needs stability", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-c93897ec59544a82b50a860355220fc9", "input": "claim: It is sometimes right for the government to restrict freedom of speech.\n perspective: Freedoms are not earned or deserved they are given to all people equally and no one should determine which agendas are too extreme to receive this protection.", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-9faba77bb7284636b22b57d5341de194", "input": "claim: Drones Should Be Used to Take Out Enemy Combatants.\n perspective: Not enough legal oversight prevents the accountability resulting from secret drone strikes.", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-467ee4d383754746a868362ef37721e4", "input": "claim: Europe should be federal.\n perspective: Member states will reap the benefits of a federal Europe.", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-a4b42f69b2d34fb79f518ac2e0956a12", "input": "claim: The use of animals as objects of sport and entertainment should be banned.\n perspective: Using animals in sport demeans humans. ", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-784cdd0532b3482e94ce8112fef2242a", "input": "claim: Disclose previous convictions in court.\n perspective: Allowing this motion would lead to a miscarriage of justice.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-2f885841fcfa43d0ba0abff7ee8de695", "input": "claim: Tablets should replace textbooks in K-12 schools.\n perspective: Tablets increase the number of excuses available for students not doing their schoolwork.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-167c82ff7dc743a7945dc7ebb992af3c", "input": "claim: Reality TV shows are an important part of popular culture today.\n perspective: Reality TV is disgusting.", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-4ef765ba5e2c4d68b037f6b3d4696e75", "input": "claim: Same sex relationships should have the same legal status as heterosexual relationships under EU law.\n perspective: Legalizing gay marriage is a stepping stone toward disgusting and harmful marriage practices such as incestuous, bestial and child marriages. ", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-a13b5d667ada4ad9b3c2c4f3098903e6", "input": "claim: Same sex relationships should have the same legal status as heterosexual relationships under EU law.\n perspective: There are economic advantages for states to approve gay marriages. ", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-1fc16332fca24f209ef77c3bf4e62177", "input": "claim: 16 year olds should be able to vote at presidental elections.\n perspective: 16 year olds are informed enough to cast a vote.", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-7025a09304d44f71a97131bc4c09cb82", "input": "claim: Same sex relationships should have the same legal status as heterosexual relationships under EU law.\n perspective: Gay marriage is contrary to the word of God and is incompatible with the beliefs, sacred texts, and traditions of many religious groups. ", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-1bb7ed2e71004de2a6833474231f8bc1", "input": "claim: Wikileaks is not and has never been a non-profit organization.\n perspective: Wikileaks is not accountable ", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-7345e5224ed749cba292946c8c645b2f", "input": "claim: Positive Discrimination Towards Women in Society Is Justified.\n perspective: It does not address the underlying issues", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-8f3c7c6841c34fe18d5b10110e8bd8ce", "input": "claim: Voting should be compulsory in the UK.\n perspective: There is precedent to compulsory voting working.", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-138ca2d835994c6693d0011aa4ed0e37", "input": "claim: All nations should ban bullfighting.\n perspective: Bullfighting should be treated like other forms of animal torture", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-8ef4e6637c45402b801d359b84d00010", "input": "claim: Developing nations should place restrictions on rural-urban migration.\n perspective: It is practically impossible to control people's movement", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-56055cc093144503b2e60eaffdeb07ec", "input": "claim: The niqab and other face coverings in schools must be banned.\n perspective: It causes division within society", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-49099fa9b2f84e2fa17fddaca4a9a1e3", "input": "claim: Everyone should go vegetarian.\n perspective: Studies show that vegetarians are up to 40% less likely to develop cancer than meat eaters. ", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-dc7eab43a64d4c079729b7609c50fe53", "input": "claim: The use of child performers should be banned.\n perspective: Being a performer can make the child physically vulnerable", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-c3b3d12e905c4b9aa0dee27e246b0f53", "input": "claim: Gay couples should be allowed to marry.\n perspective: Same-sex marriage may have a lower divorce rate than heterosexual marriage proving once and for all that gay marriage is good for the institution of marriage. ", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-12625021551e49d9ae5195be8b6124f9", "input": "claim: The world should go vegan.\n perspective: The risk of heart disease is reduced in people who adhere to a vegetarian diet.", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-33873d41b1b0464ca4f999248aa9d363", "input": "claim: Teachers Should Have The Right To Punish Pupils Physically If The Parents Consent.\n perspective: Allowing children to be hit sends the message that it is OK to treat children in this way.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-21d3e6a68cdd40ada21d9e5ea50ac592", "input": "claim: The United States should maintain its embargo against Cuba.\n perspective: The embargo prevents the people of Cuba from joining the digital age by cutting them off from technology, and restricts the electronic flow of information to the island. ", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-9a0258ff3c5e4957b4d0d3effb847f7f", "input": "claim: School Uniforms Should Be Mandatory.\n perspective: Making school uniforms mandatory creates a sense of equality since everyone will be wearing the same clothes.", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-f186796e9e2942ea8a3a71c520c98fc5", "input": "claim: Deny Organs to Non-Donors.\n perspective: People may have valid religious reasons not to donate organs", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-167ee0b08f2e4425bf340371370e839a", "input": "claim: We should build new nuclear power plants.\n perspective: Nuclear energy will not change carbon emissions in the atmosphere ", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-c4038473c1ea4d46ac3d468ce0d927bb", "input": "claim: Eliminate All Nuclear Weapons.\n perspective: countries have to right to self defense with nuclear weapons, even when they lack capacity in conventional weapon", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-d5db9920fd364287a5958241c2ce00b3", "input": "claim: The United States should use the electoral college in presidential elections.\n perspective: With the electoral college in place, it weakens people's incentives for voting.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-7fd1e579419e4177bc04c42de4a20267", "input": "claim: Strict parenting works best.\n perspective: Kids deserve some freedom. ", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-93a5139742fd4d2789e78a90284c2083", "input": "claim: The US should immediately close Guantanamo Bay.\n perspective: Release is not the Solution", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-f19ffef4b3bf436986d3ed3ca6af9269", "input": "claim: We must ban negative advertising in political campaigns.\n perspective: Negative campaigns reduce diversity", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-610711bb5669485e9cf916439b3bcb01", "input": "claim: All nations have a right to nuclear weapons.\n perspective: No country has an inherent right to invade or use aggression against another.", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-d8f87852811642d481e01d7aaed7ec42", "input": "claim: You have nothing to worry about surveillance if you have done nothing wrong.\n perspective: Power trips can be had by agencies.", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-21ce4e9f80ec404cadef5df04c0a5f6a", "input": "claim: We must ban negative advertising in political campaigns.\n perspective: Negative campaigning creates voter apathy and prevents accurate reporting of candidates\u2019 policies and ideologies.", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-22db4694ffa04244acac91bb710d309a", "input": "claim: Scotland should cede from the union.\n perspective: Scotland's economy cannot survive if it doesn't have England to lean on.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-bef8becebe1143c3baa5a0f351768b96", "input": "claim: Performing tests on animals must be banned.\n perspective: Testing is needed for really new drugs", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-e563887e1c6f4ba4a482bea229bc8b97", "input": "claim: Tennessee is correct to protect teachers who wish to explore the merits of creationism.\n perspective: Teachers shouldn't teach whatever they want.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-8e6a0689088145778de1a021671d1112", "input": "claim: Widen the East African Community.\n perspective: Conflicts and insecurity in the region will be resolved.", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-40d7fb2e47804a8e9259b9633ab8b11f", "input": "claim: School vouchers should be encouraged.\n perspective: School vouchers improve education in general by making public schools compete with private schools for students in a free market", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-02499eac013747419f1bb07b156b1fc1", "input": "claim: Increased taxes are good for America.\n perspective: Changing the wealth around to help income disparity ", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-10d23a7952af4c7fa1d2fe0029f935c7", "input": "claim: Gay couples should be allowed to marry.\n perspective: The concept of \"traditional marriage\" has changed over time, and the definition of marriage as always being between one man and one woman is historically inaccurate. ", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-da431bde321d499bb30d56603da75bf4", "input": "claim: Basic income tax should be abolished.\n perspective: Balancing governmental problems for society", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-3c56b3af2c3d426ebbfc65808c12785e", "input": "claim: It is time to stop buying bottled water.\n perspective: Bottled water is important for travelers to avoid illnesss.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-bdb32a02e39441acb7642d399f79e3f1", "input": "claim: We should expand NATO.\n perspective: NATO development was important  for international stability ", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-dd5fd91596ed44b38181b13d4ad5b1c3", "input": "claim: Everyone Should Automatically Be Opted into an Organ Donation Scheme.\n perspective: Some just don\u2019t bother to register as a donor, even if they support the cause.", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-c65f1555232d49bd9772e501d0068972", "input": "claim: The American Jobs Act should pass.\n perspective: The American Jobs Act Will Help the Long Term Unemployed", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-739a60f4bb834150a9583b144b13e46a", "input": "claim: We must negotiate with terrorists.\n perspective: Negotiations cannot take place while innocents are being threatened", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-cd0b2b13c73349fdb64b517ed86a8bb8", "input": "claim: Fast Food Advertising Should Be Banned.\n perspective: There are alternative methods of distributing the toys.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-7cfd93569c6a425782e0d6ab69d51e97", "input": "claim: Basic income tax should be abolished.\n perspective: Income tax is not the best way to redistribute wealth or pay for public goods.", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-df72a31689eb42219dccc3174763efc3", "input": "claim: Marriage is an outdated institution.\n perspective: Those who are observant religiously think that marriage is important.", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-39bcc9d6059f4f7a8982e87a4d8dcfe0", "input": "claim: The US and its allies were justified in taking military action against Iraq following Iraq\u2019s invasion of Kuwait.\n perspective: The Coalition had a high probability of success", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-8cc31542ab944a3994fe0ce7d17b637c", "input": "claim: Africans are worse off due to natural resources.\n perspective: Conflict is centered around resources. ", "output": ["support"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-80e4c0292b65466da5549342f73bc20d", "input": "claim: Global Warming is not an issue.\n perspective: Because people are losing lives and our climate is changing", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-edc361fe22054ee5bcbcfc7f74cac7ba", "input": "claim: The US and its allies were justified in taking military action against Iraq following Iraq\u2019s invasion of Kuwait.\n perspective: The US' intentions were wrong.", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-fc3f0d2bfedf4f689329cba0cd31b71c", "input": "claim: We should allow death penalty for the worst of the worst criminals.\n perspective: The penalty of death is a crime deterrent.", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-bd9cca55cd7443279fe833d39af80615", "input": "claim: permit the use of performance enhancing drugs in professional sports.\n perspective: Sports will become even more dangerous for athletes if they are allowed to take performance enhancing drugs. ", "output": ["undermine"]}, "Prediction": "undermine"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-89ad1c0e78c2440cb0c6033d630d998b", "input": "claim: Same sex relationships should have the same legal status as heterosexual relationships under EU law.\n perspective: A proper marriage is between two heterosexual people of different genders.", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-554a6f1d9fa3484fa004a2dcd610930f", "input": "claim: UK should have a second Brexit referendum before leaving the EU.\n perspective: The referendum is inconsistent with the UK's tradition of representative democracy  EU membersh", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-64c076c130a84ce7974ba89ee7b042e8", "input": "claim: Arming the police is a good idea.\n perspective: arming police will not help violence", "output": ["undermine"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-3b6fef95407a4932b075b73b66065c0c", "input": "claim: Compensation should be paid for those who have had their culture appropriated.\n perspective: Compensation rights a wrong", "output": ["support"]}, "Prediction": "support"}
{"Task": "task738_perspectrum_classification_gpt3_0", "Definition": ["In this task you will be given a claim and a perspective. You should determine whether that perspective supports or undermines the claim. If the perspective could possibly convince someone with different view, it is supporting, otherwise it is undermining. When the model should output \"undermine\", it means that the perspective given does not support the claim. For example, if the claim is \"Abolish the US Electoral College\" and the perspective is \"The Electoral College is an important part of the US Constitution\", then the model should output \"undermine\" because the perspective does not support the claim."], "Instance": {"id": "task738-06e6e098ae844c36ae9fd2190a7ae30b", "input": "claim:  College education is worth it.\n perspective: Attending college is a great way to network. ", "output": ["support"]}, "Prediction": "support"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-ffcc6924a4c549cdafa6dc4d657e7639", "input": "Sentence 1: They, too, have not produced a practical, commercially acceptable maglev. Sentence 2: Maglev is commercially used.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-6c83d96463084d55896cde1769075da3", "input": "Sentence 1: Allen was renowned for his skill at scratch-building and creating scenery, and he pioneered the technique of weathering his models to make them look old and more realistic. Sentence 2: Allen introduced a new technique of creating realistic scenery.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-4a3ab858d2d24e619b75f9fa62f6f2fe", "input": "Sentence 1: Digging in a different trench Phoenix's robotic Arm connected with a hard surface that has scientists excited about the prospect of next uncovering an icy layer.  \"We have dug a trench and uncovered a hard layer at the same depth as the ice layer in our other trench,\" said Washington University robotic arm investigator for Phoenix, Ray Arvidson. The arm tried at least three times to penetrate the layer, but was unsuccessful. As a result the arm went into a holding pattern, awaiting its next commands. Sentence 2: A robotic arm has been used for scientific discoveries.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-d2167b581dad4811a8dc6008b2403060", "input": "Sentence 1: The Salt Lake City 2002 Winter Olympics will take place from February 8th to February 24th 2002. The Paralympics will take place in Salt Lake City from March 7th to March 16th 2002. Sentence 2: 2002 Olympic Winter games take place in Salt Lake.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-53cd80e55d8a42ff930b56e5d3cc4923", "input": "Sentence 1: The main race track in Qatar is located in Shahaniya, on the Dukhan Road. Sentence 2: Qatar is located in Shahaniya.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-c224f0457d8f44d3830b3ee47c3bdb78", "input": "Sentence 1: A rocket attack killed two Israelis, including a 3-year-old boy. Sentence 2: A three-year-old was killed in a rocket attack.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-184762b3f16a4e4bb38a9df6b33c44af", "input": "Sentence 1: Only 16 women were elected to the 223-member parliament in 1995, and only 2 women hold ministerial posts. Sentence 2: Women are poorly represented in parliament.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-3a993f23ef27405392d59c876c9ce904", "input": "Sentence 1: PARIS \u2014 Julius Meinl V, the scion of a Viennese business dynasty whose name has been synonymous since the days of the Hapsburgs with luxuries like exotic coffee, handmade tortes and discreet private banking, has been jailed on suspicion of fraud at a company linked to the family. Prosecutors accused Mr. Meinl of artificially bolstering shares of the real estate company Meinl European Land on the Vienna stock exchange, even as its investments in real estate across Eastern and Central Europe cratered. Sentence 2: Julius Meinl V is the chairman of Austria's closely-held Meinl Bank.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-22881ef446fb493c82fa0b2eddf252de", "input": "Sentence 1: Three major bombings in less than a week will be causing some anxiety among political leaders in Baghdad and Washington.  Last Thursday 10 people were killed by a car bomb at a crowded cattle market in Babel province, south of Baghdad.  On Sunday more than 30 died when a suicide bomber riding a motorbike blew himself up at a police academy in the capital. Tuesday's bombing in Abu Ghraib also killed and wounded a large number of people - including journalists and local officials. Sentence 2: Some journalists and local officials were killed in one of the three bombings in the Baghdad area.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-8193daefd6ab40a3b8185855290faef6", "input": "Sentence 1: Fast forward a decade or two and scientists began to notice antibiotic-resistant strains of bacteria. Sentence 2: Bacteria is winning the war against antibiotics.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-55d41f3047214ad291a8c026d6152ed9", "input": "Sentence 1: Mr Fitzgibbon expects some of the 17,000 additional US troops heading for Afghanistan will bolster Australian forces operating in the dangerous Oruzgan province in the south. The defence minister was planning to raise the issue specifically with US Defence Secretary Robert Gates. He has already held talks with US central command chief General David Petraeus and director of the Central Intelligence Agency (CIA) Leon Panetta. General Petraeus discussed the new US strategy for Afghanistan and the troop surge in which an extra 17,000 troops will be deployed in the southern provinces where Taliban insurgents have been most active. Sentence 2: David Petraeus is the director of the CIA.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-a52ea7a712b74586abed5cb44686c3d1", "input": "Sentence 1: The US state of Kansas has ruled that science classes in public schools should include the teaching of intelligent design and the doubts it casts on Darwinian evolution. Sentence 2: Intelligent design supports Darwinian evolution.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-d32886d71ef54a6e95ce6070c98422b9", "input": "Sentence 1: The cost of the consumer of the United States fell in June. Sentence 2: U.S. consumer spending dived in June.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-b62df9194c074ee995144bbf227fbc96", "input": "Sentence 1: Brazil, Australia and Thailand argued that the EU, one of the world's largest exporters, broke WTO farm rules by exceeding limits on export subsidies laid down under WTO's 1994 Agreement on Agriculture. Sentence 2: The three countries argued that UE, one of the greater exporter of the world, infringed the rules of the OMC when exceeding the limit of the subsidies to the exports indicated under the Agreement on Agriculture of the OMC in 1994.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-5e744fc59c4943599a56300f44389653", "input": "Sentence 1: The Dutch, who ruled Indonesia until 1949, called the city of Jakarta Batavia. Sentence 2: Formerly ( until 1949 ) Batavia, Jakarta is largest city and capital of Indonesia.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-276406d746b749bd96db51ac0e2e8f44", "input": "Sentence 1: The experiment helped establish that the bacteria came first, causing inflammation, then ulcers. Sentence 2: Inflammation is the result of ulcers.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-8564063002504b63855613de60c3867c", "input": "Sentence 1: US Secretary of State Hillary Clinton has urged all 70 nations attending a conference on Afghanistan's future to help the country succeed. She told delegates at the one-day event in The Hague that the international effort there had been \"undermanned and underfunded\" over recent years. Among the countries to offer help has been US foe Iran. The conference comes after the US announced a major policy rethink on its approach towards Afghanistan. The meeting, called by the UN, comes amid widespread concern that not enough progress has been made since the US-led invasion in 2001. Support for Afghan reconstruction is being sought beyond the mainly-Western countries which have troops there. Sentence 2: Hillary Clinton is the US Secretary of State.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-891977bce1c14985a992896bb7a4000c", "input": "Sentence 1: State Police issued bulletins via teletype requesting patrols to be on the lookout for Robert Senacal, 35, of Cortlandt Manor. Sentence 2: Robert Senacal was arrested by police.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-f77f75e9d3df44b989a11a8128f18359", "input": "Sentence 1: The disputed waters lie close to the Sipadan and Ligitan islands, which Indonesia lost to Malaysia in a legal battle in the International Court of Justice in December 2002. Sentence 2: There is a territorial waters dispute.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-3769a0918a8f4afc93fbebaa80c6ebec", "input": "Sentence 1: The recent 14% hike in third class postage rates, accompanied by simultaneous double-digit paper price increases, has hit smaller catalogers especially hard. Sentence 2: The cost of paper is rising.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-9afdb165f2954d94b7f893b695d616f1", "input": "Sentence 1: A member of the Burmese delegation, Thaung Tun, told reporters on the eve of the meeting that his government did not wish to place ASEAN in a difficult position by insisting on assuming the chairmanship. Sentence 2: Thaung Tun is a representative of Burma.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-84db44245ebc48ec920be1b56131b409", "input": "Sentence 1: A priest who served in the Diocese of Metuchen in the mid-1980s has been sentenced to life in prison for sexually abusing a Massachusetts boy. Sentence 2: Pedophile gets life in prison", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-60cc47daca8a4af6855a9db5e96430bc", "input": "Sentence 1: English has been written using the Latin alphabet since around the ninth century. (Before that, Old English had been written using the Anglo-Saxon Futhorc.) The spelling system or orthography of English is historical, not phonological. Sentence 2: A spelling reform was approved in all German speaking countries.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-e60534d1da674b348354d9143be42605", "input": "Sentence 1: Moscow (USSR), 12 Jul 89 (PRAVDA)- Blood is flowing in Columbia, where last year, according to official statistics, there were 4,600 victims of political violence, including Jaime Pardo Leal (president of Colombia's national coordination committee), around 30 deputies and many municipal advisors and mayors. Sentence 2: Jaime Pardo Leal was killed in Moscow.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-0fc372b1c484441d92c8b29b9451db8a", "input": "Sentence 1: The outlawed Basque political party in Spain, Batasuna, called, on Monday, parties in the Basque Autonomous Government to boycott the parliament decision to ban it. Sentence 2: Spain's Basque party calls for the boycott of a parliament decision.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-a44a76bcd8b74c1cad7174e6dddf9841", "input": "Sentence 1: Military ties between the two countries have been governed officially by an arms embargo imposed by Britain on Argentina. Sentence 2: Britain has maintained an arm embargo.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-fedc8b686c304c0f808d91629be419b6", "input": "Sentence 1: Epiphyte is the name applied to the class of plants which typically do not root in the soil but, rather, attach themselves to trees or other tall objects where they can obtain light and moisture. Sentence 2: Plants are grown in substances other than soil.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-667dc24e94f94e59949c4f6fd2d60286", "input": "Sentence 1: Warrington-born Chris Evans denies he went wild, despite quitting Radio 1 in 1997 and later being sacked by Virgin Radio for not turning up for work during a five-day drinking binge. Sentence 2: Virgin Radio was the employer of Chris Evans.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-e668ccdafb2142b3a4cb1473d25a868a", "input": "Sentence 1: The United Nations last night elected eight judges for the international war crimes tribunal that will try those accused of murders and other atrocities in former Yugoslavia since 1991. Sentence 2: 11 judges in the Yugoslavia war tribunal were sworn in at the World court.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-2bf0447f5d6e40e0a64b835d3c52bcee", "input": "Sentence 1: Officials claimed they were backed by influential members of the Santa Cruz business community of Croatian descent. The security vice-minister, Marcos Farfan, said that police have surveillance photographs of Mr Dwyer at various public events attended by Mr Morales, including a peasant rally near Santa Cruz and a visit to naval installations on Lake Titicaca. Mr Farfan said that Mr Dwyer was \"following\" Mr Morales and other officials as part of the preparations for the \"assassination plot\". He added that police experts are analysing contents reportedly found in computers taken from the rooms in which the men were killed. Sentence 2: Lake Titicaca has a naval installation.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-7cb524f0409f49e593352ec1ac6ded31", "input": "Sentence 1: The release of its report led to calls for a complete ivory trade ban, and at the seventh conference in 1989, the African Elephant was moved to appendix one of the treaty. Sentence 2: The ban on ivory trade has been effective in protecting the elephant from extinction.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-53b51ed7532e485aafb2d4ce0e8ea21c", "input": "Sentence 1: Anna Nobili is no ordinary nun. The 38-year-old used to be a lap-dancer, and spent many years working in Italian nightclubs. She is now using her talents in a rather different way - for what she calls \"The Holy Dance\" in a performance on Tuesday evening at the Holy Cross in Jerusalem Basilica in Rome, in front of senior Catholic clerics including Archbishop Gianfranco Ravasi, head of the Vatican's Cultural Department. Miss Nobili told the BBC World Service that the transformation from podium lap dancer to nun happened gradually. Sentence 2: Anna Nobili became a nun in 2002.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-0e29b9f1fa0c4f1386a3084d782ac7b6", "input": "Sentence 1: The city continued to grow through much of the 20th century. Sentence 2: The city continued to grow, but its services deteriorated.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-c1fc9caf464e4334b6b524d120910487", "input": "Sentence 1: Councilman Pierce said he was advised that the car belonged to James Clark, 68, an acquaintance of the Jones family. Sentence 2: Councilman Pierce owns a car.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-e3bf8792641744d9afb5434cc420dfef", "input": "Sentence 1: This became Aquincum when the Romans established a military camp and civilian town there at the end of the 1st century AD. Sentence 2: One of the first organized settlements on the site, though, was the Roman fortress of Aquincum.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-bf16d7912f2543b084d9d18d7a24e0d5", "input": "Sentence 1: As the storm passed, a celebratory mood took over the city until early Sunday morning, when rap mogul, Suge Knight, was targeted by gunfire at a Kanye West party. Sentence 2: The most notable happening occurred early Sunday morning, when rap-label owner, Marion \"Suge\" Knight, was shot in the leg at a Kanye West party.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-3d37ee6017d84048aca248133dbdd9f4", "input": "Sentence 1: Kurdistan Regional Government Prime Minister Dr. Barham Salih was unharmed after an assassination attempt. Sentence 2: prime minister targeted for assassination", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-917de6925ba74d63ad32c60a0a5cebe5", "input": "Sentence 1: Tom Cruise has returned to The Oprah Winfrey Show and talked about his love for Katie Holmes, but this time he was denying marital problems instead of jumping on the couch to prove his passion for the young actress. \"That's laughable to me,\" Cruise said when Winfrey told him there was speculation that \"what you and Katie have is not real\". It was the first time Cruise appeared on the show since his couch-hopping stunt three years ago drew a flood of satire and ridicule. \"It was something that I just felt that way, and I feel that way about her. That's just how I felt,\" he said in the interview, which aired on Friday in the US. Sentence 2: Tom Cruise is married to Oprah Winfrey.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-210bd777aa2e4cba9b4af7a1a80ba4db", "input": "Sentence 1: But these are only first hazards. \"If the rain continues at the same magnitude and according to the forecast, then some of the rivers could reach flood stage either later [Tuesday] or Wednesday morning,\" said Allan Chapman, a hydrologist with the River Forecast Centre in Victoria. Sentence 2: Allan Chapman is employed at the River Forecast Centre.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-25a1aa165cc3455280e7293dad092d4d", "input": "Sentence 1: World health officials warned yesterday that West Africa and Central Africa were on the verge of the worst polio outbreak in years, stemming from the refusal of a single state in northern Nigeria to vaccinate children against the disease. Sentence 2: African polio outbreak feared", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-7b652a70189c432c96e9472baad7b062", "input": "Sentence 1: Other wildlife, such as gemsbok, zebras and springbok, are also dependent on the Ugab wetlands. Sentence 2: Zebras depend on the Ugab wetlands.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-e1901b69e1294f33a6ddd96795c80639", "input": "Sentence 1: Privacy lawyers are waiting with bated breath to see what the privacy commissioner has to say about this, because it has implications far beyond Google Street View, Bowman said. \"I think we're really at the beginning of this story, not the end.\" Canada's privacy laws require that a person being photographed give their consent to the pictures being published unless they are being taken for journalistic, literary or artistic purposes. However, in post-production, Google now subjects all photos to an automated process of blurring people's faces and licence plates. In addition, anyone can request specific images be removed from the site. \"The privacy concerns could be pretty severe for some and people can still be identified, even with faces blurred out,\" Bowman said. \"I'm not sure how Google is rationalizing compliance with Canadian law by service providers who are taking the pictures here.\" Sentence 2: Google is subjected to Canadian law.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-ecbf05b78aca433f8f7480959193c10f", "input": "Sentence 1: If a Mexican approaches the border, he's assumed to be trying to illegally cross. Sentence 2: Mexicans continue to illegally cross border", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-bdfc760695e541a1b45c1899a5bc95fb", "input": "Sentence 1: A zoo spokesman said the endangered lizards, believed to number less than 4,000 in the wild, all hatched in the last two weeks and 14 eggs are still under observation. He calls it the Komodo's most successful breeding year ever at the zoo. The giant reptiles first arrived in the early 1980s, but the new births brought their total from 34 to 66. The Komodo dragon can grow up to 10 feet long and weigh as much as 150 pounds. They have a bite that can be deadly and can only be found in the wild on the eastern Indonesian islands of Komodo, Padar and Rinca. Sentence 2: A Komodo dragon can be 10 feet long.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-fa7d9afce2b243f693a569bb4c26a04d", "input": "Sentence 1: National currencies will be completely replaced by the euro in within six months after the introduction of euro notes and coins. Sentence 2: The introduction of the euro has been opposed.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-db45c9ed0c2145089ab884417540b168", "input": "Sentence 1: El-Nashar was detained July 14 in Cairo after Britain notified Egyptian authorities that it suspected he may have had links to some of the attackers. Sentence 2: El-Nashar was arrested in Egypt.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-a5f4d4e601db446ab659a7243e5fa012", "input": "Sentence 1: Two trains collided in Shandong, China 4:41am local time on Monday killing at least 71 people and injuring over 400, including four French citizens. It is still not known exactly how many people were on either of the trains. The collision occurred in Zibo when one of the trains traveling from Beijing to Qingdao jumped tracks and collided head on with a train traveling in the opposite direction from Yantai to Xuzhou. Both of the trains are reported to have been traveling at their maximum speeds when they collided. Sentence 2: Zibo is in the vicinity of Beijing.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-ae81306c89584bd98a3a832eeb1c4d79", "input": "Sentence 1: German automaker, Volkswagen AG, launched a special collector's edition of its original Beetle, on Thursday, to mark the end of the line for the most popular car in history. Sentence 2: Volkswagen AG produces the 'Beetle'.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-4393609299cb4944a75a242e8011c489", "input": "Sentence 1: Brought under Ottoman rule in the 16th century, Jordan has been led only since the 1920s by Hashemite rulers, a family whose roots are in present-day Saudi Arabia. Sentence 2: The Hashemite dynasty rules Jordan.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-a8345cfc9a1f4d37a9e0f58044f9dbdf", "input": "Sentence 1: Gross domestic product, a measure of total output within the nation's borders, climbed at a 3% annual pace in the April-June period. Sentence 2: Annual rate increase of 3% in second quarter much lower than forecasts.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-50c7e5bd57fb422eaad7224dc7423485", "input": "Sentence 1: On June 28, 1997, in what would become known as the bite fight, Mike Tyson bit Evander Holyfield's ear, purportedly in retaliation for Holyfield headbutting him. Sentence 2: Mike Tyson bit Evander Holyfield's ear on June 28, 1997.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-c231cd7c1fce4e49918feaeafb41a9ef", "input": "Sentence 1: This opinion poll was conducted on the sixth and seventh of October, and included a cross section of 861 adults with a margin of error estimated at 4%. Sentence 2: This poll was carried out on the 6th and 7th of October, and included a segment of 861 people with a margin of error estimated at 4%.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-a823ef4762134197b4d96e85e0f964c5", "input": "Sentence 1: Chancellor Schroeder has presided over three years of almost zero growth in the economy and an unemployment rate that has remained stubbornly above four million people. Sentence 2: More than four million people have remained stubbornly unemployed in the last three years.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-60fc1465a3b5428a8886acdbda2b0d83", "input": "Sentence 1: Hooper, a salesman of Portland, is accused of posing as a potential home buyer on July 26, then forcing himself inside the residence and raping a 19-year-old woman. Sentence 2: Hooper bought a house in Portland.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-c1b2ba6937244ecd826c33156d23007f", "input": "Sentence 1: On the morning of 1 June, there was a blackout throughout most of the capital caused by urban commandos of the Farabundo Marti National Liberation Front (FMLN). Sentence 2: FMLN caused a blackout in the capital.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-e6f54e01fb7f473e8789b4a384450d94", "input": "Sentence 1: The 26-member International Energy Agency said, Friday, that member countries would release oil to help relieve the U.S. fuel crisis caused by Hurricane Katrina. Sentence 2: The United States has asked member states of the International Energy Agency to provide oil.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-30c95f08c77046b5a91f945ad1297776", "input": "Sentence 1: Rome is in Lazio province and Naples in Campania. Sentence 2: Rome is located in Lazio province.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-27253c1b4d2e49a6be7250940e17583a", "input": "Sentence 1: Anglo/Dutch Royal Dutch Shell, Total, of France, and Spain's Repsol were all named as examples of established oil companies involved in the oil-for-food programme before surcharges began in 2001. Sentence 2: Total participated in the oil-for-food programme.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-2a5ad5103d0849a9827653fec448cff1", "input": "Sentence 1: On Thursday, Syria said that it supports Iran's nuclear stance and said it \"has a right to atomic technology,\" and said Western objections to Tehran's nuclear ambitions were \"not persuasive.\" It comes in the wake of demands by US and European countries for Iran to halt its nuclear fuel enrichment activities. Iran notes that its nuclear program is civilian and consistent with Article IV of the Nuclear Non-Proliferation Treaty, which establishes the inalienable right of all the Parties to the Treaty to develop research, production and use of nuclear energy for peaceful purposes, and that it in line with Article IV, it will not abandon its enrichment efforts. Sentence 2: Iran is backed up by Syria.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-cdbbfecec1624160b8c872f73d220456", "input": "Sentence 1: Those accused of the assassination of six Jesuits, if found guilty, will be punished whether they are civilians, military, or influential people. Sentence 2: Six Jesuits were killed by civilians.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-db58fc97082a4a7db0becc658657cc14", "input": "Sentence 1: Reagan was seriously wounded by a bullet fired by John Hinckley Jr. Sentence 2: John W. Hinckley Jr. shot Reagan in the chest.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-235a0ae565374593b4ac8752f3a723a2", "input": "Sentence 1: Hydrogen cyanide is used in manufacturing chemicals such as tryptophan and other amino acids. Sentence 2: Cyanide is used in the production of pharmaceuticals.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-c326e71c168c435bb1936a8759123aa4", "input": "Sentence 1: Zhang and his co-workers performed behavioral tests on two purified cannabinoids. The test results indicated that these two cannabinoids have anti-anxiety and antidepression-like effects in rats that may depend on the ability of cannabinoids to promote the production of new neurons in the hippocampus. Marijuana contains a complex mixture of chemicals including cannabinoids and may have somewhat different behavioral effects than the purified cannabinoids tested so far. Sentence 2: The use of drugs can help control anxiety.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-c2871b8eeeec4cd49e0c655636ccbc08", "input": "Sentence 1: The surge in violence has occurred while U.S. Marines and Iraqi troops battle insurgents near Karabilah on the Syrian border. British and American warplanes pounded targets to support a 1,000 Marine force. A Marine statement also said patrols in the devastated city of Fallujah came under attack Sunday. According to the statement, 15 insurgents were killed while the attack was repulsed. Sentence 2: Fallujah is not far from Karabilah.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-fa8a1686205546f2853b07bf20a623e1", "input": "Sentence 1: Zinedine Zidane has beaten Thierry Henry and Ronaldo to the Fifa 2003 World Player of the Year award. Sentence 2: FIFA selects world football player of the year 1994.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-a9ae4aca850e4f45a4b898dc3e108562", "input": "Sentence 1: In addition to family, the memorial service was attended by actors and actresses who have worked with Ledger, including Cate Blanchett who starred with Ledger in the Bob Dylan bio-flick, I'm Not There. Blanchett spoke of the times she shared with Ledger in New York and Los Angeles. The Other speakers included his parents, sister and Neil Armfield, a director of Ledger's last Australian film, Candy. An emotional Williams, was wearing dark glasses and a white dress with black trim, she was not accompanied by her daughter Matilda. Williams walked in clutching the arm of Ledger's older sister, Kate. Sentence 2: Williams has a daughter called Matilda.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-3381a290394443e7bd589c7d110a8efd", "input": "Sentence 1: Our best evidence is that the crustal magma chamber is filling with molten rock. But we have no idea how long this process goes on before there either is an eruption or the inflow of molten rock stops and the caldera deflates again, added Smith. Volcanic activity in Yellowstone heats up underground water which create geysers of superheated water, and is responsible for the creation and continuous eruption of Old Faithful. Sentence 2: There is a volcano in Yellowstone.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-ddf38d933f69458b909c222668424cb0", "input": "Sentence 1: A joint survey by two conservation groups, World Conservation Union and the World Wildlife Fund, says the black rhino population has risen to over 3,600. That is an increase of 500 animals over the last two years. Sentence 2: Two conservation groups have increased the black rhino population.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-ee76d76f66894d61a7c5ec66b5b87c28", "input": "Sentence 1: Libya's case against Britain and the US concerns the dispute over their demand for extradition of Libyans charged with blowing up a Pan Am jet over Lockerbie in 1988. Sentence 2: One case involved the extradition of Libyan suspects in the Pan Am Lockerbie bombing.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-29be87e9de6049b4884fbbb6eb74aa71", "input": "Sentence 1: The increased amounts of carbon dioxide (CO2) and other greenhouse gases (GHGs) are the primary causes of the human-induced component of global warming. Sentence 2: Greenhouse effect changes global climate.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-5f1c6df6050a48769c61e67ed9e74eb8", "input": "Sentence 1: Since '82 Federal Chancellor (elected by \"constructive vote of no confidence\" against former Chancellor Helmut Schmidt, Social Democratic Party (SPD); reelected 1983, 1987, 1991 and 1994). This makes Helmut Kohl the longest-serving chancellor of the Federal Republic, passing by Konrad Adenauer, the first chancellor, this October. Sentence 2: The name of Helmut Kohl's political party is the Christian Democratic Union.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-c13c979ee9834fc097ff083de7cc41fe", "input": "Sentence 1: Tourists pay millions of dollars a year to come and see Africa 's wildlife and smugglers pay millions more in strictly illegal purchases of ivory and rhino horn from poachers. Sentence 2: African countries encourage keeping animals alive to attract tourists.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-7bc8f6a84b2b446d9b6f332d8d0804d0", "input": "Sentence 1: Authorities say Monica Meadows, who has appeared in catalogs and magazines, is in stable condition. Sentence 2: Monica Meadows is in stable condition.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-ac01f8dc32f04d5d955eca945ede1c0f", "input": "Sentence 1: Bush's second term as President of the United States, which began on January 20, 2005, expired with the swearing-in of the 44th President of the United States, Barack Obama, at noon EST (UTC-5), under the provisions of the Twentieth Amendment to the United States Constitution. Bush performed his final official act this morning, welcoming Barack Obama and Michelle to the White House for coffee before the swearing-in, shortly before 10am EST, and then accompanied them there by motorcade to attend the ceremony. Last week, Bush had made his farewells to the nation in a televised address, saying that the inauguration turns a page in race relations. \"Obama's story \u2015his black father was from Kenya, his white mother from Kansas \u2015represents \"the enduring promise of our land,\" said Bush. Sentence 2: Barak Obama is the 44th President of the United States.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-31d8416012f54723a599383aca1f19f2", "input": "Sentence 1: Kaspars Ruklis, press official at the United States Embassy, told the Baltic News Service that Mrs. Bush chose to visit Latvia's Occupation. Sentence 2: Kaspars Ruklis works for the United States Embassy.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-611ffe11a057483eb59f2ac5ce2731b8", "input": "Sentence 1: Gastrointestinal bleeding can happen as an adverse effect of non-steroidal anti-inflammatory drugs such as aspirin or ibuprofen. Sentence 2: Aspirin prevents gastrointestinal bleeding.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-8a608a93cb424793ad15bfc963dcebc9", "input": "Sentence 1: Long-distance telephone company MCI Inc., on Friday, touted its $6.75 billion deal to be bought by Verizon Communications Inc., but said it would thoroughly analyze a revised $8 billion bid by Qwest Communications International Inc. Sentence 2: MCI made no mention of its planned $6.7 billion agreement to be acquired by Verizon Communications in its release, Friday.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-7478371dad284fa6a62e8e399f964b7a", "input": "Sentence 1: Ronaldo Luiz Nazario da Silva is quite simply one of the greatest strikers in the history of world football, capable of leaving an entire team for dead with his darting runs and dribbling ability, voted FIFA World Player of the Year on three occasions and already a double FIFA World Cup winner. Sentence 2: FIFA selects world football player of the year 1994.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-b0801905d81843cdbf19ff414479bfde", "input": "Sentence 1: The new study refutes earlier findings by researchers at the University of California, Los Angeles, who concluded that the odds of getting head and neck cancers rose in tandem with the frequency and duration of marijuana use. Sentence 2: The latest findings contradict a California study that implicated regular pot smoking as having markedly higher risks for head and neck cancers.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-5f1f1e3d6681453bacdf2cfa82df5a35", "input": "Sentence 1: The Heads of state reiterated their deep concern for the serious threat that the rising trend in drug abuse poses for society and the lives and future of children and youth, and for the destabilizing effects that illegal use, production, trafficking and distribution of narcotic drugs psychotropic substances and drug-related offences have for the affected countries of the South Asian region. Sentence 2: The Heads of state expressed their deep concern at the fast and continuing degradation of the environment, including extensive destruction of forests, in the South Asian region.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-36585ba086f84ff7802da3a42833f11d", "input": "Sentence 1: In the glamorous, exclusive world of French haute couture, Sakina M'Sa is an unlikely star. Like her creations, M'Sa is the sum of many parts - a tiny woman from the Comoros, an immigrant from a working-class neighbourhood in Marseille, and a designer who follows her own dreams and embroiders the fashion world with a social conscience. \"My only strength in life is my difference,\" says M'Sa, dressed all in black and sitting in her workshop and showroom in La Goutte d'Or, a working-class neighbourhood in Paris which is home to a large population of Africans. Sentence 2: Sakina M'Sa has Comoros origins.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-f71f94c5c4834cda866a21bc71c7622d", "input": "Sentence 1: Colarusso, the Dover police captain, said authorities are interested in whether their suspect made a cell phone call while he was in the Dover woman's home. Sentence 2: Colarusso works for Dover police.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-84cbad61f136438b95be531c95fc5b8e", "input": "Sentence 1: Edwin Hubble is recongized as having been one of the foremost astronomers of the modern era. Sentence 2: Edwin Hubble was an astronomer.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-e33d6251545549fcbe96317270ce27ad", "input": "Sentence 1: Once called the \"Queen of the Danube,\" Budapest has long been the focal point of the nation and a lively cultural centre. Sentence 2: Budapest was once popularly known as the \"Queen of the Danube.\"", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-72c2a6bb441246babbbec981caad49e4", "input": "Sentence 1: September 26 - Trial against former Italian Prime Minister Giulio Andreotti, accused of Mafia connections, begins. Sentence 2: Andreotti is accused of Mafia collusion.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-8d6a25a83cb043e1baface0b7864aea1", "input": "Sentence 1: In sub-Saharan Africa about one in every 30 people is infected with HIV. Sentence 2: 30% of the people infected with HIV live in Africa.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-ae9690a0103848b4ba49faa5a2c94217", "input": "Sentence 1: There are four identified subtypes of Ebola virus. Three of the four have caused disease in humans: Ebola-Zaire, Ebola-Sudan, and Ebola-Ivory Coast. The fourth, Ebola-Reston, has caused disease in non-human primates, but not in humans. Sentence 2: The Ebola epidemic breaks out in Zaire.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-06f2195d84cf4b4099c8c65b96c1dcf4", "input": "Sentence 1: As a real native Detroiter, I want to remind everyone that Madonna is from Bay City, Mich., a nice place in the thumb of the state's lower peninsula. Sentence 2: Madonna was born in Bay City, Mich.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-9e0280dcb85f48c7b5b5e29a079f051b", "input": "Sentence 1: Mr Gregory's conclusion in 1994 was that the ceremony, transferred to the more convenient nearest Sunday, was dying out. However, that year the Conservative government proclaimed \"festivities\" to celebrate the 50th anniversary of the Normandy landings. Sentence 2: 50th Anniversary of Normandy Landings lasts a year.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-e4ff1e2b663e46cea065502a9e46e4d8", "input": "Sentence 1: Reagan announced he had Alzheimer's disease, an incurable brain affliction. Sentence 2: Reagan died of pneumonia complicated by Alzheimer's disease", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-c1200437f47e41169772408c9a72c7db", "input": "Sentence 1: I recently took a round trip from Abuja to Yola, the capital of Adamawa State and back to Abuja, with a fourteen-seater bus. Sentence 2: Abuja is located in Adamawa State.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-ba26b25487494a1db647d3b62305740f", "input": "Sentence 1: A second man, aged 24, technically freed yesterday was bailed after being questioned over alleged forged identity documents, but has been further detained on immigration matters, a spokesman for Scotland Yard said. Sentence 2: A spokesman for Scotland Yard was freed yesterday.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-e2e0b311e9054658a24644d11122ce31", "input": "Sentence 1: Victor Emmanuel III yielded most of his powers to his son Umberto II in 1944, when Umberto was appointed as Lieutenant General of the Realm, and finally abdicated in 1946. Sentence 2: Victor Emmanuel III was king of Italy from 1900 to 1946.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-67fb90b55c9e4aab8d6b4a23a6f8cbac", "input": "Sentence 1: Crude oil dips below $43 on news that Russia's justice ministry will not force Yukos to halt sales. Sentence 2: Crude oil rises.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-750072bd154a47a8a96f4b9f3d2c9839", "input": "Sentence 1: It would help the economy by putting people back to work and more money in the hands of consumers. Sentence 2: More money in the hands of consumers means more money can be spent to get the economy going.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-38dc3c42a45d404b8ae582b523f61f5e", "input": "Sentence 1: Twenty years ago, on June 6, 1968, Sen. Robert F. Kennedy died at Good Samaritan Hospital in Los Angeles, 25 -LCB- hours after he was shot at the Ambassador Hotel by Sirhan Bishara Sirhan. Sentence 2: Sirhan Bishara Sirhan killed Sen. Robert F. Kennedy", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-3c6ed8c11b3f4ee093984df63cefaad3", "input": "Sentence 1: John Lennon's widow, Yoko Ono, has topped the US dance chart at the age of 71 with a song supporting gay marriage. Sentence 2: Yoko Ono is John Lennon's widow.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-1330c0a206d841b9a8136ef1ef791368", "input": "Sentence 1: In addition to data bases and publicity, stolen art is recovered when someone seeks appraisal or offers it for sale to dealers or auction houses, responds to a reward offer, attempts to remove it through customs, or requests a ransom for the art. Sentence 2: Centralized inventory records for museums aid in theft awareness.", "output": ["0"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-0af5eeb4b25c457ba5c878d574986b33", "input": "Sentence 1: The sale was made to pay Yukos' US$ 27.5 billion tax bill, Yuganskneftegaz was originally sold for US$9.4 billion to a little known company Baikalfinansgroup which was later bought by the Russian state-owned oil company Rosneft. Sentence 2: Rosneft belonged to the Russian State.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1344_glue_entailment_classification_gpt3_0", "Definition": ["In this task, you're given two sentences. Indicate if the first sentence clearly entails the second sentence (i.e., one can conclude the 2nd sentence by reading the 1st one). Indicate your answer with '1' if the first sentence entails the second sentence, otherwise answer with '0'. (1) 0: Sentence 1: No Weapons of Mass Destruction Found in Iraq Yet. Sentence 2:Weapons of Mass Destruction Found in Iraq. Output: 0 Explanation: In our first statement we clearly say that Iraq does not have any weapon of mass destruction but the second sentence says that weapon of mass destruction is found in Iraq which is contradiction. Hence output will be 0 for non entailment.  1: Sentence 1: A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI. Sentence 2: Pope Benedict XVI is the new leader of the Roman Catholic Church. Output: 1 Explanation: In the given first sentence we"], "Instance": {"id": "task1344-fda86dc21b7f42daa9798bb507779f2f", "input": "Sentence 1: The anti-terrorist court found two men guilty of murdering Shapour Bakhtiar and his secretary Sorush Katibeh, who were found with their throats cut in August 1991. Sentence 2: Shapour Bakhtiar died in 1991.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-9612e12fc58e4dc889c4cda5756302fe", "input": "sentence_A: A woman dressed in elegant clothing is inside a crowd of people and is looking down. sentence_B: An elegant woman is inside a crowd of people and is looking down", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-65afe60bdb8e4244a0e5bd09f11cfa61", "input": "sentence_A: The lady is cracking an egg for the mixer. sentence_B: The lady isn't cracking an egg for the mixer", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-62072dfbe2514309a1bb878b725a6a20", "input": "sentence_A: Several people are sitting at small tables in a light room. sentence_B: Several people are sitting at small tables in a darkened room", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-4e6240aa99e94f5da2815fa1bdf2c989", "input": "sentence_A: Two women dressed in white and black are sitting on a bench. sentence_B: Two people are sitting on a park bench on a rainy day", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-1d7abd6832d24908b328f79d4f35a8a8", "input": "sentence_A: The crowd is watching a football game. sentence_B: A group of football players is running in the field", "output": ["B_neutral_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-e8771a22c0094267aa73a29374dd59fc", "input": "sentence_A: A car is riskily jumping over a girl. sentence_B: One girl is jumping on the car", "output": ["B_neutral_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-06cd4e3fa5ba457fb83aec6286ed6792", "input": "sentence_A: An opponent is tackling a soccer player. sentence_B: A soccer player is being tackled by his opponent", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-a46ddbba4110484f97fc9eb7ec2d7369", "input": "sentence_A: The dog is chasing the ball. sentence_B: A dog is chasing a ball", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-f7964ffe39fd499a9bcbc9d5c39b6b02", "input": "sentence_A: A man is shooting a weapon. sentence_B: A woman is riding a horse", "output": ["B_neutral_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-54acc829f98445659b73083dd0e310f1", "input": "sentence_A: Two large park benches have a person sitting and a bottle of soda between them. sentence_B: Two large persons are sitting on a park bench and they have a bottle of soda between them", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-de6cccc396ac435db7312f4d6331d603", "input": "sentence_A: A man is talking to the woman who is seated beside him and is driving a car. sentence_B: A woman is driving a car and is talking to the man who is seated beside her", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-03838fb581ab48c6af2abdc38dc224b6", "input": "sentence_A: A man is slicing some bread. sentence_B: A man is cutting a slice of bread", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-5c82e05285ab463e8617196bbf998faa", "input": "sentence_A: The brown dog is jumping in the air. sentence_B: A brown dog is jumping in the air", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-17e36c15251e44be9d2366f31d32f42d", "input": "sentence_A: A girl is applying makeup to her face. sentence_B: The girl is applying makeup to her face", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-63ef076209b0429b959dbe7e4bc3901d", "input": "sentence_A: A young boy is jumping off a chair. sentence_B: A young boy is jumping onto a chair", "output": ["B_contradicts_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-387512f54b4e459ba116b567bc026a39", "input": "sentence_A: There is no man on a rock high above some trees standing in a strange position. sentence_B: A man is on a rock high above some trees and is standing in a strange position", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-0841adf81fcb4cc2a2b5a73d619b2247", "input": "sentence_A: Two men are leaving the stage. sentence_B: Mimes are performing on a stage", "output": ["B_neutral_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-912e6740cb074342911e7bbd51994162", "input": "sentence_A: The brown horse is near a red barrel at the rodeo. sentence_B: The brown horse is far from a red barrel at the rodeo", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-9b9b2a36101d4ecc9e8461f840310eb9", "input": "sentence_A: A person, who is riding a bike, is wearing gear which is black. sentence_B: A biker is wearing gear which is black", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-bd435effc719460f9d06f538aaf242bc", "input": "sentence_A: The woman is chopping some bread and fried pork. sentence_B: The woman is frying a breaded pork chop", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-d2bba8b606664f1dbe50fc9618570ca6", "input": "sentence_A: A woman is not slicing garlic. sentence_B: A woman is slicing an onion", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-ba9c870543964bbc8a75c34e5fe6a976", "input": "sentence_A: The girl in the blue and white uniform isn't cheering. sentence_B: The girl in the blue and white uniform is cheering", "output": ["B_contradicts_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-24f29ee6139c4be1a6036bc3f3e22ffd", "input": "sentence_A: The woman is not dicing garlic. sentence_B: The woman is dicing garlic", "output": ["B_contradicts_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-b606c2840ad94f73b9412a480f1c1331", "input": "sentence_A: A boy in a red shirt is in front of a long blue wall and is suspiciously raising an eyebrow at the camera. sentence_B: A boy is standing in front of the blue building in the space reserved for handicapped people", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-624ed64547af4d95925d346ed74e42b6", "input": "sentence_A: A man is pouring liquid into a pot. sentence_B: The chef is carefully pouring some oil into a pan", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-a1c38e8bc0154883910ee4584b36cfbb", "input": "sentence_A: A man is opening a package that contains headphones. sentence_B: A man who is wearing headphones is opening a package", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-f0faa9c62f3742f7b8e45053c6e24347", "input": "sentence_A: The man is absently eating a banana by a tree. sentence_B: The man is eating a banana by a tree", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-149bf7a65e6c46c7ac03823dbfdcf31f", "input": "sentence_A: People are walking through a crowded street. sentence_B: People are walking through a street which is crowded", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-74fb51b049f24efaa8efb2a22a88ebc1", "input": "sentence_A: The man with the dyed purple hat is operating a camera that makes videos. sentence_B: The man in the purple hat is operating a camera that makes videos", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-b92ec02548a041478e1982612dabb402", "input": "sentence_A: The young girl is blowing a bubble that is huge. sentence_B: The young girl is blowing a bubble that is very small", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-3b521c44ae9b43a4b960e68e87406e24", "input": "sentence_A: Some boys being dressed with a carpet are sitting on two red tuxedos. sentence_B: Two little boys are wearing tuxedos", "output": ["B_neutral_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-5d43a7dc630a4804b76b33fd3123b20e", "input": "sentence_A: A person is throwing a cat at the ceiling. sentence_B: A cat is thrown at the ceiling by a person", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-90c166765e4f484eadde57d5896501d4", "input": "sentence_A: The band is singing. sentence_B: The band isn't singing", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-11414ded733149e5ad28de53ef75749e", "input": "sentence_A: Two brown dogs are playing with a frisbee in the water. sentence_B: Two brown dogs are playing with the frisbee in the water", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-544d945fe06f4ee18ad532d4392ffcd8", "input": "sentence_A: There is no woman peeling a potato. sentence_B: The potato is being peeled by a woman", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-e5cb28cc633f42a7badeb2f8372c9ffa", "input": "sentence_A: The man is slicing potatoes. sentence_B: A potato is being peeled by a woman", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-5e47bc5d526144e386b6e31959bc66c3", "input": "sentence_A: A black and white dog is carrying a small stick on the green grass. sentence_B: A black and white dog with a large branch is running in the field", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-509a3190eefe46628ac037d5ed555dab", "input": "sentence_A: A little boy is playing a guitar. sentence_B: A young boy is playing a guitar", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-794fe7fe09dd40faa38cb8dae2fa7c2b", "input": "sentence_A: A man is slicing a potato. sentence_B: There is no man slicing a potato", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-04c217ac94c64f66b726091069cdba49", "input": "sentence_A: Two people are standing in the ocean and watching the sunset. sentence_B: Two people are standing in the ocean and looking at the sunset", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-fac0c21950344eddb3ef405818d07dc7", "input": "sentence_A: Nobody is cutting a capsicum into pieces. sentence_B: The person is slicing a clove of garlic into pieces", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-a09c9ac884ea4367bd47bc7f99053641", "input": "sentence_A: The man is funnily playing the piano with his nose. sentence_B: A man is playing the keyboard with his nose", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-01ee49d00b9941eab2b7e2d4489a3746", "input": "sentence_A: A cyclist is biking in a snowy forest at day. sentence_B: A cyclist is biking in a snowy forest at night", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-3cca3dc5bd7a4ab5bb0020ed7a5dee76", "input": "sentence_A: Guitar is being played by a man. sentence_B: A man is playing guitar", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-a2843c2f30eb455eb3af97360723c04b", "input": "sentence_A: A race car driver is standing up and pointing his hand at the sky. sentence_B: The person in the blue jacket is putting down a colorful helmet", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-f943afd344c24bad91a178d2677f286d", "input": "sentence_A: A man is running on the road. sentence_B: The man is running on the road", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-f2e8047096eb410e85e81f30d009e5ab", "input": "sentence_A: Two white dogs and one brown dog are chasing a ball. sentence_B: Two white dogs and one brown dog are chasing a toy", "output": ["B_neutral_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-52ca50c816c849a4900633ba0a427cf0", "input": "sentence_A: A dog is swimming after a tennis ball. sentence_B: A cat is swimming after a tennis ball", "output": ["B_neutral_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-45b4c14d5e00463eaab4147764cbd060", "input": "sentence_A: Two guys are sitting around a table and holding beers in their hands. sentence_B: Two blokes are sitting around a table and holding beers in their hands", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-46362740900143bfbf9a692c000b1074", "input": "sentence_A: The man is slicing a potato. sentence_B: Potatoes are being sliced by a man", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-bd0ec61b66e949428e73338dbf0610d6", "input": "sentence_A: The horse is being ridden by the girl. sentence_B: The girl is riding the horse", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-5195ca184f024478b39cff8afd5eb32d", "input": "sentence_A: A dog is missing the ball in mid air. sentence_B: A dog is catching a ball in mid air", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-774f4a099b30475c86e42bc4e03a2722", "input": "sentence_A: There is no man massaging a woman. sentence_B: A man is massaging a woman", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-4584884377cb43e5945194d051ddf2ea", "input": "sentence_A: A boy is knocking a dog with a bottle of water. sentence_B: The dog is knocking a boy into the water", "output": ["B_neutral_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-4e8aff477e5f41bc8842b775b3847d81", "input": "sentence_A: There is no woman frying something. sentence_B: A woman is frying something", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-0fa7d83ad83b40078fefdaa5c7765ed2", "input": "sentence_A: Five adults are sitting on stone steps. sentence_B: Five adults are sitting on steps made of stone", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-73b6b24e70ce47f7bd4985b483494945", "input": "sentence_A: The young boy is running through the ocean waves. sentence_B: A child is running in and out of the waves of the ocean", "output": ["B_neutral_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-9ced3d0e2f4f4db58e7d5912befecb28", "input": "sentence_A: A person is playing a trumpet. sentence_B: There is no man playing the guitar", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-b66264605e2d466f921dd7227defc88c", "input": "sentence_A: Two men are playing table tennis. sentence_B: Two men are playing ping pong", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-2ad54246a49d4e62b0e7e3d7ae7fa487", "input": "sentence_A: A herd of deer is crossing the street. sentence_B: One herd of deer is crossing the street", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-084ded9231ea4ef4ae87f115a23448a4", "input": "sentence_A: A man is jumping into a pool. sentence_B: A man is diving into a pool", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-2b9345ee803345bc9907022a37728935", "input": "sentence_A: A father is pushing his daughter on a go-kart and another girl is watching. sentence_B: Two small children are playing with a toy car in the street", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-cb82f8ea5d194d01b65a5500a8c8e70b", "input": "sentence_A: A man is jumping a wall. sentence_B: A man is standing in front of a wall", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-6cd6b1a11f854036b9b3a6b7d38ffe86", "input": "sentence_A: A woman is removing the peel of a potato. sentence_B: A woman is slicing a tomato", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-135dc146880f4d8cbf9bf80381423cc4", "input": "sentence_A: The little boy is riding a bicycle in a race. sentence_B: The little girl is riding a bicycle in a race", "output": ["B_neutral_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-14814638c3a5405599ca074b2fc13669", "input": "sentence_A: A little girl is hitting a baseball off a tee. sentence_B: A little boy in a pink shirt is playing t-ball and taking a swing", "output": ["B_neutral_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-44eb8bc1b90a45c3a69e38d824d59da6", "input": "sentence_A: The man is singing heartily and playing the guitar. sentence_B: A bicyclist is holding a bike over his head in a group of people", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-ae545b7960dc4ff9a05216a145284595", "input": "sentence_A: A hurdle is being leapt by a horse that has a rider on its back. sentence_B: A horse is leaping a hurdle and has a rider on its back", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-4eb81dc33fe04c098f989bb17ea27133", "input": "sentence_A: The trumpet is being played by a man. sentence_B: A man is playing the trumpet", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-40c11445b85c4205bb1f1646f5ff3bf5", "input": "sentence_A: People are walking outside a building that has many murals on it. sentence_B: Nobody is in front of the colorful building", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-ae1efe3cd7c741bb8c6a980b1d3d9254", "input": "sentence_A: Two cats are fighting each other. sentence_B: The cats are playing with each other", "output": ["B_contradicts_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-abc80a80481c40fda03119c6eb98646a", "input": "sentence_A: A woman is standing and isn't looking at the waterfall. sentence_B: A woman is sitting and looking at the waterfall", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-59cc69d818fb452983b70251423df05f", "input": "sentence_A: Ingredients are being poured into a bowl by a woman. sentence_B: A woman is pouring ingredients into a bowl", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-d600e4327bc8412e879e17eecdc89aa7", "input": "sentence_A: The man is riding a horse. sentence_B: A man is riding a horse", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-78390c8639304fe7b248bab5dbae0705", "input": "sentence_A: Someone is playing the guitar. sentence_B: Someone is dismantling a piano", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-5c7602f01b5d4d80ba0944e2fdfb6006", "input": "sentence_A: The person is riding the horse. sentence_B: The person is not riding the horse", "output": ["B_contradicts_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-06776607ef56425e8791817fb7c5cbf9", "input": "sentence_A: A white dog is leaping from a cylindrical hay bale. sentence_B: A black dog is leaping from a cylindrical hay bale", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-a29bee85fdbe47da82d118bda0f7f4fa", "input": "sentence_A: The woman is picking up a baby kangaroo. sentence_B: The woman is not picking up a baby kangaroo", "output": ["B_contradicts_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-17f070024c4440aeaec56bda5ab1ba38", "input": "sentence_A: A woman is standing near three children. sentence_B: There is no woman standing near three children", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-fa1e8ddee455449988cdd717ca99b217", "input": "sentence_A: A man is singing and playing a guitar. sentence_B: A man is playing a guitar", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-90f51520d8594027bbf9d84ed66e9a87", "input": "sentence_A: A woman is cutting a tomato. sentence_B: A woman is slicing a tomato", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-b5fee60a807644f394be8ea9adb17b90", "input": "sentence_A: The panda bear is lying on the logs. sentence_B: A cute panda is not lying down", "output": ["B_contradicts_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-69f3a039c54d49409e0da416bfb7f51f", "input": "sentence_A: There is no white dog standing on the leaves on the ground. sentence_B: A white dog is standing on the leaves on the ground", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-2dbae6252392412f9a0b95321c5f158d", "input": "sentence_A: A person is not tearing paper. sentence_B: A person is tearing paper", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-117ed8eb1e96457890556e27199e80bc", "input": "sentence_A: A man is walking a woman through the woods. sentence_B: The man and woman are walking", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-579112e6586348f98ae108bc9c8eed23", "input": "sentence_A: A young boy is jumping out of the water. sentence_B: A young boy is jumping into water", "output": ["B_contradicts_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-fa8cee88ea0640859d77bfa9eb361cf1", "input": "sentence_A: The black dog is walking along a tree trunk bridge over water. sentence_B: There is no dog crossing a river on a bridge made from a fallen tree", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-4487aedcf0e24f7c8c38053333a9403d", "input": "sentence_A: The cop is not sitting on a police bike. sentence_B: The cop is sitting on a police bike", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-bbf58c5ee1ac4b12baaadbc6eb59b85c", "input": "sentence_A: Two girls are not playing inside the jumper house. sentence_B: Two girls are playing inside a jumper house", "output": ["B_contradicts_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-f4eb9792fd6e49ffad7ea5e5b15e3a2d", "input": "sentence_A: The oil is being stirred by a man. sentence_B: The man is stirring oil", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-34834d1ca5db4560b950db451d2e4e98", "input": "sentence_A: The piece of paper is being cut. sentence_B: There is no paper being cut with scissors", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-48ed498b561d4bd0b9877692ae4024be", "input": "sentence_A: A cheetah is quickly running behind its prey.. sentence_B: There is no cheetah quickly running behind its prey", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-b8d697a3e7414ce6a8f3c50190c7a84c", "input": "sentence_A: The group of people is sitting on a rocky ledge and a scenic view is behind them. sentence_B: The group of people is not sitting on a rocky ledge with a scenic view behind them", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-45fa190a6627441f90dd837fd4ce4e7c", "input": "sentence_A: Two men are riding an orange raft on the shore. sentence_B: Two men are getting off of an orange raft on the shore", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-11e57fb93c4a4a6d83ff1124cd1297a7", "input": "sentence_A: A woman is coating a pork chop. sentence_B: A cook is coating a pork chop", "output": ["B_neutral_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-f3c31fb2760d46fb8ee3dae58fbb41c5", "input": "sentence_A: One panda is eating a bamboo cane. sentence_B: The panda is eating bamboo", "output": ["B_entails_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-82020768f3f7493b8f1c73b67b548031", "input": "sentence_A: The boy is studying a calendar. sentence_B: A boy is studying a calendar", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-7dd634ca1b1e4b4c9608cc81c2248189", "input": "sentence_A: A bike rider in a black and red uniform is jumping down off a dirt bike. sentence_B: A person is riding a bike", "output": ["B_neutral_A"]}, "Prediction": "B_neutral_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-de1d6064a924486a89a125e9f23341f3", "input": "sentence_A: The man and the boy are standing at the bottom of the stairs, which are outdoors. sentence_B: A man and a boy are standing at the bottom of some stairs, which are outdoors", "output": ["B_entails_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task1615_sick_tclassify_b_relation_a_gpt3_0", "Definition": ["In this task, given 2 input sentences, you must classify the relation between them. If the second sentence has a similar meaning to that of the first sentence then the output is ' B_entails_A', if the second sentence has the opposite meaning to the first sentence then it is classified as ' B_contradicts_A'. If you cannot clearly ascertain agreement/disagreement between the two sentences, the label is ' B_neutral_A'. B_contradicts_A:  The model should output B_contradicts_A when the sentence B has the opposite meaning as sentence A. For example, if sentence A says \"A man is wearing a hat\", but sentence B says \"No man with a hat\", then B is contradicting A."], "Instance": {"id": "task1615-8f21fdff378d4176b9b028a5b2ccdc01", "input": "sentence_A: A man is cutting a box. sentence_B: There is no man cutting a box", "output": ["B_contradicts_A"]}, "Prediction": "B_contradicts_A"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-037d10a448e846e7b08ddcaf354a0d3f", "input": "sentence1:region is being bombed by organization_member sentence1:organization_member is bombing  region ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-17c8787058c84b05ab694bcba92db298", "input": "sentence1:location is handing to organization_founder sentence1:location is seeing  organization_founder ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-3505da1190ad44d7b0ecd419131149bb", "input": "sentence1:location is hub of location sentence1:location is one of city in location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-6afa615e848f4d4fb3877427fc8464e6", "input": "sentence1:person is elected President of location sentence1:person is leading  location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-0421b6f4fe394d6a843ee83a2e6f7e4e", "input": "sentence1:organization_founder is president of location sentence1:organization_founder is President of location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-0f11b44415d4409e8f55b661259e2960", "input": "sentence1:employer is continuing to work with organization_founder sentence1:organization_founder is passing  employer ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-f53bd5f808ce499b998747613c7fd958", "input": "sentence1:organization is carrying from location sentence1:organization is carrying to location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-a0637cd076504dc191a101516605352d", "input": "sentence1:organization_founder is restoring to location sentence1:organization_founder is sending to location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-7437f563b2f84906a823464c13e91f4c", "input": "sentence1:employer is targeting  employer sentence1:employer is going after employer ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-c6fec9a51e9a4dbc818145772b7f1367", "input": "sentence1:organization_member is planning invasion of location sentence1:organization_member is withdrawing from location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-26b937796dd547d79c1a56dbb9b5072c", "input": "sentence1:person is holding lead over person sentence1:person is facing against person ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-ec1300f051e04d40b7f6594616fc87ef", "input": "sentence1:book_author is holding lead over person*politician sentence1:book_author is blasting  person*politician ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-b619ea19a06c4876877a1aafbeeff15f", "input": "sentence1:book_author is writing for book.periodical*book.newspaper sentence1:book_author is writing in book.periodical*book.newspaper ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-180a397846a144ffbe93aee09db9ec8d", "input": "sentence1:person is opening lead on award_winner sentence1:person is holding lead over award_winner ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-dff4c67cee404cce954737e9e78692c3", "input": "sentence1:military_combatant launches invasion of region sentence1:military_combatant is invading  region ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-2c96c9f5105f4f96afe738b5b8be16d3", "input": "sentence1:location is fighting in region sentence1:location is maintaining in region ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-9980957f05c64d46acccfc299964be5b", "input": "sentence1:military_combatant powers in location sentence1:location is gaining from military_combatant ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-65034d1f552b4c34a5744e827697ea04", "input": "sentence1:region is country followed by organization_founder sentence1:organization_founder is behind region ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-93e9937fb3a4404591bfd21d91d7757a", "input": "sentence1:location seizes from region sentence1:location is taking from region ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-1454ecc24e38401c812f3ff16b31079b", "input": "sentence1:location is dependent on region sentence1:location is supplying  region ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-bdf7b4a399794cd4bf638c0a8f7e6449", "input": "sentence1:employer is losing  location sentence1:employer is controlling  location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-3eb79f384ecf428e8157abf198846d67", "input": "sentence1:employer is needing  employer sentence1:employer is joining with employer ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-6070ce96f9ab4ec99e527c936011110b", "input": "sentence1:location is governing  location sentence1:location is annexing  location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-e4efd9bfa47d45139e459cf12dd962e2", "input": "sentence1:employer is dominating  location sentence1:employer is taking  location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-8f3d2dce184b40f79327b8612241e731", "input": "sentence1:organization_founder is claiming  location sentence1:organization_founder is sending to location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-31eb667ae2444a9fadb7695a6e5e1202", "input": "sentence1:employer is following  employer 's leadsentence1:employer is bad a employer ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-a77747150a0b460ab7f861d87df77a43", "input": "sentence1:employer is against employer sentence1:employer is facing  employer ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-a855f9e12fad491aa308beacbb995ca9", "input": "sentence1:award_nominee is crushing  employer sentence1:award_nominee is trouncing  employer ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-820c7e9e41864233aebfaed4cbb2938f", "input": "sentence1:person wins race against person sentence1:person is beating  person ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-c9607047ada84db189ea138c7ff2f87d", "input": "sentence1:location launches invasion of region sentence1:region is bordered by location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-c4dacf9cd186429f9532a4e527e6224f", "input": "sentence1:organization_founder is firing at organization_founder sentence1:organization_founder is accusing  organization_founder ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-eadf1ead74ba482ba8827a8b24a8ae2c", "input": "sentence1:employer is taking on location sentence1:employer is losing to location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-a9565acbbef6450cb4f79c91cbac340f", "input": "sentence1:organization_founder is complaining about organization_founder sentence1:organization_founder is attacking  organization_founder ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-cc0c19e1f2e9421aa1fdff3b86437e30", "input": "sentence1:organization_founder is declaring in region sentence1:organization_founder is turning  region ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-a66e9d37cf2d4aa9962f52195a1bd649", "input": "sentence1:location is imposing on region sentence1:location is including  region ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-8d513be93bf94874b84437bacb2915b5", "input": "sentence1: is chastising  employer sentence1: is joining  employer ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-cfa3cda99e51492abaaafea39b1b79aa", "input": "sentence1:award_winner is trailing  employer sentence1:award_winner is leading  employer ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-ec26d7f2f2064822907415e25e91697d", "input": "sentence1:location is going to war with region sentence1:location is crushing  region ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-4b5effbddd864e6a8f17c81e823b07ee", "input": "sentence1: announces that something acquires business_operation sentence1: is purchasing  business_operation ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-e88f1ef9b1d044588a324fd2e9fec054", "input": "sentence1:region is being invaded by military_combatant sentence1:military_combatant is declaring war on region ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-efea2b26b8d64c8f9a756d50c2b63814", "input": "sentence1:employer is looking for employer sentence1:employer is taking  employer ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-0a93cf67673941ac8aad4361c9f9f7cd", "input": "sentence1: is campaigning in location sentence1: is travelling to location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-26f833b392ae4a42baf3006fb6b92866", "input": "sentence1:organization_founder is leader of region sentence1:organization_founder is turning  region ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-20696689857f4c8286215b2f1e132e6a", "input": "sentence1:region is trusting  organization_founder sentence1:organization_founder is driving  region ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-239b16b90265447aada73b66e4ce17cf", "input": "sentence1:employer is stopping  employer sentence1:employer is putting on employer ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-d119cbbb45174b7fae137caf591e58ce", "input": "sentence1:location retaliates against location sentence1:location is threat to location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-a2b0b1586664412ca835939489411a04", "input": "sentence1:organization is acquiring  business_operation sentence1:business_operation is being acquired by organization ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-d2704aad155741b383aff2988c2030c6", "input": "sentence1:location is belonging to location sentence1:location is including  location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-52ff5e21e27742aa9bdcdf07f6445da1", "input": "sentence1:employer is eliminating  sports_team*professional_sports_team sentence1:employer is hosting  sports_team*professional_sports_team ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-7ff464ed44fc43c6a8056eb55e80a3de", "input": "sentence1:award_winner is unveiling at time.recurring_event sentence1:award_winner announces At time.recurring_event ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-27033d783e6141abb176002ec8232d6c", "input": "sentence1:person*tv.tv_actor marries to person sentence1:person is marrying  person*tv.tv_actor ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-d48a992851f5460f84c363ccb7f9ba38", "input": "sentence1:person is engaging  organization_founder sentence1:person is accusing  organization_founder ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-fe94851e291a4676a54bfaaec4254c07", "input": "sentence1:region retaliates against region sentence1:region is provoking  region ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-c345c8e62bdd449eb959d28161a06048", "input": "sentence1:person is opening lead over person sentence1:person is defeating  person ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-b6f061bd67aa4e9cb7e2956f9fc10e7f", "input": "sentence1: is making in region sentence1: is telling in region ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-9778a70e58364daa8109d3345f02f1e8", "input": "sentence1:region is Capital of location sentence1:region is city of location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-806553acf8d14b4ba3efe2f3e69d934f", "input": "sentence1:person*politician is trailing  person*politician sentence1:person*politician is challenging  person*politician ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-28e414914e804f53ae263c6c3d508351", "input": "sentence1:person is scoring for employer sentence1:person is leading  employer ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-c8c39650b7d04deea8e4e5a7d483a161", "input": "sentence1:location is capital in location sentence1:location is one of city in location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-7d83db9b92a74df4959241b75efa1de4", "input": "sentence1:organization_founder is liking  organization_founder sentence1:organization_founder is referring to organization_founder ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-d269582a9df24b5ab2407b13b6ba42ec", "input": "sentence1:organization_founder is persuading  employer sentence1:organization_founder is making to employer ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-d52de22d313e4738b4b1f8f754d750a6", "input": "sentence1:region is dependent on location sentence1:region is supplier to location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-f79db7c05ce24858833682ed77e628e2", "input": "sentence1:location outnumbers  location sentence1:location is providing  location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-e8265d3d8e1f4ad7af1872b9f8b76f29", "input": "sentence1:employer is subsidiary of organization sentence1:organization is owning  employer ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-5cf2c441618042de8056dc18e734bed2", "input": "sentence1:location has one of economy in location sentence1:location is being located in location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-f4f8fbab99794a09ae9ffcbb8d482700", "input": "sentence1:organization_founder is pressing  location sentence1:organization_founder is dealing with location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-a174cd2d451146d0bc0177e8b8cdc813", "input": "sentence1: is speaking for employer sentence1: is leading  employer ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-a21098c33f9d42f6b15b81f7edc5a42b", "input": "sentence1:location is enemy of location sentence1:location is being defeated by location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-7b9d0e279b244bb58e7f1d17cde892b5", "input": "sentence1:influencer explains In book sentence1:influencer is writing  book ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-514eb8cce4704f96935f6998f1dd6ccc", "input": "sentence1:person is describing in book sentence1:person is writing  book ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-2a0ec32af71243c6bea3cb6a7026effe", "input": "sentence1:military_combatant is being at war with location sentence1:military_combatant is fighting in location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-b4170b5795784ddea32056e2e0b9523e", "input": "sentence1:employer is being tied with employer sentence1:employer is passing  employer ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-cf58cf04d2394dba9a1f2073ad351217", "input": "sentence1: is confronting  person sentence1: is telling  person ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-c4c27830e03e4f5ea5c0fba50eaef2f2", "input": "sentence1:location is going to war with location sentence1:location is coming from location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-66c61b77836d473984b3f958cca6f083", "input": "sentence1:organization is in discussion with organization sentence1:organization is working with organization ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-1a37b161e5884b1a86456287dd834e8b", "input": "sentence1:person is gaining on person sentence1:person is having lead over person ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-dbe44cf2e2c24e5aa516fa10f8a2046d", "input": "sentence1:sports_team*professional_sports_team is finishing game behind sports_team*award_nominee sentence1:sports_team*professional_sports_team is game behind sports_team*award_nominee ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-41c3622353e94f6a87adfe1f814b4786", "input": "sentence1:location is being ruled by location sentence1:location is different from location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-4b33ec95f7b4460fb9a2eb07b22f73d6", "input": "sentence1:organization is announcing release of computer_operating_system sentence1:organization is announcing availability of computer_operating_system ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-6c5e856a52be4906bbe9b669ad9522eb", "input": "sentence1:employer is edging  employer sentence1:employer is beating  employer ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-396c94e4ceae4ec1ab72c3ca68570fde", "input": "sentence1:location is intervening in location sentence1:location is going into location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-195a8a13fbc4479cade3fb7fd3ca2413", "input": "sentence1:organization_founder is introducing to location sentence1:organization_founder is establishing in location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-e9dac11a91764799bc08d1160fcd0ab3", "input": "sentence1:person is firing to pro_athlete*person sentence1:person is hitting  pro_athlete*person ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-6bc89280a985459da662fdec44f40383", "input": "sentence1:person discusses In book sentence1:person writes In book ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-595852e0fa0541ebbd09577b4d5cf4b2", "input": "sentence1:person is losing in location sentence1:person is campaigning in location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-64a8065f21d2403dae8ac178f7b45559", "input": "sentence1:employer is in control of location sentence1:employer is holding  location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-8a85e4a85d7641c08490040954e76e5d", "input": "sentence1:location is occupying  location sentence1:location is remaining in location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-d82286832c4a46448b7a22ed4d4224d3", "input": "sentence1:location is improving with organization_founder sentence1:location poses to organization_founder ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-1cd8d6ef1b0e41bf9aa07837805e869d", "input": "sentence1:location is signing treaty with region sentence1:location is second to region ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-04b2fefc12af4d6aa84030ec5252b0f3", "input": "sentence1:employer is trailing  award_winner sentence1:award_winner has advantage over employer ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-ec0f12bad52740acb2d32772fda275ab", "input": "sentence1:employer is controlling  location sentence1:employer is taking control of location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-597657178c554fff8c1996b1cfd99b9c", "input": "sentence1:employer is dominating  location sentence1:location is having  employer ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-35b18435e3434650b4d5f99f5d225c50", "input": "sentence1:person is trying to link person sentence1:person is edging  person ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-9bb7fec84a1344c28535c4f4e1bc60ce", "input": "sentence1:location has one of economy in location sentence1:location is one of country in location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-0aff34c44a8a4ffcacd8a8cc1aea9e3a", "input": "sentence1:organization_founder is president of location sentence1:organization_founder is ruling  location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-110effc67c074aa7863630a58e121a5c", "input": "sentence1:military_combatant is fighting war against region sentence1:military_combatant is planning to attack region ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-952db270233148278143c04320fbcacd", "input": "sentence1:region is located to border location sentence1:region is found to border location ", "output": ["yes"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-bab7f29c192d4e79a3f7f7bf2adb5bf6", "input": "sentence1:employer is outperforming  employer sentence1:employer is edging  employer ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-cb348d79023a4b88984b91378873b22d", "input": "sentence1:organization is cancelling  award.award_winning_work sentence1:award.award_winning_work is airing on organization ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task970_sherliic_causal_relationship_gpt3_0", "Definition": ["In this task, you will be given two sentences sentence1 and sentence2. You should decide whether the second sentence is entailed(agreed) by the first sentence. If it does entail, answer \"yes\", else answer \"no\". When the model should output \"yes\", it means that the two sentences are equivalent in meaning. In other words, they are saying the same thing.  When the model should output \"no\", it means that the two sentences are not equivalent in meaning. In other words, they are saying different things."], "Instance": {"id": "task970-20e9094402f94d648cfa863f4ba91e83", "input": "sentence1:location is dependent on location sentence1:location is siding with location ", "output": ["no"]}, "Prediction": "yes"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-7faab7e7d6764e50b7f125c2cf39925a", "input": "Sentence 1: Have your camera ready to record the incredible sight of a wailing Japanese child beating a hasty retreat to its parents after being chased by a group of hungry deer in a feeding frenzy. Sentence 2: Japanese children often sneaked away from there parents to pull at the deer's tail.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-c9becb2a54604b1995bb10939ed92cfb", "input": "Sentence 1: Apply total cost   Monitor budgets, costs, and schedules eee management principles   Apply variance analysis eee Sentence 2: Do not apply the total cost and do not monitor budgets.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-c8d1cc78465d4f85a9540bc1ceba2cd3", "input": "Sentence 1: The analysis also requires a distribution of piece volumes by weight interval for inbound mail. Sentence 2: Managers have been looking for a more affordable means of gleaning the same benefits that the analysis suggests.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-90a604c6b38442908802d18d35f0188a", "input": "Sentence 1: Time identifies a new racial  bilingual education. Sentence 2: Time sees a new racial bilingual education.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-900497e05eca42c481cd1d879d74daae", "input": "Sentence 1: The peninsula and Sumatra, after centuries of common language, religion, and political, cultural, and social traditions, were divided. Sentence 2: The peninsula and Sumatra were divided in 1875.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-368dd455e19248a4b353cd2cfa326a9e", "input": "Sentence 1: In fact, because of this inconsistency in reporting, the old system often produced artificial variations in reported case statistics among similar programs. Sentence 2: The old system often produced artificial variation in reported case statistics.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-4f627bd71bc24acd99c9355ccc8d25a8", "input": "Sentence 1: Sometime you may have to fight hanging upside down with nothing but your teeth, said San'doro. Sentence 2: San'doro told me that I will never have to fight.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-7ff2335a2c084f59b1cc89243e824cbf", "input": "Sentence 1: The Texan regarded the Mexican spurs joyfully, stooped to jingle them with his finger tip. Sentence 2: The Texan ignored the Mexican spurs.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-9f3e5f6241ce41c7ba83bf9a2b6be11d", "input": "Sentence 1: Ninety-five percent of the total amount of sulfur dioxide allowances allocated each year under Section 423 will be allocated based on the amount of sulfur dioxide allowances allocated under the Acid Rain Program for 2010 and thereafter and that are held in allowance accounts in the Allowance Tracking System on the date 180 days after enactment. Sentence 2: Most of the sulfur dioxide that is allowed are controlled by the Acid Rain Program.", "output": ["no", "yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-268021834d2a47238289e49986e73792", "input": "Sentence 1: You can't be turned to stone looking at one, you know--only by having one look at you.\"  \"You're cheering me up no end,\" he assured her. Sentence 2: You can't be turned to stone unless they look at you.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-5c15e9f9c56542d58e27786e50e23fba", "input": "Sentence 1: Its purpose is to identify recurring problems that result in change orders, claims, and delays and then to take positive steps to avoid such problems in the future. Sentence 2: Such problems in the future can never be avoided. ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-c9f5e17eb3ae437fb55e8b48e9ee45e8", "input": "Sentence 1: The industry now plans to strengthen warnings that children should be kept, appropriately harnessed, in the back seat, where they will be neither helped nor harmed by air bags. Sentence 2: The children should be kept in the trunk of the car, in a closed and cramped space with plenty of airbags.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-984ae8a4826f44ebb2f37271048c68e3", "input": "Sentence 1: Say it again.\" Sentence 2: Repeat yourself.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-df0453fbc9624dbb93573d682ef683b6", "input": "Sentence 1: The Crystal Cathedral (at 12141 Lewis Street, Garden Grove) is a monument to its time, having been built over the past quarter century by television evangelist Robert Schuller. Sentence 2: Television Evangelist Robert Schuller is financially capable of spearheading large projects.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-4b2c07777602409aa987149a96e718d9", "input": "Sentence 1: The liveliest, most colorful time is during the autumn grape harvest, la vendemmia, but tasting and buying goes on at many of the Chianti vineyards all year round. Sentence 2: You can take part of the harvests as a volunteer.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-43214da0bfb34989b8c49c6597126c42", "input": "Sentence 1: yeah yeah yeah uh i'm a member of an HMO and uh from all indications it's quite similar to the military Sentence 2: I prefer HMO over the military.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-343947af36994640a3ccc9c8f1c4ea12", "input": "Sentence 1: FEDERAL MISSION PROPERTY, Sentence 2: Property of Federal Mission", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-b9be6730c9b143bcabcb9fde045e15af", "input": "Sentence 1: Instead of flying down, many people prefer to take the more leisurely steamer from Mumbai. Sentence 2: Rather than fly down to New Delhi, most prefer to take the steamer out of Mumbai for it's leisure.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-5f116a7543ed43fa9ea4365b3da6c80c", "input": "Sentence 1: As you know, GAO supports the Congress in meeting its constitutional responsibilities and strives to help improve the performance and accountability of the federal government for the benefit of the American people. Sentence 2: Congress works only for the benefits of the general populous.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-0bbdffc90d7848ba84672e64c56a90f0", "input": "Sentence 1: Before the San Gabriel program was subsumed by Dudovitz's group, it offered to merge with the Legal Aid Society of Orange County. Sentence 2: Dudovitz's group also subsumed five other programs that year.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-c69a7a3f46334d4ba7070d9b9a54b3d5", "input": "Sentence 1: and uh we just had a ton of fun and i i look back now as i say the the two girls are both in college but when they're here and we're we're talking about and we're digging out the old pictures books and my twenty we took a lot of eight millimeter movies Sentence 2: During break from college, my daughters come home to spend time reminiscing. ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-050707010b334464b9fa3ef7c7e14de2", "input": "Sentence 1: well let's see if you're in Plano and i'm in Plano are you in east Plano or west Plano Sentence 2: We are both in Plano, which side are you in?", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-abe5768068824296a91859349645b68e", "input": "Sentence 1: No wonder, then, that right-wingers think of PBS as liberal and lefties regard it as a corporate/conservative tool. Sentence 2: Reality has a known liberal bias and that's why PBS appears so.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-093faa6ac3b5420888c297856dd7f89f", "input": "Sentence 1: so i do things like that you know if i had more time i'd probably do it and sell the stuff but you know i don't have enough time to do it to really you know take orders on it and Sentence 2: I would make a lot of money selling the stuff.  ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-500cda71c84c472d90b8c50b2f63ae96", "input": "Sentence 1: Photo No.  Sentence 2: There was no photo.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-0caa05659d9940368b73e521b47f0774", "input": "Sentence 1: You can't trust a publication owned by Microsoft to keep an eye on Microsoft, but you can expect it to keep an eye on Conde Nast and Time Warner, and youcan reasonably expect Conde Nast and Time Warner to keep an eye on Microsoft. Sentence 2: You can't trust a Microsoft owned publication to monitor Microsoft.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-858e1c46732d4e68bb96b21f1bb5e2ed", "input": "Sentence 1: I am Jacob White. Sentence 2: My father was Jacob White Sr. ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-a6605c994ff44e2f987fc0090f4b6e2b", "input": "Sentence 1: The train station itself is fascinating, with hundreds of people waiting in line and a parking lot full of bicycle-driven pedicabs and vintage taxis. Sentence 2: The train station is fascinating because of the decor that it has.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-000b5b5daf16428ea99a1b6a541176a8", "input": "Sentence 1: We were detained under suspicion by the hospital porter, until Cynthia appeared to vouch for us, looking very cool and sweet in her long white overall.  Sentence 2: Cynthia lied, we were guilty. ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-45a08365f6464774b5cb2f02555d1137", "input": "Sentence 1: He is happy to bury us here. Sentence 2: He wants to kill us.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-a3975e54f4894f99858ba26b1033358c", "input": "Sentence 1: The club itself was a bastion of Ascendancy establishment. Sentence 2: The club was a fortification of Ascendancy establishment.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-040869ec588e413dac03e1155bb4cbc8", "input": "Sentence 1: Like rape and forced abortion for women, spermination invades bodily privacy and denies reproductive choice. Sentence 2: Spermination is similar to rape and abortion because it denies reproductive choice.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-60bd4b72e6bc4d75a07e56160a42b181", "input": "Sentence 1: An example of an investment with a split purpose is a grant issued to a teaching hospital to perform both medical education and medical research. Sentence 2: An investment would be considered a split investment if it allowed teaching and research at the same location, and allowed students the chance to participate in an internship.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-0d5461c1dd2846f9a54b65a58f2a14fa", "input": "Sentence 1: However, if neither the Allowance Tracking System regulations nor the allocation regulations are timely promulgated, then the second default applies under which each affected EGU is required for the year involved to meet an emission rate limit of 0.14 lb/mmBtu for units in Zone 1 or 0.25 lb/mmBtu for units in Zone 2. Sentence 2: They were advocating for stricter emission rates.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-7daff0054eac40f09eed102ed7fcdd1b", "input": "Sentence 1: They were swallowing space as the monster moved purposefully away. Sentence 2: They were moving very quickly with the monster.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-fc6d332ea2ac49ec9c8ba7596e466352", "input": "Sentence 1: Other critical positions, such as attorneys, criminal investigators, and mission support, are also vulnerable. Sentence 2: Critical positions are subject to vulnerability.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-a6b85d86cfb04f5db861c6c74f539106", "input": "Sentence 1: George's), was taken over by the government in 1960 and is now part of the Public Records Office. Sentence 2: The Public Record Office encompasses more than one building.  ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-012c56b4f4314a8696398742554037a8", "input": "Sentence 1: Reilly does not deny putting information on the application form that he knew was incorrect. Sentence 2: Reilly admits to lying on the application.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-5752c4994a3a48d78df452982184a94e", "input": "Sentence 1:  He was wrong, but not by too much. Sentence 2: He was only slightly wrong.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-e12b038189fb4239a9970e9a46244269", "input": "Sentence 1: Second is the exciting but all too often disappointing notion that people can unite against a common enemy. Sentence 2: The enemy of my enemy if often my friend.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-5ab4602faad44c5d9c8d81aed80d90e9", "input": "Sentence 1: For three decades, Krakew existed as an independent city-state, though it was again incorporated into the Austrian partition in 1846. Sentence 2: Krakew fought not to be a part of the Austrian 1846 partition.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-00982d22157b4b72b4c389eee72ec6f8", "input": "Sentence 1: Did you really think I was the kind of girl to roll about on the floor and whine for mercy? Sentence 2: She might be that kind of person, but not see her self as such.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-c563f283917d4aa89596f3c2e04bcdc8", "input": "Sentence 1: that is correct Sentence 2: That's right. ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-9ee9cfe163a5445ca0ec579c3315c33b", "input": "Sentence 1: Nowadays the bay is so cluttered with all kinds of yachts, fishing boats, sailing boats, ferry boats, glass-bottom boats, and even workaday freighters that the town has become something of a full-fledged Mediterranean resort of white skyscrapers. Sentence 2: Fishing boats are not permitted in the bay.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-2ca897f5303a43778de4fd71e38bbb7a", "input": "Sentence 1: i like Night Court in fact it's on right now Sentence 2: Night Court is on for the next hour.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-41987f6ac792494aac86229e183dbb7d", "input": "Sentence 1: It charts the history of Scotland, bringing under one roof a number of important collections of artifacts. Sentence 2: The history of Scotland is shown from 1300 to 1900.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-e5d3b89ba41a463c98d549d594b352dc", "input": "Sentence 1: Only one-fourth of non-SES managers reported that to a great or very great extent employees received positive recognition from their agencies for efforts to help accomplish strategic goals. Sentence 2: Only a quarter of non-SES managers stated that great employees didn't receive agency recognition for their help.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-4173b1aa8d894f14b56d88b21309c0b6", "input": "Sentence 1: okay that's what i'm saying there there's so much problem with the handouts and then now by the economy being like it is this is the worst time they could have for everybody coming into the United States Sentence 2: The economy has been as its worst lately.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-6dcc9183865c4827a2020e6c301096c7", "input": "Sentence 1: A survey of selected programs in the spring of 1993, when LSC funding was substantially higher than it is today, revealed that nearly half of all people who applied for assistance from local programs were turned away because of a lack of program resources. Sentence 2: Other similar surveys have been conducted throughout different points in history.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-99f200c2f61f427ea6b5aaec365d29d4", "input": "Sentence 1: This route takes you through Morne Rouge and Ajoupa Bouillon. Sentence 2: The route will take you around the entire country.  ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-9e6635f952a946e59aed093ec25b07d7", "input": "Sentence 1: Critics love this British film directed by Udayan Prasad about the life and dreams of a downtrodden Pakistani taxi driver in the north of England. Sentence 2: The British film directed by Udayan Prasad has been loved by critics, because it is about an Islamic uber driver.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-d413f1f63e85446fbba8090cc7085507", "input": "Sentence 1: Doing a good case study is more than just looking at what is happening in a few instances. Sentence 2: To be considered good, a case study should look at at least 1,000 individual instances. ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-b6e53b42df0f429f8746f04fb101d22b", "input": "Sentence 1: yeah and i i did the family thing so my sweetie could go too Sentence 2: My sweetie and I enjoyed going there and working out together.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-159bb12d6c6740539a36495375b35e1c", "input": "Sentence 1: would the loss of volume to cream skimmers have on the resulting prices the Postal Service would have to charge in order to maintain universal service? Sentence 2: The Postal Service doesn't charge. ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-8fef535148e647c3ab7a5380294010d2", "input": "Sentence 1: so what are the most important benefits to you Sentence 2: What is the best benefit? ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-8c1998ec9ef740069489b3f96edd2966", "input": "Sentence 1: now it probably doesn't work that way in our household because i have strong opinions about things too but Sentence 2: My opinions are pretty meek, baseless and wishy-washy.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-e8ff6df722b2407e87a2e7b9c0ac76ad", "input": "Sentence 1: Newsweek also publishes a dispatch from a U.N. weapons  [W]hile they delayed us from entering some sites, we have seen Iraqi officials burning documents and throwing the embers into a river. Sentence 2: No Iraqi officials were seen destroying documents.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-6bd6d44ca2db4827bb3341088cf0f72f", "input": "Sentence 1: A recent study of the kiosks' first 18 months of operation concluded it is too soon to tell if the system will relieve pressure on court calendars. Sentence 2: The study concluded that the system has ill effects on court calendars.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-8e183733452b4d41ae32de79931a221a", "input": "Sentence 1: You can tell the difference by wetting a corner of a white handkerchief and rubbing the carpet. Sentence 2: Rubbing at the carpet with a handkerchief won't enable you to tell the difference. ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-5090468b1cf64b01966f305b74bca42f", "input": "Sentence 1: Anyway, it was all, 'my people' this, and 'my people' that. Sentence 2: We talked about lots of topics and not once did he mention \"his people.\"", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-4f535aca238e46aa95c1aa760bcbdb50", "input": "Sentence 1: The nearby Musee de Normandie makes a handsome introduction to regional folklore. Sentence 2: The museum is well cultivated and informative. ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-4874558fe1664c678550997c57fe3ffe", "input": "Sentence 1: The entrance hall also portrays famous Scots in a beautifully detailed frieze just below the cornice; it's a veritable Who's Who of the Scottish establishment. Sentence 2: Famous Scots are not seen anywhere else in the building.  ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-014597f9ddda478b921fca3061342d66", "input": "Sentence 1: Throughout Jerusalem, other spots important to Jesus's life were commemorated with religious structures. Sentence 2: Some spots not important to Jesus's life were also commemorated with religious structures.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-9efcd4f803af471da5d1c6ee672b5019", "input": "Sentence 1: 'Well, except for George III. Sentence 2: George III is excluded.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-e29c8ffccacb4ccda5c8662c6c3f7a54", "input": "Sentence 1: and um who are the other two he stole two associates Sentence 2: He stole 2 associates from his competition, Bridgestone", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-976d1cbd8d8241198e58694466835be2", "input": "Sentence 1: What it can do is suggest some general principles. Sentence 2: It is unable to suggest any general principles.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-6bc1c56a1fef4dfe8964035ff82c1d24", "input": "Sentence 1: um no we're pretty much um we we've been around long enough as a couple that we learned a long time ago not to wallpaper together Sentence 2: We learned long ago not to wallpaper together. ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-8fc48f12852843eca8c63e99897524df", "input": "Sentence 1: But you would help me if you could? Sentence 2: You will just ignore me and not attempt to do anything to help me. ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-b02f5359b24547398b008a31734f8e3e", "input": "Sentence 1:  Ibiza lies nearer to the coast of North Africa than to the Catalonian city of Barcelona. Sentence 2: Ibiza, however, holds more cultural influence from the Catalonian city of Barcelona.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-e58e22436be045ba8ec2468607dfa432", "input": "Sentence 1: We went on with the begonias, sir. Sentence 2: The begonias are better than the roses.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-7954a71c0bfd42159a97ca1b19f4dd9c", "input": "Sentence 1: However, I am just a little disappointed that there is no representation in your measurement for popular music. Sentence 2: There is no representation for popular music and that makes me just a little disappointed. ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-f986f40c6c2549e5914e82c9b00fc9ad", "input": "Sentence 1: Burton, too, is both investigator and investigatee. Sentence 2: Burton was seen at the scene of the crime before police arrived. ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-1efa87b4992b49318ee24b0f905ea467", "input": "Sentence 1: Nearby Canongate Church was built in 1688, and the churchyard has a number of famous residents.  Sentence 2: Nobody was allowed to live in the churchyard of Canongate Church.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-4971488c770944509301e2d5148436bb", "input": "Sentence 1: Much of our town's prosperity comes from these mines. Sentence 2: The mines brought a lot of money to our town.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-0abdae6ba31a45279f806ecab2fb13bb", "input": "Sentence 1: yeah yeah see the problem i have now is uh i i want mobile because i'm not really sure what is going to happen a year from now i've moved like Sentence 2: I have a problem about not knowing what I\"ll be doing in a year, so it's impossible to make a decision.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-26e04c2a7bb946929633bd72a34ccc67", "input": "Sentence 1: The first major rebellion occurred in 1770 when the Russians, hoping to distract the Turks while they waged their own attacks on the Ottoman Empire elsewhere, promised support to Dhaskaloyiannis, a wealthy shipowner. Sentence 2: The Russians were allies of the Turks.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-f0f9333e1dda4e59bb4d0d2968a26579", "input": "Sentence 1: Pashupatinath, 5 km (3 miles) northeast of old Kathmandu, is dedicated to Shiva in his incarnation as Pashupati, the Lord of the Animals. Sentence 2: Pashupatinath is dedicated to the Lord of the Newborn Babies.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-c76cb91bc46f465c98f7bacd9eccb9bb", "input": "Sentence 1: Obviously, evolutionary psychology hasn't yet come close to finding the Holy Grail. Sentence 2: The holy grail of evolutionary psychology is when early man began using tools.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-81d282eab6d04099849ed52a2259212d", "input": "Sentence 1: But in her hurry to be in time for the village entertainment Mrs. Inglethorp forgot to take her medicine, and the next day she lunched away from home, so that the last \u201dand fatal \u201ddose was actually taken twenty-four hours later than had been anticipated by the murderer; and it is owing to that delay that the final proof \u201dthe last link of the chain \u201dis now in my hands.\" Amid breathless excitement, he held out three thin strips of paper.  Sentence 2: Because Mrs. Inglethorp took her medicine later than expected, the murderer will be caught.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-f31b075a622b48d681dfc84569d984a9", "input": "Sentence 1: Chris DeMuth's contribution is an outstanding illustration of the ideological dead weight carried by Bob Dole's campaign so far. Sentence 2: Chris DeMuth was the biggest detriment on Bob Dole's campaign.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-af374af761b04e2bb6cf4798ac83d2ca", "input": "Sentence 1: Information in agencies' plans and reports produced under the Results Act, high quality financial and program cost data, and other related information, can help Congress in targeting its oversight efforts and identifying opportunities for additional improvements in agencies' management. Sentence 2: Thanks to agencies' plans and reports, over $30 billion has been saved in agency operating costs.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-cab0cf75010e42c99c4e0970c921b623", "input": "Sentence 1: but uh this guy i mean you can earn a lot more money so you say i go why you still there if you can earn a lot more money once you've get your your you know Master's Sentence 2: The man just wants to explore their options.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-139608b08665452990a21ba46a859c9d", "input": "Sentence 1: yeah it uh works out uh really quite well course i have i have a dog also my son brought me a little Lhasa Apso uh for my birthday last Thanksgiving he brought him from Dallas he Sentence 2: My son bought me a dog because he knew I was lonely.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-a972c34714ac42f7b03ecff915beb5f7", "input": "Sentence 1: I looked good. Sentence 2: I did not look bad. ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-1e94172cac6c4649a7290b66240c7cfc", "input": "Sentence 1: The former congressman and ex-husband of conservative glamour-puss Arianna Huffington says he never liked politics and is glad he lost his Senate race (on which he dropped $30 million). Sentence 2: The former congressman and past husband of Ariana Huffington says he didn't like politics and was glad to lose his senate race.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-d8db55fb5d304133876ef1bc6baa77ad", "input": "Sentence 1: In Tivoli itself, overlooking the Roman plain, the Villa d'Este is a 16th-century counterpart, celebrating all the extravagance of the late Renaissance. Sentence 2: Tivoli is very far from the Roman plain, being located in Sicily.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-910198ca599c4badb4b3e82c3045d158", "input": "Sentence 1: There's also a 1-acre swimming pool with water slides and a vast array of amenities and services all over the 62-acre (25-hectare) oceanfront grounds. Sentence 2: The swimming pool features five water slides.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-0e67d6ca26744bf0833460a55f77fd91", "input": "Sentence 1: This is the place to come to check out the full range of local handicrafts and souvenirs. Sentence 2: This is a terrible place to come if you want a souvenir.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-d445bc43c81c41cabfa1ba61d5370df1", "input": "Sentence 1: Colleagues had called Notra Trulock's allegations against Wen Ho Lee racist and had said there was not a shred of evidence against Lee . Trulock countered that only three of the 12 initial suspects in the case were of Chinese background and called a recent report exonerating the Clinton administration a whitewash. Sentence 2: Nortra Trulock said Wen Ho Lee was smart only because he was Asian.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-be3bdd74a96642d584070280a7d96f07", "input": "Sentence 1: There he established a school of navigation that attracted astronomers, cartographers, and other leading scientists of the day. Sentence 2: He had no interest in education.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-ee54ba91d42e4ff089adab3828895cda", "input": "Sentence 1: It's not their game to show suspicion. Sentence 2: They don't show suspicion about their neighbors.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-e8c4740598914ee988a0c010b88a4c00", "input": "Sentence 1: yeah they do kind of follow or Sentence 2: It could be said that they come after.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-b34fc897119042379c6229db90dbe59a", "input": "Sentence 1: Impaling all the old men took a long time and when the armored men stood the pikes upright, the sharp tips gleaming from the elders' gaping mouths. Sentence 2: It took a long time but old men were impailed. ", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-e75895bcdc014231b07b41aa3805968e", "input": "Sentence 1: The companion maxim is that people often make no attempt at all to look out for the interests of others. Sentence 2: The maxim is that people care more about themselves than anyone else.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-f6422377c1984b27bb52767672024d35", "input": "Sentence 1: Another teaser came out of the stud barn, this one named Dew. Sentence 2: A teaser named Bob refused to come out of the stud barn.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-8a330d20c35047539d489b5b63d38189", "input": "Sentence 1: Nahariya is a quiet beach resort with fine white sands and good leisure facilities. Sentence 2: Nahariya has awful leisure facilities.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-8c6ce6c5fe5c4572b3a865ad0ff82f50", "input": "Sentence 1: I had no idea. Sentence 2: Why didn't you tell me? ", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-e17114f052b64f679e0217e2db1c4576", "input": "Sentence 1: One- I would have to do it. Sentence 2: I do not want to do it, but I have to.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-8ac141596c2743e2a2184e4182829666", "input": "Sentence 1: In addition to establishing a single statewide coordinated fund raising plan, the Symposium is exploring legislative proposals involving fee-shifting statutes, as well as more traditional approaches, such as filing fees, surcharges, or an increase in bar dues. Sentence 2: If this legislative were to pass it would mean more money for the average tax payer.", "output": ["no"]}, "Prediction": "no"}
{"Task": "task199_mnli_classification_gpt3_0", "Definition": ["In this task, you're given a pair of sentences, sentence 1 and sentence 2. Your job is to determine if the two sentences clearly agree/disagree with each other, or if this can't be determined. Indicate your answer as yes or no respectively. 1. The model should output no when the two sentences do not share any common information. For example, if Sentence 1 is about a restaurant and Sentence 2 is about a movie, the model should output no because the two sentences are about different topics.  2. The model should output yes when the two sentences share information that agrees with each other. For example, if Sentence 1 is \"The sky is blue\" and Sentence 2 is \"The sun is up\", the model should output yes because the two sentences share information that agrees with each other."], "Instance": {"id": "task199-eb11cc63e3d3415cbd42f1474b0cdfad", "input": "Sentence 1: Performance  State Experiences and Implications for the Federal Government (GAO/AFMD-93-41, Feb. 17, 1993). Sentence 2: This was written in the 12th century on the month of July.", "output": ["yes"]}, "Prediction": "no"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-d889f5953c18432295e426a6a024fcc7", "input": "Premise: The 1998 Idaho Vandals football team represented the University of Idaho in the 1998 NCAA Division I-A football season. The Vandals, led by fourth-year head coach Chris Tormey, were members of the Big West Conference and played their home games at the Kibbie Dome, an indoor facility on campus in Moscow, Idaho. <sep> Hypothesis: The 1998 Idaho Vandals football team played football in nineteen hundred and ninety eight", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-487e5fca75214112a90ec6b7a15ff3c2", "input": "Premise: Garverg\u00e5rden (lit. \"The Tanner's House\") is a half-timbered building complex from circa 1600 situated in Vestergade in K\u00f8ge, Denmark. Owned by shoemakers and tanner for almost 200 years, from 1732, until the early 1920s, it bears testament to a time when K\u00f8ge was a centre for shoemaking and tanning. The building fronting the street and a side wing on its rear are listed. <sep> Hypothesis: K\u00f8ge, Denmark was once a center for tanning hides", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-e653888a578d45c38346111cc5651781", "input": "Premise: Nicola or Niccolo Massaro (died 1704) was an Italian painter of the late-Baroque period, active in his native city of Naples. He painted mainly marine vedute and landscapes in the style of his master, Salvatore Rosa. One of his colleagues was Marzio Masturzo. One of his pupils was Gaetano Martoriello, and Massaro's son's Girolamo and Gennaro. <sep> Hypothesis: Salvatore Rosa was active in the city of Rome", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-3b76f328b0c94ecdb03bb37486a73e31", "input": "Premise: Listennn... the Album is the debut studio album by American hip hop disc jockey DJ Khaled. It was released on June 6, 2006. by Terror Squad Entertainment and Koch Records. The album features guest appearances from Young Jeezy, Bun B, Birdman, Juelz Santana, Slim Thug, Krayzie Bone, Chamillionaire, Trina, Twista, Freeway, Jadakiss, Beanie Sigel, Styles P and Lil Scrappy, among others. <sep> Hypothesis: At least 19 people appear on the album", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-892c47fa106a49019557b5564328e8fe", "input": "Premise: The Last Boy Scout is a 1991 American action comedy film directed by Tony Scott, starring Bruce Willis, Damon Wayans, Chelsea Field, Noble Willingham, Taylor Negron and Danielle Harris. The film was released in the United States on December 13, 1991. <sep> Hypothesis: The film released before the 2nd month of 1991", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-514cf35ffd9440a3819d1a1a98809396", "input": "Premise: Tosca Musk is an American filmmaker. She is a producer and director of feature films, television programs and web content. Her web series, \"Tiki Bar TV\", and Hallmark television movie, \"Holiday Engagement\" have garnered some attention, with \"Holiday Engagement\" setting records for the most-watched television movie on Hallmark. She is the sister of entrepreneurs Elon and Kimbal Musk. <sep> Hypothesis: Tosca is the daughter of Elon Musk.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-1ce1183915984ab5a1e8f8b40eaeb4ce", "input": "Premise: State Route 204 (SR 204) is part of Maine's system of numbered state highways, located in Hancock County. It runs from State Route 3 in Trenton, passing State Route 184 in Lamoine, and ending at the intersection with Seal Point and Marlboro Beach roads. The route is 6.5 mi long. <sep> Hypothesis: State Route 204 is more than 6 miles long.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-f728f4da4b2741ed914fa26708caa3c8", "input": "Premise: Amelio Robles Avila was a colonel during the Mexican Revolution. He was born a woman with the name of Amelia Robles \u00c1vila on November 3, 1889 in Xochipala, Guerrero. His father was named Casimiro Robles and his mother Josefa \u00c1vila. His father was a wealthy farmer who owned 42 acres of land and owned a small Mezcal factory. <sep> Hypothesis: Casimiro Robles was born on November 3, 1859.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-5a7a7c7c878c48cc83747b72e6830683", "input": "Premise: Am\u00e9lie Simone Mauresmo ] (born 5 July 1979) is a French former professional tennis player, and a former world No. 1. Mauresmo won two Grand Slam singles titles at the Australian Open and at Wimbledon, and also won a Silver Medal at the 2004 Summer Olympics. <sep> Hypothesis: Am\u00e9lie Simone Mauresmo is a French former professional titres player", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-efc3dd7243344ecc9704abba637989e2", "input": "Premise: The Florida Board of Regents was from 1965 to 2001 the governing body for the State University System of Florida, which includes all public universities in the state of Florida, United States. It was created to replace a predecessor body called the Florida Board of Control, which had existed from 1905. Its powers are now held by the Florida Board of Governors. <sep> Hypothesis: The Florida Board of Regents lasted more than 40 years.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-9f03679bf9544394845c766b27f5b36e", "input": "Premise: \"I Don't Ever Want to See You Again\" is a song performed by American contemporary R&B singer Uncle Sam. It is the closing track on his eponymous debut album and was issued as the album's lead single. The song was written and produced by Boyz II Men member Nathan Morris. Released in 1997, it was Sam's only hit on the \"Billboard\" Hot 100, peaking at #6 in 1998. <sep> Hypothesis: Nathan Morris was born in nineteen hundred sixty six.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-64900233a2ba42d5811df419fd69afa2", "input": "Premise: Thirteen Ghosts (also known as 13 Ghosts and stylized as THIR13EN Ghosts) is a 2001 Canadian-American supernatural horror film directed by Steve Beck. It is a remake of the 1960 film \"13 Ghosts\" by William Castle. It follows the remake of another one of Castle's films, \"House on Haunted Hill\", and was shot entirely around Lower Mainland, British Columbia. <sep> Hypothesis: Other than \"13 Ghosts\", there has been more than one remake of William Castle's films.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-413dd60ae7424897910239b1d4871653", "input": "Premise: Wireshark is a free and open source packet analyzer. It is used for network troubleshooting, analysis, software and communications protocol development, and education. Originally named Ethereal, the project was renamed Wireshark in May 2006 due to trademark issues. <sep> Hypothesis: Wireshark is not used for playing games.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-90a2120411b549d8b1e5460e8bec3521", "input": "Premise: Pixote: a Lei do Mais Fraco (] , lit. \"Pixote (small child): The Law of the Weak\") is a 1980 Brazilian drama film directed by H\u00e9ctor Babenco. The screenplay was written by Babenco and Jorge Dur\u00e1n, based on the book \"A Inf\u00e2ncia dos Mortos\" (\"The Childhood of the Dead Ones\") by Jos\u00e9 Louzeiro. <sep> Hypothesis: Pixote: a Lei do Mais Fraco is a drama play and the screenplay was written by two different men.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-2f0d85d9952f445cb97ea3ddc2219528", "input": "Premise: Niels Bagge Hansen better known by the stage name Vinnie Who (born on 1 November 1987) is a Danish indie pop and disco singer and songwriter who released two albums, whose the debut \"Then I Met You\" in 2010 and \"Midnight Special\" and is signed to EMI Denmark. An androgynous male singer, he sings in a distinctive high-pitched feminine voice. <sep> Hypothesis: Vinnie Who's third album was called \"Then I Left You.\"", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-86f37e2d296440259f4a49ac0e177d8f", "input": "Premise: The Argentine Grand Prix (Spanish: \"Gran Premio de Argentina\") was a round of the Formula One championship, held intermittently from to , all at the same autodrome in the Argentine national capital of Buenos Aires. Argentine president Juan Per\u00f3n was the driving force behind the creation of the circuit, after seeing the success of the country's own Juan Manuel Fangio. <sep> Hypothesis: The Argentine Grand Prix involves the racing of automobiles with four wheels", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-d19989e7af1741e4a66d0996c3c4854c", "input": "Premise: New Hampshire Route 78 (abbreviated NH 78) is a 3.456 mi secondary state highway in Cheshire County in the southern part of the U.S. state of New Hampshire. A northward extension of Massachusetts Route 78, NH 78 runs entirely within the town of Winchester from the state border to downtown, where it ends at New Hampshire Route 10 and New Hampshire Route 119. <sep> Hypothesis: NH78 is south of Massachusetts.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-6c663319c7a3426a9ec85081f629660a", "input": "Premise: Alan R Duffy (born 1983) is a professional astronomer and science communicator. He was born in England, raised in Ireland, and is currently based in Australia. He is a Research Fellow and Associate Professor at the Centre for Astrophysics and Supercomputing at Swinburne University of Technology. <sep> Hypothesis: Alan R Duffy (born 1983 and died 1953) is a professional astronomer and science communicator.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-4b69881494fb416599830955c80ebe01", "input": "Premise: The Birds, The Bees & The Monkees is the fifth studio album by The Monkees released in April 1968. It was the first Monkees album not to reach Billboard's number one, peaking at No. 3 in the U.S. charts. It was also their first album to miss the UK charts altogether, with their four previous efforts all having reached the top ten. The album has sold over a million copies. <sep> Hypothesis: The Birds, The Bees & The Monkees was released by The Monkees in 1968, a year before the Band was formed", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-6817cd9189fa46c5bd7630aab88ee83c", "input": "Premise: Project Gasbuggy was an underground nuclear detonation carried out by the United States Atomic Energy Commission on December 10, 1967 in rural northern New Mexico. It was part of Operation Plowshare, a program designed to find peaceful uses for nuclear explosions. <sep> Hypothesis: It started on December 9, 1967.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-af0d8d807f2b4f1194fb30371ff088d7", "input": "Premise: Valhalla Avenue was the fourth album release of Irish alternative rock act The Fatima Mansions. Released in 1992 by Kitchenware Records, the album included the singles \"Evil Man\" and \"1000%\". Frontman Cathal Coughlan wrote, and with the assistance of Ralph Jezzard and Victor Van Vugt, produced and engineered the album. <sep> Hypothesis: Valhalla Avenue was The Fatima Mansions' first album with Kitchenware Records.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-2c38bef37667456dbce2bb2d08d55cee", "input": "Premise: Barry and Stuart (Barry Jones and Stuart MacLeod) are two Scottish BAFTA nominated magicians and comedians whose work has been seen on television and on stage around the world. The double act are known for their comically dark performing style, for taking as inspiration the accounts of Biblical miracles and faking paranormal phenomena to form the basis for some of their illusions. <sep> Hypothesis: Barry and Stuart have worked together an no one else", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-8facaa5022384616948d430f633c244e", "input": "Premise: Boxcar Bertha is a 1972 American romantic crime drama film directed by Martin Scorsese. It is a loose adaptation of \"Sister of the Road\", a pseudo-autobiographical account of the fictional character Bertha Thompson, written by Ben L. Reitman. It was Scorsese's second feature film. <sep> Hypothesis: Martin Scorsese knows Bertha Thompson.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-e543f42f0d04482db00c7fd96172725b", "input": "Premise: The Frank J. Selke Memorial Trophy is awarded annually to the most sportsmanlike player in the Quebec Major Junior Hockey League. The award began in the 1969\u201370 season as a team trophy awarded to the league's West Division champions. It has been awarded in its present form since 1970\u201371 after just one season. The award is named after former NHL general manager and Hall of Famer Frank J. Selke. <sep> Hypothesis: The Frank J. Selke Memorial Trophy was won by Nixon.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-a79c4e73e2dc4a55a6a49c43c0acd75c", "input": "Premise: Play with Me Sesame is a children's television series, spin off from \"Sesame Street\". It featured \"Sesame Street\" characters, such as Bert, Ernie, Grover, and Prairie Dawn. From April 1, 2002 until September 2, 2007, the show was aired on Noggin, which was rebranded as Nick Jr. on September 28, 2009. The series was produced by Sesame Workshop and Nick Digital. <sep> Hypothesis: The series was for mostly children", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-ad34a0e7f6b14fd88f4ef855af27abb7", "input": "Premise: Inferno (also released with the title, Operation Cobra) is a 1997 feature film directed by Fred Olen Ray starring Don Wilson, Deepti Bhatnagar and R. Madhavan. Evan Lurie, Michael Cavanaugh and Tan\u00e9 McClure appear in other pivotal roles. Wilson plays the role of Interpol agent Kyle Connors on a mission set in India. <sep> Hypothesis: Fred Olen Ray was born in nineteen hundred fifty six.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-98de0bb62c264d139525d2233c806edf", "input": "Premise: The 1989 European Cup Winners' Cup Final was a football match contested between Barcelona of Spain and Sampdoria of Italy. It was the final match of the 1988\u201389 European Cup Winners' Cup and the 29th European Cup Winners' Cup Final. The final was held at Wankdorf Stadium in Bern, Switzerland, on 10 May 1989. Barcelona won the match 2\u20130 thanks to goals by Julio Salinas and Luis L\u00f3pez Rekarte. <sep> Hypothesis: In the past Barcelona lost to Sampdoria.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-6a222cbf668c4fc791da2daa028edbc0", "input": "Premise: Captain Scarlett is a 1953 American Technicolor Adventure film directed by Thomas Carr, that was shot in Mexico. The film is set in France following the fall of Napoleon I, and stars Richard Greene playing the title role, a Robin Hood type avenger, and Brazilian actress Leonora Amar in her final screen role. <sep> Hypothesis: Leonora Amar starred in the film Captain Scarlett, which was released the same year that she died.", "output": ["Neutral"]}, "Prediction": "Entailment"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-24e64b975198459c9d65baa36afa2962", "input": "Premise: Johnson & Johnson is an American multinational medical devices, pharmaceutical and consumer packaged goods manufacturing company founded in 1886. Its common stock is a component of the Dow Jones Industrial Average and the company is listed among the Fortune 500. <sep> Hypothesis: I guarantee you this is crazy", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-ea2c4e005601401fb88ebc7d1afd11c9", "input": "Premise: Mary Eliza Mahoney (May 7, 1845 \u2013 January 4, 1926) was the first African American to study and work as a professionally trained nurse in the United States, graduating in 1879. Mahoney was one of the first African Americans to graduate from a nursing school, and she prospered in a predominantly white society. She also challenged discrimination against African Americans in nursing. <sep> Hypothesis: Mary Eliza Mahoney healed people.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-18f41a15972045f2a972d9e6acd85184", "input": "Premise: Tom Clancy's Splinter Cell is a 2002 stealth video game developed by Ubi Soft Montreal and built on the Unreal Engine 2. It is the first \"Splinter Cell\" game in the series. Endorsed by author Tom Clancy, it follows the activities of NSA black ops agent Sam Fisher. The character of Fisher is voiced by actor Michael Ironside. <sep> Hypothesis: Tom Clancy was involved in the production of the Splinter Cell games by providing some writing.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-342a33ec87354382b248c5b46478ee86", "input": "Premise: William Daniel \"Dan\" McCafferty (born 14 October 1946, Dunfermline, Scotland) is a Scottish vocalist, best known as the lead singer for the Scottish hard rock band Nazareth from its founding in 1968 to his retirement from touring with the band in 2013. McCafferty continues to perform solo around the world and record on occasion. <sep> Hypothesis: McCafferty was the lead singer of Nazareth for 47 years", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-c2d519f0e9f34e86a96a8e69cf04f7d1", "input": "Premise: Allen West (born October 17, 1967, Brandon, Florida) is an American death metal guitarist who has been a member of Massacre, Obituary, Six Feet Under, Lowbrow, and Southwicked. He is considered to be a pioneering figure of the death metal genre in the 1980s. <sep> Hypothesis: Allen West will be 52 years old on his next birthday.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-be1e10e748184d1a88dc91df597a41df", "input": "Premise: RM Films International is a film distribution company based in Hollywood, California. It was started by filmmaker Russ Meyer to distribute his movies. Since Meyer\u2019s death in 2004, RM Films International has been owned and operated by the Russ Meyer Charitable Trust and is a recognized 501(c) private foundation. <sep> Hypothesis: RM Fils is a non profit film company based in California's capital.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-3741e4f7933f4ac1a57a87642bb0c752", "input": "Premise: Roc-A-Fella Records Presents Teairra Mar\u00ed is the debut album by recording artist Teairra Mar\u00ed. It was released on August 2, 2005, by Roc-A-Fella Records. The album debuted in the top five selling 69,000 copies in the first week, eventually selling 248,000 units. <sep> Hypothesis: Teairra Mar\u00ed signed with Roc-A-Fella Records before August 2, 2005", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-53fd58f6abba4d4db4e7222837c47b61", "input": "Premise: The Disenchanted Forest is a 1999 documentary film that follows endangered orphan orangutans on the island of Borneo as they are rehabilitated and returned to their rainforest home. It centres on the three main Borneo Orangutan Survival Foundation (BOS) projects - Wanariset, Nyaru Menteng and Mawas. It is narrated by Brooke Shields. <sep> Hypothesis: The Disenchanted Forest is a documentary about orangutans trying to learn how to fly by building their own planes on the tiny island of Borneo", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-67ad11054d154562b6a505a6d398f8b9", "input": "Premise: Rastafari, sometimes termed Rastafarianism, is an Abrahamic religion. Classified as a new religious movement, it developed in Jamaica during the 1930s. It lacks any centralised authority and there is much heterogeneity among practitioners, who are known as Rastafari, Rastafarians, or Rastas. <sep> Hypothesis: People have been following Rastafarianism for around eight decades.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-581945f53dfa4741a8f860e7a4dc6a52", "input": "Premise: \"White as Snow\" is a song by Irish rock band U2 and the ninth track on their 2009 album \"No Line on the Horizon\". It was written from the perspective of a dying soldier serving in Afghanistan, and lasts the length of time it takes him to die. The track is based on the hymn \"Veni, veni Emmanuel\", and is the only political song on the album. <sep> Hypothesis: U2 wrote no political songs on the 2009 album.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-6ee0784138a749e5aa4c44de5eb028ca", "input": "Premise: The Latin American Boom was a flourishing of literature, poetry and criticism in Latin America during the 1960s and 1970s, when writers from this region explored new ideas and came to international renown in a way that had not happened previously. Major figures of the boom include Julio Cort\u00e1zar, Gabriel Garc\u00eda M\u00e1rquez, Carlos Fuentes, Jorge Luis Borges, and Mario Vargas Llosa. <sep> Hypothesis: Gabriel Garcia Marquez was a journalist.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-05b41dfb099a473785e7118147d886ae", "input": "Premise: The Sea Hornet is a 1951 American adventure film directed by Joseph Kane and written by Gerald Drayson Adams. The film stars Rod Cameron, Adele Mara, Lorna Gray, Chill Wills, Jim Davis and Richard Jaeckel. The film was released on November 6, 1951, by Republic Pictures. <sep> Hypothesis: Adams did not want Cameron in the film.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-ca3b5844bab9425e8ce4005e4bc8ca3b", "input": "Premise: The Sun Also Rises is a one-act opera by Webster A. Young, based on Ernest Hemingway's \"The Sun Also Rises\". It is one of a pair of Hemingway works that Young adapted into operas. The opera's libretto is by the composer, and includes direct quotations from the novel. It premiered on May 7, 2000 at the Long Island Opera. <sep> Hypothesis: The opera's libretto is by Webster, and includes direct citations from the novel.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-3a3c39bcbf974417aded91a8fb2aab89", "input": "Premise: Latin Jam Workout is a Latin Dance Fitness Program created by professional athlete and choreographer JP Santana. Founded in 2007 in Los Angeles, California, Latin Jam Workout combines techno and Latin music with dance and aerobic movements. It is a fusion of Latin dance steps such as Salsa, Merengue, Raeggaeton, Cumbia, Samba, Soca, Belly-Dancing and the faster-paced rhythms of Pop and Techno. <sep> Hypothesis: Ernest Guiraud is a Citizen  of France born in the United states of America", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-d37fce607544400caf4d3bc3c98efbe9", "input": "Premise: Keystone is an unincorporated community and census-designated place in central Keith County, Nebraska, United States. It lies along local roads near the North Platte River, northeast of the city of Ogallala, the county seat of Keith County. Its elevation is 3,100\u00a0feet (945\u00a0m). Although Keystone is unincorporated, it has a post office, with the ZIP code of 69144. <sep> Hypothesis: The elevation of Keystone is not more than 3,000 feet.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-82164ca640c94d04b9015a82ec216839", "input": "Premise: Keith Martin (1969 or 1970 \u2013 December 5, 2014), one of the world heaviest lived people, was famous for being at one point the UK\u2019s heaviest man, weighing approximately 980 lbs at his peak. Keith Martin was given a gastric bypass operation by the NHS, and had lost over 50% of his body weight. <sep> Hypothesis: Keith Martin died less than 20,000 seconds ago.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-fd3bb049b7cf4799892cb48d7cc69d65", "input": "Premise: Melinda Heather \"Mindy\" Cohn (born May 20, 1966) is an American actress, voice actress, comedian and singer. She is known for her role as Natalie Green, the student of Edna Garrett (played by Charlotte Rae) in the long-running sitcom \"The Facts of Life\", and for being the voice of Velma Dinkley in the \"Scooby-Doo\" franchise from 2002 to 2015. <sep> Hypothesis: Melinda Heather \"Mindy\" Cohn  is likely still alive", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-76da12d69160420d8f3fe6fcf5c4c5ca", "input": "Premise: In field hockey, a penalty stroke, sometimes known as a penalty flick, is the most severe penalty given. It is predominantly awarded when a foul has prevented a certain goal from being scored or for a deliberate infringement by a defender in the penalty circle. <sep> Hypothesis: The penalty circle in field hockey contains more than one defender.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-c0e95c2ca4b640438e6b8c9cddd48aea", "input": "Premise: Till-Holger Borchert (born 1967, in Hamburg) is a German art historian and writer specialising in 14th and 15th-century art. He has been the chief curator of the Groeningemuseum and Arentshuis museums in Bruges between 2003 and 2014. In december 2014, he was appointed as artistic director of the Municipal Museums in Bruges. <sep> Hypothesis: Till-Holger Borchert was the highest curator at a museum.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-0dfb736a0dd8403b910f7378f7e3de04", "input": "Premise: Elmhurst is a residential neighborhood in the southernmost part of Oakland, California. Originally a separate town, it was annexed by Oakland in 1909, and today is considered part of East Oakland. It lies at an elevation of 39 feet (12 m). It contains the Eastmont Town Center. <sep> Hypothesis: Elmhurst is a small town in Oakland, California.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-5a80454442fb4def924a202652736f92", "input": "Premise: Kim Da-som (born May 6, 1993), better known mononymously as Dasom, is a South Korean singer and actress. She is best known as a former member of South Korean girl group Sistar under Starship Entertainment. She has acted in films and television dramas, including \"Family\" (2012\u20132013), \"Melody of Love\" (2013\u20132014) and \"The Virtual Bride\" (2015). <sep> Hypothesis: Kim Da-som was from the southern hemisphere", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-2d3244655c58422b85a1f2330fa407b3", "input": "Premise: Libya TV (also known as Libya Al Ahrar TV) is a Libyan TV channel broadcast by satellite from its headquarters in Doha. The channel was created in 2011 during the Libyan Civil War. Its presents news, opinions, analysis, photo and video reports about Libya in specific and the region in a wider scope. It focuses on Libya\u2019s revolution and future toward building a democratic state. <sep> Hypothesis: Libya TV's headquarters are in Libya.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-09757b4b3afb49148b2dc6785d33154f", "input": "Premise: Caddyshack is a 1980 American comedy film directed by Harold Ramis and written by Brian Doyle-Murray, Ramis and Douglas Kenney. It stars Michael O'Keefe, Chevy Chase, Rodney Dangerfield, Ted Knight, and Bill Murray. Doyle-Murray also has a supporting role. The film was later dedicated to producer Douglas Kenney, who died shortly after the film's release. <sep> Hypothesis: Caddyshack was dedicated to producer Douglas Kenney in 2001.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-3af0b97d158d492fa5d0ecf1769ffd6a", "input": "Premise: Michael Blodgett (September 26, 1939 \u2013 November 14, 2007) was an American actor, novelist, and screenwriter. Of his many film and television appearances he is best known for his performance as gigolo Lance Rocke in Russ Meyer's 1970 cult classic \"Beyond the Valley of the Dolls\". He retired from acting in the late 1970s and began a writing career. <sep> Hypothesis: Blodgett was born in the ninth month.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-f66cf9fa1ccd498aae72a0e2830e8589", "input": "Premise: James Duncan Scurlock (born September 15, 1971) is an American director, producer, writer and financial adviser. He is probably best known for his critically acclaimed documentary \"Maxed Out: Hard Times, Easy Credit and the Era of Predatory Lenders\" and his award-winning book, \"Maxed Out: Hard Times in the Age of Easy Credit\". His most recent book, \"\", is a biography of Larry Hillblom. <sep> Hypothesis: James Duncan Scurlock was born on an even day", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-7ede77b7649c44bdb1050dba4fcfb5c7", "input": "Premise: The Vermont State Police (VSP) is the state police agency for the US state of Vermont. The force has jurisdiction throughout the entire state. The Vermont Public Safety Commission directs policy and selects the commander. The commander is Colonel Matthew Birmingham. The Vermont Public Safety Commissioner is Keith W. Flynn. There are 327 sworn state troopers. <sep> Hypothesis: The Vermont State Police has authority in the city of Montpelier.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-78107a64e97c46d3a46220d680f214f3", "input": "Premise: The 464th Troop Carrier Group was a theater airlift unit of the United States Air Force during the Cold War. It served in the United States under Tactical Air Command between 1953 and 1957. The group operated Fairchild C-119 Flying Boxcar and Fairchild C-123 Provider aircraft as the flying element of the 464th Troop Carrier Wing until being inactivated when the wing was reorganized. <sep> Hypothesis: The United States Air Force currently has 464 troop carrier groups.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-76043a3076df4364b480348ca3e66299", "input": "Premise: \"You Are My Sunshine\" is a popular song recorded by Jimmie Davis and Charles Mitchell and first recorded in 1939. It has been declared one of the state songs of Louisiana because of its association with Davis, a country music singer and governor of the state in the years 1944\u20131948 and 1960\u20131964. <sep> Hypothesis: Jimmie Davis was the governor of Alabama.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-50d53e87b2aa4a9c9ba5599da9e094aa", "input": "Premise: \"Oh My\" is a song by American hip hop artist DJ Drama, released on May 13, 2011, as the lead single from his third studio album \"Third Power\". The song was produced by frequent collaborator Drumma Boy and features rappers Fabolous, Roscoe Dash and Wiz Khalifa. The song peaked at #18 on the \"Billboard\" and #12 on the Top R&B/Hip-Hop Songs, making it the most successful song for DJ Drama to date. <sep> Hypothesis: \"Oh My\" does not appear in quotation marks in this context.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-bcb074a6bd6849e98d14f50b9fa2ec51", "input": "Premise: SuperpinkyMandy is the debut studio album of British singer Beth Orton. Largely in the style of electronica, and produced closely with then boyfriend William Orbit, it was a limited Japan-only release, with about 5000 copies pressed. As such, it is very much sought after. Orton largely passes over the release when interviewed, citing 1996's \"Trailer Park\" as her first release. <sep> Hypothesis: trailer park was japan only release", "output": ["Contradiction"]}, "Prediction": "Entailment"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-5d4924aa7ae746abb317b43d5c4c1f4e", "input": "Premise: Kim Da-som (born May 6, 1993), better known mononymously as Dasom, is a South Korean singer and actress. She is best known as a former member of South Korean girl group Sistar under Starship Entertainment. She has acted in films and television dramas, including \"Family\" (2012\u20132013), \"Melody of Love\" (2013\u20132014) and \"The Virtual Bride\" (2015). <sep> Hypothesis: She acted recently for three years", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-e90487b5651f4239a5589bb437766591", "input": "Premise: Connacht Rugby (Irish: \"Rugba\u00ed Connachta\" ) is one of the four professional provincial rugby teams from the island of Ireland. Connacht competes in the Pro14 and the European Rugby Challenge Cup. The team represents the IRFU Connacht Branch, which is one of four primary branches of the IRFU, and is responsible for rugby union throughout the geographical Irish province of Connacht. <sep> Hypothesis: Connacht often competes in continental europe", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-accc3b6a18eb4702841622f2fa69595b", "input": "Premise: The Asian Institute is a research centre at the Munk School of Global Affairs at the University of Toronto, and is located in the historical Devonshire House, a former residential hall of the university's Trinity College. Ritu Birla is the Richard Charles Lee Director of the Asian Institute. <sep> Hypothesis: The Asian Institute has a director named Rita", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-8e7fc9ff3f194589b40fa172eb1132b7", "input": "Premise: Frank Viola is an American author, speaker, and blogger on Christian topics. His work focuses on Jesus studies and biblical narrative, with a strong emphasis on helping the poor and the oppressed. He is most noted for his emphasis on the centrality and supremacy of Jesus Christ. <sep> Hypothesis: Frank Viola has written books that focus on Jesus.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-fbaf9d1499e94349b37d6fa7c5f08986", "input": "Premise: Jean le F\u00e8vre de Saint-Remy or Jean Lefebvre de Saint-Remy (c. 1394 \u2013 June 16, 1468) born in Abbeville, was a Burgundian chronicler during the Hundred Years' War and lord (\"seigneur\") of Saint Remy, la Vacquerie, Avesnes and Morienne. He is also known by the formal title of authority \"Toison d'or\" (Golden Fleece) because he served as the King of Arms to the Order of the Golden Fleece. <sep> Hypothesis: Saint-Remy was born in the 14th century.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-f03d07a6f30145a28f4efa272e3d629f", "input": "Premise: Shanakht(Urdu: \u200e )(English Translation: \"Identity\") is a Pakistani television social drama series that debuted on Hum TV on 5 August 2014. It is written and directed by Amna Nawaz Khan and is Produced by Momina Duraid. It is produced by Momina Duraid and is a A N K Production project. The show stars Maya Ali, Fahad Mirza and Noor Hassan Rizvi in pivotal roles. The show aired Tuesdays at 8:00 pm. <sep> Hypothesis: Shanakht is written by a different person who directs it.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-85de012564864d15ac65056993eb933e", "input": "Premise: Drifters is a British sitcom that stars Jessica Knappett, Lydia Rose Bewley and Lauren O'Rourke as three female friends who live in Leeds following their graduation from university. All three actresses had previously appeared together in \"The Inbetweeners Movie\". Four series were broadcast, between 2013 and 2016. <sep> Hypothesis: The show featured three non partnered lesbian feature characters.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-e37aba889368426caf8a0cfdc6ec3fa6", "input": "Premise: Anna Pihl is a Danish police drama produced by TV2. The series stars Charlotte Munck (\"Kongekabale\") as the title character Anna Pihl, Peter Mygind, and Iben Hjejle (\"High Fidelity\" and \"Blinkende Lygter\") as Mikala. Three seasons have been produced between 2006 and 2008, each having 10 episodes. <sep> Hypothesis: Only a few seasons of the show were made over the course of two years", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-bf6253f64c1a4dae9049f93fc10b16c5", "input": "Premise: \"Sunny Sundae Smile\" is a song by the alternative rock band My Bloody Valentine. It was released as a non-album single in February 1987 on Lazy Records. Recorded at Alaska Studios in London, \"Sunny Sundae Smile\" was the band's first release on Lazy Records and the final release to feature original vocalist David Conway. <sep> Hypothesis: Sunny Sundae Smile was released in MCMLXXXXII", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-e8d9d7836d724bfdb0d7e306bbd77b42", "input": "Premise: Angus Scott (16 August 1927 \u2013 16 March 1990) was a British track and field athlete who competed in sprinting events. He represented Great Britain at the 1952 Summer Olympics. He was affiliated with the Achilles Club. He was part of the winning British 4\u00d7400 metres relay team at the 1950 European Athletics Championships. <sep> Hypothesis: Angus Scott (16 August 1927 \u2013 16 March 1990) was a British long jump athlete who competed in sprinting events.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-e85213ac5085489e8392e67584f41222", "input": "Premise: Hell's Kitchen Australia is an Australian cooking reality competition television series which premiered on the Seven Network on 6 August 2017. The series is hosted by British chef Marco Pierre White, who previously hosted two seasons of the British version of the format and appeared in rival program \"MasterChef Australia\". <sep> Hypothesis: The show premiered in the first decade of the new millenium.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-b172488bb93e47669fb115cbd3186111", "input": "Premise: Arturo Guzm\u00e1n Decena (a.k.a. Z-1) (13 January 1976 \u2013 21 November 2002) was a Mexican Army Special Forces operative who in 1997 defected to the Gulf Cartel and subsequently founded the criminal syndicate's enforcement wing at the behest of drug baron Osiel C\u00e1rdenas Guill\u00e9n. Known today as Los Zetas, the cartel's armed wing ultimately broke apart and formed its own drug trafficking organization. <sep> Hypothesis: Arturo Guzm\u00e1n Decena was asked to defect by Osiel C\u00e1rdenas.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-e276eb7f5f79404cb31c66266515ae36", "input": "Premise: \"Drivin' Around Song\" is a song recorded by American country rap singer Colt Ford and country music singer Jason Aldean. It is the third single from his fourth studio album, \"Declaration of Independence\". The song was written by Chris Tompkins and Craig Wiseman. <sep> Hypothesis: The song was written by someone with a first name not starting with a C", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-f994ae0f00024c7ca78d05fda88e3953", "input": "Premise: Marguerite Aimee Rosine Coppin (2 February 1867 \u2013 1931) was born in Brussels and became woman Poet Laureate of Belgium and a noted feminist and pioneer in female emancipation and equal rights for women. She was compared with women's rights activists Amelia Bloomer and Emmeline Pankhurst. <sep> Hypothesis: Marguerite Aimee Rosine Coppin was 66 at the time of her death", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-0accb611422049ec8949d42f4a67a9c9", "input": "Premise: The Argentine Grand Prix (Spanish: \"Gran Premio de Argentina\") was a round of the Formula One championship, held intermittently from to , all at the same autodrome in the Argentine national capital of Buenos Aires. Argentine president Juan Per\u00f3n was the driving force behind the creation of the circuit, after seeing the success of the country's own Juan Manuel Fangio. <sep> Hypothesis: Juan Manuel was responsible for the creation of the Argentine Grand Prix", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-532a669e0db94fce96a6eee88bfb3121", "input": "Premise: Ernest Guiraud (] ; 26 June 1837 \u2013 6 May 1892) was a French composer and music teacher born in New Orleans, Louisiana. He is best known for writing the traditional orchestral recitatives used for Bizet's opera \"Carmen\" and for Offenbach's opera \"Les contes d'Hoffmann\" (\"The Tales of Hoffmann\"). <sep> Hypothesis: Although from europe, Ernest Guiraud was not born there", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-8b217d767b5c4d23a414bde1a2c5f684", "input": "Premise: \"The Candidate\" is the 14th episode of the American Broadcasting Company's sixth season of the serial drama television series \"Lost\" and 117th episode overall. The episode aired on May 4, 2010, on ABC in the United States. The episode was written by Elizabeth Sarnoff and Jim Galasso and directed by Jack Bender. The episode is centered on Jack Shephard and John Locke. <sep> Hypothesis: The Candidate airs in all countries on May 4, 2010.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-8fd159df87884804baf6336e4d664da6", "input": "Premise: Glaiza Herradura-Agullo (born February 24, 1978) is a Filipino former child actress. She was the first-ever grand winner of the Little Miss Philippines segment of \"Eat Bulaga!\" in 1984. She starred in RPN-9's television series \"Heredero\" with Manilyn Reynes and Richard Arellano. She won the 1988 FAMAS Best Child Actress award for her role in \"Batas Sa Aking Kamay\" starring Fernando Poe, Jr.. <sep> Hypothesis: Glaiza Herradura-Agullo is a currently active actress.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-893d5ecdb7a64cd5bce5719e185c5841", "input": "Premise: Earlly Mac is an American rapper from Detroit, Michigan, who is best known for his collaborations with American rapper Big Sean. In 2010 he released his debut mixtape, \"Party Up!\". His debut EP, \"God Knows\", was released in January 2015, by Foolay Ent., LLC. The EP included the single \"Do It Again\" featuring Big Sean, which peaked at number 6 on the \"Billboard\" Twitter Emerging Artists chart. <sep> Hypothesis: Earlly Mac collaborated with other rappers.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-be857f94f343419ea3db17ccabd3edc5", "input": "Premise: Hamsalekha (born Govindaraju Gangaraju on 23 June 1951) is an Indian film composer and a songwriter who works in South Indian cinema, predominantly in the Kannada film industry since the late 1980s. He is also a screenplay writer, dialogue writer, instrumentalist and a conductor. Composed and written for over 300 feature films. <sep> Hypothesis: Hamsalekha (born Govindaraju Gangaraju on 23 June 1950 + 2) is an Indian film composer and a songwriter who works in South Indian cinema", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-af5e8af01f544745999e8c6a8b470cad", "input": "Premise: The Death and Life of John F. Donovan is an upcoming Canadian drama film, co-written, co-produced and directed by Xavier Dolan in his English-language debut. It stars Kit Harington, Natalie Portman, Jessica Chastain, Susan Sarandon, Kathy Bates, Jacob Tremblay, Ben Schnetzer, Thandie Newton, Amara Karan, Chris Zylka, Jared Keeso, Emily Hampshire and Michael Gambon. <sep> Hypothesis: The Death and Life of John F. Donovan is not avialable to view yet.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-442cb644979b4fe7b0fd8290dbd0fee4", "input": "Premise: A For\u00e7a do Querer (English: Edge of Desire) is a Brazilian telenovela produced and aired by Rede Globo. It is created by Gl\u00f3ria Perez, and directed by Rog\u00e9rio Gomes and Pedro Vasconcelos. It premiered on 3 April 2017, replacing \"A Lei do Amor\" at the traditional 9 pm timeslot. <sep> Hypothesis: A For\u00e7a do Querer took over an empty timeslot during its premier", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-0e9931b62a794422892869ed103a2738", "input": "Premise: Frederick Hale (October 7, 1874September 28, 1963) was the United States Senator from Maine from 1917 to 1941. He was the son of Eugene Hale, the grandson of Zachariah Chandler, both also U.S. Senators. He was the brother of diplomat Chandler Hale, and the cousin of U.S. Representative Robert Hale. <sep> Hypothesis: Frederick Hale voted on laws.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-7442c352e4bc444c92a1512f020d7425", "input": "Premise: National Security is a 2003 action comedy film, directed by Dennis Dugan, starring Martin Lawrence and Steve Zahn. In addition to Lawrence and Zahn, \"National Security\" boasts an additional cast of Bill Duke, Eric Roberts, Colm Feore, Matt McCoy, and others. <sep> Hypothesis: Martin Lawrence and Steve Zahn have never acted in a scene with Colm Feore.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-aaf7c0954f6442c7b26c2f3674cd84de", "input": "Premise: Kristine Valdresdatter is a Norwegian silent film from 1930. This was the last silent film produced in Norway and it was directed by Rasmus Breistein. Breistein also wrote the script, which was based on Hans Andersen Foss's novel \"Kristine: En fort\u00e6lling fra Valdres\" (Kristine: A Tale from Valdres). The film premiered on December 26, 1930 and it has been aired several times by NRK. <sep> Hypothesis: Valdresdatter appeared in 30 films in her lifetime.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-14a880793f6d4f05b4bd091777a4b28c", "input": "Premise: EMP Merchandising also known as EMP Merchandising Handelsgesellschaft mbH, Large Popmerchandising, and Sweden Rock Shop is a German-based music mail order and merchandising store. The company distributes a quarterly catalog to customers. In a 2003 report the Osnabr\u00fcck Chamber of Commerce considered the company to be the largest mail order business for Heavy Metal and Hard Rock music in Germany. <sep> Hypothesis: EMP Merchandising starts with an A.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-86b5568c8e7e45b1a45ebbf1a34bb39f", "input": "Premise: Goodlettsville is a city in Davidson and Sumner counties, Tennessee. Goodlettsville was incorporated as a city in 1958 with a population of just over 3,000 residents; at the 2010 census, the city had a total population of 15,921 and in 2015 the population was 16,994. Goodlettsville chose to remain autonomous in 1963 when the city of Nashville merged with the government of Davidson County. <sep> Hypothesis: after being founded in the 50's, with a minimal resident population, the population slowy increased in the later 2000's", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-137053453ea447cdbd6727a1709e446b", "input": "Premise: Polarbr\u00f6d is a Swedish bread company. Their head office is in \u00c4lvsbyn in northern Sweden. Polarbr\u00f6d is Sweden's third-largest bread company. Its typical product is a soft compact bread formed into round, flat shapes. It is also noted for ready-made sandwiches produced from such bread and reindeer meat, which was introduced as a product in the 1960s under the name \"renkl\u00e4mma\". <sep> Hypothesis: The companies noteworthy product is a circular flat disc shape.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-433f01e81ca74ee2920a1dc0ae3377eb", "input": "Premise: Caddyshack is a 1980 American comedy film directed by Harold Ramis and written by Brian Doyle-Murray, Ramis and Douglas Kenney. It stars Michael O'Keefe, Chevy Chase, Rodney Dangerfield, Ted Knight, and Bill Murray. Doyle-Murray also has a supporting role. The film was later dedicated to producer Douglas Kenney, who died shortly after the film's release. <sep> Hypothesis: caddyshack was written by three separate people", "output": ["Entailment"]}, "Prediction": "False"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-639eb09f67a6482b91979a7ed458ec14", "input": "Premise: Shenzhen Airlines () is an airline headquartered in Shenzhen Bao'an International Airport in Bao'an District, Shenzhen, Guangdong, China. It has been a member of Star Alliance since 2012, and is currently one of two Chinese airlines that is part of the global airline network. <sep> Hypothesis: Shenzhen Airlines joined the Star Alliance in 2012 A.D.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-8e3a7a06eace43a590f2f818ae4718cd", "input": "Premise: Discover Financial Services, Inc. is an American financial services company, which issues the Discover Card and operates the Discover and Pulse networks, and owns Diners Club International. Discover Card is the third largest credit card brand in the United States, when measured by cards in force, with nearly 50 million cardholders. <sep> Hypothesis: Discover Card is a way to build credit for less than 50 million cardholders", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-d941c473437c4533885089a78836aef1", "input": "Premise: Joona Veteli (born 21 April 1995) is a Finnish football player currently playing for Norwegian OBOS-ligaen side Fredrikstad. Veteli plays in the position of centre midfielder but can also operate as an attacking midfielder, defensive midfielder, right-back and winger. <sep> Hypothesis: Joona Veteli has met Elvis Presley.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-429856cbbef140778ed5243e775dee1c", "input": "Premise: Supervixens is a 1975 sexploitation film by American filmmaker Russ Meyer. The cast features Meyer regulars Charles Napier, Uschi Digard, and Haji. The film also features Shari Eubank (in a dual role) in one of her only two film roles ever and Christy Hartburg in her only film role ever. <sep> Hypothesis: Christy Hartburg was much better in her previous movie than her performance in Supervixens.", "output": ["Contradiction"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-8bfe8926de7748079a761658f66ce35e", "input": "Premise: The 2017\u201318 Puebla season is the 70th professional season of Mexico's top-flight football league. The season is split into two tournaments\u2014the Torneo Apertura and the Torneo Clausura\u2014each with identical formats and each contested by the same eighteen teams.The Club will also play Copa MX.Rafael Garc\u00eda Torres was named the club head coach on June 5, 2017, taking over for sacked coach Jos\u00e9 Cardozo. <sep> Hypothesis: The 2017\u201318 Puebla season does not have two tournaments that have different formats.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-34d43499d4794b659b8f31437476ef31", "input": "Premise: Cairn Energy PLC is one of Europe's leading independent oil and gas exploration and development companies and is listed on the London Stock Exchange. Cairn has discovered and developed oil and gas reserves in a variety of locations around the world. Cairn Energy has a primary listing on the London Stock Exchange and is a constituent of the FTSE 250 Index. <sep> Hypothesis: Cairn Energy is listed on the New York Stock Exchange", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-0bc90dca10604d96b0eb86b37ced6a75", "input": "Premise: Susarion (Greek: \u03a3\u03bf\u03c5\u03c3\u03b1\u03c1\u03af\u03c9\u03bd) was an Archaic Greek comic poet, was a native of Tripodiscus in Megaris (see Megara) and is considered one of the originators of metrical comedy and, by others, he was considered the founder of Attic Comedy. Nothing of his work, however, survives except one iambic fragment (see below) and this is not from a comedy but instead seems to belong within the Iambus tradition. <sep> Hypothesis: Funny dramatic poetry is the specialty of the Greek poet named Susarion.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-22d580be0be849beaf6bf73cde3b7800", "input": "Premise: Mark Arm (born Mark Thomas McLaughlin, February 21, 1962) is the vocalist for the grunge band Mudhoney. His former group, Green River, is one of the first grunge bands, along with Malfunkshun, Soundgarden, Skin Yard, the U-Men, and others. He is also the manager of the Sub Pop warehouse and previously worked at Fantagraphics Books. <sep> Hypothesis: Green River was founded before Soundgarden.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-ab55b89b7a1b4641b08dd056bf028c40", "input": "Premise: \"I'd Be Lost\" and \"Only One\" are two songs recorded by Australian singer-songwriter Sarah Blasko for her fifth studio album \"Eternal Return\". Both songs premiered on 13 September 2015 during Richard Kingsmill's new music segment on Triple J and were released as a double A-side on 18 September 2015. <sep> Hypothesis: Sarah Blasko has a middle name./", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-66047db18c1a4ab7a9c3b0b6d782b601", "input": "Premise: The Toffee Crisp bar is a chocolate bar first manufactured in the United Kingdom by Mackintosh's in 1963. It is now produced by Nestl\u00e9 in the UK. It consists of puffed rice embedded in soft toffee and shaped into a rectangular cuboid, the whole bar being covered by milk chocolate. <sep> Hypothesis: The Toffee Crisp bar is not sold in the US.", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-ec4cd199573541b28327147d7ddb824e", "input": "Premise: Eddie Vedder (born Edward Louis Severson; December 23, 1964) is an American musician, singer and songwriter best known as a member of the rock band Pearl Jam, with whom he performs lead vocals and is one of three guitarists. He is known for his powerful baritone vocals. He also appeared as a guest vocalist in Temple of the Dog, the one-off tribute band dedicated to the late singer Andrew Wood. <sep> Hypothesis: Edward Severson  dedicated a song to late singer Andrew Wood.", "output": ["Entailment"]}, "Prediction": "Entailment"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-0d7641544cb04c93a13618085a2be231", "input": "Premise: Datong () is a prefecture-level city in northern Shanxi province, People's Republic of China, located in a basin at an elevation of 1040 m and bordering Inner Mongolia to the north and west and Hebei to the east. It had a population of 3,318,057 at the 2010 census of whom 1,629,035 lived in the built up area made of 3 out of 4 urban districts, namely Chengqu, Kuangqu and Nanjiao District. <sep> Hypothesis: chengqu has a population of just under 1 million", "output": ["Neutral"]}, "Prediction": "Neutral"}
{"Task": "task1386_anli_r2_entailment_gpt3_0", "Definition": ["In this task, you will be presented with a premise and a hypothesis sentence. Determine whether the hypothesis sentence entails (implies), contradicts (opposes), or is neutral with respect to the given premise. Please answer with \"Contradiction\", \"Neutral\", or \"Entailment\". 1) If the premise and hypothesis are both true and the hypothesis is a subset of the premise, then the model should output Entailment.  2) If the premise and hypothesis are both true but the hypothesis contradicts the premise, then the model should output Contradiction.  3) If the premise is true but the hypothesis is false or vice versa, then the model should output Neutral."], "Instance": {"id": "task1386-c0e85ff7394445b1a03bd4fa0d67fed2", "input": "Premise: My Dinner with Herv\u00e9 is an upcoming American television drama film directed and written by Sacha Gervasi based on the later days of actor Herv\u00e9 Villechaize. The film stars Peter Dinklage as Villechaize, Jamie Dornan as a struggling journalist, and Andy Garc\u00eda as Ricardo Montalb\u00e1n, Villechaize\u2019s \"Fantasy Island\" co-star. <sep> Hypothesis: Ricardo Montalb\u00e1n's will also be portrayed in this movie.", "output": ["Entailment"]}, "Prediction": "Neutral"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-c6f877e446ea46b882044b2273d294ac", "input": "Statement: Rennie nodded. Choices:  1. Rennie was napping. 2. Rennie was in agreement. 3. Rennie was nodding.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-c3f4cefe763b45608a16b5153002e5f6", "input": "Statement: The recent Internet Explorer was just that. Choices:  1. Internet explorer wasn't that.  2. The new internet explorer was that.  3. Internet explorer is the worst browser. ", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-5655e2e279b74ff1b9c6d6c5d01f65fd", "input": "Statement: yeah she's just not much at all  i mean i would get there at eight o'clock in the morning the children usually weren't awake by then and she would get home at like five thirty in the afternoon Choices:  1. I would get there in the late afternoon and she'd be back at midnight.  2. I would get there at 8:00AM, and she'd be back by 5:30PM.  3. I still stayed after she got home at 5:30. ", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-4b75839b85b84b3bbb63afed756b7382", "input": "Statement: Goya's harrowing black paintings, done when he was depressed and going deaf (see Saturn Devouring One of His Sons) have been moved, temporarily, from the ground floor to the second floor. Choices:  1. Goya's black paintings were his better ones. 2. Goya's black paintings were done when he regained his vision. 3. Goya created black paintings when he was depressed and going deaf.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-2945a607deba464fb7987fde4ac9b5b2", "input": "Statement: But there was no mention of when you would be given those names. Choices:  1. As for when the names would be given, there was no mention. 2. Nor was the information on the troop formations forthcoming. 3. Everyone knew the names would be given in an hour, maximum.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-82cdb6197cf74391af01353a28d8c3bc", "input": "Statement: The four AICPA generally accepted standards of reporting are as follows. Choices:  1. The four least accepted AICPA standards are as follows. 2. The four AICPA standards of reporting that are usually accepted are as follows.  3. The AICPA has a hundred more standards of reporting.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-56ef0bb630d247e6815080598a04d02f", "input": "Statement: Adrin and Jon stood, pistols in hand and swords at the ready as they faced the last of the Sticks. Choices:  1. Jon and Adrin had both guns and swords.  2. The Sticks ruthlessly attacked an unarmed Adrin.  3. The Sticks were a ruthless band of thieves from Camaroon.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-e8fc9c64be3d410d8bed16e131ac3dd9", "input": "Statement: You there Rennie! Drew saw the involuntary spasm of Don Cazar's lips, the shadow of an expression which might mean he anticipated a distasteful scene to come. Choices:  1. Drew knew Don Cazar's expression well because he has known him for a long time. 2. Drew knew Don Quixote. 3. Drew knew Don Cazar's expression well.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-33aee7c96e004212abcfc2335591974f", "input": "Statement: yeah well i know that that um like they can hold it off for years by uh i'm trying to think of the word that you were um retrials and um Choices:  1. They can hold it off for more than 10 years.  2. I know they can hold it off for years.  3. They cannot hold it off for years. ", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-3c5ada14f8544d42a1e7cbb006e9a1aa", "input": "Statement: Let us hope the others are more accepting of one another. Choices:  1. We can hope that there are others who are more accepting.  2. We can only hope that they don't accept us.  3. Let's hope that the women are more accepting than the men. ", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-804d05a90a4e418688b3ae169963acd3", "input": "Statement: This is the most curiously located of the stations, in the Ethiopian Convent on the roof of the Church of the Holy Sepulchre. Choices:  1. The most commonplace station is the Ethiopian Convent located in the basement of the Church of the Holy Sepulchre. 2. The Ethiopian Convent is the most curiously located station because it is so far out of the way. 3. The most extraordinary station is the Ethiopian Convent above the Church of the Holy Sepulchre.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-d8cd21ebc5aa40088388ae63f2a98352", "input": "Statement: Individual employers were aware as claims were pursued against them after their former H-2A workers had left the United States. Choices:  1. Claims were pursued against individual employers after their former H-2A workers had left the United States. 2. The claims against employers of former H-2A workers did not succeed, but caused significant trouble for the employers. 3. Individual employers of former H-2A workers were not aware of anything.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-23279481274847e0b75778b8f8c9c347", "input": "Statement: Tommy fumed at the delay. Choices:  1. Tommy managed to remain calm in spite of the delay. 2. The delay was for a train that Tommy was to get on board. 3. Tommy was very angry that he would have to wait.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-8bc1272cce1c4066975752aade8ac261", "input": "Statement: On the first floor are the main offices of the Yokohama International Tourist Association. Choices:  1. You will not find any offices of Yokohama International Tourist Association on first floor. 2. Yokohama International Tourist Association has a regional office in Hong Kong as well. 3. Yokohama International Tourist Association has their head offices on the first floor.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-5369433242eb425eb8fc7821bd8f7ea0", "input": "Statement: Well, sir, not very often nowadays, though from time to time we do have what the young gentlemen call 'a dress-up night.' And very funny it is sometimes, sir.  Choices:  1. We occasionally have dress up night. 2. We don't often have dress up night because we are very busy. 3. We have dress up night everyday and it is very serious.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-82765f7c63a34be39c11e4902400a7d9", "input": "Statement: Its popular attraction is the cave called Orecchio di Dionisio (Dionysius' Ear), dubbed as such by Caravaggio in 1608 because of its acoustics. Choices:  1. There are no popular attractions to see there. 2. The cave was named by Caravaggio after he visited it in the summer of 1608. 3. The most popular attraction there is the cave named Orecchio di Dionisio, famous for its acoustics.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-b6494c655a00439ea4bd4a5316bb711b", "input": "Statement: Holbrooke's U.N. nomination may be iced by Helms for a bit longer, but everyone agrees that he will be confirmed. Choices:  1. Holbrooke's nomination might be put on hold for six months. 2. Holbrooke's nomination might be put on hold. 3. Holbrooke's nomination is getting pushed through rapidly.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-55a3b18a423a415fbf7afdec73f4f143", "input": "Statement: Was it a joke? Choices:  1. It was not a joke 2. Was it a joke? 3. It was a joke?", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-6668e0db009d4960866b25278ab80e7c", "input": "Statement: Its costs included $15,600 in broker commissions and a $9,234 prepayment penalty to terminate the New Century loan. Choices:  1. It costs a lot of money to terminate the loan. 2. The high fee is made to prevent people terminating loans. 3. The loan cost five hundred Dollars to terminate.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-f4e33111749740089dc5d21f348cd450", "input": "Statement: Hari Raya Haji : Muslim families celebrate the return of pilgrims from their journey to Mecca. Choices:  1. Hari Raya Haji is a holiday where muslims celebrate the return of pilgrims from Mecca. 2. Hari Raya Haji is a holiday that celebrates the deaths of pilgrims. 3. Hari Raya Haji is a muslim holiday similar to Thanksgiving.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-74a1466bda0c40f6b3b36ac50208f98f", "input": "Statement: This area has fallen into decay, but there are still vestiges of its fine history to be seen. Choices:  1. The fine history of the area is nowhere to be found. 2. This area has fallen into decay because the villagers became very poor. 3. The area's fine history can still be seen even though it as a whole has fallen into decay. ", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-988cd702152b441a996574dc747dc58f", "input": "Statement: It shone now like a tiny bit of white-hot metal; but the older man touched it, and it snuggled down into Dave's chest, dimming its glow and somehow purring. Choices:  1. The older man was unable to touch it. 2. Dave was immune to it's heat. 3. The tiny metal snuggled into Dave's chest.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-9c217e99a6e84ce59986099298d5653e", "input": "Statement: I will give you a toast. Choices:  1. I shall toast you and your family. 2. I refuse to give you a toast. 3. I shall toast you.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-cebca0e13bf94da7b4d942f992ed267d", "input": "Statement: She stabbed me in the heart. Choices:  1. I got stabbed to death. 2. I got stabbed. 3. I ran away before she could hit me.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-93708dd5a8f74a878714cbaad4847ea9", "input": "Statement: Caesars Magical A particularly unusual interactive dinner and show experience set in a series of elaborately themed underground chambers rather than a showroom proper. Choices:  1. There is an interactive dinner and show. 2. There is an interactive dinner and show at Caeser's Palace on the strip. 3. They no longer have dinner shows in Vegas.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-3517cd90cf904f65961c4b7999995c78", "input": "Statement: And I think, earlier this year, of Serbia, where the bones of Prince Lazar, the martyr of the battle against the Turks in 1389, have become hallowed in history and whose legends were written down by church scribes and canonized in cycles of folk poetry. Choices:  1. The 1389 battle against the Turks has been canonized in folk poetry, among others. 2. The battle took place in Turkey. 3. Prince Lazar was killed in the battle.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-75fd59ee45ee4cc58261ecfb066c22cc", "input": "Statement: 2 The federal government's human capital weaknesses did not emerge overnight and will not be quickly or easily addressed. Choices:  1. The federal government's human capital weakness did not emerge over a single night. 2. Human capital weakness is the bad things associated with human life value. 3. The federal government's human capital weakness emerged very quickly.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-85cb081a3e91401d8f7af92153fe438a", "input": "Statement: He was pro-German, as he would have been pro-Boer. Choices:  1. He speaks fluent German. 2. German beliefs were ones he believed in. 3. The man is a loyal American.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-1458c4861b2e45c9b68594805359437f", "input": "Statement: BUDGET AUTHORITY - The authority provided by Federal law to incur financial obligations that will result in immediate or future outlays. Choices:  1. The outlays are recorded on a supercomputer. 2. Federal law can incur financial obligations. 3. Financial obligations do not result in outlays.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-4a33049a535147acaed5f5deab979004", "input": "Statement: To gain a better understanding of how tax incentives affect national saving, look at one  how a tax deduction for a traditional tax-deferred IRA may affect government and ultimately national saving. Choices:  1. Most people reading this have poor knowledge of taxes 2. To gain a better understanding of how tax incentives affect national saving it is suggested to look at one how a tax deduction for a traditional tax-deferred IRA may affect government. 3. To gain a worse understanding of how tax incentives affect national saving it is suggested to look at one how a tax deduction for a traditional tax-deferred IRA may affect government.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-c650772252dd43f28a6d47cc401f9e6a", "input": "Statement: Moreover, GAO's statutory right of access to an agency's records is not diminished by the certification provisions of the legislation. Choices:  1. Access of an agency's records is not diminished by the certification provisions by the statutory rights of the GAO. 2. The Supreme Court of the United States have declared that agency's are not subject to review by the GOA. 3. Many agency's don't realize that the GOA still have the right to access their records by statutory rights.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-1c1d629c39894070b241d6f9e4a4c080", "input": "Statement: Shadows here were not gray or black; they were violet and purple. Choices:  1. Shadows looked ifferent because of the eclipse. 2. The shadows were pitch black. 3. Shadows were colorful.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-28de8f175ecc43789a3f3b50ca16b3ab", "input": "Statement: just real funny things you know people skiing and doing funny things on in the water and you know just really it's it's really a good program i really enjoy that Choices:  1. There are funny things like people skiing and doing things on the water. 2. It is not a good program, and people don't enjoy it. 3. There are funny things like people skiing, it's a really good program.", "output": ["3"]}, "Prediction": "2"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-4ae2fb798bd44f26a81465412b853ad0", "input": "Statement: The point is not simply to wander aimlessly through Neil Simon country but also to establish that not so long ago to participate in an American election you needed to own property, pass a literacy test, and be a male relative. Choices:  1. Passing a literacy test is needed to participate in an American election to ensure that voters know what they are doing. 2. Passing a literacy test is needed to participate in an Austrian election. 3. Passing a literacy test is needed to participate in an American election.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-ba9600806a4a49e59fc3e691a1836a58", "input": "Statement: The Faltats Museum is housed in an old mansion and features costumes, arts and crafts, and photographs. Choices:  1. The Faltats Museum was built this year with an expensive building budget. 2. An old mansion houses the Faltats Museum and has various arts and crafts amongst the photographs. 3. The Faltats Museum is a world famous museum.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-ad0dcee546724451a5f02a46558fc723", "input": "Statement: Given the extensiveness of the proposed revisions, we plan to issue a new version of GAGAS that will incorporate existing amendments. Choices:  1. Three revisions were added to the new version of GAGAS.  2. We will issue a new set of guidelines that includes all amendments and revisions. 3. Lady Gaga will be releasing a new version soon.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-80ab740ced074a238e78af0e4a6d57b3", "input": "Statement: Cete d'Or Choices:  1. Cete d'Or 2. Maybe Cete d'Or 3. France", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-7eb2675f1d69427f84e9030f854cd18b", "input": "Statement: oh yeah most of my my forms of exercise come in the form of a five year old and a two year old Choices:  1. I do not get exercise. 2. The kids give me exercise. 3. They are my kids.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-907687e8c19a4cd9b3e09c88d1c41b77", "input": "Statement: um and you know you and uh let's see there's another one up in uh just north of Baltimore called Ralphie's Diner Choices:  1. The Diner is south of Baltimore. 2. Ralphie's Diner is north of Baltimore. 3. It is an excellent choice.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-d0901d77012c4ba199eca650e30a6796", "input": "Statement: but are you at TI Choices:  1. I know you're not at TI. 2. Are you a temp at TI? 3. Are you at TI?", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-8a53afabd52c4c679b90b07198906a27", "input": "Statement: right i know oh yeah Choices:  1. That is incorrect. 2. Correct. 3. I am aware of that is being said.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-ee80087984be4c748690656657a3f413", "input": "Statement: One of the nice things about Java is that the most difficult parts of C (indirection and pointer arithmetic, among other things) have been left out of the language, while other convenience features unavailable in C (such as memory management) have been added to it. Choices:  1. One nice thing about Java is that the most difficult parts of C (indirection and pointer arithmetic, for example) have been left out of the language, while other convenience features unavailable in C have been added to it. 2. There aren't any nice things about Java. 3. C is still more popular than Java is.", "output": ["1"]}, "Prediction": "2"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-7728de8a1ca64ef7b0ef0a3262f7bb67", "input": "Statement: The official Maison de la France Web site (&lt;www.franceguide.com&gt;) is also a good starting place; the section called Discover the Regions of France directs you to local Web sites of tourist offices around France. Choices:  1. France has websites that will direct you to various local tourist attractions. 2. Local websites are not a good idea for tourists to check out. 3. Discover the Regions of France is the front page upon entering the France guide website.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-e63dbbf764394240a22ff06a6741cf64", "input": "Statement: and i know some of the i know those people i i mean i know they're people too and i know they deserve to have food to eat and water to drink Choices:  1. I see those people as subhuman and they should be left to starve. 2. Those people should have food but it shouldn't be fancy cuisine. 3. While I understand those people need basic necessities.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-75f3f41030fe485396351668057bfaef", "input": "Statement: yeah yeah where what part of Texas oh okay now i i i ask that because my wife is from the Palestine area in East Texas and you can tell she's native too yeah Choices:  1. Ah, okay, I didn't think you were from Texas. 2. My wife is from Texas, too. 3. I grew up in Oklahoma.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-8312abe3eb674b8091b8029e3c278d4b", "input": "Statement: The REIMS II countries are all industrial countries, so the distribution is likely a reasonable approximation for mail received by the U.S. Choices:  1. REIMS II countries all participate in agricultural economic actions. 2. REIMS II countries all participate in industrial economic actions. 3. REIMS II countries all participate in industrial economic actions, so they are usually on urban postal routes.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-bb7a479d1a6b43629b8160c6dfbdb687", "input": "Statement: so if they've just taken such action it would seem to indicate to me either they're doing it because they're afraid they might become a state and want to declare this before they become a state or maybe because they don't want to become a state for fear of losing the Spanish or Hispanic heritage Choices:  1. They might not become a state. 2. They may be scared they'll lose heritage. 3. They want to lose Spanish heritage.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-ae1728d34e2947e18d95d67a4a785340", "input": "Statement: This guide is intended to help auditors conduct more Choices:  1. The guide is for use by those being audited. 2. Auditors use the guide to conduct more. 3. The guide is written to be easy to understand.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-3b84cb2f8f734b88a3a07ec88388e913", "input": "Statement: He sat next to Johnny Carson and in his helium-pitched foreign man voice told jokes without punch lines (Her cooking ees so bad--ees terrible) and did non-impressionistic impressions Choices:  1. In his high pitched foreign voice, the man told Johnny Carson jokes without punchlines and terrible impressions.  2. The man told Johnny Carson terrible jokes that Carson did not understand.  3. The foreign man told Johnny Carson some hilarious jokes. ", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-14dc603bc0dc4e949ac4b627fb0a8a85", "input": "Statement: Jon returned to the camp with good tidings and two wrapped loaves of Gauve's wife's bread. Choices:  1. When Jon came back to camp, he had 17 loaves of wheat bread with him. 2. Jon arrived back at camp with 2 loaves of bread.  3. He was having an affair with Guave's wife. ", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-8a34e612714f4f9aa977849544b1d2c9", "input": "Statement: uh-huh i don't know Choices:  1. I don't know why. 2. I don't know. 3. I do know.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-08d1e7dc61bb4a079df4a57325902a06", "input": "Statement: so lots of times i'll just play cassettes instead of listening to the radio actually but uh most of my cassettes i guess i don't i don't like hard rock Choices:  1. Instead of listening to the radio, often I'll just play cassettes.  2. I never play cassettes, only the radio.  3. All of my cassettes are definitely hard rock. ", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-48b19d1213a049d9af1143264baf2a0f", "input": "Statement: Wilson also observes that besides the Unabomber's manifesto, his skill in manufacturing bombs and the clever ways in which he concealed his identity suggest to me that he was clearly sane. Choices:  1. There is a lot of evidence to show that he was clearly sane. 2. He often made bombs and went out of his way to hide his identity so he wouldn't be recognized by the local press. 3. He didn't do a good job of hiding his identity.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-d217542046cd49e4979fe5b72c2a6cc7", "input": "Statement: Less...I can do that.' Choices:  1. It will be easy for me to do less. 2. I can do less. 3. I want to do more.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-c7201c24883c42389b396a8885805a3e", "input": "Statement: (observable and unobservable characteristics) of the household. Choices:  1. The household consists of a family of 4. 2. There is nothing to see in that household. 3. The household has witnessed both observable and unobservable characteristics.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-2bc1d9931aaa40a793554ca1d4007b65", "input": "Statement: right he's supposed to be able to do that Choices:  1. No, he has no idea how to do that. 2. He's able to do that easily. 3. Yeah supposedly he's able to do that.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-f9b49f1496ce4980b6dea078c9c0338c", "input": "Statement: and i i sort of i like the really raw land you know go out and where no man has gone before and that sort of thing Choices:  1. I liked to feel like I was exploring a new territory. 2. The land was untouched by humans. 3. The land was destroyed by the humans that inhibited it. ", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-c3ddc482101443c7be8d01622ac9e7c0", "input": "Statement: Some states have established insurance-buying groups that employers can join. Choices:  1. Employers will not be able to join state established insurance-buying groups. 2. Employers can join state established insurance-buying groups. 3. Almost all of the states have established at least one insurance-buying group.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-070e8761c4c54d798341a38ae00c5c8e", "input": "Statement: As to why I'm here--\" She dropped her eyes, frowning, while a touch of added color reached her cheeks. Choices:  1. She frowned, blushed, and refused to say any more. 2. She met his eyes and smiled before continuing to speak. 3. She looked down, frowned, and blushed.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-71f7b37264594379b42852864e07b49e", "input": "Statement: I guess we're down and out for good. Sir James stroked his chin thoughtfully. Choices:  1. Sir James had a number of ideas they could try. 2. Sir James was very upset that there was nothing left to be done. 3. Sir James thought there was nothing they could do.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-f942712c700b4e01ad6ad40f6f557f6e", "input": "Statement: and uh i guess it's in fact i think it was started by somebody who was a travel agent and they got this brainstorm that you know they could make a living Choices:  1. An insurance agent got the idea for this company. 2. They have great customer service. 3. A travel agent started this company.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-bf19d6fd6a8348499059611a1f1bd38b", "input": "Statement: the executives Choices:  1. They are executives. 2. They are cashiers. 3. They work in the corporate office.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-38ed987f6dcd4f66bc6b9f20fc291cbc", "input": "Statement: Each June, the Malaysian Nature Society supports an international bird race, where teams compete to identify the largest number of birds. Choices:  1. There is an international bird race every year. 2. There is a special prize for one of the rarest birds. 3. Each June, the Malaysian Nature Society has shunned the international bird race.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-19eec9b72c4342aaab9acd67a42660c0", "input": "Statement: The beautiful Wicklow Mountains, and the Wicklow Mountains National Park provide a more rugged countryside, and the area has breathtaking houses and gardens such as Castletown, Mount Usher, and Powerscourt. Choices:  1. The Wicklow Mountains provide the most rugged countryside in the region. 2. The Wicklow Mountains' rugged countryside has breathtaking sights.  3. The Wicklow Mountains are uninteresting and barren. ", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-34bd6e3211c94da88f7ca900c2a4dc33", "input": "Statement: If it's foodstuffs you're after, there are some unusual offerings in the Lakes. Choices:  1. The lake has no restaurants. 2. The lake has james beard winning chefs. 3. If you want food, the lake has a lot of options.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-d002f00a5297451caf7cfd2e8baf60ce", "input": "Statement: His expansionism brought the bulk of Ionia under Lydian rule, but also resulted in conflict with the advancing Persians in the east, where he was roundly defeated. Choices:  1. The Lydian ruler was able to conquer much of Ionia, but lost his war with the Persians. 2. After defeating the Lydians, the Persians brought the whole of Ionia under their rule. 3. The Lydian ruler was a pacifist who never allowed his country to fight any wars.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-969818784a4f4545bf2f07ce85447e0c", "input": "Statement: The impact of screening on referral and intervention, as well as outcomes such as reduced risk behaviors, must be demonstrated. Choices:  1. We must show the overall impact of intervention. 2. Reducing risk behaviors is positive in the long run. 3. We do not know the impact of screening on referral and intervention.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-e0c43064cf48400b8754aed3e8a48be6", "input": "Statement: well i think i think i i mean what we've turned the schools into now are just day care centers Choices:  1. Schools are educational institutions that do more than just watch our children 2. Schools are day care for older children 3. Schools are essentially just day care", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-1f564ea3a8124b09a28ec1198ed2e483", "input": "Statement: However, young and old, stranger and Dubliner rub shoulders quite happily. Choices:  1. Dubliners hate outsiders, with a particular contempt for the old.  2. Dubliners and strangers get along well regardless of age.  3. Young and old, stranger and Dubliner give one another shoulder massages. ", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-8ddbfdba94384b35ad731ca81a39ef06", "input": "Statement: The protocols identify what the agencies can expect from GAO and what GAO expects of the agencies. Choices:  1. The protocol points out that the agencies should not expect anything from GAO. 2. There is a symbiosis between GAO and the agencies. 3. GAO and the agencies depend on each other for proper functioning.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-91638fca55104577be643e92c0c1c3d8", "input": "Statement: Today, a reinforced-concrete replica reproduces only the great five-storied tower, 42 m (138 ft) high, surrounded by moats and ivy-covered ramparts. Choices:  1. The ramparts surrounding the tower are fairly new. 2. The replica of the tower is pretty small, only about 5 m tall. 3. The tower is surrounded by moats and ivy covered ramparts.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-44323f2cda734a08833450b34a43100d", "input": "Statement: A key measure of design stability was stakeholders' agreements that engineering drawings were complete and supported by testing and prototyping when necessary. Choices:  1. A key measure of design stability involves agreement and testing. 2. The most important design stability is that the product has functional use. 3. Engineering drawings should never be complete and supported by testing.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-a2a9fef5d479424fa1957ca4474a701a", "input": "Statement: yeah i think i was the one who did that actually Choices:  1. I was the one who did that I think.  2. I think I did it and I think that many other people did it.  3. I don't think I did that. ", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-8f51c0160a1e432ebe33f9989783647d", "input": "Statement: That is true, he admitted. Choices:  1. That is true, he admitted with great reluctance. 2. that is false, he admitted. 3. He admitted that is was true.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-d9c995fe17504d379f0921b8ad3c00a4", "input": "Statement: I pointed. Choices:  1. I pointed at the unicorn.  2. I didn't point. 3. It was me who pointed.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-9b44222f3d324366bc619877dbb35c06", "input": "Statement: right well the when this war broke out it frustrated me all this the antiwar people and Choices:  1. The war was a good thing. 2. I was frustrated when the war started. 3. I was happy about the antiwar people.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-263ae37eefc14d28938bf1b8577e0cb5", "input": "Statement: yeah well it'd take me a good seven hours to get to Shay Stadium Choices:  1. The person says that it would take them seven hours to get to Shay Stadium. 2. The man says that it would take them seven hours to reach the stadium. 3. The man says that he could teleport to Shay Stadium.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-5c25a64586c14adb8bdaaaabc9490a73", "input": "Statement: Israel i saw that on Twenty uh 20/20 or something last week you know the about the migration and it's just and and jeez i don't know what their doing with all the people Choices:  1. I don't know what Israel is doing with all the people, with the migration. 2. Israel has way too many people apparently. 3. There must be so many people coming into Israel.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-8d602557336749baacbe64d3692ac299", "input": "Statement: From the town of Ibi onwards you'll see many castles and forts, some of them visible for miles. Choices:  1. Past Ibi, there is a dwindling number of forts and castles to be seen.  2. There are many castles and forts past Ibi. 3. There are many castles and forts, but not many are worth seeing.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-cc7cebb5e2e44c19a3899d8615204dff", "input": "Statement: You must have heard peasant superstitions. Choices:  1. Peasants had no superstitions. 2. These superstitions are about Vampires. 3. The subject of the sentence should be familiar with peasant superstitions. ", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-707dac3b8160436ba787ef5e5ca1ae0d", "input": "Statement: was it was it a criminal Choices:  1. Was it a celebrity or maybe big foot? 2. Was it a thief or a burglar or someone who broke the law. 3. Last night she thought she spotted someone attempting to break into her car.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-887703c95b0b4907bd96c856072088a3", "input": "Statement: Tuppence was in that house!  Choices:  1. That's the house that Tuppence was in. 2. Tuppence was never in that house.  3. Tuppence was in Mrs. Smith's house.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-cead7c9c0bba48acb8d028bfe86a335c", "input": "Statement: Moot Hall, a slate structure built in the early 19th century and used for Church of England services when the community had no church, sits in the center of town surrounded by the bustle of small shops and, on Saturdays, market stalls. Choices:  1. At the center of the town is a building called Moot Hall. 2. The community has always had at least one church. 3. Moot Hall still has the original bare brick walls.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-16f3cb62b82e4f15abf1e5ca455c99dc", "input": "Statement: But it's just the  The purpose of boxing gloves is not to cushion the head but to shield the knuckles. Choices:  1. Boxing gloves are used to cushion the head - not shield the knuckles. 2. Boxing gloves are used to shield the knuckles - not to cushion the head or body. 3. Boxing gloves are used to shield the knuckles - not to cushion the head.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-d2a80383919c4effb6fbefb610cbc300", "input": "Statement: At the start of production, 78 percent of These critical processes were in control. Choices:  1. 78 percent of critical processes were under control when production began.  2. A vast majority of critical processes were under control when uranium production began.  3. All critical processes were in disarray from the beginning of production. ", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-0f61378dcac34a2289bbd5c3725b4f82", "input": "Statement: These protocols are intended to govern the U.S. Choices:  1. These guidelines are set in place by the government in order to limit the power of the governing powers of the United States. 2. These guidelines won't assist governing the U.S., but will help with international affairs.  3. These guidelines are meant to govern the U.S.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-3f20d65ec9904357944fd11d0e95c4f9", "input": "Statement: Not so with trendy new items like Lands' End's $395 ultimate cashmere sweater. Choices:  1. The less trendy items are selling twice as much. 2. Lands' End's ultimate cashmere sweater costs $25. 3. It is not the case for the trendy items.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-acfa05af5c97427dbf7967cbd9e95952", "input": "Statement: Formal and informal areas are landscaped with pools and fountains, while terraces tumble down the hillsides. Choices:  1. Pools and fountains were used in the landscaping of formal areas. 2. There were no pools or fountains in the informal areas. 3. The architect of the pools and fountains drew inspiration from the gardens of Versailles.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-b2974ddcfe344904a91e65a71f6e2185", "input": "Statement: The Armitt Library and Museum Centre, just a little way beyond Bridge House, offers an interesting view on the life of the Lakes through the letters and books of local people. Choices:  1. An interesting view on the life of the Lakes through the letters and books of local people is offered by The Armitt Library and Museum Centre. 2. The only thing beyond Bridge House is the graveyard. 3. Letters and books of local people have been collected and donated by locals for the last 25 years.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-5bd6dc34d80d40e69c98203b46e8709a", "input": "Statement: i guess that's what about thirty forty thousand dollars Choices:  1. I think it's less than fifty thousand dollars. 2. That definitely costs twenty five thousand dollars. 3. Isn't that around thirty five thousand dollars?", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-ec3474b0ca7b48759d7ecb0b359f21b1", "input": "Statement: The first Europeans to arrive in the Pearl River Delta were the Portuguese, who settled in Macau in 1557 and for several centuries had a monopoly on trade between Asia, Europe, and South America. Choices:  1. As the first settlers from Europe, the Portuguese maintained a monopoly on the Macau goods trafficking for a few hundred years. 2. After the Portuguese came to Macau in the mid 16th century, they establish a monopoly on the selling and buying of goods for nearly 300 years. 3. The Portuguese soon abandoned trade in Macau after landing there in 1557.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-455473e032404376b4312efe3396a811", "input": "Statement: Some commentators adopt a stance of racial pessimism because they fear that making concessions to the optimists will breed complacency and inhibit the efforts needed for still further progress. Choices:  1. There's a fear in some commentators that compromise will have a stifling effect on making progress. 2. These commentators were largely the same folks involved in the original push on racial issues. 3. Many commentators believe that compromise would do more for inspiring people and promoting continued progress.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-66599b030e864145a3b3a589d850fdd8", "input": "Statement: Have the above trends continued for household-level demand in 1995 and 1996? Choices:  1. Household-level demand has been increased from 1995 through 1996. 2. Household-level demand was not studied from 1995 through 1996. 3. Household-level demand has been studied from 1995 through 1996.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-5043444411d04ec893970bb83fb8837b", "input": "Statement: Whether the shift from Hildy Johnson to Abe Rosenthal was a good or bad thing, it must be noted that not even Rosenthal's most passionate detractors have ever accused him of being a fictional character or of writing a sentence like Crushing all Chechen resistance, Russian troops made their dreamy, romantic, and elegant way to the outskirts of Grozny. Choices:  1. Grozny outskirts we're passed by the Russian troops. 2. The Chechen resistance destroyed the Russian army at Grozny. 3. The Chechen retreated in the mountains after they were defeated by Russian troops.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-f8646d283f77417dbad3aa0763a039d8", "input": "Statement: well i uh appreciate that information about Richardson i know it was um it's got a really good reputation and Choices:  1. Richardson has a bad reputation and I know that. 2. I know Richardson got a good reputation. 3. Richardson is pretty close to my grandfather's house.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-399cfda306bf4e8895e7942868d2728b", "input": "Statement: Sailing is a popular sport around Sardinia and Sicily, but also on Tuscany's Argentario peninsula (see page 107). Choices:  1. Boats can be rented at the beaches to go sailing. 2. In Sardinia and Sicily, sailing is very popular. 3. Sicilians don't care for sailing much.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-3d9f7f2864844c41955236a13ab74b68", "input": "Statement: (If that were my name, I might not want to talk about the scandal either.) Choices:  1. If my name was Cornelius I'd also want to avoid talking about it.  2. I wouldn't want to discuss the scandal either if that was my name.  3. If that were my name, I wouldn't stop talking about the scandal.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-9c71bdd4e60f42159d6a14f389e3301a", "input": "Statement: It carried passengers between Yokohama and Seattle for some thirty years; in summer, it has a pleasant beer garden on the upper deck. Choices:  1. It was only able to carry passengers between Yokohama and Seattle for 10 years. 2. There is a plan for it to carry passengers between Yokohama and Seattle again. 3. On the upper deck there is a beer garden.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-7bfa4ac5c1584d8594d68601d7ad4ab6", "input": "Statement: A good or service is the product of a process resulting from the consumption of resources. Choices:  1. Goods and services can be produced without any cost. 2. Resources are consumed to produce goods and services. 3. Different resources may be better suited to producing different goods and services. ", "output": ["2"]}, "Prediction": "1"}
{"Task": "task200_mnli_entailment_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine which sentence can be inferred from the statement. Incorrect choices change the meaning in important ways or have details that are not mentioned in the statement. Indicate your answer as 1,2, or 3 corresponding to the choice number of the selected sentence. The model should output 2 when the statement is true and the choices are either true or false.  The model should output 1 when the statement is false and the choices are either true or false.  The model should output 3 when the statement is true and the choices are true."], "Instance": {"id": "task200-fd7aaee0d9cf4d38b8b6f92661802f6a", "input": "Statement: That notice was summarized in the Federal Register. Choices:  1. The Federal Register is where the notice was summarized. 2. The notice was regarding the lack of funds for public schools. 3. The Federal Register has never been used to summarize a notice. ", "output": ["1"]}, "Prediction": "1"}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-d133937df763488bb844ff66d37f564c", "input": "Premise: \u0628\u0647 \u0645\u062c\u0645\u0648\u0639 \u0642\u0648\u0647 \u0642\u0627\u0646\u0648\u0646\u200c\u06af\u0630\u0627\u0631\u06cc \u0627\u0633\u067e\u0627\u0646\u06cc\u0627 \u06cc\u0639\u0646\u06cc \u0647\u0631 \u062f\u0648 \u0645\u062c\u0644\u0633 \u00ab\u0634\u0648\u0631\u0627\u06cc \u0639\u0627\u0644\u06cc\u00bb \u06cc\u0627 \u06a9\u0631\u062a\u0633 \u062e\u0646\u0631\u0627\u0644\u0633 \u06af\u0641\u062a\u0647 \u0645\u06cc\u200c\u0634\u0648\u062f. <sep> Label: Neutral", "output": ["\u0627\u0633\u067e\u0627\u0646\u06cc\u0627 \u06a9\u0634\u0648\u0631\u06cc \u062f\u0631 \u0627\u0631\u0648\u067e\u0627 \u0627\u0633\u062a."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-c35b387ce760463e826a861cbb183f3e", "input": "Premise: \u062e\u0627\u0646 \u0642\u0627\u062c\u0627\u0631 \u0628\u0631\u0627\u06cc \u0633\u0631\u06a9\u0648\u0628 \u0622\u0646\u0627\u0646 \u0639\u0627\u0632\u0645 \u0642\u0641\u0642\u0627\u0632 \u0634\u062f \u0627\u0645\u0627 \u0647\u0646\u0648\u0632 \u0628\u0647 \u0622\u0646\u062c\u0627 \u0646\u0631\u0633\u06cc\u062f\u0647 \u0628\u0648\u062f \u06a9\u0647 \u062f\u0631 \u06f1\u06f9 \u0622\u0628\u0627\u0646 \u0645\u0627\u0647 \u0633\u0627\u0644 \u06f1\u06f1\u06f7\u06f5 \u060c \u06a9\u0627\u062a\u0631\u06cc\u0646 \u062f\u0648\u0645 \u062a\u0632\u0627\u0631 \u0645\u0642\u062a\u062f\u0631 \u0631\u0648\u0633\u06cc\u0647 \u062f\u0631\u06af\u0630\u0634\u062a. <sep> Label: Neutral", "output": ["\u062e\u0627\u0646 \u0642\u0627\u062c\u0627\u0631 \u062f\u0631 \u062d\u0627\u0644 \u06a9\u0634\u0648\u0631\u06af\u0634\u0627\u06cc\u06cc \u0628\u0648\u062f."]}, "Prediction": "                                                           "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-f519a44af0ed4fbcb5a89877a9e315df", "input": "Premise: Gauve \u062e\u0646\u062f\u06cc\u062f \u0648 Celeste \u0633\u0631\u062e \u0634\u062f. <sep> Label: Entailment", "output": ["\u0633\u0644\u0633\u062a \u062e\u062c\u0627\u0644\u062a \u0632\u062f\u0647 \u0634\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-854265cc14ea468fbb78cc8851eb8519", "input": "Premise: \u0647\u0645\u0627\u0646 \u0637\u0648\u0631 \u06a9\u0647 \u06af\u0641\u062a\u0645 \u0627\u0632 \u06f6 \u0628\u0627\u0632\u06cc \u0627\u0628\u062a\u062f\u0627\u06cc\u06cc \u0641\u0635\u0644 \u0641\u0642\u0637 \u06f5 \u0627\u0645\u062a\u06cc\u0627\u0632 \u06af\u0631\u0641\u062a\u06cc\u0645 \u0648\u0644\u06cc \u0622\u0642\u0627\u06cc \u0634\u06cc\u0639\u06cc \u0628\u0627 \u0645\u0635\u0627\u062d\u0628\u0647\u200c\u0647\u0627\u06cc \u0645\u062b\u0628\u062a\u06cc \u06a9\u0647 \u0627\u0646\u062c\u0627\u0645 \u062f\u0627\u062f\u060c \u0631\u0648\u062d\u06cc\u0647 \u0645\u062b\u0628\u062a\u06cc \u0628\u0647 \u062a\u06cc\u0645 \u0627\u0644\u0642\u0627 \u06a9\u0631\u062f. <sep> Label: Neutral", "output": ["\u0642\u0631\u0627\u0631\u062f\u0627\u062f \u0627\u06cc\u0646 \u0628\u0627\u0632\u06cc\u06a9\u0646 \u0641\u0631\u0627\u0646\u0633\u0648\u06cc \u0628\u0627 \u0628\u0627\u0634\u06af\u0627\u0647 \u067e\u06cc\u06a9\u0627\u0646 \u06f3\u06f5 \u0647\u0632\u0627\u0631 \u062f\u0644\u0627\u0631 \u0627\u0633\u062a \u0648 \u062f\u0631 \u0635\u0648\u0631\u062a\u06cc \u06a9\u0647 \u0628\u062a\u0648\u0627\u0646\u062f \u06a9\u06cc\u0641\u06cc\u062a \u0644\u0627\u0632\u0645 \u0631\u0627 \u0646\u0634\u0627\u0646 \u062f\u0647\u062f \u0642\u0631\u0627\u0631\u062f\u0627\u062f\u0634 \u062a\u0627 \u06f8\u06f0 \u0647\u0632\u0627\u0631 \u062f\u0644\u0627\u0631 \u0627\u0641\u0632\u0627\u06cc\u0634 \u067e\u06cc\u062f\u0627 \u0645\u06cc\u200c\u06a9\u0646\u062f."]}, "Prediction": "                                                           "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-db28370a6cbf4207adf53d550a1dc4b7", "input": "Premise: \u067e\u0633 \u0627\u0632 \u062a\u0634\u06a9\u06cc\u0644 \u06a9\u0634\u0648\u0631 \u06a9\u0631\u0647 \u062c\u0646\u0648\u0628\u06cc \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f9\u06f4\u06f8\u060c \u0633\u0626\u0648\u0644 \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u067e\u0627\u06cc\u062a\u062e\u062a \u0627\u06cc\u0646 \u06a9\u0634\u0648\u0631 \u0628\u0631\u06af\u0632\u06cc\u062f\u0647\u200c\u0634\u062f. <sep> Label: Entailment", "output": ["\u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f9\u06f4\u06f8 \u0628\u0647 \u0628\u0639\u062f\u060c \u0633\u0626\u0648\u0644 \u067e\u0627\u06cc\u062a\u062e\u062a \u06a9\u0631\u0647 \u06cc \u062c\u0646\u0648\u0628\u06cc \u0628\u0648\u062f\u0647 \u0627\u0633\u062a."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-0d494abc28a54ba28bb74972416c3276", "input": "Premise: \u0646\u06cc\u0645\u0647 \u0646\u0648\u0631\u06cc \u06a9\u0647 \u0627\u0632 \u062a\u0627\u0628\u0634 \u0646\u0648\u0631 \u062e\u0648\u0631\u0634\u06cc\u062f \u0645\u0646\u0639\u06a9\u0633 \u0645\u06cc \u0634\u062f \u06a9\u0645 \u0646\u0648\u0631\u0634\u062f \u0648 \u0632\u0645\u06cc\u0646 \u0628\u0647 \u0634\u062f\u062a \u0644\u0631\u0632\u06cc\u062f. <sep> Label: Neutral", "output": ["\u06cc\u06a9 \u0632\u0644\u0632\u0644\u0647 \u0627\u062a\u0641\u0627\u0642 \u0627\u0641\u062a\u0627\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-875639e455794be0a1097d995e8801ee", "input": "Premise: \u0633\u0631\u0627\u0646\u062c\u0627\u0645 \u060c \u0628\u0631\u0627\u06cc \u0634\u0628\u06cc\u0647 \u0633\u0627\u0632\u06cc \u0627\u062b\u0631\u0627\u062a \u0628\u0647 \u0631\u0648\u0632\u0631\u0633\u0627\u0646\u06cc \u06a9\u0645\u06a9 \u0647\u0632\u06cc\u0646\u0647 \u060c \u0645\u06cc \u062a\u0648\u0627\u0646 \u0627\u0631\u0632\u0634 \u06a9\u0645\u06a9 \u0647\u0632\u06cc\u0646\u0647 \u0647\u0627\u06cc \u062a\u0648\u0632\u06cc\u0639 \u0645\u062c\u062f\u062f \u0631\u0627 \u0627\u0632 \u0647\u0632\u06cc\u0646\u0647 \u062a\u0648\u0644\u06cc\u062f \u0648\u0627\u062d\u062f\u0647\u0627\u06cc \u0648\u0627\u062d\u062f \u0645\u062d\u0627\u0633\u0628\u0647 \u0648 \u062a\u0641\u0631\u06cc\u0642 \u06a9\u0631\u062f - \u0627\u0632 \u0627\u06cc\u0646 \u0637\u0631\u06cc\u0642 \u0647\u0631 \u0648\u0627\u062d\u062f \u0631\u0627 \u0648\u0627\u062f\u0627\u0631 \u0645\u06cc \u06a9\u0646\u062f \u062a\u0627 \u0633\u0637\u062d \u062a\u0648\u0644\u06cc\u062f \u062d\u062f\u0627\u06a9\u062b\u0631 \u0633\u0648\u062f \u062e\u0648\u062f \u0631\u0627 \u062f\u0631 \u067e\u0627\u0633\u062e \u0628\u0647 \u0645\u062c\u0645\u0648\u0639\u0647 \u0645\u0634\u062e\u0635\u06cc \u0627\u0632 \u0633\u0648\u062e\u062a \u060c \u0631\u0627 \u062a\u063a\u06cc\u06cc\u0631 \u062f\u0647\u062f. <sep> Label: Entailment", "output": ["\u0627\u0631\u0632\u0634 \u06a9\u0645\u06a9 \u0647\u0632\u06cc\u0646\u0647 \u0647\u0627\u06cc \u062a\u0648\u0632\u06cc\u0639 \u0634\u062f\u0647 \u0645\u062c\u062f\u062f \u0627\u0632 \u0647\u0632\u06cc\u0646\u0647 \u0647\u0631 \u0648\u0627\u062d\u062f \u0642\u0627\u0628\u0644 \u0645\u062d\u0627\u0633\u0628\u0647 \u0648 \u062a\u0641\u0631\u06cc\u0642 \u0627\u0633\u062a ."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-5cec16d746b8438cac77556a3cdb8dc7", "input": "Premise: \u0645\u0638\u0627\u0647\u0631\u06cc\u0627\u0646 \u062f\u0631\u0628\u0627\u0631\u0647 \u0648\u0636\u0639\u06cc\u062a \u0628\u0627\u0632\u0627\u0631 \u0645\u0633\u06a9\u0646 \u06cc\u0627\u062f\u0622\u0648\u0631 \u0634\u062f: \u0647\u0645\u0627\u0646\u0637\u0648\u0631 \u06a9\u0647 \u062f\u0631 \u06f4 \u0633\u0627\u0644 \u06af\u0630\u0634\u062a\u0647 \u0642\u06cc\u0645\u062a \u0645\u0633\u06a9\u0646 \u0622\u0646\u0686\u0646\u0627\u0646 \u0631\u0634\u062f\u06cc \u0646\u062f\u0627\u0634\u062a\u0647\u060c \u0648\u0636\u0639\u06cc\u062a \u0628\u0627\u0632\u0627\u0631 \u0646\u0634\u0627\u0646 \u0645\u06cc\u200c\u062f\u0647\u062f \u0633\u0627\u0644 \u0622\u06cc\u0646\u062f\u0647 \u0646\u06cc\u0632 \u0642\u06cc\u0645\u062a \u0648\u0627\u062d\u062f\u0647\u0627\u06cc \u0645\u0633\u06a9\u0648\u0646\u06cc \u062f\u0631 \u06a9\u0634\u0648\u0631 \u0627\u0641\u0632\u0627\u06cc\u0634 \u0634\u062f\u06cc\u062f\u06cc \u0646\u062e\u0648\u0627\u0647\u062f \u062f\u0627\u0634\u062a. <sep> Label: Contradiction", "output": ["\u0628\u0631 \u062e\u0644\u0627\u0641 \u0633\u0627\u0644\u200c\u0647\u0627\u06cc \u06af\u0630\u0627\u0634\u062a\u0647 \u06a9\u0647 \u0645\u0633\u06a9\u0646 \u0631\u0634\u062f \u0632\u06cc\u0627\u062f\u06cc \u062f\u0627\u0634\u062a \u0627\u0645\u0633\u0627\u0644 \u0642\u06cc\u0645\u062a \u0645\u0633\u06a9\u0646 \u0627\u0641\u0632\u0627\u06cc\u0634 \u0634\u062f\u06cc\u062f\u06cc \u0646\u062e\u0648\u0627\u0647\u062f \u062f\u0627\u0634\u062a."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-043aee1cc1364325b5b31336594d36e0", "input": "Premise: \u062f\u0631 \u0633\u0627\u0644 1443\u060c \u0645\u062c\u062f\u062f\u0627 \u0628\u0647 \u0633\u06cc\u0633\u06cc\u0644 \u0645\u0644\u062d\u0642 \u0634\u062f \u0648 \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u067e\u0627\u062f\u0634\u0627\u0647\u06cc \u062f\u0648 \u0633\u06cc\u0633\u06cc\u0644 \u062a\u062d\u062a \u067e\u0627\u062f\u0634\u0627\u0647\u06cc \u0622\u0644\u0641\u0648\u0646\u0633\u0648 \u067e\u0646\u062c\u0645 \u0622\u0631\u0627\u06af\u0648\u0646 \u0627\u0633\u067e\u0627\u0646\u06cc\u0627\u06cc\u06cc\u060c \u0634\u0646\u0627\u062e\u062a\u0647 \u0634\u062f. <sep> Label: Entailment", "output": ["\u067e\u0627\u062f\u0634\u0627\u0647 \u0622\u0644\u0641\u0648\u0646\u0633\u0648 \u067e\u0646\u062c\u0645 \u0622\u0631\u0627\u06af\u0648\u0646\u060c \u0645\u062c\u062f\u062f\u0627 \u0628\u0647 \u0633\u06cc\u0633\u06cc\u0644 \u0645\u0644\u062d\u0642 \u0634\u062f."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-f28e76bc1c0345c49e0e7eb6740c092d", "input": "Premise: \u06af\u0634\u062a \u0648 \u06af\u0630\u0627\u0631 \u062f\u0631 \u0628\u0647\u0627\u0631 \u0648 \u062a\u0627\u0628\u0633\u062a\u0627\u0646 \u0628\u0647\u062a\u0631 \u0627\u0633\u062a\u060c \u0645\u06cc \u062a\u0648\u0627\u0646\u06cc\u062f \u0627\u0632 \u0632\u0646\u0628\u0642 \u0647\u0627 \u0648 \u0628\u0648\u062a\u0647 \u0647\u0627\u06cc \u06af\u0644 \u062f\u0627\u0631 \u0628\u0627\u063a \u0647\u0627\u06cc \u062f\u0627\u062e\u0644\u06cc \u0644\u0630\u062a \u0628\u0628\u0631\u06cc\u062f. <sep> Label: Contradiction", "output": ["\u06af\u0634\u062a \u0648 \u06af\u0630\u0627\u0631 \u062f\u0631 \u0637\u0648\u0644 \u0641\u0635\u0644 \u067e\u0627\u06cc\u06cc\u0632 \u0648 \u0632\u0645\u0633\u062a\u0627\u0646\u060c \u0628\u0647\u062a\u0631 \u0627\u0633\u062a."]}, "Prediction": "                                                           "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-8bb90423fded4e7bbdd980e95dd9c8d7", "input": "Premise: \u0645\u0631\u062f\u0627\u0646 \u0642\u0648\u0644 \u0645\u06cc \u062f\u0647\u0646\u062f \u0628\u0647 \u062e\u0627\u0646\u0648\u0627\u062f\u0647 \u0647\u0627\u06cc \u0639\u0631\u0648\u0633 \u067e\u0648\u0644 \u0628\u062f\u0647\u0646\u062f \u060c \u0633\u067e\u0633 \u0627\u063a\u0644\u0628 \u0628\u0627 \u0647\u0645\u0633\u0631\u0627\u0646 \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u0628\u0631\u062f\u0647 \u0647\u0627\u06cc \u062c\u0646\u0633\u06cc \u0631\u0641\u062a\u0627\u0631 \u0645\u06cc \u06a9\u0646\u0646\u062f \u06cc\u0627 \u0628\u062f\u062a\u0631. <sep> Label: Neutral", "output": ["\u0647\u0645\u0633\u0631\u0627\u0646 \u0648 \u062e\u0627\u0646\u0648\u0627\u062f\u0647 \u0647\u0627\u06cc \u0622\u0646\u0647\u0627 \u0647\u06cc\u0686 \u062a\u0635\u0648\u0631\u06cc \u0627\u0632 \u0622\u0646\u0686\u0647 \u062f\u0631\u06af\u06cc\u0631\u0634 \u0645\u06cc\u200c\u0634\u0648\u0646\u062f\u060c \u0646\u062f\u0627\u0631\u0646\u062f."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-498356a29435490f834822ed8011d5a0", "input": "Premise: \u0648 \u062d\u062f\u0633 \u0645\u06cc \u0632\u0646\u0645 \u0642\u0648\u0627\u0646\u06cc\u0646 \u0646\u0627\u0645\u0632\u062f\u06cc \u0627\u06cc\u0646 \u0631\u0648\u0632\u0647\u0627 \u0628\u0633\u06cc\u0627\u0631 \u0634\u0628\u0647 \u062f\u0645\u0648\u06a9\u0631\u0627\u062a\u06cc\u06a9 \u0627\u0633\u062a.  <sep> Label: Contradiction", "output": ["\u0622\u0646\u0647\u0627 \u0628\u0631\u0627\u06cc \u0627\u06cc\u0646 \u062f\u0648\u0631\u0647 \u0647\u06cc\u0686 \u0642\u0627\u0646\u0648\u0646 \u0646\u0627\u0645\u0632\u062f\u06cc \u0646\u062f\u0627\u0631\u0646\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-ee10feab81724f80ad17f82a21d365fe", "input": "Premise: \u0646\u0627\u0628\u0648\u06a9\u0648 \u0645\u06cc\u200c\u06af\u0648\u06cc\u062f \u06a9\u0647 \u0633\u0644\u0627\u0645\u062a\u0634 \u0631\u0627 \u0628\u0627\u0632\u06cc\u0627\u0641\u062a\u0647\u200c\u0627\u0633\u062a. <sep> Label: Entailment", "output": ["\u0646\u0627\u0628\u0648\u06a9\u0648 \u06a9\u0627\u0631\u0634 \u0631\u0627 \u0627\u0632 \u0641\u0631\u062f\u0627 \u0628\u0627 \u0633\u0644\u0627\u0645\u062a\u06cc \u06a9\u0627\u0645\u0644\u060c \u0627\u0632 \u0633\u0631 \u062e\u0648\u0627\u0647\u062f \u06af\u0631\u0641\u062a. "]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-54ca1b31fe6b4279be9655bcc1065fe3", "input": "Premise: \u0627\u0648 \u0631\u0627 \u0646\u06cc\u0632 \u0628\u06a9\u0634\u062a\u0646\u062f \u0648 \u067e\u0633 \u0627\u0632 \u0627\u0648\u060c \u0647\u06cc\u0686\u200c\u06a9\u0633 \u0631\u0627 \u0646\u06cc\u0627\u0641\u062a\u0646\u062f \u06a9\u0647 \u0634\u0627\u06cc\u0633\u062a\u0647 \u067e\u0627\u062f\u0634\u0627\u0647\u06cc \u0628\u0627\u0634\u062f. <sep> Label: Contradiction", "output": ["\u0627\u0648 \u0631\u0627 \u0646\u06cc\u0632 \u0628\u06a9\u0634\u062a\u0646\u062f \u0648 \u067e\u0633 \u0627\u0632 \u0627\u0648 \u067e\u0633\u0631\u0634 \u0631\u0627 \u0634\u0627\u06cc\u0633\u062a\u0647 \u062a\u0631\u06cc\u0646 \u0641\u0631\u062f \u0628\u0631\u0627\u06cc \u067e\u0627\u062f\u0634\u0627\u0647\u06cc \u06cc\u0627\u0641\u062a\u0646\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-150044fdef294e898917881132213b94", "input": "Premise: \u0628\u0627 \u0627\u06cc\u0646 \u062d\u0627\u0644 \u060c \u06cc\u06a9 \u0628\u0631\u0646\u0627\u0645\u0647 \u0645\u0648\u0642\u062a \u0628\u06cc\u0646 \u06f4 \u0622\u0648\u0631\u06cc\u0644 \u0648 \u06f4 \u0627\u06a9\u062a\u0628\u0631 \u06f1\u06f9\u06f9\u06f6 \u0628\u0631\u0627\u06cc \u062d\u0641\u0638 \u06cc\u06a9 \u0628\u0631\u0646\u0627\u0645\u0647 \u0627\u0633\u0627\u0633\u06cc \u062a\u0627 \u0632\u0645\u0627\u0646 \u0634\u0631\u0648\u0639 EQIP \u0627\u06cc\u062c\u0627\u062f \u0634\u062f. <sep> Label: Entailment", "output": ["\u0622\u0646\u0647\u0627 \u0628\u0631\u0646\u0627\u0645\u0647 \u0645\u0648\u0642\u062a\u06cc \u062f\u0627\u0634\u062a\u0646\u062f."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-23b7c4f9ac764c5e8f0a46b6f63e576e", "input": "Premise: \u0628\u0646\u0627\u0628\u0631\u0627\u06cc\u0646 \u0645\u0646 \u062d\u062f\u0633 \u0645\u06cc \u0632\u0646\u0645 \u062a\u062c\u0631\u0628\u0647 \u0645\u0646 \u0641\u0642\u0637 \u0628\u0627 \u06a9\u0627\u0631\u06cc \u0627\u0633\u062a \u06a9\u0647 \u0645\u0627 \u06a9\u0631\u062f\u06cc\u0645. \u0622\u0646\u0647\u0627 \u0648\u0627\u0642\u0639\u0627\u064b \u0628\u0647 \u062f\u0646\u0628\u0627\u0644 \u0645\u0647\u062f \u06a9\u0648\u062f\u06a9 \u0646\u0628\u0648\u062f\u0646\u062f \u0648 \u062f\u0631 \u062e\u0627\u0646\u0647 \u0627\u0632 \u06a9\u0648\u062f\u06a9 \u0645\u0631\u0627\u0642\u0628\u062a \u06a9\u0631\u062f\u0646\u062f. <sep> Label: Entailment", "output": ["\u0622\u0646\u0647\u0627 \u062a\u0648\u0627\u0646\u0633\u062a\u0646\u062f \u0628\u0647 \u062c\u0627\u06cc \u0627\u06cc\u0646\u06a9\u0647 \u0646\u06af\u0631\u0627\u0646 \u0645\u0647\u062f \u06a9\u0648\u062f\u06a9 \u0628\u0627\u0634\u0646\u062f\u060c \u062f\u0631 \u062e\u0627\u0646\u0647 \u0628\u0645\u0627\u0646\u0646\u062f."]}, "Prediction": "                                                           "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-1dad763611334f91a2457e564ea3a06c", "input": "Premise: \u0647\u0632\u06cc\u0646\u0647 \u062e\u0627\u0644\u0635 \u0639\u0645\u0644\u06cc\u0627\u062a <sep> Label: Contradiction", "output": ["\u0647\u0632\u06cc\u0646\u0647  \u0646\u0627\u062e\u0627\u0644\u0635"]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-e90fc18143aa401799f81c50434e7b20", "input": "Premise: \u0648 \u0633\u067e\u0633 \u0628\u0647 \u0645\u0627 \u0627\u06cc\u062f\u0647 \u062e\u0648\u0628\u06cc \u062f\u0627\u062f \u06a9\u0647 \u0686\u0647 \u0627\u0637\u0644\u0627\u0639\u0627\u062a\u06cc \u0628\u0631\u0627\u06cc \u0631\u0633\u06cc\u062f\u0646 \u0628\u0647 \u0627\u0647\u062f\u0627\u0641 \u062e\u0648\u062f \u0646\u06cc\u0627\u0632 \u062f\u0627\u0631\u06cc\u0645. <sep> Label: Contradiction", "output": ["\u0645\u0627 \u0628\u06cc\u200c\u0631\u0645\u0642 \u0628\u0648\u062f\u06cc\u0645 \u0648 \u0647\u06cc\u0686 \u0647\u062f\u0641\u06cc \u0646\u062f\u0627\u0634\u062a\u06cc\u0645."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-36074f69c379415582a341c6e1ca5498", "input": "Premise: \u0645\u062f\u062a \u0632\u0645\u0627\u0646 \u0628\u0627\u0631\u06af\u0630\u0627\u0631\u06cc \u0645\u0642\u0627\u062f\u06cc\u0631 \u0628\u0631\u0627\u0633\u0627\u0633 \u062a\u0639\u062f\u0627\u062f \u0642\u0637\u0639\u0627\u062a \u0628\u0627\u0631\u06af\u06cc\u0631\u06cc \u0634\u062f\u0647 \u0645\u062a\u0641\u0627\u0648\u062a \u0627\u0633\u062a. <sep> Label: Entailment", "output": ["\u0645\u062f\u062a \u0632\u0645\u0627\u0646 \u0628\u0627\u0631\u06af\u0630\u0627\u0631\u06cc \u0645\u0642\u0627\u062f\u06cc\u0631 \u0628\u0631\u0627\u0633\u0627\u0633 \u062a\u0639\u062f\u0627\u062f \u0642\u0637\u0639\u0627\u062a \u0628\u0627\u0631\u06af\u06cc\u0631\u06cc \u0634\u062f\u0647 \u0645\u062a\u0641\u0627\u0648\u062a \u0627\u0633\u062a."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-afb0632b162d41f88617a89e3ddb21bc", "input": "Premise: \u062e\u0648\u0628 \u060c \u062f\u0648\u0633\u062a \u0645\u0646 \u060c \u062f\u06cc\u062f\u0645 \u06a9\u0647 \u0641\u0642\u0637 \u06cc\u06a9 \u0641\u0631\u0635\u062a \u0648\u062c\u0648\u062f \u062f\u0627\u0631\u062f. <sep> Label: Entailment", "output": ["\u0645\u0646 \u0641\u0642\u0637 \u06cc\u06a9 \u0641\u0631\u0635\u062a \u0648\u0627\u062d\u062f \u0631\u0627 \u062f\u06cc\u062f\u0645."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-7ce3a284f24347fcb5b18ada00d8bf17", "input": "Premise: \u0622\u0646\u0647\u0627 \u062d\u062a\u06cc \u0645\u06cc \u062a\u0648\u0627\u0646\u0646\u062f \u062f\u0631 \u06a9\u0646\u0627\u0631 \u0631\u0627\u0646\u0646\u062f\u0647 \u0628\u0646\u0634\u06cc\u0646\u0646\u062f. <sep> Label: Neutral", "output": ["\u0635\u0646\u062f\u0644\u06cc \u06a9\u0646\u0627\u0631 \u0631\u0627\u0646\u0646\u062f\u0647 \u0628\u0647\u062a\u0631\u06cc\u0646 \u0645\u0646\u0638\u0631\u0647 \u0631\u0627 \u0627\u0631\u0627\u0626\u0647 \u0645\u06cc \u062f\u0647\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-cc31ed0ef2c947ae9b52dc34bf042c16", "input": "Premise: \u064a\u06a9 \u0633\u062e\u0646\u06af\u0648\u06cc \u0648\u0632\u0627\u0631\u062a \u0627\u0645\u0646\u064a\u062a \u0645\u0644\u06cc \u062a\u0648\u0642\u064a\u0641 \u0647\u0648\u0627\u067e\u064a\u0645\u0627 \u0631\u0627 \u062a\u0627\u0626\u064a\u062f \u06a9\u0631\u062f.  <sep> Label: Neutral", "output": ["\u064a\u06a9 \u0633\u062e\u0646\u06af\u0648\u06cc \u0648\u0632\u0627\u0631\u062a \u0627\u0645\u0646\u064a\u062a \u0645\u0644\u06cc \u0627\u0633\u062a\u0639\u0641\u0627 \u062f\u0627\u062f. "]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-532dcab9b6994d1ea78f3e8580a52147", "input": "Premise: \u0628\u062e\u0634 \u063a\u0631\u0628\u06cc \u0645\u0627\u0644\u0633\u06cc\u0627 \u0633\u0627\u0646\u062f\u0627\u0644\u064e\u0646\u062f (Sundaland) \u0646\u0627\u0645 \u062f\u0627\u0631\u062f \u06a9\u0647 \u0634\u0627\u0645\u0644 \u0634\u0628\u0647 \u062c\u0632\u06cc\u0631\u0647 \u0645\u0627\u0644\u0632\u06cc \u0648 \u062c\u0632\u0627\u06cc\u0631 \u0633\u0648\u0645\u0627\u062a\u0631\u0627\u060c \u062c\u0627\u0648\u0627\u060c \u0628\u0627\u0644\u06cc\u0648 \u0628\u0648\u0631\u0646\u0626\u0648 \u0627\u0633\u062a. <sep> Label: Entailment", "output": ["\u0634\u0628\u0647 \u062c\u0632\u0627\u06cc\u0631\u0645\u0627\u0644\u0632\u06cc \u0648 \u062c\u0632\u0627\u06cc\u0631 \u0633\u0648\u0645\u0627\u062a\u0631\u0627\u060c \u062c\u0627\u0648\u0627 \u0630\u0631 \u0647\u0645\u0633\u0627\u06cc\u06af\u06cc \u0645\u0627\u0644\u0633\u06cc\u0627 \u0642\u0631\u0627\u0631 \u062f\u0627\u0631\u0646\u062f. "]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-0422785307484e13a7dfbc162f17b63a", "input": "Premise: \u0648 \u0645\u0646 \u0647\u0631\u06af\u0632 \u062f\u0631 \u06cc\u06a9 \u0634\u0647\u0631 \u0628\u0627 \u0644\u06cc\u06af \u062c\u0632\u0626\u06cc \u0646\u0628\u0648\u062f\u0645 \u062a\u0627 \u0627\u06cc\u0646\u06a9\u0647 \u0645\u0646 \u062f\u0627\u0644\u0627\u0633 \u0622\u0645\u062f\u0645 \u062f\u0631 \u0627\u06cc\u0646 \u0634\u0647\u0631 \u062f\u0631 \u0644\u06cc\u06af \u062c\u0632\u0626\u06cc \u0628\u0648\u062f\u06cc\u0645 \u06a9\u0647 \u062f\u0631 \u0633\u0627\u0644 \u067e\u0646\u062c\u0627\u0647 \u0648 \u0646\u0647 \u0628\u0647 \u0627\u06cc\u0646\u062c\u0627 \u0622\u0645\u062f\u0645 \u0648 \u0628\u0644\u0627\u0641\u0627\u0635\u0644\u0647 \u0628\u0644\u06cc\u0637 \u0647\u0627\u06cc \u0641\u0635\u0644 \u0631\u0627 \u0628\u0631\u0627\u06cc \u0646\u0648\u0639 \u0622\u06cc \u0633\u0647 \u06af\u0627\u0646\u0647 \u06cc \u062f\u0627\u0644\u0627\u0633 \u0631\u0646\u062c\u0631\u0632 \u062e\u0631\u06cc\u062f\u0627\u0631\u06cc \u06a9\u0631\u062f\u0645 <sep> Label: Contradiction", "output": ["\u062f\u0627\u0644\u0627\u0633 \u0647\u0645\u06cc\u0634\u0647 \u062f\u0631 \u0644\u06cc\u06af \u0628\u0632\u0631\u06af \u0628\u0648\u062f."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-8d2905b7373c4b84866a88f85dc4495a", "input": "Premise: \u0627\u0648\u0647 \u0645\u0646 \u0646\u0645\u06cc \u062f\u0627\u0646\u0645 \u0645\u0646 \u0639\u0648\u0627\u0637\u0641 \u0645\u062a\u0641\u0627\u0648\u062a\u06cc \u0646\u0633\u0628\u062a \u0628\u0647 \u0627\u0648 \u062f\u0627\u0631\u0645. \u06af\u0627\u0647\u06cc \u0627\u0648\u0642\u0627\u062a \u0627\u0648 \u0631\u0627 \u062f\u0648\u0633\u062a \u062f\u0627\u0631\u0645 \u0627\u0645\u0627 \u062f\u0631 \u0647\u0645\u0627\u0646 \u0632\u0645\u0627\u0646 \u0645\u0646 \u0639\u0627\u0634\u0642 \u062f\u06cc\u062f\u0646 \u06a9\u0633\u06cc \u0647\u0633\u062a\u0645 \u06a9\u0647 \u0627\u0648 \u0631\u0627 \u0645\u0648\u0631\u062f \u0636\u0631\u0628 \u0648 \u0634\u062a\u0645 \u0642\u0631\u0627\u0631 \u0645\u06cc \u062f\u0647\u062f <sep> Label: Entailment", "output": ["\u0645\u0646 \u0627\u0648 \u0631\u0627 \u0628\u0647 \u0627\u0646\u062f\u0627\u0632\u0647 \u06cc \u0632\u06cc\u0627\u062f\u06cc \u062f\u0648\u0633\u062a \u062f\u0627\u0631\u0645 \u060c \u0627\u0645\u0627 \u0647\u0646\u0648\u0632 \u0647\u0645 \u0627\u0632 \u062f\u06cc\u062f\u0646 \u06a9\u0633\u06cc \u06a9\u0647 \u0627\u0648 \u0631\u0627 \u0645\u0648\u0631\u062f \u0636\u0631\u0628 \u0648 \u0634\u062a\u0645 \u0642\u0631\u0627\u0631 \u0645\u06cc \u062f\u0647\u062f \u0644\u0630\u062a \u0645\u06cc \u0628\u0631\u062f."]}, "Prediction": "                                                             "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-2cfb4cb5d4564eda9bf13bccbf0eb5f9", "input": "Premise: \u0622\u0645\u0631\u064a\u06a9\u0627 \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f9\u06f7\u06f9 \u0628\u0627 \u062a\u063a\u064a\u064a\u0631 \u0645\u0648\u0636\u0639\u060c \u0634\u0646\u0627\u0633\u0627\u0626\u06cc \u062f\u064a\u067e\u0644\u0645\u0627\u062a\u064a\u06a9 \u062a\u0627\u064a\u0648\u0627\u0646 \u0631\u0627 \u067e\u0633 \u06af\u0631\u0641\u062a \u0648 \u0628\u0647 \u0686\u064a\u0646 \u062f\u0627\u062f\u060c \u0627\u0645\u0627 \u0648\u0627\u0634\u0646\u06af\u062a\u0646 \u0647\u0645\u0686\u0646\u0627\u0646 \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u0628\u0632\u0631\u06af\u062a\u0631\u064a\u0646 \u062a\u0627\u0645\u064a\u0646 \u06a9\u0646\u0646\u062f\u0647 \u0633\u0644\u0627\u062d \u0647\u0627\u06cc \u062a\u0627\u064a\u067e\u0647 \u0628\u0627\u0642\u06cc \u0645\u0627\u0646\u062f. <sep> Label: Contradiction", "output": ["\u0622\u0645\u0631\u064a\u06a9\u0627 \u062f\u0631 \u0633\u0627\u0644 \u06f1\u06f9\u06f7\u06f9 \u0628\u0627 \u062a\u063a\u064a\u064a\u0631 \u0645\u0648\u0636\u0639\u060c \u0634\u0646\u0627\u0633\u0627\u0626\u06cc \u062f\u064a\u067e\u0644\u0645\u0627\u062a\u064a\u06a9 \u062a\u0627\u064a\u0648\u0627\u0646 \u0631\u0627 \u067e\u0633 \u06af\u0631\u0641\u062a \u0648\u0628\u0647 \u0627\u062e\u062a\u06cc\u0627\u0631 \u062e\u0648\u062f \u062f\u0631\u0622\u0648\u0631\u062f."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-58986ef4e2b94af683b43c8988b23845", "input": "Premise: \u062a\u0628\u062d\u0631 \u06a9\u0627\u0631\u06af\u0631\u062f\u0627\u0646 \u062f\u0631 \u062a\u0648\u062c\u0647 \u062f\u0642\u06cc\u0642 \u0628\u0647 \u062c\u0632\u0626\u06cc\u0627\u062a \u062c\u0644\u0648\u0647 \u0645\u06cc \u06cc\u0627\u0628\u062f. <sep> Label: Entailment", "output": ["\u0648\u06cc \u0627\u06cc\u0646 \u062c\u0632\u0626\u06cc\u0627\u062a \u0631\u0627 \u0628\u062e\u0634\u06cc \u0634\u0627\u062e\u0635 \u0627\u0632 \u06a9\u0627\u0631 \u062e\u0648\u062f \u062e\u0648\u0627\u0646\u062f. "]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-38175fc54f5f4a50a96f1d55492b88d7", "input": "Premise: \u062f\u0633\u062a\u064a\u0627\u0631\u0627\u0646 \u0648\u06cc\u060c \u0639\u0644\u062a \u0627\u0646\u0632\u0648\u0627\u06cc \u0627\u0648 \u0631\u0627 \u0627\u0633\u062a\u0631\u0627\u062d\u062a \u067e\u0633 \u0627\u0632 \u0645\u0628\u0627\u0631\u0632\u0627\u062a \u0627\u0646\u062a\u062e\u0627\u0628\u0627\u062a\u06cc \u0648 \u0637\u0631\u062d \u0631\u064a\u0632\u06cc \u0628\u0631\u0646\u0627\u0645\u0647 \u0647\u0627\u06cc \u0628\u0644\u0646\u062f\u067e\u0631\u0648\u0627\u0632\u0627\u0646\u0647 \u062e\u0648\u062f \u0628\u0631\u0627\u06cc \u0646\u062e\u0633\u062a\u064a\u0646 \u06f1\u06f0\u06f0 \u0631\u0648\u0632 \u0631\u064a\u0627\u0633\u062a \u062c\u0645\u0647\u0648\u0631\u06cc \u0627\u0639\u0644\u0627\u0645 \u06a9\u0631\u062f\u0647 \u0627\u0646\u062f. <sep> Label: Neutral", "output": ["\u0627\u0648 \u067e\u0633 \u0627\u0632 \u0645\u0628\u0627\u0631\u0632\u0627\u062a \u0627\u0646\u062a\u062e\u0627\u0628\u0627\u062a\u06cc\u060c \u0628\u0631\u0627\u06cc 100 \u0631\u0648\u0632 \u0628\u0647 \u0627\u0633\u062a\u0631\u0627\u062d\u062a \u067e\u0631\u062f\u0627\u062e\u062a."]}, "Prediction": "                                                           "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-f9a8ed913e6b4c99ad7887e5a6eff8c0", "input": "Premise: \u067e\u0633 \u0627\u0632 \u0627\u06cc\u0646 \u0627\u0646\u062a\u062e\u0627\u0628\u060c \u0628\u0627\u0646\u06a9\u0648\u06a9 \u0646\u062e\u0633\u062a\u06cc\u0646 \u0634\u0647\u0631\u06cc \u0634\u062f \u06a9\u0647 \u0645\u06cc\u0632\u0628\u0627\u0646\u06cc \u0686\u0647\u0627\u0631 \u0628\u0627\u0631\u06c0 \u0628\u0627\u0632\u06cc\u200c\u0647\u0627\u06cc \u0622\u0633\u06cc\u0627\u06cc\u06cc \u0631\u0627 \u0628\u0631\u0639\u0647\u062f\u0647 \u06af\u0631\u0641\u062a\u0647 \u0627\u0633\u062a. <sep> Label: Contradiction", "output": ["\u0628\u0627\u0646\u06a9\u0648\u06a9 \u0686\u0647\u0627\u0631\u0645\u06cc\u0646 \u0634\u0647\u0631\u0634\u06cc \u0634\u062f \u06a9\u0647 \u0645\u06cc\u0632\u0628\u0627\u0646\u06cc \u0686\u0647\u0627\u0631 \u0628\u0627\u0631\u0647\u200c\u06cc \u0628\u0627\u0632\u06cc\u200c\u0647\u0627\u06cc \u0622\u0633\u06cc\u0627\u06cc\u06cc \u0634\u062f."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-955ebbe63e8a4ba28fb160d754cfd00d", "input": "Premise: \u0645\u06a9 \u06a9\u0627\u0631\u062a\u0646\u06cc \u060c \u0647\u0634\u062a \u0633\u0627\u0644 \u067e\u064a\u0634 \u060c \u0647\u0645\u0633\u0631\u06cc \u0631\u0627 \u06a9\u0647 \u0628\u064a\u0633\u062a \u0648 \u0646\u0647 \u0633\u0627\u0644 \u0628\u0627 \u0627\u0648 \u06af\u0630\u0631\u0627\u0646\u062f\u0647 \u0628\u0648\u062f\u060c \u0628\u0647 \u0633\u0628\u0628 \u0628\u064a\u0645\u0627\u0631\u06cc \u0633\u0631\u0637\u0627\u0646 \u0627\u0632 \u062f\u0633\u062a \u062f\u0627\u062f\u060c \u0648 \u0627\u062e\u064a\u0631\u0627 \u0646\u064a\u0632 \u0627\u0639\u0644\u0627\u0645 \u06a9\u0631\u062f \u06a9\u0647 \u0627\u0632 \u062f\u0648\u0645\u064a\u0646 \u0647\u0645\u0633\u0631\u0634 \u067e\u0633 \u0627\u0632 \u0686\u0647\u0627\u0631 \u0633\u0627\u0644 \u0632\u0646\u062f\u06af\u06cc \u062c\u062f\u0627 \u0634\u062f\u0647 \u0627\u0633\u062a. <sep> Label: Contradiction", "output": ["\u067e\u0627\u0648\u0644 \u0645\u06a9\u200c\u06a9\u0627\u0631\u062a\u0646\u06cc \u0627\u06a9\u0646\u0648\u0646 \u0628\u0627 \u0647\u0645\u0633\u0631 \u062f\u0648\u0645 \u062e\u0648\u062f \u0632\u0646\u062f\u06af\u06cc \u0645\u06cc\u200c\u06a9\u0646\u062f"]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-1be746003d0d4339a985c9394c504da5", "input": "Premise: \u0627\u0648 \u06cc\u06a9 \u067e\u06cc\u062a\u0631 \u067e\u0646 \u0639\u062c\u06cc\u0628 \u0627\u0633\u062a - \u0628\u0632\u0647\u06a9\u0627\u0631 \u0646\u0648\u062c\u0648\u0627\u0646 \u06a9\u0647 \u0631\u0634\u062f \u0646\u0645\u06cc \u06a9\u0646\u062f. <sep> Label: Contradiction", "output": ["\u0627\u0648 \u0647\u0645\u06cc\u0634\u0647 \u0628\u0633\u06cc\u0627\u0631 \u062c\u062f\u06cc \u0639\u0645\u0644 \u0645\u06cc \u06a9\u0646\u062f \u0648 \u0647\u0631\u06af\u0632 \u0631\u0641\u062a\u0627\u0631 \u06a9\u0648\u062f\u06a9\u0627\u0646\u0647 \u0627\u06cc \u0646\u062f\u0627\u0634\u062a\u0647 \u0627\u0633\u062a."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-62ffc61ec9074e38b9feaf46a5fae418", "input": "Premise: \u062f\u0631 \u0648\u0627\u0642\u0639 \u0632\u0628\u0627\u0646 \u06af\u0648\u0631\u0627\u0646\u06cc \u0628\u0631 \u0634\u06cc\u0648\u0647 \u0645\u06a9\u0627\u0644\u0645\u0647 \u0627\u0631\u062f\u0644\u0627\u0646\u06cc \u0633\u0646\u0646\u062f\u062c\u06cc \u062a\u0623\u062b\u06cc\u0631\u06af\u0630\u0627\u0631 \u0628\u0648\u062f\u0647\u200c\u0627\u0633\u062a \u0627\u0645\u0627 \u0627\u06cc\u0646 \u062a\u0627\u062b\u06cc\u0631 \u0632\u06cc\u0627\u062f \u0646\u0628\u0648\u062f\u0647 \u0627\u0633\u062a \u0648 \u062f\u0631 \u062d\u062f \u0645\u0628\u0627\u062f\u0644\u0647 \u0648 \u0642\u0631\u0636 \u062f\u0627\u062f\u0646 \u0648\u0627\u0698\u06af\u0627\u0646 \u0628\u06cc\u0646 \u06af\u0648\u06cc\u0634 \u0627\u0631\u062f\u0644\u0627\u0646\u06cc \u0648 \u0632\u0628\u0627\u0646 \u06af\u0648\u0631\u0627\u0646\u06cc \u062f\u0631 \u0637\u0648\u0644 \u0633\u0627\u0644\u06cc\u0627\u0646 \u062f\u0631\u0627\u0632 \u0628\u0648\u062f\u0647 \u0627\u0633\u062a. <sep> Label: Neutral", "output": ["\u0627\u0645\u0627 \u0647\u0645\u0686\u0646\u0627\u0646\u06a9\u0647 \u06af\u0641\u062a\u0647 \u0634\u062f \u062f\u0631 \u0645\u062d\u062f\u0648\u062f\u0647 \u062c\u063a\u0631\u0627\u0641\u06cc\u0627\u06cc\u06cc \u0646\u0641\u0648\u0630 \u06af\u0648\u06cc\u0634 \u0639\u0645\u0648\u0645\u06cc \u0633\u0646\u0646\u062f\u062c\u06cc \u0648 \u0641\u0631\u0627\u06cc\u0646\u062f\u0647\u0627\u06cc \u0648\u0627\u062c\u06cc \u0644\u0647\u062c\u0647\u0654 \u0627\u0631\u062f\u0644\u0627\u0646\u06cc \u062f\u0631 \u0686\u0627\u0631\u0686\u0648\u0628 \u0646\u0638\u0631\u06cc\u0647\u0654 \u0628\u0647\u06cc\u0646\u06af\u06cc \u062a\u0641\u0627\u0648\u062a\u200c\u0647\u0627\u06cc\u06cc \u062f\u0631 \u0644\u062d\u0646 \u0628\u06cc\u0627\u0646 \u06a9\u0644\u0645\u0627\u062a \u0648 \u0648\u0627\u0698\u0647\u200c\u0647\u0627 \u062f\u06cc\u062f\u0647 \u0645\u06cc\u200c\u0634\u0648\u062f."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-cb9987c16d484c54b0a598e42aef2d46", "input": "Premise: \u062f\u0631 \u0634\u0647\u0631 \u06a9\u0627\u0631\u0645\u0644 \u062f\u0631 \u06a9\u0627\u0644\u06cc\u0641\u0631\u0646\u06cc\u0627\u060c \u0647\u06cc\u0686\u200c\u06af\u0648\u0646\u0647 \u0634\u0645\u0627\u0631\u0647\u0654 \u067e\u0644\u0627\u06a9\u06cc \u0648\u062c\u0648\u062f \u0646\u062f\u0627\u0631\u062f. <sep> Label: Contradiction", "output": ["\u0634\u0645\u0627\u0631\u0647 \u067e\u0644\u0627\u06a9 \u0645\u0646 \u062f\u0631 \u0634\u0647\u0631 \u06a9\u0627\u0631\u0645\u0644 \u062f\u0631 \u06a9\u0627\u0644\u06cc\u0641\u0631\u0646\u06cc\u0627\u060c \u062e\u0627\u0635 \u0628\u0648\u062f"]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-752731c61b194bba8ce760c2c230d025", "input": "Premise: \u0646\u0647\u0627\u062f \u062f\u0631\u06cc\u0627\u0641\u062a \u06a9\u0646\u0646\u062f\u0647 \u0647\u06cc\u0686 \u0645\u0642\u062f\u0627\u0631\u06cc \u0631\u0627 \u0627\u0632 \u062f\u0633\u062a \u0646\u0645\u06cc\u062f\u0647\u062f \u0648 \u0646\u0647\u0627\u062f \u0627\u0646\u062a\u0642\u0627\u0644 \u062f\u0647\u0646\u062f\u0647 \u0686\u06cc\u0632\u06cc \u0627\u0632 \u0645\u0642\u062f\u0627\u0631 \u0631\u0627 \u0635\u0627\u062d\u0628 \u0646\u0645\u06cc\u0634\u0648\u062f. <sep> Label: Neutral", "output": ["\u0628\u0631\u0627\u06cc \u0627\u0646\u062c\u0627\u0645 \u0627\u06cc\u0646 \u0627\u0646\u062a\u0642\u0627\u0644 \u0647\u0627 \u0647\u0646\u0648\u0632 \u0628\u0647 \u0645\u0642\u0627\u062f\u06cc\u0631 \u0632\u06cc\u0627\u062f\u06cc \u0627\u0632 \u0648\u0642\u062a \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u0627\u062f\u0627\u0631\u06cc \u0646\u06cc\u0627\u0632 \u0627\u0633\u062a."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-6af3e2904c0e43159e3c828444c9ae7b", "input": "Premise: \u0631\u0648\u0632 \u0633\u0647 \u0634\u0646\u0628\u0647 \u0647\u0645\u0686\u0646\u064a\u0646 \u0633\u0647 \u0631\u0627\u06a9\u062a \u0628\u0647 \u0633\u0648\u06cc \u0645\u062d\u0644\u0647 \u0627\u06cc \u062f\u0631 \u063a\u0631\u0628 \u06a9\u0627\u0628\u0644 \u067e\u0631\u062a\u0627\u0628 \u0634\u062f \u0648 \u0628\u062e\u0634\u06cc \u0627\u0632 \u062e\u0627\u0646\u0647 \u0627\u06cc \u0631\u0627 \u0648\u064a\u0631\u0627\u0646 \u06a9\u0631\u062f\u060c \u0627\u0645\u0627 \u062a\u0644\u0641\u0627\u062a\u06cc \u0628\u0628\u0627\u0631 \u0646\u064a\u0627\u0648\u0631\u062f. <sep> Label: Neutral", "output": ["\u0631\u06cc\u06cc\u0633 \u062c\u0645\u0647\u0648\u0631 \u0627\u0641\u063a\u0627\u0646\u0633\u062a\u0627\u0646 \u0628\u0627 \u0633\u0631\u0627\u0646 \u06a9\u0634\u0648\u0631 \u062f\u0631 \u06a9\u0627\u0628\u0644 \u062f\u06cc\u062f\u0627\u0631 \u06a9\u0631\u062f."]}, "Prediction": "                                                           "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-7fd506ee6d2e4e4ca60377170481a420", "input": "Premise: \u062e\u0648\u0628 \u0647\u0645\u0647 \u0622\u0646\u0647\u0627 \u0627\u0632 \u067e\u0627\u06cc\u06cc\u0646 \u0628\u0627\u0632 \u0645\u06cc \u06af\u0631\u062f\u0646\u062f <sep> Label: Entailment", "output": ["\u0622\u0646\u0647\u0627 \u0627\u0632 \u067e\u0627\u06cc\u06cc\u0646 \u0628\u0627\u0632\u062a\u0627\u0628 \u06cc\u0627\u0641\u062a\u0646\u062f \u0648 \u0628\u0631\u06af\u0634\u062a\u0646\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-a2c9e0d4cc7146bc802f9e50e78525f9", "input": "Premise: \u0627\u0646\u0642\u0644\u0627\u0628\u06cc\u0648\u0646\u06cc \u06a9\u0647 \u0628\u0627 \u062a\u0645\u0633\u06a9 \u0628\u0647 \u0627\u0633\u062a\u0642\u0631\u0627\u0631 \u0639\u062f\u0627\u0644\u062a \u0627\u062c\u062a\u0645\u0627\u0639\u06cc \u0648 \u0631\u0641\u0639 \u0647\u0631 \u06af\u0648\u0646\u0647 \u062a\u0628\u0639\u06cc\u0636\u060c \u062d\u06a9\u0648\u0645\u062a \u0631\u0627 \u062f\u0631 \u0627\u062e\u062a\u06cc\u0627\u0631 \u06af\u0631\u0641\u062a\u0647 \u0628\u0648\u062f\u0646\u062f\u060c \u0628\u0647 \u0645\u0635\u0627\u062f\u0631\u0647 \u0648 \u0645\u0644\u06cc \u06a9\u0631\u062f\u0646 \u06a9\u0627\u0631\u062e\u0627\u0646\u062c\u0627\u062a\u060c \u0634\u0631\u06a9\u062a\u200c\u0647\u0627 \u0648 \u062f\u0627\u0631\u0627\u06cc\u06cc\u200c\u0647\u0627\u06cc \u0628\u062e\u0634 \u062e\u0635\u0648\u0635\u06cc \u0631\u0648\u06cc \u0622\u0648\u0631\u062f\u0646\u062f. <sep> Label: Entailment", "output": ["\u062f\u0631\u0627\u06cc\u06cc\u200c\u0647\u0627\u06cc \u0628\u062e\u0634 \u062e\u0635\u0648\u0635\u06cc \u0628\u0647 \u0628\u0647\u0627\u0646\u0647\u200c\u06cc \u0627\u0633\u062a\u0642\u0631\u0627\u0631 \u0639\u062f\u0627\u0644\u062a \u0627\u062c\u062a\u0645\u0627\u0639\u06cc \u0645\u0635\u0627\u062f\u0631\u0647 \u0634\u062f."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-b671171c4d45422ab8fbbd6542311ae3", "input": "Premise: \u062c\u0648 \u067e\u0633 \u0627\u0632 \u0648\u0631\u0648\u062f \u0628\u0647 \u06a9\u0627\u0631\u062e\u0627\u0646\u0647 \u067e\u0627\u06a9 \u0648 \u062a\u0645\u06cc\u0632 \u0645\u06cc\u200c\u0634\u0648\u062f. <sep> Label: Neutral", "output": ["\u067e\u0633 \u0627\u0632 \u0622\u0646 \u0646\u0648\u0628\u062a \u0628\u0647 \u0627\u0646\u062c\u0627\u0645 \u0639\u0645\u0644\u06cc\u0627\u062a \u062a\u062e\u0645\u06cc\u0631 \u0645\u06cc\u0631\u0633\u062f \u06a9\u0647 \u0646\u06cc\u0627\u0632\u0645\u0646\u062f \u06a9\u0627\u0631 \u0628\u06cc\u0634\u062a\u0631\u06cc\u0633\u062a."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-1b4a2e473bdf4f36971275ff6cdd1f10", "input": "Premise: \u0627\u0639\u062a\u0631\u0627\u0641 \u06af\u0631\u0648\u0647\u0628\u0627\u0646 \u06a9\u0648\u0631\u062a\u0632 \u0628\u0647 \u062c\u0631\u0645 \u062e\u0648\u062f \u0628\u0627\u0639\u062b \u0634\u062f \u06a9\u0647 \u0627\u0632 \u0645\u062c\u0627\u0632\u0627\u062a \u062d\u0628\u0633 \u0631\u0647\u0627\u0626\u06cc \u064a\u0627\u0628\u062f <sep> Label: Neutral", "output": ["\u0627\u0648 \u0628\u0627 \u0645\u062c\u0627\u0632\u0627\u062a \u062d\u0628\u0633 \u0627\u0628\u062f \u0628\u062f\u0648\u0646 \u0627\u062d\u062a\u0645\u0627\u0644 \u0622\u0632\u0627\u062f\u06cc \u0645\u0634\u0631\u0648\u0637 \u0645\u0648\u0627\u062c\u0647 \u062e\u0648\u0627\u0647\u062f \u0628\u0648\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-ed23116d031a467989e1fb7ee5617e52", "input": "Premise: \u0627\u06cc\u062f\u0647 \u062e\u0648\u0628\u06cc \u0647\u0633\u062a <sep> Label: Neutral", "output": ["\u0628\u0647\u062a\u0631\u06cc\u0646 \u0627\u06cc\u062f\u0647 \u0627\u06cc \u0628\u0648\u062f \u06a9\u0647 \u0645\u0646 \u0634\u0646\u06cc\u062f\u0647 \u0627\u0645."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-2773b7ad839b4d199c854861fd811d30", "input": "Premise: \u062f\u0631 \u06a9\u0631\u0645\u0627\u0646\u0634\u0627\u0647 \u062f\u0631 \u0645\u0646\u0637\u0642\u0647 \u0633\u0646\u0642\u0631 \u0628\u0627 \u062f\u0648 \u0641\u0631\u0648\u0646\u062f \u0645\u06cc\u06af \u06f2\u06f3 \u0639\u0631\u0627\u0642\u06cc \u0648 \u06cc\u06a9 \u0641\u0631\u0648\u0646\u062f \u0645\u06cc\u06af \u06f2\u06f5 \u0639\u0631\u0627\u0642\u06cc \u062f\u0631\u06af\u06cc\u0631 \u0645\u06cc\u200c\u0634\u0648\u062f.\n\u0633\u0631\u06cc\u0639\u0627\u064b \u0628\u0647 \u0633\u0645\u062a \u06cc\u06a9\u06cc \u0627\u0632 \u0647\u0648\u0627\u067e\u06cc\u0645\u0627 \u06af\u0631\u062f\u0634 \u06a9\u0631\u062f\u0647 \u0648 \u0628\u0647 \u067e\u0631\u0648\u0627\u0632 \u0627\u062f\u0627\u0645\u0647 \u0645\u06cc\u200c\u062f\u0647\u062f \u0648 \u062f\u0631 \u0627\u0631\u062a\u0641\u0627\u0639 \u06f3\u06f5\u06f0\u06f0\u06f0 \u067e\u0627\u06cc\u06cc \u06cc\u06a9\u06cc\n \u0627\u0632 \u0645\u06cc\u06af\u200c\u0647\u0627\u06cc \u06f2\u06f3 \u0631\u0627 \u0645\u0648\u0631\u062f \u0647\u062f\u0641 \u0642\u0631\u0627\u0631 \u0645\u06cc\u200c\u062f\u0647\u062f \u06a9\u0647 \u067e\u0633 \u0627\u0632 \u0628\u0631\u062e\u0648\u0631\u062f \u0645\u0648\u0634\u06a9\u060c \u0645\u06cc\u06af \u0645\u0646\u0647\u062f\u0645 \u0645\u06cc\u200c\u0634\u0648\u062f. <sep> Label: Neutral", "output": ["\u0628\u0631\u062e\u0648\u0631\u062f \u0645\u0648\u0634\u06a9 \u062e\u0633\u0627\u0631\u0627\u062a \u0632\u06cc\u0627\u062f\u06cc \u0628\u0647 \u0648\u062c\u0648\u062f \u0645\u06cc \u0622\u0648\u0631\u062f."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-0832bcae4c0c431ca6fee4a8826f0f0a", "input": "Premise: \u0645\u0646\u0638\u0648\u0631\u0645 \u0627\u06cc\u0646 \u0627\u0633\u062a \u06a9\u0647 \u062e\u06cc\u0627\u0631 \u062f\u0631 \u0627\u06cc\u0646\u062c\u0627 \u062e\u06cc\u0644\u06cc \u062e\u0648\u0628 \u0631\u0634\u062f \u0645\u06cc \u06a9\u0646\u062f <sep> Label: Neutral", "output": ["\u062e\u06cc\u0627\u0631 \u062f\u0631 \u0627\u06cc\u0646\u062c\u0627 \u0628\u0647 \u062f\u0644\u06cc\u0644 \u0628\u0627\u0631\u0627\u0646 \u0648\u0627\u0642\u0639\u0627\u064b \u062e\u0648\u0628 \u0631\u0634\u062f \u0645\u06cc \u06a9\u0646\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-85240a5d388e42bfaa6f7b88ecd96d31", "input": "Premise: \u0644\u06cc\u200c\u0644\u06cc \u0631\u0627\u0628\u0637\u0647 \u062e\u0648\u0628\u06cc \u0628\u0627 \u0647\u0645\u0647 \u0627\u0639\u0636\u0627\u06cc \u06af\u0631\u0648\u0647 \u062f\u0627\u0631\u062f \u0648 \u062a\u0646\u0647\u0627 \u06a9\u0633\u06cc \u0627\u0633\u062a \u06a9\u0647 \u0647\u0645\u0647 \u0645\u0633\u0627\u06cc\u0644 \u0634\u062e\u0635\u06cc \u062e\u0648\u062f \u0631\u0627 \u0628\u0647 \u0627\u0648 \u0645\u06cc\u200c\u06af\u0648\u06cc\u0646\u062f \u0627\u0645\u0627 \u0628\u0627 \u0627\u06cc\u0646 \u062d\u0627\u0644 \u0627\u0648 \u0631\u0627\u0632\u062f\u0627\u0631 \u062e\u0648\u0628\u06cc \u0646\u06cc\u0633\u062a \u0648 \u062f\u0631 \u0645\u0648\u0642\u0639\u06cc\u062a\u200c\u0647\u0627\u06cc \u0645\u062e\u062a\u0644\u0641 \u0631\u0627\u0632\u0647\u0627\u06cc \u0632\u06cc\u0627\u062f\u06cc \u0631\u0627 \u0628\u0631\u0645\u0644\u0627 \u0645\u06cc\u200c\u06a9\u0646\u062f \u0648\u0644\u06cc \u0628\u0633\u06cc\u0627\u0631 \u0645\u0647\u0631\u0628\u0627\u0646 \u0627\u0633\u062a. <sep> Label: Contradiction", "output": ["\u0644\u06cc \u0644\u06cc \u0631\u0627\u0632\u062f\u0627\u0631 \u062e\u0648\u0628\u06cc \u0646\u06cc\u0633\u062a \u0648 \u0628\u0647 \u0647\u0645\u06cc\u0646 \u062f\u0644\u06cc\u0644 \u0627\u06a9\u062b\u0631 \u0627\u0641\u0631\u0627\u062f \u0627\u0632 \u062f\u0631 \u0645\u06cc\u0627\u0646 \u06af\u0630\u0627\u0634\u062a\u0646 \u0645\u0633\u0627\u0626\u0644 \u0634\u062e\u0635\u06cc \u062e\u0648\u062f \u0628\u0627 \u0627\u0648 \u0627\u0645\u062a\u0646\u0627\u0639 \u0645\u06cc \u06a9\u0646\u0646\u062f"]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-7bd0a81ceb8b49e78009fe6a1552a356", "input": "Premise: \u0645\u0635\u0631\u0641 \u0627\u0644\u06a9\u0644 \u0648 \u062a\u0631\u0648\u0645\u0627. <sep> Label: Neutral", "output": ["\u062a\u0631\u0648\u0645\u0627 \u0639\u0644\u062a \u0627\u0635\u0644\u06cc \u0633\u0648\u0621 \u0645\u0635\u0631\u0641 \u0627\u0644\u06a9\u0644 \u0627\u0633\u062a."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-5aa779c33fe34ca28ca5d22a100e372f", "input": "Premise: \u0628\u0647 \u062f\u0646\u0628\u0627\u0644 \u06a9\u0648\u062f\u062a\u0627 \u0648 \u067e\u0633 \u0627\u0632 \u0645\u062a\u0644\u0627\u0634\u06cc \u0634\u062f\u0646 \u062a\u0634\u06a9\u06cc\u0644\u0627\u062a \u062d\u0632\u0628 \u062a\u0648\u062f\u0647 \u062f\u0631 \u062f\u0627\u062e\u0644 \u06a9\u0634\u0648\u0631\u060c \u0642\u0631\u0634\u06cc \u062f\u0631 \u0627\u0648\u0627\u062e\u0631 \u0633\u0627\u0644 \u06f3\u06f5 \u2013 \u06f1\u06f3\u06f3\u06f4 \u0628\u0627\u0631 \u062f\u06cc\u06af\u0631 \u062f\u0633\u062a\u06af\u06cc\u0631 \u0634\u062f \u0648 \u062a\u0627 \u0633\u0627\u0644 \u06f1\u06f3\u06f3\u06f7 \u062f\u0631 \u0632\u0646\u062f\u0627\u0646 \u0645\u0627\u0646\u062f. <sep> Label: Neutral", "output": ["\u0632\u0646\u062f\u0627\u0646\u06cc \u0647\u0627 \u0647\u0646\u0648\u0632 \u0622\u0632\u0627\u062f \u0646\u0634\u062f\u0647 \u0627\u0646\u062f."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-f0954fccf9334356bea2204faf1769e2", "input": "Premise: \u067e\u0634\u062a \u0635\u062d\u0646\u0647\u060c \u067e\u0627\u062f\u06af\u0627\u0646 \u06af\u0644\u0627\u062f\u06cc\u0627\u062a\u0648\u0631\u0647\u0627 \u0642\u0631\u0627\u0631 \u062f\u0627\u0634\u062a \u06a9\u0647 \u06f6\u06f3 \u0627\u0633\u06a9\u0644\u062a \u062f\u0631 \u0622\u0646 \u067e\u06cc\u062f\u0627 \u0634\u062f. <sep> Label: Entailment", "output": ["\u06f6\u06f3 \u0627\u0633\u06a9\u0644\u062a \u062f\u0631 \u062e\u0627\u0631\u062c \u0627\u0632 \u0635\u062d\u0646\u0647\u060c \u062f\u0631 \u067e\u0627\u062f\u06af\u0627\u0646 \u06af\u0644\u0627\u062f\u06cc\u0627\u062a\u0648\u0631 \u06cc\u0627\u0641\u062a \u0634\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-d6a6bb4c43b14e839d5509c89bbeee08", "input": "Premise: \u067e\u0633 \u0627\u0632 \u062a\u0638\u0627\u0647\u0631\u0627\u062a \u06af\u0633\u062a\u0631\u062f\u0647\u0654 \u0631\u0648\u0632 \u0639\u0627\u0634\u0648\u0631\u0627 \u062f\u0631 \u0634\u0628 \u0634\u0627\u0645 \u063a\u0631\u06cc\u0628\u0627\u0646\u060c \u0645\u0639\u062a\u0631\u0636\u0627\u0646 \u062a\u0647\u0631\u0627\u0646\u06cc \u0628\u0631 \u0628\u0627\u0645\u200c\u0647\u0627 \u0641\u0631\u06cc\u0627\u062f \u00ab\u0627\u0644\u0644\u0647 \u0627\u06a9\u0628\u0631\u00bb\u060c \u00ab\u0645\u0631\u06af \u0628\u0631 \u062f\u06cc\u06a9\u062a\u0627\u062a\u0648\u0631\u00bb \u0633\u0631 \u062f\u0627\u062f\u0646\u062f. <sep> Label: Neutral", "output": ["\u062a\u0638\u0627\u0647\u0631\u0627\u062a \u06af\u0633\u062a\u0631\u062f\u0647 \u0627\u06cc \u062f\u0631 \u0686\u0646\u062f\u06cc\u0646 \u0634\u0647\u0631 \u062f\u0631 \u0631\u0648\u0632 \u0639\u0627\u0634\u0648\u0631\u0627 \u0627\u062a\u0641\u0627\u0642 \u0627\u0641\u062a\u0627\u062f."]}, "Prediction": "                                                            "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-55203d3b4ed54d9e8fd3287f8c5042c1", "input": "Premise: \u0648\u06cc \u062f\u0631 \u062c\u0631\u06cc\u0627\u0646 \u0627\u0639\u062a\u0631\u0627\u0636\u0627\u062a \u067e\u0633 \u0627\u0632 \u0627\u0646\u062a\u062e\u0627\u0628\u0627\u062a \u0631\u06cc\u0627\u0633\u062a\u200c\u062c\u0645\u0647\u0648\u0631\u06cc \u06f1\u06f3\u06f8\u06f8 \u062f\u0633\u062a\u06af\u06cc\u0631 \u0648 \u0628\u0647 \u0646\u0647 \u0633\u0627\u0644 \u0632\u0646\u062f\u0627\u0646 \u0645\u062d\u06a9\u0648\u0645 \u0634\u062f \u06a9\u0647 \u062f\u0631 \u062f\u0627\u062f\u06af\u0627\u0647 \u062a\u062c\u062f\u06cc\u062f\u0646\u0638\u0631 \u0628\u0647 \u0634\u0634 \u0633\u0627\u0644 \u06a9\u0627\u0647\u0634 \u06cc\u0627\u0641\u062a \u0648 \u062f\u0631 \u062a\u06cc\u0631 \u06f1\u06f3\u06f9\u06f2 \u0646\u06cc\u0632 \u0628\u0627 \u062a\u0648\u0642\u0641 \u062d\u06a9\u0645\u0634\u060c \u0622\u0632\u0627\u062f \u0634\u062f. <sep> Label: Contradiction", "output": ["\u062f\u0631\u062e\u0648\u0627\u0633\u062a \u0648\u06cc \u0628\u0631\u0627\u06cc \u062a\u062c\u062f\u06cc\u062f \u0646\u0638\u0631 \u062f\u0631 \u062d\u06a9\u0645\u0634 \u0646\u0627\u0645\u0648\u0641\u0642 \u0628\u0648\u062f\u0647 \u0627\u0633\u062a."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-b2c2c1b55c5f4e59aa96dacd51db97cd", "input": "Premise: \u0627\u0648 \u062a\u0648\u0633\u0637 \u0645\u062c\u0644\u0633 \u06cc\u0627 \u0645\u062c\u0644\u0633 \u0645\u0644\u06cc \u0628\u0631\u0627\u06cc \u06cc\u06a9 \u062f\u0648\u0631\u0647 \u0634\u0634 \u0633\u0627\u0644\u0647 \u0627\u0632 \u0633\u0627\u0644 \u06f2\u06f0\u06f0\u06f8 \u0645\u0646\u0635\u0648\u0628 \u0634\u062f. <sep> Label: Contradiction", "output": ["\u0627\u0632 \u0633\u0627\u0644 \u06f2\u06f0\u06f0\u06f8 \u062a\u0648\u0633\u0637 \u0631\u064a\u064a\u0633 \u062c\u0645\u0647\u0648\u0631 \u0628\u0631\u0627\u06cc \u06cc\u06a9 \u062f\u0648\u0631\u0647 \u0634\u0634 \u0633\u0627\u0644\u0647 \u0645\u0646\u0635\u0648\u0628 \u0634\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-865c4ad4ee9f472db17b149cb39cd5eb", "input": "Premise: \u0628\u0639\u0636\u06cc \u0627\u0648\u0642\u0627\u062a \u0686\u0646\u06cc\u0646 \u0628\u0648\u062f\u062c\u0647 \u0627\u06cc \u0628\u0631\u0627\u06cc \u0622\u0645\u0648\u0632\u0634 \u0645\u062c\u062f\u062f IT \u0628\u0647 \u067e\u0631\u0633\u0646\u0644 \u063a\u06cc\u0631 \u0641\u0646\u06cc \u0645\u0648\u062c\u0648\u062f  \u062a\u062e\u0635\u06cc\u0635 \u062f\u0627\u062f\u0647 \u0645\u06cc\u0634\u0648\u062f. <sep> Label: Neutral", "output": ["\u0628\u0639\u0636\u06cc \u0627\u0648\u0642\u0627\u062a \u0628\u0648\u062f\u062c\u0647 \u0628\u0647 \u0622\u0645\u0648\u0632\u0634 \u0645\u062c\u062f\u062f \u067e\u0631\u0633\u0646\u0644 \u063a\u06cc\u0631 \u0641\u0646\u06cc \u0645\u0648\u062c\u0648\u062f \u0627\u062e\u062a\u0635\u0627\u0635 \u0645\u06cc \u06cc\u0627\u0628\u062f \u062a\u0627 \u0622\u0646\u0647\u0627 \u0628\u062a\u0648\u0627\u0646\u0646\u062f \u0646\u062d\u0648\u0647 \u0628\u0631\u0646\u0627\u0645\u0647 \u0646\u0648\u06cc\u0633\u06cc \u0628\u0627 \u0631\u0627\u06cc\u0627\u0646\u0647 \u0647\u0627\u06cc \u062e\u0648\u062f \u0631\u0627 \u06cc\u0627\u062f \u0628\u06af\u06cc\u0631\u0646\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-cbe6b94c245940deba66c82aa47ce9bf", "input": "Premise: \u0645\u0642\u0627\u0645\u0627\u062a \u0639\u0631\u0627\u0642\u06cc \u0645\u06cc \u06af\u0648\u064a\u0646\u062f \u0627\u0646\u0641\u062c\u0627\u0631 \u064a\u06a9 \u062a\u0635\u0627\u062f\u0641 \u0628\u0648\u062f\u060c \u0627\u0645\u0627 \u0645\u0642\u0627\u0645\u0627\u062a \u0627\u0648\u06a9\u0631\u0627\u064a\u0646 \u062f\u0631 \u0627\u064a\u0646 \u0628\u0627\u0631\u0647  \u0645\u06cc \u06af\u0648\u064a\u0646\u062f \u06a9\u0647 \u0622\u064a\u0627 \u0627\u064a\u0646 \u062d\u0627\u062f\u062b\u0647 \u064a\u06a9 \u062d\u0645\u0644\u0647 \u0628\u0648\u062f \u064a\u0627\u0646\u0647\u060c \u062a\u062d\u0642\u064a\u0642 \u0645\u06cc \u06a9\u0646\u0646\u062f. <sep> Label: Contradiction", "output": ["\u0622\u0646 \u0647\u0627 \u0647\u0645\u06af\u06cc \u0645\u0639\u062a\u0642\u062f\u0646\u062f \u06a9\u0647 \u0627\u06cc\u0646 \u062d\u0627\u062f\u062b\u0647 \u062a\u0635\u0627\u062f\u0641 \u0646\u0628\u0648\u062f\u0647 \u0648 \u06cc\u06a9 \u062d\u0645\u0644\u0647 \u0645\u062d\u0633\u0648\u0628 \u0645\u06cc \u0634\u0648\u062f."]}, "Prediction": "                                                            "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-53a09286b5194ee3b38e4483fdb1f146", "input": "Premise: \u0634\u0627\u06cc\u062f \u0634\u0646\u0627\u062e\u062a\u0647 \u0634\u062f\u0647\u200c\u062a\u0631\u06cc\u0646 \u0646\u0642\u0634 \u0627\u0648\u060c \u0646\u0642\u0634 \u0698\u0627\u0646 \u0648\u0627\u0644\u0698\u0627\u0646 \u062f\u0631 \u0641\u06cc\u0644\u0645 \u0628\u06cc\u0646\u0648\u0627\u06cc\u0627\u0646 (\u06f1\u06f9\u06f8\u06f2) \u0628\u0627\u0634\u062f \u06a9\u0647 \u0628\u0647 \u062e\u0627\u0637\u0631 \u0622\u0646 \u0646\u0627\u0645\u0632\u062f \u062c\u0627\u06cc\u0632\u0647 \u0633\u0632\u0627\u0631 (\u0627\u0633\u06a9\u0627\u0631 \u0641\u0631\u0627\u0646\u0633\u0648\u06cc) \u0634\u062f. \u0644\u06cc\u0646\u0648 \u0648\u0646\u062a\u0648\u0631\u0627 \u062a\u0627 \u0622\u062e\u0631\u06cc\u0646 \u0633\u0627\u0644\u200c\u0647\u0627\u06cc \u0639\u0645\u0631\u0634 \u0628\u0647 \u0628\u0627\u0632\u06cc \u062f\u0631 \u0641\u06cc\u0644\u0645 \u067e\u0631\u062f\u0627\u062e\u062a. <sep> Label: Contradiction", "output": ["\u0644\u06cc\u0646\u0648 \u0648\u0646\u062a\u0648\u0631\u0627 \u0628\u0631\u0627\u06cc \u0628\u0627\u0632\u06cc \u062f\u0631 \u0641\u06cc\u0644\u0645 \u0628\u06cc\u0646\u0648\u0627\u06cc\u0627\u0646 \u062c\u0627\u06cc\u0632\u0647\u200c\u06cc \u0627\u0633\u06a9\u0627\u0631 \u0628\u0631\u062f.", "\u0644\u06cc\u0646\u0648 \u0648\u0646\u062a\u0648\u0631\u0627 \u0628\u0631\u0627\u06cc \u0628\u0627\u0632\u06cc \u062f\u0631 \u0641\u06cc\u0644\u0645 \u0628\u06cc\u0646\u0648\u0627\u06cc\u0627\u0646 \u062c\u0627\u06cc\u0632\u0647\u200c\u06cc \u0627\u0633\u06a9\u0627\u0631 \u0628\u0631\u062f.", "\u0644\u06cc\u0646\u0648 \u0648\u0646\u062a\u0648\u0631\u0627 \u0628\u0631\u0627\u06cc \u0628\u0627\u0632\u06cc \u062f\u0631 \u0641\u06cc\u0644\u0645 \u0628\u06cc\u0646\u0648\u0627\u06cc\u0627\u0646 \u062c\u0627\u06cc\u0632\u0647\u200c\u06cc \u0627\u0633\u06a9\u0627\u0631 \u0628\u0631\u062f."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-23c0b2462ab347f1ac3e5620e9e6db5c", "input": "Premise: \u0627\u0645\u0627 \u062f\u0631 \u0622\u0646\u062c\u0627 \u062e\u0627\u0646 \u062f\u0648\u0645 \u062f\u0647\u060c \u0641\u062a\u062d\u200c\u0627\u0644\u0644\u0647 \u062e\u0627\u0646 \u06af\u0644\u0647 \u062f\u0627\u0631\u06cc \u0627\u0632 \u0645\u062d\u0645\u0648\u062f \u067e\u062f\u0631 \u0633\u062a\u0627\u06cc\u0634 \u06a9\u06cc\u0646\u0647 \u062f\u06cc\u0631\u06cc\u0646\u0647 \u062f\u0627\u0631\u062f. <sep> Label: Neutral", "output": ["\u0633\u062a\u0627\u06cc\u0634 \u062f\u0631 \u0641\u0631\u0627\u0642 \u0628\u0631\u0627\u062f\u0631 \u0628\u0627 \u062a\u0648\u062c\u0647 \u0628\u0647 \u0648\u0636\u0639\u06cc\u062a \u0646\u0627\u0645\u0646\u0627\u0633\u0628 \u067e\u062f\u0631 \u0628\u0647 \u0632\u0646\u062f\u06af\u06cc \u062e\u0648\u062f \u0627\u062f\u0627\u0645\u0647 \u0645\u06cc \u062f\u0647\u062f."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-1d8a50469bfa4d1db7d5b32cffa7b55c", "input": "Premise: \u0645\u0648\u0631\u06cc\u0646\u06cc\u0648 \u0628\u0639\u062f \u0627\u0632 \u06cc\u06a9 \u0628\u0631\u062f \u06f3\u2013\u06f0 \u062f\u0631 \u0628\u0631\u0627\u0628\u0631 \u0627\u0633\u067e\u0648\u0631\u062a\u06cc\u0646\u06af\u060c \u0627\u0632 \u0645\u062f\u06cc\u0631\u06cc\u062a \u0628\u0627\u0634\u06af\u0627\u0647 \u062e\u0648\u0627\u0633\u062a \u062a\u0627 \u0642\u0631\u0627\u0631\u062f\u0627\u062f\u0634 \u0631\u0627 \u062a\u0645\u062f\u06cc\u062f \u06a9\u0646\u062f \u0627\u0645\u0627 \u0648\u06cc\u0644\u0627\u0631\u06cc\u0646\u0648 \u0627\u0632 \u0627\u0646\u062c\u0627\u0645 \u0627\u06cc\u0646\u06a9\u0627\u0631 \u0627\u0645\u062a\u0646\u0627\u0639 \u06a9\u0631\u062f \u0648 \u062f\u0631\u062e\u0648\u0627\u0633\u062a \u0645\u0648\u0631\u06cc\u0646\u06cc\u0648 \u0631\u0627 \u0646\u067e\u0630\u06cc\u0631\u0641\u062a. <sep> Label: Entailment", "output": ["\u0642\u0631\u0627\u0631\u062f\u0627\u062f \u0645\u0648\u0631\u06cc\u0646\u06cc\u0648 \u0628\u0627 \u0648\u062c\u0648\u062f \u0628\u0631\u062f \u0628\u0631\u0627\u0628\u0631 \u0627\u0633\u067e\u0648\u0631\u062a\u06cc\u0646\u06af \u062a\u0645\u062f\u06cc\u062f \u0646\u0634\u062f."]}, "Prediction": "                                                           "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-ff106a44aa2d4508a5cf5f1ca0a523e0", "input": "Premise: \u0632\u06cc\u0631\u0627 \u0628\u06cc\u0634\u062a\u0631 \u0636\u0628\u0637\u200c\u0647\u0627 \u062e\u0635\u0648\u0635\u06cc \u0628\u0648\u062f\u0647\u200c\u0627\u0646\u062f. <sep> Label: Contradiction", "output": ["\u0627\u0632 \u06a9\u0627\u0631\u0647\u0627\u06cc\u06cc\u06a9\u0647 \u0627\u0648 \u0627\u0646\u062c\u0627\u0645 \u062f\u0627\u062f\u0647 \u0627\u0633\u062a \u0627\u0637\u0644\u0627\u0639\u0627\u062a \u0686\u0646\u062f\u0627\u0646\u06cc \u062f\u0631 \u062f\u0633\u062a \u0646\u06cc\u0633\u062a\u061b \u0686\u0648\u0646 \u0627\u0648 \u0628\u06cc\u0634\u062a\u0631 \u06a9\u0627\u0631\u0647\u0627\u06cc\u0634 \u0631\u0627 \u0628\u0635\u0648\u0631\u062a \u062e\u0635\u0648\u0635\u06cc \u0627\u0646\u062c\u0627\u0645 \u0645\u06cc\u062f\u0627\u062f\u0647 \u0648 \u0622\u0646\u0647\u0627 \u0631\u0627 \u0636\u0628\u0637 \u0646\u0645\u06cc\u06a9\u0631\u062f\u0647 \u0627\u0633\u062a. "]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-234afebe8aa24de198519a1adf54e259", "input": "Premise: \u067e\u06cc\u062a \u0627\u0633\u062a\u0627\u0631\u06a9 \u0628\u0631\u0627\u06cc \u0645\u062a\u0648\u0642\u0641 \u06a9\u0631\u062f\u0646 \u062a\u0645\u0631\u06cc\u0646 \u060c \u062f\u0631 \u062d\u0627\u0644 \u062c\u0646\u06af \u0635\u0644\u06cc\u0628\u06cc \u0627\u0633\u062a. <sep> Label: Neutral", "output": ["\u062a\u0645\u0631\u06cc\u0646 \u0634\u0631 \u0627\u0633\u062a \u0648 \u067e\u06cc\u062a \u0627\u0633\u062a\u0627\u0631\u06a9 \u0642\u0647\u0631\u0645\u0627\u0646 \u0627\u0633\u062a."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-f1889f407c4d445099ec43aefc7516ea", "input": "Premise: \u0627\u0648\u0647 \u0628\u0644\u0647 \u0627\u06cc\u0646 \u0645\u0633\u0626\u0644\u0647\u200c\u06cc \u0632\u0645\u0627\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0627\u062d\u062a\u0645\u0627\u0644\u0627\u064b \u062f\u0648 \u062a\u0627 \u067e\u0646\u062c \u0633\u0627\u0644 \u062f\u06cc\u06af\u0631 \u0637\u0648\u0644 \u062e\u0648\u0627\u0647\u062f \u06a9\u0634\u06cc\u062f \u062a\u0627 \u0627\u06cc\u0646\u200c\u06a9\u0647 \u0628\u0647 \u06cc\u06a9 \u0633\u0637\u062d \u0628\u0631\u0633\u0646\u062f.  <sep> Label: Entailment", "output": ["\u0631\u0633\u06cc\u062f\u0646 \u0628\u0647 \u06cc\u06a9 \u0633\u0637\u062d \u0628\u0631\u0627\u06cc \u0627\u06cc\u0646 \u062f\u0648 \u062f\u0648 \u062a\u0627 \u067e\u0646\u062c \u0633\u0627\u0644 \u062f\u06cc\u06af\u0631 \u0637\u0648\u0644 \u062e\u0648\u0627\u0647\u062f \u06a9\u0634\u06cc\u062f."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-4c31ca8d1e0d425ead4e63044a7ffbf2", "input": "Premise: \u0646\u0638\u0631\u062a \u0631\u0627\u062c\u0639 \u0628\u0647 \u0622\u0646 \u0686\u06cc\u0633\u062a\u061f \u06f3\u06f8 \u0627\u06cc\u0646 \u0642\u0637\u0639\u0647 \u0631\u0627 \u0628\u0631\u0631\u0633\u06cc \u06a9\u0631\u062f\u0645. <sep> Label: Contradiction", "output": ["\u0628\u0631\u0627\u06cc \u0645\u0646 \u0645\u0647\u0645 \u0646\u06cc\u0633\u062a \u06a9\u0647 \u0634\u0645\u0627 \u0686\u0647 \u0641\u06a9\u0631 \u0645\u06cc \u06a9\u0646\u06cc\u062f"]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-e011f1a7db4e4b3782da30f376e23120", "input": "Premise: \u0645\u0627 \u0642\u062a\u0644 \u062f\u0631 \u0686\u0634\u0645\u0627\u0646 \u0622\u0646\u0647\u0627 \u0648 \u062e\u0648\u0646 \u0631\u0648\u06cc \u062f\u0633\u062a \u0622\u0646\u0647\u0627 \u0631\u0627 \u062f\u06cc\u062f\u06cc\u0645. <sep> Label: Neutral", "output": ["\u0645\u0627 \u062e\u0648\u0646 \u062f\u0631 \u062f\u0633\u062a\u0627\u0646 \u067e\u0644\u06cc\u062f \u0648 \u0642\u062a\u0644 \u062f\u0631 \u0686\u0634\u0645\u0627\u0646 \u0634\u06cc\u0637\u0627\u0646\u06cc \u0622\u0646\u0647\u0627 \u062f\u06cc\u062f\u06cc\u0645."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-fb4c1a0cce084770b313d8b89bc4b8b0", "input": "Premise: \u0627\u06cc\u0646 \u062e\u0648\u0631\u0634\u06cc\u062f\u06af\u0631\u0641\u062a\u06af\u06cc \u062f\u0631 \u062a\u0627\u0631\u06cc\u062e \u06f2\u06f0 \u0698\u0648\u0626\u06cc\u0647 \u06f1\u06f9\u06f4\u06f4 \u0645\u06cc\u0644\u0627\u062f\u06cc \u0631\u0648\u06cc \u062f\u0627\u062f \u06a9\u0647 \u0632\u0645\u0627\u0646 \u0627\u0648\u062c \u0622\u0646\u060c \u0633\u0627\u0639\u062a \u06f5:\u06f4\u06f3:\u06f1\u06f3 \u0628\u0647 \u200c\u0648\u0642\u062a \u0633\u0627\u0639\u062a \u0647\u0645\u0627\u0647\u0646\u06af \u062c\u0647\u0627\u0646\u06cc \u0628\u0648\u062f\u0647\u200c\u0627\u0633\u062a. <sep> Label: Entailment", "output": ["\u062e\u0648\u0631\u0634\u06cc\u062f\u06af\u0631\u0641\u062a\u06a9\u06cc \u0633\u0627\u0644 \u06f1\u06f9\u06f4\u06f4 \u062f\u0631 \u0645\u0627\u0647 \u0698\u0648\u0626\u0646 \u0628\u0648\u062f."]}, "Prediction": "                                                            "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-b76140d89e254ff2bfdafe7afb4f366d", "input": "Premise: \u062a\u0628\u062d\u0631 \u06a9\u0627\u0631\u06af\u0631\u062f\u0627\u0646 \u062f\u0631 \u062a\u0648\u062c\u0647 \u062f\u0642\u06cc\u0642 \u0628\u0647 \u062c\u0632\u0626\u06cc\u0627\u062a \u062c\u0644\u0648\u0647 \u0645\u06cc \u06cc\u0627\u0628\u062f. <sep> Label: Neutral", "output": ["--"]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-be671a8d7e9d44dfa12cdb8dc3f3e105", "input": "Premise: \u0627\u0648 \u06af\u0641\u062a \u060c \u0645\u0634\u06a9\u0644 \u0648\u06cc \u062a\u0648\u0642\u0641 \u0641\u0639\u0644\u06cc \u0627\u0633\u062a\u062e\u062f\u0627\u0645 \u0627\u0633\u062a \u06a9\u0647 \u0628\u0647 \u0647\u0645\u0647 \u0622\u0698\u0627\u0646\u0633 \u0647\u0627\u06cc \u0634\u0647\u0631\u06cc \u062a\u062d\u0645\u06cc\u0644 \u0634\u062f\u0647 \u0627\u0633\u062a. <sep> Label: Neutral", "output": ["\u0628\u0647 \u062f\u0644\u06cc\u0644 \u062a\u0648\u0642\u0641 \u0627\u0633\u062a\u062e\u062f\u0627\u0645\u060c \u062f\u0631 \u06cc\u0627\u0641\u062a\u0646 \u0634\u063a\u0644 \u0645\u0634\u06a9\u0644 \u062f\u0627\u0634\u062a."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-1de8ea052d0d4d97931b24a41b53aec8", "input": "Premise: \u0627\u0645\u0627 \u0627\u06cc\u0646 \u0641\u06cc\u0644\u0645 \u0628\u062e\u0627\u0637\u0631 \u0648\u062c\u0648\u062f \u0635\u062d\u0646\u0647\u200c\u0647\u0627\u06cc\u06cc \u0628\u0627 \u0633\u0627\u0646\u0633\u0648\u0631\u0647\u0627\u06cc \u0632\u06cc\u0627\u062f \u0645\u0646\u0647\u062f\u0645 \u0634\u062f \u0648 \u0628\u0647 \u0647\u06cc\u0686 \u0645\u0648\u0641\u0642\u06cc\u062a\u06cc \u062f\u0633\u062a \u067e\u06cc\u062f\u0627 \u0646\u06a9\u0631\u062f. <sep> Label: Contradiction", "output": ["\u0627\u06cc\u0646 \u0641\u06cc\u0644\u0645 \u0628\u0627 \u0648\u062c\u0648\u062f \u0645\u0648\u0641\u0642\u062a \u0641\u0631\u0627\u0648\u0627\u0646  \u062f\u0627\u0631\u0627\u06cc \u0635\u062d\u0646\u0647\u200c\u0647\u0627\u06cc \u0632\u06cc\u0627\u062f\u06cc \u0628\u0648\u062f \u0648 \u0628\u0647 \u0647\u0645\u06cc\u0646 \u062f\u0644\u06cc\u0644 \u062e\u0648\u0634\u0627\u06cc\u0646\u062f \u0628\u0631\u062e\u06cc \u0627\u0632 \u0645\u062e\u0627\u0637\u0628\u0627\u0646 \u0642\u0631\u0627\u0631 \u0646\u06af\u0631\u0641\u062a."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-0d94b88ceae447728421028a63b369b3", "input": "Premise: \u062f\u0631 \u0634\u0631\u0627\u06cc\u0637 \u062f\u06cc\u06af\u0631 \u060c \u0645\u0627 \u0645\u062a\u0630\u06a9\u0631 \u0634\u062f\u06cc\u0645 \u06a9\u0647 \u06cc\u06a9 \u0628\u0631\u0646\u0627\u0645\u0647 \u0641\u0627\u0642\u062f \u0631\u0648\u0634\u06cc \u0645\u0624\u062b\u0631 \u0628\u0631\u0627\u06cc \u0646\u0638\u0627\u0631\u062a \u0628\u0631 \u0631\u0634\u062f \u062d\u0631\u0641\u0647 \u0627\u06cc \u06a9\u0627\u0631\u0645\u0646\u062f\u0627\u0646 \u062c\u062f\u06cc\u062f \u0648 \u0628\u06cc \u062a\u062c\u0631\u0628\u0647 \u0627\u0633\u062a. <sep> Label: Neutral", "output": ["\u06f9 \u0645\u0648\u0642\u0639\u06cc\u062a \u0648\u062c\u0648\u062f \u062f\u0627\u0634\u062a\u0647 \u06a9\u0647 \u0645\u0627 \u0628\u0647 \u0622\u0646\u0647\u0627 \u0627\u0634\u0627\u0631\u0647 \u06a9\u0631\u062f\u06cc\u0645."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-6e1736e741f94a4798803f8d7c684406", "input": "Premise: \u0631\u0648\u0632 \u06f4\u0634\u0646\u0628\u0647 \u0648 \u0642\u0628\u0644 \u0627\u0632 \u062a\u0635\u0648\u06cc\u0628 \u0627\u06cc\u0646 \u0644\u0627\u06cc\u062d\u0647 \u062f\u0631 \u0633\u0646\u0627 \u0642\u06cc\u0645\u062a \u0634\u0627\u062e\u0635 \u062f\u0627\u0648 \u062c\u0648\u0646\u0632 \u06f2\u06f0\u06f0 \u0648\u0627\u062d\u062f \u0633\u0642\u0648\u0637 \u06a9\u0631\u062f. <sep> Label: Neutral", "output": ["\u0631\u0648\u0632 \u0686\u0647\u0627\u0631\u0634\u0646\u0628\u0647 \u0647\u0648\u0627 \u0622\u0641\u062a\u0627\u0628\u06cc \u0628\u0648\u062f."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-a37e1ef7a28549eb95058a62ae96618a", "input": "Premise: \u0622\u0646\u062c\u0627 \u0648\u062d\u0634\u06cc \u0648 \u0628\u0627\u062f\u062e\u06cc\u0632 \u0627\u0633\u062a \u0648 \u067e\u0648\u0634\u0634 \u06af\u06cc\u0627\u0647\u06cc \u0645\u062d\u062f\u0648\u062f \u0622\u0646 \u0628\u0633\u06cc\u0627\u0631 \u0645\u062a\u0641\u0627\u0648\u062a \u0627\u0632 \u0633\u0631\u0633\u0628\u0632\u06cc \u0641\u0636\u0627\u06cc \u062f\u0627\u062e\u0644\u06cc \u0627\u0633\u062a. <sep> Label: Neutral", "output": ["\u0628\u0647 \u0647\u0645\u06cc\u0646 \u062f\u0644\u06cc\u0644 \u06a9\u0634\u0627\u0648\u0631\u0632\u0627\u0646 \u0627\u0632 \u0645\u062f\u062a\u0647\u0627 \u0642\u0628\u0644 \u062a\u0631\u062c\u06cc\u062d \u0645\u06cc \u062f\u0647\u0646\u062f \u062e\u0627\u0646\u0647 \u0647\u0627\u06cc \u062e\u0648\u062f \u0631\u0627 \u062f\u0631 \u0641\u0636\u0627\u06cc \u062f\u0627\u062e\u0644\u06cc \u0628\u0633\u0627\u0632\u0646\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-b602a221b51140ebad53495448f8581f", "input": "Premise: \u0628\u0639\u0636\u06cc \u0627\u0648\u0642\u0627\u062a \u0627\u0641\u0631\u0627\u062f\u06cc \u06a9\u0647 \u0646\u0645\u0627\u06cc\u0646\u062f\u0647 \u062e\u0648\u062f \u0647\u0633\u062a\u0646\u062f \u062d\u062a\u06cc \u0648\u0627\u0642\u0639\u06cc\u062a\u0647\u0627\u06cc \u0645\u0647\u0645 \u067e\u0631\u0648\u0646\u062f\u0647 \u062e\u0648\u062f \u0631\u0627 \u0646\u0645\u06cc \u062f\u0627\u0646\u0646\u062f. <sep> Label: Contradiction", "output": ["\u062f\u0631\u06a9 \u0627\u06cc\u0646 \u0642\u0627\u0646\u0648\u0646 \u0628\u0633\u06cc\u0627\u0631 \u0622\u0633\u0627\u0646 \u0627\u0633\u062a \u060c \u0628\u0646\u0627\u0628\u0631\u0627\u06cc\u0646 \u0646\u0645\u0627\u06cc\u0646\u062f\u06af\u06cc \u062e\u0648\u062f \u062f\u0631 \u062f\u0627\u062f\u06af\u0627\u0647 \u0628\u0647\u062a\u0631\u06cc\u0646 \u0631\u0627\u0647 \u0628\u0631\u0627\u06cc \u067e\u06cc\u0631\u0648\u0632\u06cc \u062f\u0631 \u06cc\u06a9 \u067e\u0631\u0648\u0646\u062f\u0647 \u0627\u0633\u062a."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-195afe8f50324f6ea091644f0cb4dd4e", "input": "Premise: \u0633\u067e\u0633 \u0627\u0648 \u062f\u0648\u06cc\u062f. <sep> Label: Neutral", "output": ["\u0627\u0648 \u0645\u0627\u0646\u0646\u062f \u06cc\u06a9 \u0648\u0631\u0632\u0634\u06a9\u0627\u0631 \u062f\u0648\u06cc\u062f."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-bd516e79552b43f3b0a0614ebbb9b307", "input": "Premise: \u0627\u06cc\u062c\u0627\u062f \u062f\u0631\u06cc\u0627\u0686\u0647 \u062f\u0631 \u0646\u062a\u06cc\u062c\u0647 \u06cc  \u0633\u0627\u062e\u062a \u0633\u062f \u0628\u0644\u0646\u062f \u0627\u0633\u0648\u0627\u0646 \u0628\u0627\u0639\u062b \u0646\u06af\u0631\u0627\u0646\u06cc \u0647\u0627\u06cc \u0627\u062c\u062a\u0645\u0627\u0639\u06cc \u0648 \u0633\u06cc\u0627\u0633\u06cc \u0628\u0633\u06cc\u0627\u0631\u06cc \u0634\u062f \u060c \u0628\u0647 \u0648\u06cc\u0698\u0647 \u0627\u0632 \u0622\u0646\u062c\u0627 \u06a9\u0647 \u0627\u06cc\u0646 \u0622\u0628 \u0647\u0627 \u062a\u0639\u062f\u0627\u062f\u06cc \u0627\u0632 \u0628\u0646\u0627\u0647\u0627\u06cc \u0645\u0647\u0645 \u0628\u0627\u0633\u062a\u0627\u0646\u06cc \u0645\u0647\u0645 \u0631\u0627 \u0628\u0647 \u062e\u0637\u0631 \u0645\u06cc \u0627\u0646\u062f\u0627\u062e\u0646\u062a\u062f. <sep> Label: Neutral", "output": ["\u0645\u062e\u0627\u0644\u0641\u062a \u0632\u06cc\u0627\u062f\u06cc \u0628\u0627 \u0633\u062f \u0622\u0633\u0648\u0627\u0646 \u0648\u062c\u0648\u062f \u062f\u0627\u0634\u062a."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-5367d97273544bb8bcaa4bcfd05c0c4d", "input": "Premise: \u0645\u062a\u0623\u0633\u0641\u0627\u0646\u0647 \u060c \u0627\u06cc\u0646\u0647\u0627 \u062f\u0627\u0645\u0646\u0647 \u0647\u0627\u06cc\u06cc \u0647\u0633\u062a\u0646\u062f \u06a9\u0647 \u062f\u0627\u0631\u0627\u06cc \u0628\u0631\u0686\u0633\u0628 \u0642\u06cc\u0645\u062a \u0645\u06cc\u0644\u06cc\u0627\u0631\u062f \u062f\u0644\u0627\u0631\u06cc \u0645\u062a\u0635\u0644 \u0634\u062f\u0647 \u0627\u0646\u062f. <sep> Label: Entailment", "output": ["\u0627\u06cc\u0646 \u0631\u062f\u06cc\u0627\u0628\u06cc \u0647\u0627 \u0647\u0645\u0627\u0646 \u0686\u06cc\u0632\u06cc \u0627\u0633\u062a \u06a9\u0647 \u0627\u0632 \u0628\u0631\u0686\u0633\u0628 \u0642\u06cc\u0645\u062a \u0645\u06cc\u0644\u06cc\u0627\u0631\u062f \u062f\u0644\u0627\u0631\u06cc \u0645\u0631\u062a\u0628\u0637 \u0628\u0627 \u0622\u0646\u0647\u0627 \u0646\u0627\u0634\u06cc \u0645\u06cc \u0634\u0648\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-a74933ad099643d387a2b99a007d6730", "input": "Premise: \u062d\u0645\u06cc\u0631\u0647 (\u0627\u0647\u0648\u0627\u0632)\u060c \u0631\u0648\u0633\u062a\u0627\u06cc\u06cc \u0627\u0632 \u062a\u0648\u0627\u0628\u0639 \u0628\u062e\u0634 \u0645\u0631\u06a9\u0632\u06cc \u0634\u0647\u0631\u0633\u062a\u0627\u0646 \u0627\u0647\u0648\u0627\u0632 \u062f\u0631 \u0627\u0633\u062a\u0627\u0646 \u062e\u0648\u0632\u0633\u062a\u0627\u0646 \u0627\u06cc\u0631\u0627\u0646 \u0627\u0633\u062a. <sep> Label: Contradiction", "output": ["\u062d\u0645\u06cc\u0631\u0647 \u06cc\u06a9\u06cc \u0627\u0632 \u0634\u0647\u0631\u0633\u062a\u0627\u0646 \u0647\u0627\u06cc \u0645\u0647\u0645 \u0627\u0633\u062a\u0627\u0646 \u062e\u0648\u0632\u0633\u062a\u0627\u0646 \u0627\u06cc\u0631\u0627\u0646 \u0627\u0633\u062a."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-3abf5c267819419485b0fe74bead6241", "input": "Premise: \u0627\u0632 \u062e\u0648\u062f\u062a\u0627\u0646 \u067e\u0630\u06cc\u0631\u0627\u06cc\u06cc \u06a9\u0646\u06cc\u062f \u0648 \u0647\u0632\u06cc\u0646\u0647\u200c\u06cc \u0622\u0646 \u0631\u0627 \u0628\u0631\u0627\u06cc \u0633\u06cc \u0628\u0641\u0631\u0633\u062a\u06cc\u062f. <sep> Label: Contradiction", "output": ["\u062e\u0631\u062c \u0627\u0636\u0627\u0641\u06cc \u0646\u062a\u0631\u0627\u0634\u06cc\u062f\u060c \u0633\u06cc \u0645\u062c\u0628\u0648\u0631 \u0627\u0633\u062a \u0647\u0632\u06cc\u0646\u0647 \u0622\u0646 \u0631\u0627 \u0628\u067e\u0631\u062f\u0627\u0632\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-0248840b894f4a71926b007cb41bf2be", "input": "Premise: \u0631\u0648\u06cc\u062f\u0627\u062f \u0633\u0627\u0631\u06cc\u0646 \u062f\u0631 \u0645\u062a\u0631\u0648 \u0645\u0647\u0645\u062a\u0631\u06cc\u0646 \u062d\u0645\u0644\u0647 \u062f\u0631 \u0698\u0627\u067e\u0646 \u067e\u0633 \u0627\u0632 \u067e\u0627\u06cc\u0627\u0646 \u06cc\u0627\u0641\u062a\u0646 \u062c\u0646\u06af \u062c\u0647\u0627\u0646\u06cc \u062f\u0648\u0645 \u0627\u0633\u062a. <sep> Label: Neutral", "output": ["\u0698\u0627\u067e\u0646 \u0628\u0627 \u062d\u0645\u0644\u0647 \u0628\u0647 \"\u067e\u0631\u0644 \u0647\u0627\u0631\u0628\u0631\" \u0645\u06cc\u062e\u0648\u0627\u0633\u062a \u06a9\u0646\u062a\u0631\u0644 \u0627\u0642\u06cc\u0627\u0646\u0648\u0633 \u067e\u0627\u0633\u06cc\u0641\u06cc\u06a9 \u0631\u0627 \u0628\u0647 \u062f\u0633\u062a \u062e\u0648\u062f\u0634 \u0628\u06af\u06cc\u0631\u062f. "]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-b29fd8bee9f240f4a0feadbca40b18a0", "input": "Premise: \u0645\u06cc\u0633\u062a\u0648\u0648 \u06f4\u06f1\u06f0 \u0646\u0641\u0631 \u062c\u0645\u0639\u06cc\u062a \u062f\u0627\u0631\u062f. <sep> Label: Entailment", "output": ["\u062c\u0645\u0639\u06cc\u062a \u0645\u06cc\u062a\u0633\u0648\u0648 \u0628\u0627\u0644\u0627\u06cc \u06f3\u06f0\u06f0 \u0646\u0641\u0631 \u0627\u0633\u062a."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-0abf66c3c98c4a2095aeb26cd72d4e06", "input": "Premise: \u0645\u0646 \u0647\u0645\u06cc\u0634\u0647 \u0627\u0632 \u0637\u0631\u062d \u062c\u0627\u06cc\u06af\u0632\u06cc\u0646 - \u067e\u0631\u0648\u0628 \u0647\u0627\u06cc \u06a9\u0648\u0686\u06a9 \u0648 \u0628\u062f\u0648\u0646 \u0633\u0631\u0646\u0634\u06cc\u0646 \u060c \u0628\u0647 \u0647\u0645\u0631\u0627\u0647 \u0622\u062a\u0634 \u0633\u0648\u0632\u06cc \u0633\u0627\u0644\u0627\u0646\u0647 \u06f1\u06f0\u06f0\u06f0 \u062f\u0644\u0627\u0631\u06cc \u06a9\u0647 \u0628\u0647 \u062c\u0631\u062b\u0642\u06cc\u0644 \u0647\u0627\u06cc \u0627\u0648\u0631\u06cc\u06af\u0627\u0645\u06cc \u062e\u0648\u0631\u062f\u0647 \u0627\u0633\u062a \u060c \u0637\u0631\u0641\u062f\u0627\u0631\u06cc \u06a9\u0631\u062f\u0647 \u0627\u0645. <sep> Label: Contradiction", "output": ["\u0645\u0646 \u0637\u0631\u062d \u062c\u0627\u06cc\u06af\u0632\u06cc\u0646 \u0631\u0627 \u062f\u0648\u0633\u062a \u0646\u062f\u0627\u0634\u062a\u0645."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-508f37e823ac4a84a2781c10973254e2", "input": "Premise: \u0627\u0645\u0627 \u067e\u0631\u0632\u064a\u062f\u0646\u062a \u0628\u0648\u0634 \u0647\u0645\u064a\u0634\u0647 \u0627\u062d\u0633\u0627\u0633 \u06a9\u0631\u062f\u0647 \u0627\u0633\u062a \u06a9\u0647 \u0633\u0627\u0632\u0645\u0627\u0646 \u0645\u0644\u0644 \u0645\u062a\u062d\u062f \u0646\u0642\u0634\u06cc \u062d\u064a\u0627\u062a\u06cc \u062f\u0627\u0631\u062f. <sep> Label: Entailment", "output": ["\u067e\u0631\u0632\u064a\u062f\u0646\u062a \u0628\u0648\u0634 \u0628\u0631 \u0646\u0642\u0634 \u0645\u0647\u0645 \u0633\u0627\u0632\u0645\u0627\u0646 \u0645\u0644\u0644 \u0645\u062a\u062d\u062f \u062a\u0627\u06a9\u06cc\u062f \u06a9\u0631\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-8fd93b9eab744e9da33fa50e7fe2868e", "input": "Premise: \u06af\u0644 \u0632\u06cc\u0628\u0627\u06cc \u0632\u06cc\u0631 \u0637\u0627\u0642 \u0627\u0648 \u062f\u0631 \u062f\u0631\u0628\u06cc \u0645\u0639\u0631\u0648\u0641 \u0633\u0627\u0644 \u06f1\u06f3\u06f7\u06f9 \u0628\u0647 \u0627\u062d\u0645\u062f\u0631\u0636\u0627 \u0639\u0627\u0628\u062f\u0632\u0627\u062f\u0647 \u06a9\u0647 \u062f\u0631 \u0622\u0646 \u0631\u0648\u0632\u0647\u0627 \u062f\u0631 \u0627\u0648\u062c \u0622\u0645\u0627\u062f\u06af\u06cc \u0642\u0631\u0627\u0631 \u062f\u0627\u0634\u062a \u0648 \u062f\u0631\u06af\u06cc\u0631\u06cc \u0646\u0648\u0627\u0632\u06cc \u0648 \u062d\u0645\u06cc\u062f \u0627\u0633\u062a\u06cc\u0644\u06cc\u060c \u067e\u0627\u06cc\u0627\u0646 \u0631\u0623\u0641\u062a \u0648 \u067e\u0631\u0648\u06cc\u0632 \u0628\u0631\u0648\u0645\u0646\u062f \u06a9\u0647 \u0645\u0646\u062c\u0631 \u0628\u0647 \u0631\u0641\u062a\u0646 \u062f\u0648 \u0631\u0648\u0632\u0647 \u0627\u0648 \u0628\u0647 \u0632\u0646\u062f\u0627\u0646 \u0634\u062f \u062f\u0631 \u0647\u0645\u0627\u0646 \u0628\u0627\u0632\u06cc \u0631\u062e \u062f\u0627\u062f. <sep> Label: Entailment", "output": ["\u062f\u0631\u0628\u06cc \u0633\u0627\u0644 \u06f1\u06f3\u06f7\u06f9 \u0634\u0627\u0645\u0644 \u062f\u0631\u06af\u06cc\u0631\u06cc \u0646\u0648\u0627\u0632\u06cc \u0648 \u0627\u0633\u062a\u06cc\u0644\u06cc \u0648 \u06af\u0644 \u062e\u0648\u0631\u062f\u0646 \u0639\u0627\u0628\u062f \u0632\u0627\u062f\u0647 \u0628\u0648\u062f."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-f9b6fa9352bd4a3891b4374ab6248d27", "input": "Premise: \u0627\u06cc\u0646 \u062e\u0648\u062f\u0631\u0648 \u062f\u0631 \u0646\u0645\u0627\u06cc\u0634\u06af\u0627\u0647 \u062e\u0648\u062f\u0631\u0648 \u0641\u0631\u0627\u0646\u06a9\u0641\u0648\u0631\u062a \u0633\u0627\u0644 \u06f2\u06f0\u06f1\u06f5 \u0631\u0648\u0646\u0645\u0627\u06cc\u06cc \u0634\u062f. <sep> Label: Neutral", "output": ["\u0646\u0645\u0627\u06cc\u0634\u06af\u0627\u0647 \u062e\u0648\u062f\u0631\u0648 \u0641\u0631\u0627\u0646\u06a9\u0641\u0648\u0631\u062a \u062f\u0631 \u0633\u0627\u0644 2016 \u0628\u0631\u06af\u0632\u0627\u0631 \u0634\u062f"]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-1c9220b14bb64f1e8dc11a653766487a", "input": "Premise: \u0628\u0644\u0647 \u0641\u0642\u0637 \u0627\u06cc \u06a9\u0627\u0634 \u06a9\u0645\u06cc \u0622\u0633\u0627\u0646 \u062a\u0631 \u0628\u0648\u062f\u060c \u0645\u06cc\u062f\u0627\u0646\u06cc\u062f <sep> Label: Entailment", "output": ["\u0645\u0646 \u0645\u06cc \u062e\u0648\u0627\u0647\u0645 \u0627\u06cc\u0646 \u06a9\u0627\u0631 \u0622\u0633\u0627\u0646 \u062a\u0631 \u0634\u0648\u062f"]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-c9f6a10d1524432197074ae466eed713", "input": "Premise: \u0628\u0644\u0647 \u060c \u0622\u0646\u0647\u0627 \u0627\u06a9\u0646\u0648\u0646 \u067e\u06cc\u0631\u062a\u0631 \u0645\u06cc \u0634\u0648\u0646\u062f \u060c \u0628\u0646\u0627\u0628\u0631\u0627\u06cc\u0646 \u0622\u0646\u0647\u0627 \u0622\u0646\u0642\u062f\u0631 \u0645\u0633\u0626\u0648\u0644\u06cc\u062a \u0633\u062e\u062a\u06cc \u0646\u06cc\u0633\u062a\u0646\u062f\u060c \u0627\u0645\u0627 \u0647\u0646\u0648\u0632 \u0647\u0645 \u062f\u0631 \u0622\u0646\u062c\u0627 \u0647\u0633\u062a\u0646\u062f\u060c \u0645\u06cc \u062f\u0627\u0646\u06cc\u062f \u06a9\u0647 \u0647\u0646\u0648\u0632 \u0648\u0642\u062a \u0645\u06cc \u06af\u06cc\u0631\u0646\u062f \u0648 <sep> Label: Contradiction", "output": ["\u0622\u0646\u0647\u0627 \u0627\u06a9\u0646\u0648\u0646 \u0628\u0647 \u0647\u0645\u0627\u0646 \u0627\u0646\u062f\u0627\u0632\u0647\u200c\u06cc \u062f\u0648\u0631\u0627\u0646 \u062c\u0648\u0627\u0646\u06cc\u200c\u0634\u0627\u0646 \u0646\u06cc\u0627\u0632 \u0628\u0647 \u062a\u0648\u062c\u0647 \u062f\u0627\u0631\u0646\u062f."]}, "Prediction": "                                                            "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-d633b7d1fb164537ac162f32087a593d", "input": "Premise: \u0648\u0638\u06cc\u0641\u0647 \u0634\u0631\u06a9\u062a \u0627\u06cc\u0646 \u0628\u0648\u062f \u06a9\u0647 \u062f\u0631 \u062f\u0631\u0648\u0646 \u06a9\u0645\u067e\u0627\u0646\u06cc \u00ab\u0628\u0647 \u0646\u0648\u06cc\u0633\u0646\u062f\u06af\u0627\u0646 \u0648\u0627\u0642\u0639\u06cc (\u0627\u0645\u06a9\u0627\u0646\u0627\u062a) \u0648 \u0648\u0633\u06cc\u0644\u0647 \u0646\u0642\u0644\u06cc\u0647 \u0627\u0631\u0627\u0626\u0647 \u062f\u0647\u062f \u062a\u0627 \u0628\u062a\u0648\u0627\u0646\u0646\u062f \u0641\u06cc\u0644\u0645\u200c\u0647\u0627\u06cc\u0634\u0627\u0646 \u0631\u0627 \u0628\u0633\u0627\u0632\u0646\u062f. <sep> Label: Contradiction", "output": ["\u0634\u0631\u06a9\u062a \u062a\u0646\u0647\u0627 \u0628\u0631\u0627\u06cc \u0628\u0627\u0632\u06cc\u06af\u0631\u0627\u0646 \u0627\u0645\u06a9\u0627\u0646\u0627\u062a \u0648 \u0648\u0633\u06cc\u0644\u0647\u200c\u06cc \u0646\u0642\u0644\u06cc\u0647 \u0627\u0631\u0627\u0626\u0647 \u0645\u06cc\u200c\u06a9\u0646\u062f."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-d2c2f635f3374e62ad424c96bd1fe62e", "input": "Premise: \u0645\u0646 \u062d\u0642\u0627\u06cc\u0642 \u0631\u0627 \u0646\u0645\u06cc \u067e\u0648\u0634\u0627\u0646\u0645. <sep> Label: Contradiction", "output": ["\u0645\u0646 \u062d\u0642\u0627\u06cc\u0642 \u0631\u0627 \u0645\u06cc\u067e\u0648\u0634\u0627\u0646\u0645."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-1521fe902edf4295a182fc361672fd09", "input": "Premise: \u0634\u0627\u064a\u062f \u062c\u0646\u062c\u0627\u0644\u064a\u200c\u062a\u0631\u064a\u0646 \u0633\u0648\u0627\u0644\u064a \u0643\u0647 \u0645\u064a\u200c\u0634\u062f \u0627\u0632 \u0627\u0648 \u067e\u0631\u0633\u064a\u062f\u060c \u0633\u0648\u0627\u0644 \u0627\u0632 \u0622\u0645\u062f\u0646 \u064a\u0627 \u0646\u064a\u0627\u0645\u062f\u0646\u0634 \u0628\u0647 \u0639\u0631\u0635\u0647 \u0627\u0646\u062a\u062e\u0627\u0628\u0627\u062a \u0633\u0627\u0644 \u06f9\u06f6 \u0628\u0648\u062f. <sep> Label: Neutral", "output": ["\u0627\u0648 \u0628\u0647 \u0627\u0646\u062a\u062e\u0627\u0628\u0627\u062a \u0633\u0627\u0644 \u06f9\u06f6 \u0648\u0627\u0631\u062f \u0646\u0634\u062f."]}, "Prediction": "                                                          "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-8543f662cd014dcb8e227507c2cc4d20", "input": "Premise: \u0640 \u0622\u0645\u0648\u0632\u0634 \u0646\u06a9\u0627\u062a \u0628\u0631\u0646\u0627\u0645\u0647\u200c\u0646\u0648\u06cc\u0633\u06cc \u0647\u0645\u0631\u0627\u0647 \u0628\u0627 \u0645\u062b\u0627\u0644\u200c\u0647\u0627\u06cc \u06a9\u0627\u0631\u0628\u0631\u062f\u06cc <sep> Label: Entailment", "output": ["\u0645\u0627 \u0645\u06cc\u062a\u0648\u0627\u0646\u06cc\u0645 \u0627\u06cc\u0646 \u0645\u062b\u0627\u0644\u0647\u0627 \u0631\u0627 \u0628\u0631\u0627\u06cc \u0634\u0645\u0627 \u0627\u06cc\u0645\u06cc\u0644 \u06a9\u0646\u06cc\u0645. "]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-ed329f6e124541a0b431a89b9f4e9382", "input": "Premise: \u0633\u06cc\u0627\u0633\u062a \u0648\u0632\u0627\u0631\u062a \u0641\u0627\u0642\u062f \u0645\u0639\u06cc\u0627\u0631\u0647\u0627\u06cc\u06cc \u0628\u0631\u0627\u06cc \u0633\u0646\u062c\u0634 \u067e\u0627\u06cc\u062f\u0627\u0631\u06cc \u0637\u0631\u0627\u062d\u06cc \u0648 \u06a9\u0646\u062a\u0631\u0644 \u0641\u0631\u0627\u06cc\u0646\u062f\u0647\u0627 \u0627\u0633\u062a. <sep> Label: Entailment", "output": ["\u0648\u0632\u0627\u0631\u062a \u062f\u0641\u0627\u0639 \u062f\u0627\u0631\u0627\u06cc \u0633\u06cc\u0627\u0633\u062a \u0645\u0639\u06cc\u0627\u0631\u0647\u0627\u06cc\u06cc \u0628\u0631\u0627\u06cc \u0633\u0646\u062c\u0634 \u062b\u0628\u0627\u062a \u062f\u0631 \u0637\u0631\u0627\u062d\u06cc \u0648 \u06a9\u0646\u062a\u0631\u0644 \u0641\u0631\u0622\u06cc\u0646\u062f \u0646\u06cc\u0633\u062a."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-69984bc100984e1d8fdf04467e04beda", "input": "Premise: \u0627\u0648 \u0628\u0631 \u0627\u06cc\u0646 \u0628\u0627\u0648\u0631 \u0627\u0633\u062a \u06a9\u0647 \u067e\u0627\u0644 \u062f\u0631 \u06a9\u0648\u06cc\u0631 \u0622\u0631\u0627\u06a9\u06cc\u0633 \u0645\u0631\u062f\u0647 \u0627\u0633\u062a. <sep> Label: Contradiction", "output": ["\u067e\u0627\u0644 \u062f\u0631 \u0642\u06cc\u062f \u062d\u06cc\u0627\u062a \u0628\u0647 \u0633\u0631 \u0645\u06cc \u0628\u0631\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-b6014b08924b418e88eaf61aba1ff5a7", "input": "Premise: \u062f\u0631\u0633\u062a \u0627\u0633\u062a \u060c \u0627\u0648\u0647 \u060c \u062e\u0648\u0628 \u060c \u0634\u0645\u0627 \u0645\u06cc \u062f\u0627\u0646\u06cc\u062f \u06a9\u0647 \u062f\u0642\u06cc\u0642\u0627\u064b \u0645\u062b\u0644 \u0627\u06cc\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0645\u06cc \u06af\u0648\u06cc\u06cc\u062f \u06a9\u0627\u0631\u0647\u0627\u06cc \u0628\u0633\u06cc\u0627\u0631\u06cc \u0648\u062c\u0648\u062f \u062f\u0627\u0631\u062f \u06a9\u0647 \u0628\u0627\u06cc\u062f \u062f\u0631 \u0627\u06cc\u0646\u062c\u0627 \u062f\u0631 \u0627\u06cc\u0646 \u06a9\u0634\u0648\u0631 \u0627\u0646\u062c\u0627\u0645 \u0634\u0648\u062f \u0648 \u0634\u0645\u0627 \u0645\u06cc \u062f\u0627\u0646\u06cc\u062f \u0627\u06af\u0631 \u0645\u06cc \u062a\u0648\u0627\u0646\u0633\u062a\u06cc\u062f \u0628\u0647 \u0686\u06cc\u0632\u06cc \u0645\u062b\u0644 \u0645\u0627\u0646\u0646\u062f \u06cc\u06a9 \u0645\u0624\u0633\u0633\u0647 \u0635\u0644\u062d \u0641\u06a9\u0631 \u06a9\u0646\u06cc\u062f. \u0645\u0646\u0638\u0648\u0631\u0645 \u0627\u06cc\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0627\u06af\u0631 \u0627\u06cc\u0646 \u0633\u0627\u0632\u0645\u0627\u0646 \u0641\u0642\u0637 \u0628\u0647 \u0639\u0646\u0648\u0627\u0646 \u0645\u062b\u0627\u0644 \u0641\u0642\u0637 \u0628\u0647 \u0627\u0641\u0631\u0627\u062f \u0642\u062f\u06cc\u0645\u06cc \u06a9\u0645\u06a9 \u06a9\u0646\u062f \u0628\u0633\u06cc\u0627\u0631 \u0645\u0641\u06cc\u062f \u062e\u0648\u0627\u0647\u062f \u0628\u0648\u062f. <sep> Label: Entailment", "output": ["\u062f\u0631 \u0627\u06cc\u0646 \u06a9\u0634\u0648\u0631 \u06a9\u0627\u0631\u0647\u0627\u06cc \u0632\u06cc\u0627\u062f\u06cc \u0648\u062c\u0648\u062f \u062f\u0627\u0631\u062f \u06a9\u0647 \u0628\u0627\u06cc\u062f \u0627\u0646\u062c\u0627\u0645 \u062f\u0647\u06cc\u0645."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-d01946c97d5f47958c2f7ae8e7501d31", "input": "Premise: \u0648\u0627\u06cc\u062a \u0628\u0647 \u0622\u0631\u0627\u0645\u06cc \u0645\u0646 \u0631\u0627 \u0646\u06af\u0627\u0647 \u06a9\u0631\u062f. <sep> Label: Entailment", "output": ["\u0648\u0627\u06cc\u062a \u0646\u06af\u0627\u0647 \u062e\u0648\u062f \u0631\u0627 \u0628\u0647 \u0622\u0631\u0627\u0645\u06cc \u0628\u0627\u0644\u0627 \u0622\u0648\u0631\u062f \u062a\u0627 \u0628\u0647 \u0646\u06af\u0627\u0647 \u0645\u0646 \u062a\u0644\u0627\u0642\u06cc \u06a9\u0631\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-dc57743c44ec4b5cbbc20b632bdb8050", "input": "Premise: \u062c\u062f\u0648\u0644 2: \u0646\u0645\u0648\u0646\u0647 \u0647\u0627\u06cc\u06cc \u0627\u0632 \u0627\u0646\u062a\u0638\u0627\u0631\u0627\u062a \u0631\u0636\u0627\u06cc\u062a \u0645\u0634\u062a\u0631\u06cc BLM \u060c FHWA \u060c IRS \u0648 VBA \u0628\u0631\u0627\u06cc \u0639\u0645\u0644\u06a9\u0631\u062f \u0645\u062f\u06cc\u0631\u0627\u0646 \u0627\u0631\u0634\u062f <sep> Label: Entailment", "output": ["\u0645\u062f\u06cc\u0631\u0627\u0646 \u0627\u0631\u0634\u062f \u0628\u0631\u0627\u06cc \u0631\u0633\u06cc\u062f\u0646 \u0628\u0647 \u0627\u0646\u062a\u0638\u0627\u0631\u0627\u062a \u0645\u0637\u0627\u0644\u0639\u0627\u062a\u06cc \u062f\u0631 \u0645\u0648\u0631\u062f \u062c\u0646\u0628\u0647 \u0647\u0627\u06cc \u0645\u062e\u062a\u0644\u0641 \u0627\u0646\u062c\u0627\u0645 \u062f\u0627\u062f\u0647 \u0627\u0646\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-08e80445cee743f9a647c4fb11563eee", "input": "Premise: \u0647\u0648\u0634\u064a\u0627\u0631 \u0632\u0628\u0627\u0631\u06cc \u0648\u0632\u064a\u0631\u0627\u0645\u0648\u0631\u062e\u0627\u0631\u062c\u0647 \u0639\u0631\u0627\u0642 \u0645\u06cc \u06af\u0648\u064a\u062f \u0646\u064a\u0631\u0648\u0647\u0627\u06cc \u062a\u062d\u062a \u0631\u0647\u0628\u0631\u06cc \u0622\u0645\u0631\u064a\u06a9\u0627 \u067e\u0633 \u0627\u0632\u06f3\u06f0 \u0698\u0648\u0626\u0646 \u0648\u0627\u0646\u062a\u0642\u0627\u0644 \u062d\u0627\u06a9\u0645\u064a\u062a \u0628\u0647 \u062f\u0648\u0644\u062a \u0645\u0648\u0642\u062a \u0639\u0631\u0627\u0642 \u0628\u0627\u064a\u062f \u0647\u0645\u0686\u0646\u0627\u0646 \u0628\u0631\u0627\u06cc \u0628\u0631\u0642\u0631\u0627\u0631\u06cc \u0627\u0645\u0646\u064a\u062a \u062f\u0631\u0639\u0631\u0627\u0642 \u0628\u0627\u0642\u06cc \u0628\u0645\u0627\u0646\u0646\u062f. <sep> Label: Contradiction", "output": ["\u062f\u0648\u0644\u062a \u0639\u0631\u0627\u0642 \u062e\u0648\u0627\u0633\u062a\u0627\u0631 \u062e\u0631\u0648\u062c \u0646\u06cc\u0631\u0648\u0647\u0627\u06cc \u0622\u0645\u0631\u06cc\u06a9\u0627\u06cc\u06cc \u0627\u0633\u062a."]}, "Prediction": "                                                            "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-d6fe9dc69aa84709b42a29b11581f66e", "input": "Premise: \u0648\u0627\u06cc\u062a \u0633\u0631\u0634 \u0631\u0627 \u0628\u0647 \u0639\u0644\u0627\u0645\u062a \u0645\u062b\u0628\u062a \u062a\u06a9\u0627\u0646 \u062f\u0627\u062f <sep> Label: Contradiction", "output": ["\u0648\u0627\u06cc\u062a \u0633\u0631\u0634 \u0631\u0627 \u0628\u0647 \u0639\u0644\u0627\u0645\u062a \u0645\u0646\u0641\u06cc \u062a\u06a9\u0627\u0646 \u062f\u0627\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-0f60777148384bb3b57c4a293e597915", "input": "Premise: \u0622\u0646\u0686\u0647 \u06a9\u0627\u0645\u0644\u0627 \u063a\u06cc\u0631\u0642\u0627\u0628\u0644 \u062a\u062d\u0645\u0644 \u0627\u0633\u062a \u0627\u06cc\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0628\u0647 \u062f\u0631\u0633\u062a\u06cc \u0646\u0642\u0644 \u0648 \u062f\u06cc\u062f\u0647 \u0634\u0648\u062f - \u062d\u062a\u06cc \u062a\u0648\u0633\u0637 \u062e\u0648\u062f\u062a\u0627\u0646 - \u06a9\u0647 \u0686\u06cc\u0632\u06cc \u0628\u0647\u062a\u0631 \u0627\u0632 \u0622\u0646\u0686\u0647 \u062f\u0631 \u0648\u0627\u0642\u0639 \u0647\u0633\u062a\u06cc\u062f\u060c \u0646\u06cc\u0633\u062a\u06cc\u062f. <sep> Label: Neutral", "output": ["\u0622\u0646\u0686\u0647 \u06a9\u0627\u0645\u0644\u0627\u064b \u063a\u06cc\u0631\u0642\u0627\u0628\u0644 \u062a\u062d\u0645\u0644 \u0627\u0633\u062a \u0627\u06cc\u0646 \u0627\u0633\u062a \u06a9\u0647 \u0628\u0647 \u0635\u0648\u0631\u062a \u062f\u0642\u06cc\u0642 \u0646\u0642\u0644 \u0642\u0648\u0644 \u0634\u0648\u06cc\u062f \u0648 \u0647\u0646\u0648\u0632 \u0647\u0645 \u0628\u062f \u0628\u0627\u0634\u062f."]}, "Prediction": "                                                           "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-14cab00d6c17414aaa8a364def50a79a", "input": "Premise: \u062d\u0645\u0644\u0647 \u0627\u0645\u0631\u0648\u0632 \u0628\u0647 \u0641\u0627\u0635\u0644\u0647 \u064a\u06a9 \u0631\u0648\u0632 \u067e\u0633 \u0627\u0632 \u0627\u0646\u062a\u0634\u0627\u0631 \u0646\u0648\u0627\u0631\u06cc \u0635\u0648\u062a\u06cc \u062a\u0648\u0633\u0637 \u0627\u0628\u0648 \u0645\u0635\u0639\u0628 \u0627\u0644\u0632\u0631\u0642\u0627\u0648\u06cc \u062a\u0631\u0648\u0631\u064a\u0633\u062a \u062a\u062d\u062a \u062a\u0639\u0642\u064a\u0628 \u0631\u062e \u062f\u0627\u062f \u06a9\u0647 \u062f\u0631 \u0622\u0646 \u0634\u064a\u0639\u064a\u0627\u0646 \u0628\u0631\u0627\u06cc \u062c\u0646\u06af\u064a\u062f\u0646 \u062f\u0631 \u06a9\u0646\u0627\u0631 \u0633\u0631\u0628\u0627\u0632\u0627\u0646 \u0622\u0645\u0631\u064a\u06a9\u0627\u0626\u06cc \u062a\u0642\u0628\u064a\u062d \u0634\u062f\u0647 \u0627\u0646\u062f. <sep> Label: Entailment", "output": ["\u06af\u0631\u0648\u0647 \u062a\u0631\u0648\u0631\u06cc\u0633\u062a\u06cc \u062a\u0628\u0644\u06cc\u063a\u0627\u062a\u06cc \u0639\u0644\u06cc\u0647 \u0634\u06cc\u0639\u06cc\u0627\u0646 \u0645\u062a\u062d\u062f \u0627\u0645\u0631\u06cc\u06a9\u0627 \u0634\u0631\u0648\u0639 \u06a9\u0631\u062f\u0647 \u0627\u0633\u062a."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-6121789e9b79453ebe2e8b663cdc186b", "input": "Premise: \u062f\u0631\u0635\u0648\u0631\u062a\u06cc\u200c\u06a9\u0647 \u062f\u0627\u0648\u0631 \u0646\u0633\u0628\u062a \u0628\u0647 \u0635\u062d\u06cc\u062d \u0628\u0648\u062f\u0646 \u0633\u0631\u0648\u06cc\u0633 \u0634\u06a9 \u062f\u0627\u0634\u062a\u0647 \u0628\u0627\u0634\u062f (\u0628\u0631\u0627\u06cc \u0627\u0648\u0644\u06cc\u0646 \u0628\u0627\u0631) \u062a\u0646\u0647\u0627 \u0628\u0627 \u062f\u0627\u062f\u0646 \u0627\u062e\u0637\u0627\u0631 \u0628\u0647 \u0632\u0646\u0646\u062f\u0647 \u0633\u0631\u0648\u06cc\u0633 \u0627\u06a9\u062a\u0641\u0627 \u0645\u06cc\u200c\u06a9\u0646\u062f\u060c \u0627\u0645\u0627 \u0627\u0645\u062a\u06cc\u0627\u0632 \u0628\u0647 \u062f\u0631\u06cc\u0627\u0641\u062a\u200c\u06a9\u0646\u0646\u062f\u0647 \u0633\u0631\u0648\u06cc\u0633 \u062f\u0627\u062f\u0647 \u0646\u0645\u06cc\u200c\u0634\u0648\u062f. <sep> Label: Contradiction", "output": ["\u062f\u0631 \u0635\u0648\u0631\u062a \u0639\u062f\u0645 \u0642\u0637\u0639\u06cc\u062a \u062f\u0627\u0648\u0631 \u062f\u0631 \u0631\u0627\u0628\u0637\u0647 \u0628\u0627 \u0633\u0631\u0648\u06cc\u0633\u060c \u0633\u0631\u0648\u06cc\u0633 \u062a\u06a9\u0631\u0627\u0631 \u062e\u0648\u0627\u0647\u062f \u0634\u062f \u0648 \u0627\u0645\u062a\u06cc\u0627\u0632\u06cc \u0628\u0647 \u0632\u0646\u0646\u062f\u0647\u200c\u06cc \u0633\u0631\u0648\u06cc\u0633 \u062f\u0627\u062f\u0647 \u0646\u0645\u06cc\u200c\u0634\u0648\u062f."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-378242c3d14049d9b9d9de7f335f9e54", "input": "Premise: \u06cc\u06a9 \u0645\u0631\u062f \u0642\u062f \u0628\u0644\u0646\u062f \u0628\u0627 \u06cc\u06a9 \u06a9\u0644\u0627\u0647 \u0628\u0644\u0646\u062f\u062a\u0631. <sep> Label: Neutral", "output": ["\u0642\u062f \u0622\u0646 \u0645\u0631\u062f \u062d\u062f\u0648\u062f \u06f2 \u0645\u062a\u0631 \u0627\u0633\u062a \u0648 \u0627\u0648 \u06cc\u06a9 \u06a9\u0644\u0627\u0647 \u0628\u0644\u0646\u062f \u0633\u06cc\u0627\u0647 \u0628\u0647 \u0633\u0631 \u062f\u0627\u0631\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-2d343b8bd0b54f3caa37ad80e8648440", "input": "Premise: \u0639\u0644\u0627\u0648\u0647 \u0628\u0631 \u0627\u06cc\u0646 \u060c \u062f\u0631 \u062d\u0627\u0644\u06cc \u06a9\u0647 \u0627\u06cc\u0646 \u0622\u0698\u0627\u0646\u0633\u200c\u0647\u0627 \u0645\u0634\u0627\u0631\u06a9\u062a \u0628\u0627 \u0645\u0634\u062a\u0631\u06cc\u0627\u0646 \u0648 \u0633\u0627\u06cc\u0631 \u0630\u06cc\u0646\u0641\u0639\u0627\u0646 \u0631\u0627 \u0645\u0648\u0631\u062f \u062a\u0648\u062c\u0647 \u0642\u0631\u0627\u0631 \u0645\u06cc \u062f\u0647\u0646\u062f \u060c \u0628\u0627\u06cc\u062f \u0628\u06cc\u0634\u062a\u0631 \u0628\u0631 \u062a\u0642\u0648\u06cc\u062a \u0647\u0645\u06a9\u0627\u0631\u06cc \u062f\u0631 \u062f\u0627\u062e\u0644 \u0648 \u062f\u0631 \u0645\u0631\u0632\u0647\u0627\u06cc \u0633\u0627\u0632\u0645\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u062f\u0633\u062a\u06cc\u0627\u0628\u06cc \u0628\u0647 \u0646\u062a\u0627\u06cc\u062c \u062a\u0623\u06a9\u06cc\u062f \u0634\u0648\u062f. <sep> Label: Entailment", "output": ["\u0622\u0698\u0627\u0646\u0633\u200c\u0647\u0627 \u0628\u0627 \u0645\u0634\u062a\u0631\u06cc\u0627\u0646 \u0648 \u0633\u0627\u06cc\u0631 \u0630\u06cc\u0646\u0641\u0639\u0627\u0646 \u0647\u0645\u06a9\u0627\u0631\u06cc \u0645\u06cc \u06a9\u0646\u0646\u062f."]}, "Prediction": "                                                               "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-e8fd9cd4efec4e17be260b03f15f98ea", "input": "Premise: \u0627\u0648\u0647 \u060c \u0628\u0646\u0627\u0628\u0631\u0627\u06cc\u0646 \u0645\u0645\u06a9\u0646 \u0627\u0633\u062a \u0634\u0645\u0627 \u0631\u0627 \u0628\u0647 \u06cc\u06a9 \u062a\u0635\u0645\u06cc\u0645 \u0645\u063a\u0631\u0636\u0627\u0646\u0647 \u0633\u0648\u0642 \u062f\u0647\u062f \u0627\u06af\u0631 \u0634\u0645\u0627  <sep> Label: Contradiction", "output": ["\u0645\u0646 \u0645\u0637\u0645\u0626\u0646 \u0647\u0633\u062a\u0645 \u06a9\u0647 \u0634\u0645\u0627 \u0628\u0627 \u0647\u0631 \u062f\u0648 \u0637\u0631\u0641 \u0645\u0646\u0635\u0641 \u062e\u0648\u0627\u0647\u06cc\u062f \u0628\u0648\u062f"]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-e4a15e9b2e03440c997cb7d336a8981e", "input": "Premise: \u0634\u0647\u0631 Antiparoseeems \u0628\u0627 \u0633\u0631\u0639\u062a \u06a9\u0645\u062a\u0631\u06cc \u0646\u0633\u0628\u062a \u0628\u0647 Parikia \u062d\u0631\u06a9\u062a \u0645\u06cc \u06a9\u0646\u062f. \u062f\u0631 \u0648\u0627\u0642\u0639 \u060c \u0627\u06cc\u0646 \u0634\u0647\u0631 \u0645\u06cc \u062a\u0648\u0627\u0646\u062f \u062a\u0642\u0631\u06cc\u0628\u0627\u064b \u0641\u0631\u0633\u0648\u062f\u0647 \u0627\u0632 \u0641\u0635\u0644 \u0628\u0627\u0634\u062f. <sep> Label: Contradiction", "output": ["Parikia \u06cc\u06a9 \u0634\u0647\u0631 \u0628\u0633\u06cc\u0627\u0631 \u06a9\u0646\u062f\u062a\u0631 \u0627\u0632 Antiparo \u0627\u0633\u062a."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-2cb6fe375f5a43f7b0a805ea2f00e209", "input": "Premise: \u06a9\u0645\u06cc \u062f\u0648\u0631\u062a\u0631 \u0627\u0632 \u0632\u0627\u062f\u06af\u0627\u0647 \u0698\u0648\u0632\u0641\u06cc\u0646 \u0632\u0645\u06cc\u0646 \u06af\u0644\u0641\u06cc \u0648\u062c\u0648\u062f \u062f\u0627\u0634\u062a. <sep> Label: Neutral", "output": ["\u06af\u0648\u06cc\u06cc \u062c\u0648\u0632\u0641\u06cc\u0646 \u0628\u0631\u0627\u06cc \u062a\u0627\u0633\u06cc\u0633 \u06cc\u06a9 \u0628\u0627\u0634\u06af\u0627\u0647 \u06af\u0644\u0641 \u0645\u062a\u0648\u0644\u062f \u0634\u062f\u0647 \u0628\u0648\u062f."]}, "Prediction": "                                                         "}
{"Task": "task464_parsinlu_entailment_sentence_generation_gpt3_0", "Definition": ["In this task, you are given a premise sentence in Persian and a label in English. Label determines whether a hypothesis sentence entails, contradicts, or is neutral with respect to the given premise sentence. You have to generate the hypothesis sentence based on the label and the premise sentence. Your sentence should be fluent and grammatically correct. Even though there exist multiple answers, we only need a single answer. (1)  The model should output \"\u0622\u0628\u0631\u0633\u0627\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0634\u0631\u0648\u0639 \u0634\u062f.\" in response to the premise \"\u062f\u0627\u0631\u06cc\u0648\u0634 \u0641\u0631\u0645\u0627\u0646 \u062f\u0627\u062f \u062a\u0627 \u06a9\u0627\u0631 \u062f\u0648\u0628\u0627\u0631\u0647 \u0622\u063a\u0627\u0632 \u0634\u0648\u062f \u0648 \u0628\u0631 \u0633\u0631 \u0631\u0627\u0647 \u0686\u0627\u0647\u200c\u0647\u0627\u06cc\u06cc \u06a9\u0646\u062f\u0647 \u0634\u0648\u0646\u062f \u062a\u0627 \u0622\u0628 \u0622\u0634\u0627\u0645\u06cc\u062f\u0646\u06cc \u0628\u0631\u0627\u06cc \u06a9\u0627\u0631\u06af\u0631\u0627\u0646 \u0628\u062f\u0633\u062a \u0622\u06cc\u062f.\" The output"], "Instance": {"id": "task464-e5da613101744c66a546f9d0984913d0", "input": "Premise: \u067e\u0633 \u0627\u0632 \u0646\u062a\u06cc\u062c\u0647 \u06af\u06cc\u0631\u06cc \u0645\u0630\u0627\u06a9\u0631\u0627\u062a \u0627\u06cc\u0646 \u062a\u0648\u0627\u0641\u0642\u0646\u0627\u0645\u0647 \u060c FCC \u0642\u0627\u0646\u0648\u0646 \u067e\u06cc\u0634\u0646\u0647\u0627\u062f\u06cc \u062e\u0648\u062f \u0631\u0627 \u0645\u0648\u0631\u062f \u062a\u062c\u062f\u06cc\u062f \u0646\u0638\u0631 \u0642\u0631\u0627\u0631 \u062f\u0627\u062f \u0648 \u062f\u0631 \u06f2\u06f9 \u0698\u0648\u0626\u06cc\u0647 \u06f1\u06f9\u06f9\u06f7 \u06cc\u06a9 \u0627\u0637\u0644\u0627\u0639\u06cc\u0647 \u0628\u06cc\u0634\u062a\u0631 \u062f\u0631\u0628\u0627\u0631\u0647 \u062a\u0635\u0645\u06cc\u0645 \u067e\u06cc\u0634\u0646\u0647\u0627\u062f\u06cc \u0631\u0627 \u0645\u0646\u062a\u0634\u0631 \u06a9\u0631\u062f. <sep> Label: Contradiction", "output": ["FCC \u0627\u06cc\u0646 \u0642\u0627\u0646\u0648\u0646 \u0631\u0627 \u062a\u062c\u062f\u06cc\u062f \u0646\u0638\u0631 \u0646\u06a9\u0631\u062f."]}, "Prediction": "                                                            "}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-8d88b4a7098d457fbcc15d9817213847", "input": "Statement: Jaffa has been courted, crushed, and rebuilt by a succession of conquerors, from the ancient Egyptians to the Ottoman Turks. Choices: 1. The Ottoman Turks devastated Jaffa when they invaded. 2. Jaffa's original buildings are still standing. 3. Jaffa has been rebuilt many times.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-0124a81ffa9a4adcb2578f0b164af292", "input": "Statement: The commentariat agrees that Barry Goldwater 1) was a giant in modern political conservatism and 2) was an endearing straight-talker. Choices: 1. People agree that Barry Goldwater is a great straight talker who is quite conservative. 2. Barry Goldwater is an important figure when it comes to political conservatism. 3. Barry Goldwater is a staunch liberal.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-74a16d6116e54c4d8acd050926d025c1", "input": "Statement: The place also offers a terrific view. Choices: 1. A terrific view can be seen at the place. 2. Aside from other advantages, the place has great views. 3. The place lacks any good views unfortunately.", "output": ["2"]}, "Prediction": "1 The place also offers a terrific view."}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-52d12eaea9ad4e5f91fd7acdfe5ebd13", "input": "Statement: These amounts are not large, but competition generally prevents charging higher rates to some customers in order to fund reduced rates for others. Choices: 1. All customers are charged at the same rates. 2. These amounts are small, but competition restricts charging higher rates to some clients. 3. The maximum rate that can be charged to customers is three percent.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-129e702450a14d3faa3f1d1ff41bae8b", "input": "Statement: Luckily, he is highly placed, but I mean, how does one gracefully NOT contribute? Choices: 1. He is placed highly. 2. The contributions were to a good cause. 3. It is easy to not contribute gracefully.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-15c6ce87639d461a99e724a8d5099f22", "input": "Statement: -This Act may be cited as the 6 ''Clear Skies Act of 2002''. Choices: 1. The act was passed to limit pollution. 2. The act is dated as 2001. 3. The act may be cited elsewhere.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-e047a21f70ab4f44a036069c9f9669c0", "input": "Statement: You've never had a job. Choices: 1. You've never worked. 2. You've never been employed.  3. You had a job in the past. ", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-8d1ebac0a45147b3980d195bdcd1424c", "input": "Statement: Mark Shields looks directly at Robert Novak on Capital Gang and calls him Al Hunt, much to the amusement of the other panelists. Choices: 1. Mark Shields looked at Novack and called him a name that Novack was offended by. 2. Mark Shields looked at Novack and called him a name. 3. Mark Shields didn't speak.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-fc7255b483ed4510bbac083b430b8836", "input": "Statement: i don't have any of them i don't carry them he carries them i try to take them away from him Choices: 1. I'm glad he carries them and I don't. 2. I tend to carry them more than he does. 3. I'm not the one who carries them, he is.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-0a9c3e524e0f410aa4b92798eec33e2f", "input": "Statement: A'deem spoke of it with contempt. Choices: 1. He spoke of something with contempt. 2. A'deem spoke of it with extreme admiration. 3. A'deem wasn't impressed by the new weapons.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-808b53377b884ba5b32d85d8caa783e2", "input": "Statement: oh i know it and i have gone back and after i i graduated i read some of the old classics that i just bluffed my way through and have found that i enjoy them quite a bit too uh Choices: 1. After graduation, I read old books that are considered classics and I enjoyed them. 2. After I graduated, I read books by Mark Twain. 3. I haven't done any reading since graduation.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-2527250396e54dbd8b03b8dbc5f565c0", "input": "Statement: the dominant provider. Choices: 1. The dominant provider of the household.  2. The important and powerful provider.  3. The meek, inferior provider. ", "output": ["1"]}, "Prediction": "1 The dominant provider of the household. 2. The important and powerful provider. 3. The meek, superior provider."}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-11234d8eb87646d6898bd7a27fe15f27", "input": "Statement: Nathan Road has many electronics shops. Choices: 1. Nathan Road has 6 electronics shops. 2. There are electronics shops on Nathan Road. 3. There are no stores on Nathan Road.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-9fe132c2d4664275a0b642afe45153e2", "input": "Statement: Best known as the site of a pivotal World War II battle in the Pacific, Midway is no longer a military base but is open to the public, managed by the U.S. Choices: 1. Midway is still operating as a military base and closed off to public. 2. It is a popular tourist attraction due to being known as the location of an important World War II battle. 3. Midway is not a military base anymore and the public can go see it under the operation of the U.S.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-a97c400f240c46baba5947739257b905", "input": "Statement: The city is built on hills by legend seven, but in fact many more providing several splendid vantage points. Choices: 1. The city is built inside of a deep valley. 2. The actual number of hills on which the city is built is 20. 3. According to the legend, the city is built on seven hills.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-9585724dbe70493fbc6b0898600c99ff", "input": "Statement: Sir James stroked his chin and smiled. Choices: 1. Sir James rubbed his face. 2. Sir James rubbed his face and frowned. 3. Sir James didn't move.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-38d06b0ab97b4561b48ed5b1abdd6e5e", "input": "Statement: A priori, population density should have an important effect on rural delivery cost. Choices: 1. Population density is not correlated with delivery costs. 2. High population density reduces average fuel costs for delivery trucks. 3. Rural delivery costs should be tied to population density.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-18c544d731564292831332b5453d0978", "input": "Statement: When you work with people who are as dedicated as my colleagues, it's contagious. Choices: 1. It's contagious when you work with people, who are as dedicated as my colleagues. 2. When you work with people passionate about their work, you become like that too. 3. Even if everyone around you is dedicated, you stay unmotivated.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-903b679dacd04b1c9491f6d247074e53", "input": "Statement: Marcel Proust spent many summers at its splendid Grand H??tel, where he wrote part of his A la Recherche du Temps Perdu. Choices: 1. Victor Hugo is the author of A la Recherche du Temps Perdu. 2. A la Recherche du Temps Perdu was a play written by Marcel Preest. 3. Marcel Proust is the author of A la Recherche du Temps Perdu.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-6922316730654f3a9a98edc6629d0e46", "input": "Statement: The modern town sits on the east bank of the Nile some 800 km (500 miles) from Cairo. Choices: 1. There is a town 800km from Cairo. 2. The modern town on the east bank of the Nile has a large population.   3. The town is only 10km from Cairo.", "output": ["2"]}, "Prediction": "1 The modern town on the east bank of the Nile has a large population. 3 The town is only 10km from Cairo."}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-afdb738da6f9442191db9888baa7570a", "input": "Statement: In books, you simply leapt into another, promised the driver a sovereign or its modern equivalent and there you were. Choices: 1. In books it was difficult to get the drivers to do much. 2. In books if you promised the driver a sovereign you were there. 3. In books if you promised the driver cash you were there.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-86f38f91fc164ee8933e51e3a1f4c697", "input": "Statement: or uh machines like uh IBM thirty eight twenty high speed uh APA printers and so i get frustrated uh watching things slowly come out upon my matrix printer more so than i do over over access speed um Choices: 1. Slow electronics are very irritating.  2. My printer is much too fast.  3. My matrix printer is too slow. ", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-db8b44b4954c4b3f9e7f0375cf4c9380", "input": "Statement: There are, of course, other contribution or cost coverage goals that could be selected. Choices: 1. Other contribution or cost coverage goals could be selected. 2. The cost coverage goals must be effective in order to be selected. 3. You don't need to choose any cost coverage goals.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-4cc9a04be392477b8a7870d46ce27f7d", "input": "Statement: i mean the Kurds have tried it before they've gotten their butts kicked and this is just another time that it's happening Choices: 1. The Kurds tried it but lost. 2. The Kurds have never tried this. 3. The kurds weren't successful in the battle.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-34c2a772661b443b922a0adf683fbe4f", "input": "Statement: This estimate for the potential number of FGD retrofits considers the resource and labor requirements of the simultaneous installation of SCRs, which is further discussed under the labor section (6. Choices: 1. It is a comprehensive cost analysis.  2. Labor requirements are considered when considering the estimate for retrofits. 3. No other information is available on the subject. ", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-87dd034b27374927a609ace510f6c768", "input": "Statement: And please accept cookies so you can enjoy Choices: 1. Accept cookies to enjoy the experience. 2. It's important that you accept cookies. 3. You will enjoy regardless of if you accept cookies.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-863f9e03e1af4f248e32482fe9d6d4b0", "input": "Statement: This report has some value but it is not as valuable as it once was. Choices: 1. This report is helpful, but not as much as it used to be. 2. This report is helpful, even moreso than it used to be. 3. This report is helpful, but not as much as it was in 1976.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-fe8793e15d65443b925a51390590d39e", "input": "Statement: In 1991, the American Historical Association criticized Oates for not adequately footnoting his use of Thomas' book. Choices: 1. Oates didn't footnote his use of several of Thomas' books, and so he was criticized for it.  2. The Thomas book that Oates used was thoroughly footnoted.  3. The AHA criticized Oates in 1991. ", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-64d29bb1b03a49cfba502419033c85cc", "input": "Statement: For insight into the local tin mining industry, visit the excellent Geological Museum on Jalan Sultan Azlan Shah. Choices: 1. Illustrations about local tin mining can be seen at the Geological Museum. 2. The Geological was destroyed by the tin miners. 3. The Geoligical Museum shows how tin was and is mined.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-32f3b8d03d1a4960a69500c02b707dcd", "input": "Statement: Lending practices still face scrutiny Choices: 1. Lending practices must be monitored. 2. Lending practices are not scrutinized. 3. Lending practices are scrutinized still.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-0957b738571745ed8100656aa97849da", "input": "Statement: ABC's George Will chimed in, Is this out of character? Choices: 1. George Will chimed in, which may have been out of character. 2. George Will generally did not speak, so him chiming in was strange. 3. George Will stayed silent.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-5887d4413caf4d18ada329a7b522161c", "input": "Statement: One of the old god-kings spoke of condemning them. Choices: 1. The god-king was happy to have condemned them. 2. The god-king did not speak at all. 3. The god-king talked about condemning them.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-f672d214d5e8426cad12dbdb1c59c439", "input": "Statement: Take home a bunch of tiny packets of colourful azafr?\u00a1n (saffron) and any other dried herbs you may fancy. Choices: 1. Saffron is colorful and comes in tiny packets. 2. The only herbs you can take must be fresh. 3. The other dried herbs come in larger packets.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-8696dd7fa37b413fa963cb2488c5b04f", "input": "Statement: Construction of the offices obliterated much of the archaeological dig which had unearthed the original layout of the ninth-century quay, but the Viking artifacts that were found are on view in the National Museum  and in the Viking Adventure exhibit. Choices: 1. The National museum has Viking artifacts on display. 2. Construction of the offices was permanently halted when Viking artifacts were found. 3. The Viking Adventure exhibit displays Thor's hammer.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-bdab7192107c4719a687bbaca4d05b5f", "input": "Statement: The focus on legalistic descriptions of punishable human behavior ignores unconscious behavior, the habits many men are accustomed to that don't call for punishment but are still harmful--what Conley says occurs within the reverberating circuitry of maleness. Choices: 1. The law sees no distinction between conscious and unconscious behavior. 2. It's important for men to restrain their unconscious urges. 3. Men often do things unconsciously and are not culpable but still inadvertently cause harm.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-b53f0cbb443b486d94941c07f5db001c", "input": "Statement: oh so once you buy a vehicle and you pay you pay the sales tax that's it they don't tax you on it anymore Choices: 1. You don't have to pay any further tax on a vehicle once you've paid the sales tax. 2. When you own a car, you have to continue to pay tax on it every year. 3. I was worried that I'd have to keep paying a lot of tax on my new car.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-733f3bd478754627914be4778f294e25", "input": "Statement: i drive a Honda Prelude and Choices: 1. My car is a Honda Prelude and 2. I don't know how to drive so I don't own a car 3. I drive a red Honda Prelude, I bought it 2 years ago", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-ac1f7207a64e42ea9f3da5617b2d545b", "input": "Statement: And suddenly a dread clutched at his heart. Choices: 1. A feeling of giddy relief took hold of heart. 2. He was overwhelmed by feelings of dread. 3. His premonitions were completely correct.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-bb29c90a73e74ab08f303ddc53b41b27", "input": "Statement: As a preliminary matter, using the fixed/variable ratios for U.S. Choices: 1. The ratios help determine the outcomes. 2. Fixed/variable ratios are never used. 3. The fixed/variable ratios for the U.S. were used.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-3fae0b6d87b84d31b0169ec065804773", "input": "Statement: fitness and exercise Choices: 1. Fitness and exercise are important to me. 2. Sitting around and doing nothing all day every day. 3. Working out and getting into shape.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-ee734c8ca4b2458f81aa912e8aa922c3", "input": "Statement: there's only three places in Georgia that requires that and uh even with that it hasn't done any good Choices: 1. Georgia mandates recycling in those three counties but it hasn't done any good.  2. In Georgia, that's a requirement in some places and it's a huge help.  3. Georgia requires that in a few spots and even that doesn't seem to help at all. ", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-bd2328520cea496cb77f6320efde8d5c", "input": "Statement: But there is a little more noble cause in this for me. Choices: 1. There is little more noble cause for me in this. 2. There is nothing noble about me. 3. There is little else that is as noble as fighting for your rights.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-370749015a8246928f095c872fa8840a", "input": "Statement: This might be one of his brood.\"   Choices: 1. He has a large family and this is part of it. 2. He is the only one there is. 3. This could be one of his race.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-93549e0873d546b6b7509f9c7fe489a2", "input": "Statement: He was thin, with long muscles and a topknot of braided hair running down his back. Choices: 1. He was fat and bald. 2. He had long hair and big muscles. 3. He was a striking figure.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-89cb284569554d789d96a9e7e3535f20", "input": "Statement: We believe that other agencies could benefit from these additional authorities. Choices: 1. We believe that these additional authorities could be beneficial to other agencies. 2. Most agencies that we have spoken to agree that these additional authorities could help them. 3. We don't think that these additional authorities would be helpful to other agencies.", "output": ["2"]}, "Prediction": "1 Most agencies that we have spoken to agree that these additional authorities could help them. 3"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-83adf77702ed4ee9921673d135da1ed2", "input": "Statement: from scrutinizing any agency activity except the final program result. Choices: 1. from scrutinizing agency activity except the last results from the final survey. 2. from scrutinizing agency activity including the last results. 3. from scrutinizing agency activity except the last results.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-b66ed8c4155443eb9c7c64a2202d6c9b", "input": "Statement: Professor Aleinikoff has experience both in the public sector and in academia that has provided him with expertise in immigration law. Choices: 1. Professor Aleinikoff lacks experience in both the public sector and academia. 2. Professor Aleinikoff's experience in both academia and the pubic sector has provided him with expertise in immigration law. 3. Immigration law has become the favorite subject for professor Aleinikoff.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-5ba4eb1c9f154fdf8bb5d966d2869165", "input": "Statement: Spun and spun and spun the president's denial for months without bothering to check if it was true. Choices: 1. The President's advisors knew that it wasn't true. 2. The President was completely open from the start and made no denials. 3. The President kept denying, but did not check to see if it was true.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-92855a49bd1746c893fbff1a7d0bef2a", "input": "Statement: well i don't know what how do we end this thing i think it just says hang up why don't we do that good-bye Sharon Choices: 1. I think we end this by just hanging up. 2. I know the way to end this. 3. I am not sure how we end this thing.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-e751866455854760886db81e08a47a00", "input": "Statement: For example, mail could be sorted one day and delivered the next, resulting in a less demanding schedule. Choices: 1. The schedule is more hectic when mail is sorted in one day and delivered in another. 2. If mail can be sorted in one day, delivered the next the schedule will be less demanding.  3. A two day system of mail delivery works best. ", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-92728ea21a60447580dfd65fc94e90a8", "input": "Statement: The festivities had died down; the streets were empting out. Choices: 1. The annual carnival was coming to a close.  2. The streets were packed as the festivities raged on. 3. The streets were clearing out as the festivities were ending. ", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-84494afbee47431283f9e3d5850ca951", "input": "Statement: Jones from Jude Wanniski--one of the founders of supply-side economics and its reigning guru. Choices: 1. Jue Wanniski does not believe in supply side economics. 2. Jude Wanniski formed and educated people about supply side economics. 3. Jude Wanniski is one of the founders of supply side economics.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-a2bf8383dafd422487fcfdb71c71c7e3", "input": "Statement: I have not asked other attorneys to handle cases, so I havent been turned down, Frank Smith said.  Choices: 1. Frank asked about the cases. 2. Frank did not ask other attorneys to handle cases. 3. Frank would have been turned down if he asked.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-7074fd4a171d41f29c5c8cdc8188b40a", "input": "Statement: oh taxes lord forbid forbid lord forbid taxes goodness gracious if we would uh plan our expressways a little better that ten dollars for the bridges and the roads we'd cut that in half and give to the teachers we might have such a problem Choices: 1. If the expressways were planned better some of the tax money could be used for education. 2. We are in a dire situation in need for funding in the field of education. 3. The expressways are planned just fine.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-1aaa6a7bdbc24b83acb8fd7d17ba403f", "input": "Statement: These publications can be searched by title, theme, or date. Choices: 1. These publications are a chronicle of the NASA Apollo missions. 2. These publications can be searched using person, place, or thing. 3. These volumes can now be searched using title, theme, and date.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-46594340c8f04eefbb63197b53a4a9a8", "input": "Statement: Participants also noted that the PCAOB should take advantage of the fact that under the current environment no one has more motivation for getting bad auditors off the street than the accounting firms themselves. Choices: 1. The PCAOB should not be concerned with bad auditors at accounting firms. 2. Accounting firms are motivated to remove bad auditors. 3. Bad auditors are identified by cameras in the office lunch room.", "output": ["3"]}, "Prediction": "1 The PCAOB should not be concerned with bad auditors at accountant firms. 2. Accounting firms are motivated to remove bad auditors. 3. Bad auditors are identified by cameras in the office lunch room."}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-7184cc54dcd444eba7fde741aa12b0c8", "input": "Statement:  Hanson staggered back, panting from his efforts. Choices: 1. Hanson stood strong and firm, having caught his breath. 2. Hanson stumbled back, breathing heavily from his labor. 3. Hanson's legs were weak from his hard work.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-ca02397d73944d899d6c14165ed9b368", "input": "Statement: You mean you want to slip into something that might attract the attention and admiration of a fellow mammal? Choices: 1. You want to get into something more attractive?  2. You want to change into something that will attract all the men?  3. You want to get into something that will make you less attractive?", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-26a5937e93c241b6a808383cecda632f", "input": "Statement: For the Senate and the Roman People--that's what gladiators used to say. Choices: 1. Gladiators never spoke. 2. Gladiators used to say that. 3. Gladiators gave short speeches after battles.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-a72397171d9f4fbdb2b35f740c458d1a", "input": "Statement: It is true it is told from the point of view primarily of those who tried to save preference, and one may be able to take issue with some of the journalistic flourishes, as you do, but aside from characterization of the participants I don't detect bias. Choices: 1. Nobody is concerned about the bias of the piece under discussion. 2. The article discussed is factually correct. 3. The speaker believes that accusations of bias are unfounded.", "output": ["2"]}, "Prediction": "1 The speaker believes that accusations of bias are unfounded."}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-259deeb9ce9547088307a87b5448a17a", "input": "Statement: The former Duchy of Warsaw, called the Congress Kingdom, enjoyed some autonomy and prosperity in the early 19th century. Choices: 1. The Duchy of Warsaw had no prosperity in the early 19th century. 2. In the early 1800s, there was a degree of autonomy for the Duchy of Warsaw. 3. The Duchy of Warsaw had not been prosperous before the 1800s.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-4ae753f0ee154ebbb90e4acc8b84e605", "input": "Statement: i i absorbed all of that movie in one sitting uh i guess what made it so good was the cinematography cinematography Choices: 1. I watched all of the movies in one go. 2. The cinematography was great! 3. I watched them one at a time over many days.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-cc7813eb00974e2589097a7a856fb031", "input": "Statement: Scheduled to reopen in 2002 or 2003, the Malibu site will house only the Getty holdings in Greek and Roman antiquities, some of which date as far back as 3000 b.c. Choices: 1. The Malibu site will house only the Getty holdings in Romand and Greek antiquities, and it is scheduled to reopen in 2003 or 2002. 2. Scheduled to open in 2012, the Malibu site will house not only the Getty holdings in Greek antiquities, some of which date as far back as 2011. 3. The Getty holdings were taken hold of thanks to the researchers' effort.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-689d1ff315c9444f8b63e5136143dd7a", "input": "Statement: i've seen you know like elderly people that really can't get out too much and sometimes like we i have a great aunt that lives in a Choices: 1. I had a great aunt who could only say a few words each day. 2. All the elderly people I have seen are very chatty. 3. I have seen old people who can barely talk.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-05bdd09221af44709c650b0f3c60309e", "input": "Statement: 'I can't help noticing that you haven't...killed me on sight.' Choices: 1. I'm surprised you didn't kill me. 2. I'm surprised you didn't kill me right when I came through the door. 3. I'm not surprised you didn't kill me.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-0489b45907b342118bb7954983b020b9", "input": "Statement: I want you to spark their minds. Choices: 1. I want you to do an experiment that is exciting for them. 2. I want you to do something that makes them use their imaginations. 3. I want you to give them tedious work that bores them into submission.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-1a3426d5e95848428e38bc75f846b33f", "input": "Statement: you know it's just them there they are and they're writing the whole time Choices: 1. You don't know that it's just them there, they don't write anything either 2. they write about what your saying and your facial expressions.  3. you know for certain that it's just them there, they write the whole time your there", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-e49bc246e76a4d0fb3f0f942e3b833f2", "input": "Statement: Two large wrestlers, symbolic of the first Malla, a strongman, flank the open porch of this structure, and a gilded Garuda kneels on a column above. Choices: 1. There used to be three large wrestlers that symbolized the first Malla. 2. The first Malla was a strong man, purportedly a wrestler.  3. A stone Garuda that kneels on a column above. ", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-f48de5856b234336b527857a15aa1c1e", "input": "Statement: A dollar of saving buys more investment goods now than in the past because the price of investment goods has decreased relative to other goods in recent years. Choices: 1. Investment goods face lower prices as industrial output increases. 2. A dollar of saving actually buys less investment goods now because of inflation. 3. Over time, the price of investment goods as declined in comparison to recent years.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-6aa2374e001c415fac82f137920eab08", "input": "Statement: The house was bought with the royalties she earned from her first book, The Tales of Peter Rabbit. Choices: 1. She used the royalties from her first book to buy the house. 2. The house was bought with the money she inherited from her grandfather. 3. She received the royalties from her first book six months before it was published.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-56911679d2914c61bad496744acbc29c", "input": "Statement: and uh i run a little direct mail business on the side and i finally put together a cookbook Choices: 1. I operate a large multinational business in milk delivery. 2. I operate a small mail business and created a cookbook. 3. The cookbook is more successful than the business.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-d49e1e62bce74222bdb7dc76ae589e40", "input": "Statement: Sagittarius, as he remembered it, was supposed to be one of the signs of the Zodiac. Choices: 1. He knew that his Zodiac sign was Sagittarius. 2. He could not remember a single Zodiac sign. 3. He remembered that Sagittarius was one of the Zodiac signs.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-dbd5906aa76f4a288ac57e5433278d4c", "input": "Statement: . The reason Jews have an injunction against portraying God is that Neanderthals cannot draw. Choices: 1. Jews have an injunction against showing God. 2. Jews have no injunction against showing God. 3. Jews have an injunction against showing God because of how their art is created.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-fd0deece1a8c4a5fb9236420d7c7b6f7", "input": "Statement: The Grand Slam Breakfast just never took off. Choices: 1. The Grand Slam Lunch was a smashing success! 2. The Grand Slam Lunch never grew popular. 3. The Grand Slam Breakfast was a flop.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-25a9d79f681a4106a8311d998c22a36f", "input": "Statement: Attorney General Janet Reno said she tried to tell National Security Adviser Tony Lake about the Chinese scheme 10 months ago but was unable to reach him by phone, so she asked the FBI to tell the White House, which led to the above fiasco. Choices: 1. Janet Reno was Attorney General while Tony Lake was National Security Adviser. 2. Tony Lake was contacted by the FBI about the Chinese scheme. 3. Janet Reno worked for the George W. Bush administration.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-868c66ecd4364b4582f86cc244c36fab", "input": "Statement: In the discussion of the Regulatory Flexibility Act, the preamble to the final rule states that HUD's Economic Analysis considers the impact of the rule on small entities. Choices: 1. The small entities are the ones most affected by the act. 2. The analysis takes into consideration the small entities. 3. The Flexibility Act does not allow for analysis.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-92bba1edaf89405dbbbfd6e97efd9b3f", "input": "Statement: In an editorial Friday, the Daily Telegraph , a conservative paper, made fun of a splendid correction published in the liberal Guardian the day before. Choices: 1. The Daily Telegraph is a daily paper. 2. The Daily Telegraph is a newspaper run by conservatives. 3. The Daily Telegraph is a very liberal operation.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-7f3aef11c3db45e19deb17c93b2224d6", "input": "Statement: If a fault occurs, you can arrange to have it repaired or exchanged before you leave. Choices: 1. If an issue arises, you can plan to have it repaired or replaced before you leave. 2. If a fault happens before you leave, that is too bad cause it is not fixable. 3. Faults are uncommon so they offer free repairs and replacements for you.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-5edb4415240b4628b6ca3ccb9bad1bd1", "input": "Statement: It is also a major entertainment spot with its own appeal, from the whitewashed houses of the ancient walled city clambering up the hillside to the hustle and bustle of the harbour area, with its bistros and boutiques. Choices: 1. There is nothing to do there. 2. It is a fun place to dine and relax and do outdoor sightseeing. 3. It has a lot of entertainment in the area.", "output": ["2"]}, "Prediction": "1 The model should output 1 when the statement is \"The restaurant has many fans who love its attractions.\" This is a correct choice according to the statement. "}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-e097d77e204e442dac4fa54a10159cca", "input": "Statement: Prudie has heard nothing of the Thai herb. Choices: 1. Prudie was told that the Thai herb has medicinal properties. 2. Prudie is well aware of the Thai herb from her student days. 3. This is the first that Prudie has heard of the Thai herb.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-3defa3ec8346459395ff43903b3f8d04", "input": "Statement: Tobe Kells owns it. Choices: 1. It is Tobe's property.  2. Tobe Kells paid a lot for it.  3. It could never be owned, it was free as a bird. ", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-cc65c36f63884f769f6063fea6938376", "input": "Statement: There is an informative recorded tape in several languages (you listen on headphones as you tour the attractions) to help you make the most of your visit. Choices: 1. The tape is in several languages so all tourists can enjoy it. 2. The tape is in several languages. 3. They don't offer a formal tour.", "output": ["1"]}, "Prediction": "1 The tape is in several languages so all tourists can enjoy it. 2"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-159a483f5f714ab5b1f6f41eec5f6246", "input": "Statement: The original is still there in spirit and no visitor should neglect it. Choices: 1. All visitors feel the original in spirit. 2. The original is lone gone without the slightest trace. 3. Visitors should always remember the original in spirit.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-6fd1626bdc594818b20d1e86dbefaf3b", "input": "Statement: but uh also TI has some good uh uh some good jogging tracks every once in a while while i'm sitting there eating lunch i'll look look out and see people jogging i guess on their lunch hour Choices: 1. I wish that I had the time to jog during the day. 2. TI has some nice tracks for jogging, sometimes during lunch I see people on them. 3. TI does not let us take lunch breaks.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-8b7116b40c0943efa88537369d6ad6c5", "input": "Statement: i think the better sight seeing is in the uh British Virgins Choices: 1. British Virgins has better views for sight seeing. 2. British Virgins had the worst sight seeing. 3. I have only ever been to the British Virgins.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-53e9914ce7fd491e8446c919a852c812", "input": "Statement: it's really kind of fun especially if your spouse will get in there with you and get dirty yeah Choices: 1. It is even more fun if your spouse gets in on it. 2. It is the best activity to do together. 3. It is fun, but not if your spouse is there.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-87d27c0560ca438d8881f50d924632d2", "input": "Statement: I must have a successful career which would mask my true activities\u2026 . Choices: 1. I'll never need a job to hide my true intentions. 2. I'll need a job to hide my real activities. 3. To hide what's really going on, I must become a painter.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-415075999abf48bd99f2eef515f08014", "input": "Statement: The fandango, tango, farruca, and zambra are performed to the staccato rhythm of palmadas (hand-clapping), pitos (finger-snapping), the zapateado of fiercely drumming heels, and the fiery compulsion of the castanets. Choices: 1. The fandango, tango, farruca, and zambra are yoga positions only performed in a cave at dawn.  2. The fandango, tango, farruca, and zambra are dances.  3. The samba is also a dance. ", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-a5b9a9e890b646f2958f66acb9ee6b12", "input": "Statement: Of course, growth was faster during some periods-the 1950s and 1960s, and the second half of the 1990s-and slower during other periods-the 1970s. Choices: 1. Growth has continued to slow. 2. Some periods have faster growth than the others. 3. Growth increased the most in the 1990's.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-e9c022b8c6704905bb03f758879604b2", "input": "Statement: no no no you went to Galveston uh i have a favorite hotel that extends out over the water Choices: 1. You went to Dallas. 2. You went to Galveston while I was in Arizona. 3. You went to Galveston.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-a3493ce882cf43e38c313049d9a27eed", "input": "Statement: There are no trees and no shrubs, just 15 stark rocks embellished with ancient moss, standing in clusters amid the perfectly rakia white gravel. Choices: 1. Most of the rocks have been smoothed by erosion. 2. There are lots of trees and even more shrubs. 3. There is old moss on the 15 rocks.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-e48a0dd0ec1248c5b762748ace64b8a1", "input": "Statement: A congressional agency that funds legal services for low-income Americans is battling Charleston lawyers over control of buildings that once housed legal assistance programs in Charleston, Georgetown and Conway. Choices: 1. A congressional agency is fighting with Charleston lawyers. 2. The congressional agency and Charleston lawyers are drafting a peace treaty. 3. Charleston lawyers love a good fight, and welcome the challenge with the agency.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-6b91401dd2904cfca18e963c4c9d0d32", "input": "Statement: With mild distaste, I took the Gauntlet he handed me. Choices: 1. I wanted the gauntlet and I begged him for it.  2. I didn't want to take it but I took the gauntlet and then threw it.  3. The gauntlet was handed to be and I accepted it. ", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-a1a321f90dc24711bd33cff33d05793e", "input": "Statement: This computer is a fine scientific instrument, obeying natural law well. Choices: 1. The computer obeys natural law and is a fine scientific instrument. 2. The computer was not good in situations where natural law did not apply. 3. The computer violated numerous physical laws and could not be used for science.", "output": ["2"]}, "Prediction": "1 The computer was not good in situations where natural law did not apply. 3 The computer violated numerous physical laws and could not be used for science."}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-fd07e26a4ed74d61bced6fd8e7acb67d", "input": "Statement: Suddenly, he gave a faint exclamation.  Choices: 1. He exclaimed.  2. He realized something.  3. He sighed. ", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-1401b695f5a8403ba5ef9cb2f119598e", "input": "Statement: But building a university from scratch is far from cheap. Choices: 1. Building a university costs, in average, $1M. Very far from cheap. 2. To build a university you have to invest lots of money. 3. Building a university is actually pretty cheap.", "output": ["1"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-0126e869517d4086a175adb658f2f30d", "input": "Statement: The University of Chicago has chosen a new president--but the debate over the ongoing shake-up at the school continues. Choices: 1. The University of Chicago has kept it's previous president. 2. Even though the University of Chicago has a new president it did not help the debate. 3. The new president at the University of Chicago is doing nothing to address the school's issues.", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-052923547b384b7eb229246fa7418eeb", "input": "Statement: and it's all over him the poor thing you know so there's definitely hazards to going camping if you don't know what you're looking at Choices: 1. You should know what you're doing if you want to go camping. 2. He got covered in poison ivy because he didn't recognize it. 3. Camping is very safe and you don't know what you're looking at.", "output": ["2"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-77df057ac97f4e078faf05e8a1847e7f", "input": "Statement: Perhaps the era of fashion is over, or soon to be. Choices: 1. This era of fashion is becoming extinct right before our very eyes.  2. Fashion is thriving and there is no foreseeable end in sight.  3. The era of fashion is declining due to the amount of fashion faux pas committed by over eager young celebrities. ", "output": ["3"]}, "Prediction": "1"}
{"Task": "task201_mnli_neutral_classification_gpt3_0", "Definition": ["In this task, you're given a statement and three sentences as choices. Your job is to determine the neutral choice based on your inference from the statement and your commonsense knowledge. The neutral choice is a sentence that neither agrees nor disagrees with the statement. Indicate your answer as '1', '2', or '3', corresponding to the choice number of the selected sentence. If sentence X agrees with sentence Y, one's correctness follows from the other one. If sentence X disagrees with sentence Y, they can not be correct at the same time. (1) Input: Statement: Next to the MGM Grand you will find M and M World, four stories of merchandise and memorabilia dedicated to the candy that doesn't melt in your hand. Choices: 1. The candy has many fans who love its attractions. 2. There's four stories of memorabilia dedicated to a candy. 3. That particular candy melts and becomes difficult to eat. Output: 1  The model should output 1 when the statement is \"The candy has many fans who love its attractions.\" This is a correct choice according to the statement.  (2) Input: Statment: I've forgotten his name now, confessed Tuppence. Choices: 1. Tuppence forgot his name. 2.Tuppence remembered his name later. 3. Tuppence never could forget his name. Output: 2  The model"], "Instance": {"id": "task201-35713fd88f3843d8a818f0678ff7342a", "input": "Statement: Individuals' claims to their wealth and income must of course be balanced by the need to finance governmental activities, no matter how few and inconsequential they may be. Choices: 1. The government must be funded. 2. The government has no claim to individuals' wealth and income. 3. Government financing has been increasing as a proportion of individuals' earnings.", "output": ["3"]}, "Prediction": "1 The government must be funded. 2. The government has no claim to individuals' wealth and income. 3 Government financing has been increasing as a proportion of individuals' earnings."}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-804bc71ba4d54092a56a9a0baccccd2d", "input": "Sentence 1: Sediment is transported by currents. Sentence 2: Tidal currents are responsible for resuspension of sediment and transport of this sediment seaward (Noble and Gelfenbaum, 1990;", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-51f66136aaea4cf69971a3d67b57dc69", "input": "Sentence 1: Iguassu falls is the largest waterfall on the planet. Sentence 2: Two waterfalls feed into the Lake Shrine, one that falls approximately 25 m , and another series-waterfall, that falls approximately 10 m .", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-fc9081c0cb7f432d8a05b132d727e9d0", "input": "Sentence 1: About half of solar type of radiation is absorbed in the first 15 meters of water. Sentence 2: The darker forest surfaces absorb more solar radiation.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-e5857aaf8384455ca69f60656399178a", "input": "Sentence 1: Evenly spaced lines kind of lines does a diffraction grating produce. Sentence 2: Considering the almost perfect clarity with which the majority of spectral lines appear in the emission spectra produced with the powerful diffraction-grating spectroscopes of our day, there were good grounds for regarding these radiated lines as simple and indivisible things;", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-da9eb36271bf4300817396d372511177", "input": "Sentence 1: An underwater spider uses shiny air bubble to breathe and keep alive. Sentence 2: My body is still alive because i keep breathing (while there is a little bit of clean air somewhere).", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-5d1cc75b372b47458cfa24396d63351b", "input": "Sentence 1: Liquid has a definite volume, but not a definite shape. Sentence 2: Liquid has a definite volume but no definite shape.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-c99ce808fff24d5d9fa122ab72b4111c", "input": "Sentence 1: Ocean ridges formed by marine invertebrates living in warm shallow waters within the photic zone of the ocean are called coral reefs. Sentence 2: thus these large forams lived in the photic zone of shallow marine carbonate environment (&lt; 30 m deep) and are commonly associated with reefs and may form shoals, and dunes.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-808b7c797943484fa2efc3f535db26d5", "input": "Sentence 1: A pregnant woman should avoid toxic substances while pregnant. Sentence 2: exposure to harmful substances Pregnant women should avoid exposure to toxic and chemical substances (i.e., lead and pesticides), and radiation (i.e., x-rays).", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-ec30919ee6484639b823514bc767edfc", "input": "Sentence 1: Wavelength is the distance between two corresponding points of adjacent waves called. Sentence 2: wavelength A measure of distance between the beginning and end, two corresponding points, or a complete cycle in a wave.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-c3aac225ef6941678589768010527844", "input": "Sentence 1: The tilt of earth on its axis causes summer to be warmer than winter in the northern hemisphere because the rays of the sun strike the northern hemisphere more directly in the summer. Sentence 2: Warm summers in the northern hemisphere occur when that hemisphere is tilted toward the sun and the Earth is nearest the sun in its elliptical orbit.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-f09955692cf144e79244636e2553e99a", "input": "Sentence 1: Ovulation takes place in the ovary and is part of the menstrual cycle. Sentence 2: Ovulation and Stimulation Ovulation refers to the process by which an egg or ovum is released from the ovary, usually near the midpoint of a menstrual cycle.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-f5f7d38e0f3b42ed8383fd13cf540b20", "input": "Sentence 1: Changes in sunlight or water do plants respond to in their environment. Sentence 2: Additional information is needed on how plants perceive and respond to changes in their environment.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-5c0606d195de4a7b9b7e39e0ee3cca48", "input": "Sentence 1: A salt concentration of 32 percent is nearly ten times that of seawater abundant resource. Sentence 2: Trace contaminants in the salts used are at rather high concentrations in artificial seawater because so much salt must be added to achieve the salinity of full strength seawater.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-48c12773b1204a81aad071f2e5debb71", "input": "Sentence 1: The term percent composition means the percentage by mass of each element in a compound. Sentence 2: The term &quot;percent or percentage&quot; means the percentage by weight.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-68887d6fc9fa4f63ab1d623ab9265b32", "input": "Sentence 1: The intermolecular structure of ice has spaces that are not present in liquid water. Sentence 2: If there's ice, there might be liquid water underground.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-564c8c3628674cc4aaf0ed917e0fa2f2", "input": "Sentence 1: Adrenalin is the hormone produced in high-stress situations. Sentence 2: Catecholamine hormones such as adrenalin are released during frightening or stressful situations.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-21ac60c570fe45b9947f5aef3fae5bf7", "input": "Sentence 1: Protons and neutrons are located in the central nucleus. Sentence 2: Atoms consist of protons and neutrons in a central nucleus with electrons in different orbitals around that nucleus.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-7a35a1d1507c4b1eafaaa4a63c66eeb6", "input": "Sentence 1: Cellulose is one of the most common biochemical compounds on earth and is found in all plants. Sentence 2: Introduction Cellulose, the basic structural component of all plants, is the most abundant, naturally occurring organic compound.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-d1d7242729f345269d0a8de325446c9b", "input": "Sentence 1: Three different states of matter makes the halogen group so diverse. Sentence 2: Subject matter wherein the halogen containing product produced contains an unsaturated group.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-9ed7106ac0db4afbb141f042e162ef22", "input": "Sentence 1: Other than gametes, normal human cells have a total of 46 chromosomes per cell. Sentence 2: Human cells normally have 46 chromosomes (thread-like stuctures made up of DNA and other proteins) arranged in 23 pairs.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-12334051d5f2494882dbaa9bb9b59a7a", "input": "Sentence 1: Plasma matter makes up most of the universe. Sentence 2: Although relatively rare on earth, plasmas make up more than 99 percent of the visible matter in the universe.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-ef6bb1fd9d2b497aba78af1a61f949a9", "input": "Sentence 1: Aqueous solution is used to describe a solution in which water is the solvent. Sentence 2: aqueous solution A solution with water as the solvent.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-599b3cdfaec8448f985469db0c62dca7", "input": "Sentence 1: Light with the longest wavelengths is called infrared light. Sentence 2: This technique measures the absorption of various infrared light wavelengths by the material of interest.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-f38cf97713394a81a5b73ca649227b27", "input": "Sentence 1: Gravity attracts the earth to the sun. Sentence 2: There SOHO is balanced between the pull of Earth's gravity and the sun's gravity and so orbits the sun together with Earth.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-75bfdc8b1fb54788a5d5cd95d108f67b", "input": "Sentence 1: Elements below the second period, such as silicon, do not form n bonds as readily as second-period elements, and when they do form, they are weaker than those formed by second-period elements. Sentence 2: Prior to its synthesis, the double bond rule had suggested that elements of Period 3 and higher were unable to form double or triple bonds with lighter main group elements because of weak orbital overlap.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-174202691e4a40f4951437d1ff036ecf", "input": "Sentence 1: You decrease errors in an experiment by take many measurements. Sentence 2: The error (difference between theory and experiment) decreases as the number of measurements increases.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-606d94c450cf4ed383ddbf6049b3170f", "input": "Sentence 1: Portal veins carry blood between pairs of capillary beds. Sentence 2: In the circulatory system of animals, a portal venous system occurs when a capillary bed pools into another capillary bed through veins, without first going through the heart.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-110734d18da443b1b32ff64118ee57d8", "input": "Sentence 1: A bee will sometimes do a dance to tell other bees in the hive where to find food. Sentence 2: When a worker bee finds a food source, it flies back to the hive and relays the message of where the food is by doing an intricate dance that tells the other bees in which direction and how far the food source is with amazing accuracy.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-398c6b3743a84ceaaa3067567b6b2d94", "input": "Sentence 1: You decrease errors in an experiment by take many measurements. Sentence 2: This decreases the chance of measurement error due to sound reflections from the body of the technician.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-ab0f055b99ab4ff9bf8e5d703b1ad463", "input": "Sentence 1: Organisms that \"love\" acids are known as acidophiles Sentence 2: An acidophile is an extremophile organism which thrives in extremely acidic conditions.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-1398238a733441398f12b5ee795e05fe", "input": "Sentence 1: Motion can be defined simply as a change in position. Sentence 2: Motion can be determined by change in position over time.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-640d60b9b5e645acad515208ec720e47", "input": "Sentence 1: Weight is the measure of the force of gravity pulling down on an object. Sentence 2: weight The force of gravity acting on an object.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-b857982e6be3434e9f266c19e2e36bc3", "input": "Sentence 1: A telescope is used to make objects in space appear closer. Sentence 2: In addition to telescopes, astronomers have begun using other instruments to make observations.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-cb517e86b66647d0944fa51d23653ab7", "input": "Sentence 1: Sun does the stratosphere get most of its heat. Sentence 2: Most heat coming from the sun is trapped in the oceans, and most of that is in the tropics.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-41f9efc7028549438d490f792fb871d1", "input": "Sentence 1: A winter storm is called a blizzard. Sentence 2: WINTER STORM Winter storms include blizzards, heavy snowfall without wind, extended periods of cold weather, and ice storms.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-19ef114c1cac40bb84fce90cca251d88", "input": "Sentence 1: You call materials able to conduct electricity with 100% efficiency, meaning that no energy is lost during the electrical transmission, superconductors. Sentence 2: Superconductors can carry large amounts of current without energy-wasting resistive losses, thus they have the potential of increasing the efficiency of electric power transmission from power stations.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-44305c044f8a49de9f2b41e63ee38ee0", "input": "Sentence 1: Cell -> tissue -> organ -> organ system sequence represents the correct levels of organization for multicellular organisms. Sentence 2: and how cells are integrated into multicellular systems and organisms.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-20535b9cb0244640a9f320a905cd7392", "input": "Sentence 1: The scientific revolution took place europe starting in the 1500s. Sentence 2: It would not be controversial to say that the scientific revolution that took place in 17 th Europe could not have occurred without the help of the Muslims.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-68b863f62cb749bba9300cd40ce024f7", "input": "Sentence 1: This heat is used to convert water into steam, which is then used to turn a turbine, thus generating electrical power. Sentence 2: The energy that is it released is used to heat the water, the heated water is then turned into steam, and the steam is used to turn the turbine, generating electrical energy that we can use in our homes.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-881a1bbeb3594781b8db119c53236fa6", "input": "Sentence 1: Although it is the easiest to observe, color is not ideal as a sole way to identify minerals. Sentence 2: Although color is the most obvious property of a mineral, it is the least reliable diagnostic physical property.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-a19be7345ed2485391b46e1a73d7b44f", "input": "Sentence 1: Smaller surface area does a large log burn relatively slowly compared to the same mass of wood in the form of small twigs. Sentence 2: The salt crystals have relatively small surface area, adhere poorly, dissolve rather slowly and are difficult to blend dry.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-aaf0e214926649f5a37c6a311e7939f5", "input": "Sentence 1: Replacement reactions  occur when elements switch places in compounds. Sentence 2: Decomposition Reactions Decomposition reactions are chemical reaction in which a compound breaks down into simpler compounds or into the elements of which it is composed.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-fcf68389a65e4236ab2812e9941553a0", "input": "Sentence 1: Translucent matter transmits light but scatters the light as it passes through. Sentence 2: Lighting Lighting is a matter of preference.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-a0a3b15c79ca4e8da5945a435a2aeb3e", "input": "Sentence 1: A calorimeter is a device used to measure temperature changes during chemical processes called. Sentence 2: A bomb calorimeter measures the enthalpy change directly.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-bba2b5c01f3d4a14823939b539a5f459", "input": "Sentence 1: Autosomes is another term for body chromosomes. Sentence 2: autosomes any chromosome other than a sex chromosome .", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-6bbea97f3694478781716028a928f655", "input": "Sentence 1: Only about one percent of plants have lost photosynthesis ability, turning them into consumers and even predators, instead of producers. Sentence 2: When less daylight is available the ability of plants to produce chlorphyll to support photosynthesis is reduced.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-d65d99566ad3482e8b08666541426e23", "input": "Sentence 1: Solid takes neither the shape nor the volume of its container. Sentence 2: In the solid state, matter occupies fixed volume and has fixed shape.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-24a658b792b94b77ad76e5184399a59b", "input": "Sentence 1: A synthetic diamond is not considered a mineral because minerals must be created naturally. Sentence 2: Synthetic Mineral Fibres -", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-57d6562bce8e46e68b83d9f62376c548", "input": "Sentence 1: Not surprisingly, controlling flight is the function of the most developed part of a bird's brain. Sentence 2: A specific part of the brain controls a specific function for a specific part of the body.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-f535700a2e6249f0a960c0f54f17dffc", "input": "Sentence 1: Nuclear enevelope is a double membrane of the nucleus that encloses the genetic material. Sentence 2: The nucleus id surrounded by a double membrane , called the nuclear envelope .", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-25b1d6c279f84aee95f5cea50a28cb27", "input": "Sentence 1: Carbon atoms are bonded to as many hydrogen atoms as possible in saturated fatty acids. Sentence 2: In saturated fatty acids , carbon atoms are bonded to as many hydrogen atoms as possible.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-2497cb652f6c49239effb71b22d75771", "input": "Sentence 1: This heat is used to convert water into steam, which is then used to turn a turbine, thus generating electrical power. Sentence 2: The steam is used to turn a turbine, which is connected to, and turns an electrical generator that produces electrical power.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-4cfb340c50824dc5a6c2e56bb241b976", "input": "Sentence 1: Phosphate groups are found within phospholipids and nucleotides. Sentence 2: Nucleotides are composed of a phosphate group, a sugar (ribose in RNA, and deoxyribose in DNA) and a base which marks the  specific difference among nucleotides.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-fdd8f26b48f34349af70c4c6b6785f40", "input": "Sentence 1: You call elements that contain only atoms of one type of element native elements. Sentence 2: Element A substance comprised of only one kind of atom.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-2253db59854445df9fda62ce619d652e", "input": "Sentence 1: Exposure to ultraviolet radiation can increase the amount of pigment in the skin and make it appear darker. Sentence 2: However, exposure to ultraviolet radiation can  increase the amount of pigment in the skin and make it appear darker.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-0739088635664ffca13a58fd1a6df4bf", "input": "Sentence 1: Heart valves prevent the backflow of blood from happening in the heart. Sentence 2: Your heart valves (bicuspid and tricuspid) are essentially check valves that prevent backflow to the atria from the ventricles, forcing the fluid (that's blood) to circulate.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-82ea870aa7494ff19e4caa66c11122ef", "input": "Sentence 1: Aphotic zone zone is located below 200 meters from the surface. Sentence 2: In the episode, SpongeBob becomes stranded in an aphotic zone called Rock Bottom.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-194c97be879343788a56d421652c24d0", "input": "Sentence 1: The amniotic sac, which was sitting on top of the flat embryo, envelops the embryo as it folds. Sentence 2: This is also called an embryo sac.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-5e72012c25df45a685f98c4d774706b3", "input": "Sentence 1: Carbohydrates are an important group of biological molecules that includes sugars and starches. Sentence 2: Carbohydrates include both starches and sugars.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-6638bbbc6d16479a84505c9488cb6e51", "input": "Sentence 1: Animals can not produce their own food making them heterotrophs Sentence 2: Consumers, or heterotrophs, are those organisms that cannot make their own food, and therefore must eat producers or other consumers to gain energy.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-e5bc97841d25472b8b536625693c3941", "input": "Sentence 1: Mercury is the smallest planet in our solar system. Sentence 2: Mercury is one of the densest planets in the Solar System.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-625f40db827d4b009c07b6a655e47cf5", "input": "Sentence 1: The product of a wave's wavelength and its frequency is its speed. Sentence 2: The frequency the observer hears is the speed of propagation of the  wave, divided by its wavelength.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-7b4e8bba451842888c2fc203c7c53081", "input": "Sentence 1: Within a substance, atoms that collide frequently and move independently of one another are most likely in a gas Sentence 2: e.&#9;in solids the atoms are closely locked in position and can only vibrate, in liquids the atoms and molecules are more loosely connected and can collide with and move past one another, while in gases the atoms or molecules are free to move independently, colliding frequently.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-77f6443ce7fc4e6f9416b41c093bb100", "input": "Sentence 1: Local winds type of winds blow over a limited area. Sentence 2: A Wind Is Blowing", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-accebbeb01874fbebca1ccf00e4fc3b4", "input": "Sentence 1: The temperature at which all molecular motion has ceased is called absolute zero. Sentence 2: Only at the temperature of absolute zero (-273 degrees C) does molecular activity cease and IR radiation no longer emit.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-0f6d0d5f07ba418fad7c34d0d6cf5840", "input": "Sentence 1: The correct order of food traveling through the digestive system after it is swallowed is: esophagus, stomach, small intestine, large intestine. Sentence 2: Glossary Additional Reading Digestion of food begins in the mouth and moves through the esophagus, stomach, and the small and large intestine.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-7813eb58fc6b4b10ae5b550e1070e737", "input": "Sentence 1: Three many families are known quarks divided into. Sentence 2: Many genealogists keep their research log in a three-ring binder with dividers for each member of the family that they are researching.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-80319c48e61f46aebdb14f8fe9899569", "input": "Sentence 1: There are one electrons in the hydrogen atom. Sentence 2: Hydrogen is the simplest atom, with one proton, one electron and no pesky neutrons.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-76bd730c652746e98f27bb2d396c700d", "input": "Sentence 1: The climate of a small area is called a(n) microclimate. Sentence 2: Microclimates are small areas that have the same climate and weather patterns.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-9c3b69b914b54b44a6140074d8c3f25b", "input": "Sentence 1: Cytokinesis is the name for the division of the cytoplasm in eukaryotic cells, resulting in two genetically identical daughter cells. Sentence 2: cytokinesis (SlGH-toh-kin-EE-sis) The division of the cytoplasm to form two separate daughter cells immediately after mitosis.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-4c6eaf6f5fa84f219df82ce2e0a2e155", "input": "Sentence 1: The largest body in our solar system is the sun. Sentence 2: Solar system: sun and planets.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-907ad2817d5748e9802d73fbdc7f401d", "input": "Sentence 1: When temperature increases but amount of gas and its pressure are constantvolume increases happens to the volume of the gas . Sentence 2: If the temperature of a gas is increased, the volume increases.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-395ab5b4e9a1455da8e1d6083002e87c", "input": "Sentence 1: A normal human liver cell has 23 pairs of chromosomes. Sentence 2: The nucleus of every normal human body cell contains 46 chromosomes arranged in 23 pairs.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-66d23fc2e8784a7e849e8db7374d6dee", "input": "Sentence 1: Evolution that occurs over a short period of time is known as microevolution. Sentence 2: Unfortunately, &quot;evolution&quot; is used at various times to mean microevolution, macroevolution, evolutionary theory, neo-Darwinism and evolutionism, all of which I define below.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-b2fd257c5d694d68a924131f56bcd909", "input": "Sentence 1: A human cannot survive the loss of the liver of the following. Sentence 2: With the aid of the transgenic livers, developed by Baxter s Nextran unit, it is hoped that more patients will be able to survive until a human donor liver becomes available for transplantation.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-3c4a0803646b457f95ef659f918f8c4d", "input": "Sentence 1: The concentration of hydrogen ions in a solution is called acidity. Sentence 2: pH A logarithmic measure of the acidity or alkalinity of a solution using the hydrogen ion concentration.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-1480a543cf24410bb981b8a2e83fac2c", "input": "Sentence 1: Does water get colder or warmer the deeper you go? Sentence 2: Something wrong in the cold deep waters.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-b6da9fb419734800986d2c8a6fd11ee9", "input": "Sentence 1: The theory of biological evolution do transitional fossils best support. Sentence 2: Evolution Happens A concise presentation of the evidence supporting the theory of the biological evolution.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-cccc7f652fcf480daf1af3ae1b3ac1ee", "input": "Sentence 1: A binary molecular compound is made up of two  elements. Sentence 2: Assigning oxidation numbers To make use of the last definition of oxidation and reduction requires the ability to assign oxidation numbers to atoms or ions of the elements, whether they are found in unreacted elements, in ionic compounds, or in molecular compounds.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-f593363a2d1b40d49ca2da28a66af401", "input": "Sentence 1: What's it called favoring the reaction is sped up until equilibrium is established. Sentence 2: Although this reaction is reversible, the equilibrium favors the product (27,000 to 1) so the trichloroacetaldehyde will be essentially removed from the medium.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-ac36b9e47b1f4652aa87bc5efcd42ad6", "input": "Sentence 1: The pupil is the opening in the front of the eye. Sentence 2: Their eye pupil is round and there is no pit or opening near the nostril.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-d004b4c91a784306ad7385e7b868e471", "input": "Sentence 1: In the nuclear fusion process, two light nuclei combine to produce a heavier nucleus and great energy. Sentence 2: nuclear fusion A nuclear process that releases energy when lightweight nuclei combine to form heavy-weight nuclei.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-58d545a0ed9a4a62ab26e76d58da54a1", "input": "Sentence 1: Neutrons are electrically neutral. Sentence 2: The protons are electrically charged, and the neutrons are electrically neutral.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-52f97f18310c41d380ba2b6253768788", "input": "Sentence 1: In plants, a high concentration of iaa inhibits cell elongation. Sentence 2: It inhibits the growth of breast cancer cells, and it can completely block the growth os the cancer cells if it were used at high concentration.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-255c543a256f4207a9c97d3ff193fcd5", "input": "Sentence 1: Seed dormancy ensures that seeds germinate only when conditions for seedling survival are optimal. Sentence 2: But few seeds germinate, and literally none survive to the seedling or sapling stage.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-e27ba6f94a1d49c5a3cc1e529e443d57", "input": "Sentence 1: Range is the term for the horizontal displacement of a projectile from its starting point. Sentence 2: These range from prehistoric projectile points to jewelry made from shells and bone.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-13840a711212421fa613286a7286f82c", "input": "Sentence 1: Property to time kind of variation does a rate measure. Sentence 2: variations among different measurements over time and various measuring devices.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-795f7ad210ca4bf2a83c650132a267dd", "input": "Sentence 1: A blue block appears blue in the sunlight if only blue light is reflected by the block. Sentence 2: You'll notice a number of words blocked in light blue.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-d1e46fa22cf84cffbbed7e1499ac5223", "input": "Sentence 1: Volvox sphere has a distinct front and back end. Sentence 2: These two spheres are distinct, though they are one.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-b823ed0d96b74a38ab013c5d75d81a0b", "input": "Sentence 1: A ribosome consists of two elements, rrna and proteins. Sentence 2: The ribosome (composed of both rRNA and protein) has two subunits and the transcribed mRNA fits between the two subunits.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-9ca80dd688fe4c23a2440beeb1b39dbc", "input": "Sentence 1: Co2 gas is released into the atmosphere when fossil fuels are burned. Sentence 2: Like fossil fuel, algae fuel releases CO2 when burnt, but unlike fossil fuel, algae fuel and other biofuels only release CO2 recently removed from the atmosphere via photosynthesis as the algae or plant grew.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-6526d81d061c41fcb95470cfea380b97", "input": "Sentence 1: In weather terms, the boundary between two air masses is called front. Sentence 2: A front is the boundary between two different air masses.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-fbb09fcae758486cbd2efaa3c3830521", "input": "Sentence 1: The sequence egg -> larva -> pupa -> adult shows the life cycle of some insects. Sentence 2: These insects have 4 life stages, the egg, larva, pupa and adult.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-e99a16cd2d1b40b99648644e42f16648", "input": "Sentence 1: Clouds form(s) when water vapor condenses in the air around specs of matter. Sentence 2: As the water-vapor-laden air expands, it cools and the vapor condenses on minute particles, forming the cloud we see.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-5d62c2a79a674f4fb875af2c61961277", "input": "Sentence 1: Metal is regularly used in human hip and knee implants. Sentence 2: Inform all concerned if you have an implant containing any metal parts such as pacemakers, hip or knee implants etc.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-f2cea3b6748f4ba4a10b15b3964086b3", "input": "Sentence 1: In invertebrates kind of animals does parthenogenesis occur. Sentence 2: Invertebrates are animals without backbones.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-2ed050fe000d40cd8f0b60e15f66838f", "input": "Sentence 1: A complex machine is described by: it is made of more than one simple machine. Sentence 2: A turing machine is a simple theoritical machine that should be able to solve any problem that a more complex machine can, and hence, is used in proofs on complexity theory.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-7d18f6111dc74fa3b4a4d82976fe5f76", "input": "Sentence 1: Compound machines type of machines generally have lower efficiency but greater mechanical advantage. Sentence 2: Machines are used by all types of engineers, but are generally designed by mechanical engineers.", "output": ["neutral"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-9103a4be227b47c69ff395b2ded2e184", "input": "Sentence 1: The stratosphere is the layer above the troposphere. Sentence 2: The stratosphere is the dry layer of the atmosphere above the troposphere, where temperatures increase with height.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task1554_scitail_classification_gpt3_0", "Definition": ["In this task, you are given two statements. The task is to output whether a given textual premise, i.e. Statement 2, entails or implies a given scientific fact, i.e. Statement 1. The output should be 'entails' if Statement 2 supports Statement 1 and should be 'neutral' otherwise. When the model should output entails:  This should happen when the premise entails the hypothesis. In other words, when the premise provides evidence that supports the hypothesis. For example, if the premise is \"All dogs are animals\" and the hypothesis is \"Dogs are mammals,\" then the model should output \"entails\" because the premise supports the hypothesis.  When the model should output neutral:  This should happen when the premise and hypothesis are completely unrelated. For example, if the premise is \"I like to eat apples\" and the hypothesis is \"The sun is a star,\" then the model should output \"neutral"], "Instance": {"id": "task1554-78bfd3cec00147af949859630606b49c", "input": "Sentence 1: There are four chambers in the heart. Sentence 2: The normal heart has four chambers.", "output": ["entails"]}, "Prediction": "entails"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-e7930660bf8d493fa0a3331e1e4a3acf", "input": "Hypothesis: It's good to be honest with your partner.\nUpdate: You want to get married.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-08781fa3604544f3890aa738566bed0a", "input": "Hypothesis: It's rude to play music so loudly that it disturbs others.\nUpdate: It's 2 am.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-c3935e0c8d6c46b48ac7dae6e1c1659e", "input": "Hypothesis: Refusing to help people is mean.\nUpdate: Those people have always treated you badly.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-ad8a5ce65fbd48ac8895870de2dc95d7", "input": "Hypothesis: It is wrong to exclude family.\nUpdate: you're really close with your family", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-00fb79370ab547cd8b6007d1f029928b", "input": "Hypothesis: It's okay to exercise control over how many people are around you and who they are.\nUpdate: You are in a crowded elevator.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-f6e77c6f5dff4db68cf3a2cb08efe486", "input": "Hypothesis: It is rude to tell on others.\nUpdate: they are stealing somebody else's property.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-5269e4dcede24322bcad085b6701dc4a", "input": "Hypothesis: You shouldn't spite your partner.\nUpdate: You're getting ready to break up with them.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-8f0348b9f0ad4d7fb589eb5dbbc44d3d", "input": "Hypothesis: It's good to take care of your responsibilities even when other try to get you to do otherwise.\nUpdate: you want to be seen as dependable.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-1fe087171d984039bd7f28482e6b0d8c", "input": "Hypothesis: Children should accept their parent's decision about a situation.\nUpdate: Their parents hurt them.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-b8428cf54f2743a69becf23ed2f3877e", "input": "Hypothesis: It's rude to make lewd comments.\nUpdate: You're pestering a stranger.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-8e4ee09677b241c7ac159d20b33a038c", "input": "Hypothesis: It's fine to ask for something that will help you out in your education goals.\nUpdate: You have good reason to borrow extra money.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-94186eb717354c85826922212a5d6704", "input": "Hypothesis: It is okay to censor who is a guest in your home.\nUpdate: your partner disagrees with you", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-9aa86bd08eda49278f7a6474c38b747e", "input": "Hypothesis: Singling people of a certain persuasion out can make you look bigoted.\nUpdate: You did it unintentionally.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-52ea42bcda544693859fd1913b4f5af7", "input": "Hypothesis: Second hand smoke should be avoided.\nUpdate: You have a lung condition.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-41e35ab1d270400281061bf655e0f102", "input": "Hypothesis: It's expected that you share with your spouse.\nUpdate: you have the popcorn at the movie", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-b2c6f4e5306b42e2909dc328c67f5ca8", "input": "Hypothesis: It is wrong to sign someone up for something without their permission.\nUpdate: They will receive a full scholarship to their favorite university.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-3e121f140f174d3fbc45ee3642c1a51e", "input": "Hypothesis: It is understandable to want to protect a friend.\nUpdate: You have known them your whole life.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-d559f1f2157d4b3f963f62926f07b507", "input": "Hypothesis: It's wrong to create a false positive attitude.\nUpdate: You're at a job you don't like and must be courteous to difficult customers anyway.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-6d5d60a2df3247bcb9acf8728c610b99", "input": "Hypothesis: It is important to be able to admit you've made mistakes.\nUpdate: You want to maintain healthy relationships with people.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-53a81102ec5442e3bcf3b38294527d35", "input": "Hypothesis: You should be refunded for what is owed to you.\nUpdate: the time period for the refund has expired", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-d28f33528e8c4ed88199477c53724475", "input": "Hypothesis: It can be painful when someone doesn't want you to come to their party.\nUpdate: You can't stand them.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-7f6f8b481077476480b6fb4ab1f93f04", "input": "Hypothesis: You should not lash out at staff at the doctor's office.\nUpdate: A lot of patients are checked-in ahead of youy.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-6a8a0aa8796d4a968b7027d10d37b7f8", "input": "Hypothesis: It's expected to comment with your opinion on a friend's news.\nUpdate: You are chatting on social media.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-8db54eefaac141bab3f499f9ccf6de0e", "input": "Hypothesis: You shouldn't associate people with their friends.\nUpdate: Their friends are known criminals and you have things constantly coming up missing.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-6379ea59d97443d2a11f0cb1b8b622ab", "input": "Hypothesis: It's good to look out for the welfare of animals.\nUpdate: You are neglecting humans.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-325585f4f38b40b7a85a1816815657ce", "input": "Hypothesis: You should not treat someone differently for have a disability.\nUpdate: You are giving them an accomodation", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-989099b139934907b1943d48e7dac34d", "input": "Hypothesis: It's good to help out a significant other when they need it.\nUpdate: They're divorcing you", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-162cf3c9ff6341fe98be46f85dc68286", "input": "Hypothesis: It's good to get up early.\nUpdate: You have the flu.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-3414d4b2b4c242fa9e4ceaf567b4265e", "input": "Hypothesis: It's good to talk to members of the opposite sex.\nUpdate: You're saying inappropriate things.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-8f5a3b6f1f8b48d69aef8cd0b03651b7", "input": "Hypothesis: When someone hurts a person and makes them cry, it's bad for everyone involved.\nUpdate: The other people don\u2019t care at all", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-fbd612e15e844698a63d3d5dfe13f535", "input": "Hypothesis: If you're not interested in someone, you should let them know.\nUpdate: You do not want to lead them on.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-bf5e60b3d4394323b3cd43d0d87ff982", "input": "Hypothesis: Family is expected to be involved in each other's lives.\nUpdate: They have been abusive in the past.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-a45e34b2c7ce4647a3496039fef24eef", "input": "Hypothesis: It's okay that you want to keep your spot in a line.\nUpdate: you are walking away.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-ec939c854c0542b29ce78944c92fdb5e", "input": "Hypothesis: It is normal to address the dean first.\nUpdate: You are expecting bad news.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-a11c469f3d32414c993dbb81e6b9c77b", "input": "Hypothesis: It's ok to take trips without your significant other.\nUpdate: You are both on vacation.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-542ba478d99c4a1d99a8f584b8d33bac", "input": "Hypothesis: You shouldn't expect someone to share their money with you.\nUpdate: You are business partners", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-63e821960be84374838ef106d58a5268", "input": "Hypothesis: It is rude to disrespect your mother\nUpdate: she is supportive and loving", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-73a3f304c7ed499cac9b1fe292e28840", "input": "Hypothesis: It's good to stand up for yourself and confront someone if they do something that upsets you, even if its in public.\nUpdate: The person is being violent.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-2d45c1befd674763850879ef096d8fd8", "input": "Hypothesis: It's wrong to put animals before other people.\nUpdate: They're dying.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-69e6f28547774a4b851adb1f5a03a432", "input": "Hypothesis: You're allowed to decide to visit places without consulting your friends.\nUpdate: You want to see different places", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-7faf191f681b4439bafa46e557cc6e76", "input": "Hypothesis: It's expected that significant others kiss each other.\nUpdate: They love each other", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-7776244dce464f3193c970365e49af5c", "input": "Hypothesis: It is okay to conserve electricity.\nUpdate: You are trying to save money", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-a57281f5350b4bbd90caaf1a3257f5d2", "input": "Hypothesis: It's wrong to be mean to your struggling friend.\nUpdate: Your friend needs a shoulder to cry on", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-76e01f1218e24d68bc3d08f2b312baa6", "input": "Hypothesis: It's your choice about who to be friends with.\nUpdate: There is someone who doesnt treat you well", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-bad7cd9c59b6461587b7c5331c929ca5", "input": "Hypothesis: It is bad to chase after a person your friend is interested in.\nUpdate: That person declined your friend's advances.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-53a4894dae414e1e88febb50f48dcec1", "input": "Hypothesis: It's rude to laugh too loudly.\nUpdate: You are at a very loud party.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-58ed6c3d44234bc0923771a5fb00d391", "input": "Hypothesis: Criticism can be hurtful.\nUpdate: It is delivered with condescension.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-d05d7df7319b4564a54c4ea52b077142", "input": "Hypothesis: You should tip for service.\nUpdate: tipping makes up a large part of a service providers income.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-ae5d524dfba747d38593fd1b915464e3", "input": "Hypothesis: Informal language and slang is appropriate to use in personal conversation with friends and family.\nUpdate: everyone already talks like that.", "output": ["strengthener"]}, "Prediction": "strengthener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-7ae407462e164640b86e8a6f925baf8e", "input": "Hypothesis: It's not okay to do something that could hurt or make someone else jealous.\nUpdate: you are attacked first.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-5e4db6b9f9a94fdebd1be400b642b96f", "input": "Hypothesis: You should stay broken up if you broke up with someone.\nUpdate: They drove your car into a ditch with your baby in the car.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-287377f0940346ac9e8a727135f4520a", "input": "Hypothesis: It is good to teach your kids not to go onto other peoples property.\nUpdate: They ask permission.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-19d41aca4cbb4fa6a5abb98cefca136a", "input": "Hypothesis: It's okay to rebuke your friend for not standing up for you.\nUpdate: They were preoccupied and were not near you to stand up for you.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-df96089b65264ff588a7d0bfb1f109e4", "input": "Hypothesis: It is okay to have limits to how much you will help family.\nUpdate: You live paycheck to paycheck.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-e2770494dca14bc38e269f5250e86fc6", "input": "Hypothesis: It is rude to be self absorbed.\nUpdate: You have people depending on you", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-6ad0464eacb74578a85616b018f77370", "input": "Hypothesis: It's wrong to boss people around.\nUpdate: You are the boss", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-218cc3de9d7842589192db0e5a488f0a", "input": "Hypothesis: You should try to accommodate family members.\nUpdate: You're the head of the family.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-dec138936c754118b3c9f34085d3c68f", "input": "Hypothesis: Grandparents that likely send cards with money in them should be cherished and not shunned\nUpdate: The grandparents are racist and attempt to influence the children.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-a01f8c997909459c8990088686d4410d", "input": "Hypothesis: It is okay to get upset at your significant other if they are overly flirtatious with others\nUpdate: You have a non-monogamous relationship.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-c11c527689934050b3e14491c36bfa0d", "input": "Hypothesis: Friends shouldn't expect you to love looking at pictures of their kids as much as they do\nUpdate: you don't like kids.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-54789cc5f261467388c6cca9c61311f0", "input": "Hypothesis: You should be patient to your friends who are being abused.\nUpdate: Their abuser was a relative of yours.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-877f1823c28445089cb28512031cf72c", "input": "Hypothesis: It is childish to refuse to see an ex if it is a civil situation.\nUpdate: They don\u2019t let you see your kid", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-ed511d1643b841e8962326272cd82057", "input": "Hypothesis: It is okay to think your friend might be self-entitled.\nUpdate: Your friend donated all their money to charity", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-f309817636354580adb965d6fe05d59a", "input": "Hypothesis: You should support your partner when they are grieving.\nUpdate: Your partner has asked for time to be by themselves.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-e9b78ac4e8b94bfd8231c96db16afeaa", "input": "Hypothesis: It's okay to be attracted to some people and not others.\nUpdate: You are looking for a romantic partner.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-d62d0a13fcce453aac5fba766d92b34e", "input": "Hypothesis: It's wrong to abandon a friend that needs help.\nUpdate: they need you to help them get to the hospital.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-e28dc1a07ac442998c3b73a5884dfcba", "input": "Hypothesis: It's wrong not to accept your parent's partner.\nUpdate: That person is quite nice to you.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-b9302e272163487aa814f7877ef94a2c", "input": "Hypothesis: One should always clean up behind themselves.\nUpdate: they are in a shared space.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-08a8c0ac940341a1bcf68ee04393c266", "input": "Hypothesis: It's expected that you support your children financially.\nUpdate: They have special health needs that require them to have care even when they're grown.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-64dd091f0b1748e39c09f8bf6d705d85", "input": "Hypothesis: You should buy gifts for your friends.\nUpdate: You have recently lost your job.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-c88739a577154e8bbef79098b5f52cc6", "input": "Hypothesis: Not communicating with a friend that has anxiety can let them be more separated and potentially cause harm.\nUpdate: you are one of their only friends and they depend on your support.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-de410a80536d4467be7a6af903896e73", "input": "Hypothesis: You should respect your boyfriend's friends.\nUpdate: they are rude to you.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-8e3d7279bd7f4687bfa3219e99832b38", "input": "Hypothesis: It's okay to be put in a situation you don't fully understand.\nUpdate: The details are promised to you later.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-3c0232b2d78a4a869d85989f8326452a", "input": "Hypothesis: It is okay to be mad at another person.\nUpdate: you are the person at fault.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-44f099801e2b4c9492ebfea733ace8f6", "input": "Hypothesis: You shouldn't get drunk on a date.\nUpdate: it's a first date", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-4da4d86c2fa241d39decf5876119d8e7", "input": "Hypothesis: It's understandable to be concerned about your significant other's drinking habits.\nUpdate: your drinking is even more rampant than their's.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-5f8d0cf73e6d4e87926cb79042d60643", "input": "Hypothesis: You should be respectful of your boss.\nUpdate: Your boss has sexually harassed you.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-5eafb4dda4d549c9bab4d4e2ce76a021", "input": "Hypothesis: It is bad to keep items that are no longer useful.\nUpdate: they have sentimental value.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-8b8e527711ab4960a92fdd23188ea6f6", "input": "Hypothesis: It is wrong to make someone afraid.\nUpdate: That person has a heart condition where they can't get excited.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-6ba00c56b25b4405b779476307acc848", "input": "Hypothesis: You shouldn't lie to others.\nUpdate: You have been sworn to secrecy and it's not your secret to share.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-fd7d24dda5f94bec9ff910eb9cf12093", "input": "Hypothesis: You should try to work out problems with others with getting angry.\nUpdate: you want to keep a good relationship with them", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-13df35ace4b443029a9c5dd3632fa186", "input": "Hypothesis: You shouldn't leave people out of your plans.\nUpdate: they don't leave you out of their plans.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-b948dd1d4d824a32bd49edfe7d13ba91", "input": "Hypothesis: You are expected to tell your girlfriend about your plans for vacations.\nUpdate: They are business trips required for work.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-ed9b2ba926ea4f9d9700b06c5cb3604c", "input": "Hypothesis: It is rude to take someone else's thing.\nUpdate: they have given permission.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-d90e40d393404488b908d890c7c5dcdf", "input": "Hypothesis: It's ok to complain about bad service.\nUpdate: you know that the waiter is new.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-39537868237048bd98f4d6f023c16c07", "input": "Hypothesis: It is ok to be upset if your friends stop including you in their outings.\nUpdate: You are always checking up on them", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-87149f918ea7468e9c8b970d6154bb26", "input": "Hypothesis: It's good to address strangers politely.\nUpdate: One of them spits in your face", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-6cad0a61b3264b8ab81f4c72ad774d8f", "input": "Hypothesis: Partners should support one another.\nUpdate: One of them is trying something new.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-22f97c1080df42d5aa829c128b76ad1d", "input": "Hypothesis: It's good to report someone that is doing something wrong.\nUpdate: They insist they're doing it right.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-a370c047c7eb4366a5e0db173d7d288c", "input": "Hypothesis: You should always do what you can to help alleviate the conflicts of your friends.\nUpdate: You're a very diplomatic person.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-fa632437443246c6a1980dddb50345b2", "input": "Hypothesis: It's rude to cancel plans you have made with someone else.\nUpdate: you give very little warning.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-ad52df42de12418294a8d0733865b2b7", "input": "Hypothesis: You shouldn't discriminate against people of different religions.\nUpdate: The religion is harmful and they are trying to draw you in for your money.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-cd55d98514b64b83b859c84055a14907", "input": "Hypothesis: It's wrong to let the little things come between you and someone you care about.\nUpdate: You have told them for many decades not to do those things.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-1401a2bc08244238aa30fe86aa5accae", "input": "Hypothesis: It would be expected to be upset if your girlfriend went on a date with someone else.\nUpdate: They don't tell you about it in advance.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-b6df78d5bcd0406e971d4c1bd69bd077", "input": "Hypothesis: It's OK to control your personal property.\nUpdate: You just recently retired and worked hard for many years.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-9d0b6f791f3a4d7d84bbb793e5fa2dff", "input": "Hypothesis: It is wrong to bring up family troubles to people outside the family without consent.\nUpdate: You don't know the person you are talking to about your problems.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-a3b4e3f1cebb45c092256a7ae9e47c67", "input": "Hypothesis: Threatening to remove someone's belongings is wrong.\nUpdate: You want to steal them.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-c73e570a0cb940c2bc2853cff53be9d9", "input": "Hypothesis: It is reasonable to be angry what friend if they ignore you.\nUpdate: they are on vacation.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-f61c1a9699824004947c8ebefc38c4bb", "input": "Hypothesis: You shouldn't question your significant other.\nUpdate: You trust your significant other.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task937_defeasible_nli_social_classification_gpt3_0", "Definition": ["In this task, you are given a hypothesis and an update. The hypothesis sentence is a statement that speaks of a socially normative behavior. In other words, it is a generalizing statement about how we expect people to behave in society. The update provides additional contexts about the situation that might UNDERMINE or SUPPORT the generalization. An undermining context provides a situation that weakens the hypothesis. A supporting context provides a situation that strengthens the generalization. Your task is to output 'strengthener' or 'weakener' if the update supports or undermines the hypothesis, respectively. If the update is something that would make it more likely for the hypothesis to be true, then the output should be strengthener. For example, if the hypothesis is \"You should help your family with funeral expenses\" and the update is \"They have asked you to chip in,\" then this would be a strengthener since it would make it more likely that you would help your family in this situation.  If the update is something that would make it less likely for the hypothesis to be true, then the output should be weakener. For example, if the hypothesis is \"It's good"], "Instance": {"id": "task937-c1141b9e6088442b8e76edb131959586", "input": "Hypothesis: When giving away a friends belongings, it is best to ask them for permission first.\nUpdate: They already said they're holding a garage sale.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-dc694e2abe904d59a948afc48ea43e6b", "input": "People gathered around a table with food and wine on it. <sep> A man is riding a bicycle down the large hill.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-7738cc0de37848c49dc7cd9f27e1d1b6", "input": "A person just about to stand up while water-skiing, while people in the background watch and take photos. <sep> A person is driving an airplane over the mountains.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-8639e3d12c334d169bcd79aa7af095e7", "input": "Women playing volleyball in the sand near the ocean. <sep> Women playing a sport", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-2cdd0d0a4ad945a29486bd164b1a63a6", "input": "A man jumping a dirt ramp on a bmx bike. <sep> A man crashes his bike.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-ff1604f2e16043488539f822950f3889", "input": "The woman in the white coat is holding a camera in her hand. <sep> The woman is trying to get a picture of her friend.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-b05443ed2434472d86f6e61317ded865", "input": "A man with a duffel bag and girl pushing a cart walk down a street. <sep> A man with a duffel bag walks along side a girl pushing a cart down a busy street.", "output": ["N"]}, "Prediction": "E."}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-03bbb569b67845ba912da955da369e8f", "input": "The young Asian woman is using an umbrella, and is in front of a brightly colored patch of flowers in the back. <sep> A woman is using an umbrella.", "output": ["E"]}, "Prediction": "E."}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-2b3220def9a846599aaabfb0d456d0d2", "input": "Men work on a city street. <sep> The men are sleeping", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-b8e94fe659d54c98ada2c6d764b3b308", "input": "A crowd of people standing in front of statues. <sep> The statue is actually a gargoyle and it came to life.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-bf745036fe4c430f85a3353cd379bd22", "input": "A golfer is getting ready to putt on the green, with a crowd of people watching in the background. <sep> A golfer readies to putt the ball.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-e66f71e1778e4339abde20827ff08717", "input": "Two men, one in a blue shirt and one in a green shirt analyze a piece of paper in the middle of a workshop area. <sep> The coworkers are discussing a work related paper in their shop.", "output": ["N"]}, "Prediction": "E."}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-c59309d379a9469a9622cd7e17976297", "input": "Two small boys dressed in tuxedos sitting on a red carpeted floor. <sep> Two groomsmen sit on a carpet dressed in tuxedos.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-63735aebd92d4131a59cd804a3fdfd7d", "input": "A boy is running in a spinning metal tunnel in the playground. <sep> He is outside.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-385ac3b418cd479ea6818ef997107f7c", "input": "A man in bright shirt carrying a fallen branch. <sep> The man is cleaning up his yard after the bad thunderstorm the evening before.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-d78ad7e3d20948ec84651c6489dcbf30", "input": "Women in blue dress singing on stage. <sep> A woman is singing on stage.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-cabe19c2410247c3b0bb6fcaff99ada9", "input": "Some youngsters are playing a card game <sep> people play poker", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-260eeecb77fa4069b397b82dd9a55611", "input": "It looks like the clown has fallen off the horse. <sep> The cowboy rode the bull to the buzzer.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-ab80314a490c4b078a6d29fd759312bd", "input": "A man sitting on steps with a child as a bystander walks by. <sep> A man and a child sitting on steps saw a bystander.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-a7b8f5133ec342628f1dab06f99c9aff", "input": "A man wearing a red vest is walking past a black and green fence. <sep> The man wearing the vest is sitting on the sofa.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-968448a994ec45939dd76ac89546e429", "input": "A woman wearing white and black carries a serving tray. <sep> A woman is carrying a serving tray filled with tiny sandwiches.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-a5608f7eb25a4e22a6e6445c1c4f70b6", "input": "a black dog chases a boy wearing red and blue. <sep> a dog chases his tail", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-0a4f23cad3c24dbba987522248c74428", "input": "Some people are standing on a city sidewalk at night and waiting to get on a double-decker bus. <sep> People wait to get on a double decker bus at night.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-74144241a5474fa19aa9edbf132d4c42", "input": "Young shirtless man and asian woman jump up from a shallow rock at the shore with boats moored in the background <sep> There is a fishing boat in the harbor.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-b8f941e98ef940a6a3eb3807e3899f40", "input": "Two men are fixing the side of an old brick building. <sep> People painting in a house.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-9900ec268b7c48c59d367fff24299ff9", "input": "A man wearing red ski pants, a black jacket, and a white helmet is skiing down a mountain. <sep> The man is near another person.", "output": ["N"]}, "Prediction": "A"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-bdf479d70bac46cb9c0a9f6e63a88892", "input": "Two women, standing at a fence, are each talking on their cellphones, while two men sitting on the opposite side of the fence are having a conversation. <sep> Two men and two women are outside having conversations.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-08e4d5655d8d473fbd3dd51d4b531500", "input": "A white dog is running through the water at a beach <sep> The white dog is sitting on the sand.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-67a775223bab42a5affc29fc19d97197", "input": "A dog chasing a duck in a pond. <sep> A dog is swimming through a pond in pursuit of a duck.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-46cb2be263ed4396a8b40230f4961247", "input": "A person with brown hair wearing a blue shirt and purple bandanna around their neck is chiseling a design into a round, brick pillar. <sep> The person with a purple bandanna is taking a nap.", "output": ["C"]}, "Prediction": "E."}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-bf5affd78d334f9f812826a997f3b46e", "input": "The man walks among the large trees. <sep> The mas is walking next to dogs.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-163b91797e6b4fa9aedbc6ca39d508f4", "input": "a soccer player wearing a red uniform walks off the field after a game near a parking lot. <sep> A soccer player is walking to his car.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-5be253a87ddf4adcb5381b22c83db4ad", "input": "A crowd of people stand in street in front of a series of white tents. <sep> A crowd of people are standing at a platform waiting for a train.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-c2f1a5a4a24f4ae6b0e3d8f872065c2c", "input": "A boy rides his skateboard at the park. <sep> A sad boy rides his skateboard at the park.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-8eb0dd23ca204f90be82197af798d963", "input": "A man with black clothing is sweeping steps with a broom. <sep> The man is sweeping the steps.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-e38978931f1847f286401c0332f2f224", "input": "A man holding a baby who is petting a pony. <sep> A man with a baby is petting a pony.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-8d23c3f45e0d4cf19d6b2eca63df98d9", "input": "A man in a black business suit stands upright next to a man wearing blue and leaning against a railing. <sep> A man in a black suit is standing next to a man in a blue outfit.", "output": ["E"]}, "Prediction": "E."}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-1e07376aa17d48f18e7cbdaf4020dcb6", "input": "The man is trying to make a pottery that he can market soon. <sep> A man is making pottery.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-b6fa43a90f7a44e581d3d9d981487331", "input": "A woman and a young girl are eating side by side. <sep> A man folding his laundry.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-0c74fbdd94ba4751b3dac0f350baa201", "input": "a man walks on the icy sidewalk. <sep> The man almost slipped earlier.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-96c55e6d92434deb899efa119f5c0584", "input": "An extreme mountain biker in mid-jump from underneath rider showing a blue sky. <sep> An extreme mountain biker in mid-jump from underneath rider showing a red sky.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-5ec53b273d484caca0345f1a9833490d", "input": "Man in puffy yellow jacket on skis on a mountain. <sep> The man in the yellow jacket is having fun.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-1f08be41011b41d489df2df6b9015ed9", "input": "Several people are playing an intense game of paintball while others watch from the sidelines. <sep> People play a game.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-975c08dfa32c4b9bb07ead379cd5db0b", "input": "Three black people, two men and one woman, in the middle of a small, rural street, are piling up items on top of a taxi cab with a net dangling down on top of the windshield, while two children and two other people are nearby. <sep> The people put furniture on the taxi", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-f5a612cafb8c486daf9e1c95996cb8b5", "input": "A women's volleyball team plays in a brown and green gymnasium. <sep> A sports team is in a gym.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-fbce08ead14e4696873691bf2f4035d8", "input": "A man wearing a business suit holds up a drink as the other laughs. <sep> some men drinking at the bar together", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-9bc461e54d6e417fbd4a2e62aaf4b6df", "input": "A man talking into a microphone with a woman standing next to him. <sep> There are people giving a speech at the fair.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-f48958238ccd4a6bb3cd1fdccc9ee8d8", "input": "A person sitting on the corner, wrapped in a blanket in front of a metal door. <sep> The person is cozy.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-4b15fba7c72c46cf9e3e69a20efb1588", "input": "A man with a red helmet and numbers on his arm and leg is riding a red racing bike. <sep> A person wearing numbers is using a nonmotorized vehicle.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-192aed3d269f4dcf906e7469240e10f3", "input": "A man in a brown shirt and a white baseball cap uses a plastic barrel to water tomato plants. <sep> A man watering plants.", "output": ["E"]}, "Prediction": "E."}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-cc918800a2d3461784772be6fa410ee0", "input": "A group of women observing an event while one in military attire takes a photograph <sep> A group of people are watching a shuttle launch.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-e989a04175654cb7806bc45b264b784c", "input": "A boy scout with a red cap is looking through a telescope <sep> The boyscout looks through a telescope at the clear night sky.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-cca37e9c293c4aa1baccfca63e1e0bb4", "input": "A mother shading her baby with an umbrella as she and her partner climb the stairs. <sep> Two fathers maneuver their baby strollers into a foyer.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-7fe7d18a8b4a4ea7baaac658e0d4aba2", "input": "City street crowded with sports fans wearing orange. <sep> The sports fans are wearing a certain color.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-6d2a280482d34cbfb0469f3d077cbe28", "input": "Five children, two boys and three girls, with the girls wearing white scarves, sit on the pavement outside in front of a large window. <sep> There is snow outside.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-dd59accb08d74aa5bc744492f4ae2574", "input": "A drummer wearing a plaid shirt, jeans, and a purple had bangs his drum. <sep> A drummer playing on drums.", "output": ["E"]}, "Prediction": "E."}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-61cba81fa7c544179d9cba50def8721b", "input": "a big black dog jumps in the air to catch the tennis ball in his mouth. <sep> A dog is outdoors.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-509f8af39b79438889e67d0348a73a0a", "input": "A person walks outside carrying a bag, while a young girl in pink walks behind her. <sep> A woman carrying a girl, with a bag behind her", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-e7a9d86433b04396a1c78dbe18bc61ca", "input": "A bundled up toddler is walking over snow. <sep> A toddler is outside.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-ef6199615a60499bbf5a3d5a0af72c5e", "input": "A black man in a blue suit is talking on a cellphone while smoking. <sep> The man is jogging", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-61637da542b34e0788f1521115d972c8", "input": "A young smiling girl is holding a stuffed animal in one hand and a candy apple in the other. <sep> A young smiling girl is holding a cute stuffed animal in one hand", "output": ["E"]}, "Prediction": "E."}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-8f69f5dfbd0d4835b57c8700328d8f12", "input": "A man siting on a bench with a briefcase. <sep> The man is outdoors with his briefcase.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-8fd9836a09754c0ebe835539a9e2f98a", "input": "A man with white hair wearing a gray suit speaks into a microphone with a metal jug sitting in front of him. <sep> A man is riding in a spaceship to the moon.", "output": ["C"]}, "Prediction": "E."}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-304100e4e1e84aa9af5de78bc83f0668", "input": "Two people sitting on the sand. <sep> There are two people at the beach.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-c670b4c4e97d4fb5a9123d016ebc19e8", "input": "A dog with a purple leash is held by a woman wearing white shoes. <sep> A man is holding a leash on someone else dog.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-3081825c718e4a69afdec7a2ef7894f1", "input": "A dog is walking down steps. <sep> An animal is walking.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-3bcc7869735c4990bbdb1393da6bcb2f", "input": "A rocker standing with one foot on the stage holding the microphone attached to the stand over his head. <sep> A rocker is doing soundcheck for his performance by speaking into the microphone.", "output": ["N"]}, "Prediction": "E."}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-1aba41a5b2ed43e2ac0d228555f77062", "input": "The American footballer in yellow catches the ball whilst under pressure from the payer in white. <sep> The basketball player shoots a three pointer.", "output": ["C"]}, "Prediction": "A"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-4e482ce0d9e34937b7066ec42d90fa6d", "input": "A boy in an orange 'Spring Hill' ball team uniform, pitching the ball. <sep> A boy plays pitcher for the first time.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-86e9e98b059342ca8ad3a79de7c35c5a", "input": "A small girl in a green shirt plays on a swing. <sep> old lady sitting on a chair.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-701f3622333440b8aa4ddaa987ab2d0e", "input": "A man in a hard hat looks intimidated. <sep> He is working in a potentially dangerous field that requires a hard hat.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-8d1b8de83f974c35a5ca421601f6679b", "input": "Two older women with a baby that has a pacifier in its mouth, the baby wears an orange and brown dress. <sep> The dress was a gift.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-2f64c06ba3c142828a017148a8a47689", "input": "A girl sits at a table in front of a plate of food. <sep> The girl is near food.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-3f6396b5b0214288bc087ff7d9e58d16", "input": "The little boy stands in the middle of birds who have gathered on the sidewalk. <sep> There is a little boy standing on the sidewalk.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-8c1796e375164884b31585e58b4586db", "input": "Two men spar in martial arts gear. <sep> There are multiple people present.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-4a11e5af393e47478c4cb31cc9d2fde9", "input": "A young blond child wearing a black shirt and white shorts looks at the sky with a bridge and water in the background. <sep> A child looks at the sky outside.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-924aacd8515e48a6ae91a81521ecf577", "input": "A gentleman with his eyes closed playing an old fluglehorn into a microphone. <sep> The man is playing an old favorite tune on the flugelhorn.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-7d556f951a6a4469812c1815ed60a701", "input": "A man in a black shirt, in a commercial kitchen, holding up meat he took out of a bag. <sep> A man in a black shirt, in a commercial kitchen, holding up the old meat he took out of a bag.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-095a3407937447a1aa4de199971f28e9", "input": "A woman holding bags behind plantains. <sep> The woman is holding old trashcans to carry various objecs.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-f96184c1f427421ea4fca7e949f33f50", "input": "A man in a construction vest is looking at a vehicle. <sep> A construction worker is looking at a car.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-ecbb3e6a9642489a98d6a64011c89442", "input": "there's a woman in a pink and gray striped outfit standing with five children, three of which are making faces. <sep> the dog is eating dinner", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-d0337cb7c79e43ec99f364a5bd46a92a", "input": "A man in a red shirt is learning how to climb a cliff. <sep> A man is playing videogames.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-4ef68946e86f4f3c87314e365606af0d", "input": "Six people are jumping up in excitement with costumes on with vibrant pink and orange colors in the sky are four hot air balloons they appear to be in a dry dessert setting <sep> Six people are in a dessert.", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-9d74e9cd15b34d96b7cefd6f798fe99a", "input": "A soccer player in white kicks a ball as another soccer player lunges towards the ball and a third soccer player in red follows close by. <sep> The three players are chasing after the hockey puck.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-4f05eccc05d242438134f373c8948029", "input": "A hockey player in blue and red guarding the goal. <sep> a soccer player guards the goal", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-07b7a7a5f2514b39930ebabbda481200", "input": "The people await to cross the street while walking the dog. <sep> people are with a dog", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-278925f99db14b34a0e9d191e36e31ce", "input": "A man in a colorful shirt and a lady in a white blouse sign copies of books for people. <sep> A man in a colorful shirt and a lady in a white blouse give candy to people.", "output": ["C"]}, "Prediction": "E."}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-661511708ccb43618cc2651a4fe1e56a", "input": "A woman in a teal apron prepares a meal at a restaurant. <sep> A woman in restaurant", "output": ["E"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-fb29e860221b4c819a2837843eab89d4", "input": "A woman teaching a ballet class composed of small children holding colourful scarves. <sep> A woman is teaching a ballet class composed of small children holding green and red scarves.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-11e8aefde4784f2ea459798f3d42d63e", "input": "A man waiting for the bus in a war torn country. <sep> A man is waiting for a bus in Iraq.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-567ab787fece49daa3b8d48bd6b48d42", "input": "Two males and one female playing in a fountain of water. <sep> There are three ladies playing in the fountain.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-3777f8a3888b4365b2505da440d0be54", "input": "A man in a white t-shirt and jeans is holding a mallet and chisel next to his abstract sculpture which stands on several bricks. <sep> A man is wearing a white shirt", "output": ["E"]}, "Prediction": "E."}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-50ab6af58e2041a3ac9228998962ddb9", "input": "A man wearing a striped shirt has a camera slung over his shoulder. <sep> A man wearing a sweater is carrying a golf club.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-c391ff72dfe343a688b4e698d238adb6", "input": "Two men wearing black smile while a seated woman behind them looks tired. <sep> The woman had a long day.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-8cdc7f42172b4eabb930a749913fc04d", "input": "A group of people in a room, most with computers, some raising their hands. <sep> Some people have questions.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-6abb805ae0224736ace96be9d95972f4", "input": "A blond-haired woman squinting and wearing a bright yellow shirt. <sep> A woman is reading outside.", "output": ["N"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-d8b3d4d36a4d4cd4b9553b7a49a8df2d", "input": "Two female martial artists demonstrate a kick for an audience. <sep> Two female artists are demonstrating punches for the audience.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-37a2378da461489589839db4e87f263b", "input": "A woman is lying on her stomach on a white pillow and crying. <sep> A naked man in a bar.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-8cbda9f387824236948e2febf40afd8f", "input": "Many people who appear to be Asian stand in line at a train station waiting patiently for the next train. <sep> the people are running through fire", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-16d7378f479d47ac9c0a95d0d03da5b8", "input": "A older man in a hat is playing a accordion on the street while sitting in a chair. <sep> A man is playing guitar.", "output": ["C"]}, "Prediction": "N"}
{"Task": "task641_esnli_classification_gpt3_0", "Definition": ["Determine whether the two given sentences clearly agree with each other (entailment), disagree with each other (contradiction), or if this cannot be determined (neutral). Answer must be the letters E, C, and N, respectively. (1) If the model outputs C, it means that it has determined that either a teenager is wearing face paint or nobody is wearing face paint. In other words, it has determined that the two sentences do not contradict each other.  (2) If the model outputs E, it means that it has determined that the girl is wearing a pink dress. In other words, it has determined that the two sentences agree with each other.  (3) If the model outputs N, it means that it has determined that we can not determine whether the two sentences contradict each other or agree with each other."], "Instance": {"id": "task641-c8874490cf004a899391de85f2360cbf", "input": "a man wearing a red jacket and camouflage pants is leaning against a giant tree in the snow. <sep> A man leaning on a tree", "output": ["E"]}, "Prediction": "N"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-66ef16d5d3a742f390c39ab741be08a8", "input": "Premise: PersonX plays sports\nHypothesis: As a result, PersonX wants to get a scholarship\nUpdate: PersonX meets with the coach to express their interest.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-ab8f3cd1b5904bdd9682f4b286c55486", "input": "Premise: PersonX wins the day\nHypothesis: As a result, PersonX wants to smile\nUpdate: PersonX injured their fellow competitors.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-c30755bfd36c4311bf5a8f196aa7ac2c", "input": "Premise: PersonX wears PersonY's helmet\nHypothesis: Before, PersonX needed to pick up the helmet from PersonY\nUpdate: PersonX rides without a helmet.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-85670e63f0a14ca2a026f426d29e74f5", "input": "Premise: PersonX hurts PersonY's back\nHypothesis: Because PersonX wanted to try to fix person y's back\nUpdate: PersonX is training in chiropracty", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-bd900e60323a4fda9f28fcd6bffa08e7", "input": "Premise: PersonX starts to shake\nHypothesis: As a result, PersonX wants to calm down\nUpdate: PersonX is on a roller coaster.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-8cbf9efec8844891a0a563009d3a7318", "input": "Premise: PersonX calls PersonY's wife\nHypothesis: PersonX then hears silence\nUpdate: PersonY's wife has an exciting story to tell.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-fe3dcb01525f46c49cefe18ba5bda373", "input": "Premise: PersonX has never seen\nHypothesis: PersonX is seen as curious\nUpdate: PersonX keeps to themself.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-0f6fddf105b348d5997599c60c4fed26", "input": "Premise: PersonX sees a comedy\nHypothesis: As a result, PersonX wants to tell friends about movie\nUpdate: The movie sucked", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-e4f26114d2ee4a85ac9faa80243720d5", "input": "Premise: PersonX watches videos\nHypothesis: PersonX is seen as entertained\nUpdate: They are falling asleep", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-ecc483bd0dfd4af19d8799b6cf55158a", "input": "Premise: PersonX plays chess with PersonY\nHypothesis: Then, they win\nUpdate: PersonX themselves yells \"checkmate\"", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-8940920bedf44b76b50dd1efd820016b", "input": "Premise: PersonX burns the candle at both ends\nHypothesis: Before, PersonX needed to have been working until late at night\nUpdate: The big project is due tomorrow and it is only half way done.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-e072b655330844d3be3587d6f3b2e430", "input": "Premise: PersonX watches some television\nHypothesis: As a result, PersonX wants to catch up on a tv show\nUpdate: They start falling asleep", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-4d0b5ea493af4cc29583e9572288ea62", "input": "Premise: PersonX transports PersonY to an island\nHypothesis: As a result, PersonX feels seafaring\nUpdate: PersonX is feeling nauseated from the boatride.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-efe77777d9bc449891a4782f153fb082", "input": "Premise: PersonX makes PersonY promises\nHypothesis: Before, PersonX needed to know PersonY\nUpdate: PersonX's promises are large and important.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-a58b406485234eb9872f4d4c1901da2a", "input": "Premise: PersonX takes a trip\nHypothesis: PersonX is seen as excited and relaxed\nUpdate: PersonX is taking their first vacation in years.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-b19ac43432534d09ba098e08c67f1824", "input": "Premise: PersonX shoulders the burden\nHypothesis: Because PersonX wanted to help\nUpdate: PersonX is helping an old lady", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-02e5c0886dfe4d199623e52d25a1dfa1", "input": "Premise: PersonX puts it there\nHypothesis: As a result, PersonX wants to move something\nUpdate: PersonX thinks it's in the right place.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-8521d1d997cb49bea941bb432021b795", "input": "Premise: PersonX rides the ferris wheel\nHypothesis: PersonX then gets stuck on top\nUpdate: The ferris wheel is rusty", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-540cab67598b4f2e8eb03d4649e56c7c", "input": "Premise: PersonX obtains PersonY idea\nHypothesis: Before, he went on lunch.\nUpdate: PersonY met PersonX in the cafeteria", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-8df8890cff7a47a69fb3058979583fb1", "input": "Premise: PersonX tells PersonY's children\nHypothesis: As a result, PersonX wants to take the children for icecream\nUpdate: PersonY doesn't allow PersonX around their children.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-f5db55169e9e468292d7f94fa188bfee", "input": "Premise: PersonX takes PersonY's son out\nHypothesis: PersonX is seen as helpful\nUpdate: Person Y is angry", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-1769634ade67439182c3a8701d97e899", "input": "Premise: PersonX gets a ride\nHypothesis: PersonX is seen as thankful\nUpdate: PersonX does not tip the taxi driver", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-756140fec1b34a8895b994bcdf2404d3", "input": "Premise: PersonX changes PersonY's attitude\nHypothesis: Before, PersonX needed approach the person\nUpdate: PersonX wants other people to see things the way they do.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-28dc5137a25b4ef78d23b4a54289f0fe", "input": "Premise: PersonX hurries back\nHypothesis: PersonX is seen as fast\nUpdate: PersonX is on crutches", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-ee6f9e4767bc4ccab934720164a09051", "input": "Premise: PersonX buys new shoes\nHypothesis: As a result, PersonX feels realistic\nUpdate: PersonX applies the shoes to their ingame character", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-24fa985d3fd748ec8ca91e9751fa991e", "input": "Premise: PersonX goes down the tubes\nHypothesis: PersonX is seen as very discouraged\nUpdate: PersonX ended up missing the bus", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-ff87b14115d642688168578965e0e9da", "input": "Premise: PersonX uses PersonY number\nHypothesis: Because PersonX wanted an alternate method of contact\nUpdate: PersonX and PersonY do not know each other.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-50d0ff0535ce42c8a117249bc084c888", "input": "Premise: PersonX has trouble staying awake\nHypothesis: As a result, PersonX wants to try get some sleep\nUpdate: PersonX drinks multiple cups of coffee to wake up.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-73a43b20cb3e44179774439f50f5d5c8", "input": "Premise: PersonX always slept\nHypothesis: As a result, PersonX wants to stretch\nUpdate: PersonX is paralyzed from the waist down", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-fb09a6afdc264419a03e7a3c2fa739d4", "input": "Premise: PersonX takes PersonY word for it\nHypothesis: As a result, PersonX feels optimistic\nUpdate: PersonY said something good", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-4085737306b447109bd521b9c0408e22", "input": "Premise: PersonX meets many new friends\nHypothesis: As a result, PersonX feels outgoing\nUpdate: PersonX invites many people to their birthday celebration.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-14b10472691841cd8f899ce0de7ef3f0", "input": "Premise: PersonX rubs PersonY's cheek\nHypothesis: PersonX is seen as in love and tender\nUpdate: PersonY is their wife", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-b85b5aed97544f038a1935aecec175e0", "input": "Premise: PersonX keeps my eyes open\nHypothesis: Because PersonX wanted to examine my eyes\nUpdate: They are trying to talk to them and they want to sleep", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-0661846e26944b4e9aa314d5b510d9ed", "input": "Premise: PersonX accomplishes PersonX's goals\nHypothesis: As a result, PersonX feels determined\nUpdate: PersonX proved everyone wrong", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-ccdf9d5847ad49999d3300c4db5d5849", "input": "Premise: PersonX sees the mess\nHypothesis: Before, PersonX needed money\nUpdate: PersonX is wearing a maid's uniform.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-e105607f035e4f819b7da26237480d7d", "input": "Premise: PersonX learns how to skate\nHypothesis: Before, PersonX needed to go to the rink\nUpdate: PersonX lives in a hot climate", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-dda97b49b4b74af295ff5adc216137db", "input": "Premise: PersonX thinks PersonY was sick\nHypothesis: PersonX then notices temperature in the room\nUpdate: The room was at 69 degrees Fahrenheit.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-e1461070fb774cbe848bfdc86a32968f", "input": "Premise: PersonX helps the environment\nHypothesis: PersonX is seen as proud\nUpdate: X walks hunched over.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-3bf1aca4e2e74546a742059db3ccbc74", "input": "Premise: PersonX examines PersonY\nHypothesis: Before, PersonX needed tell person Y about his/her intentions\nUpdate: PersonX collates the information and then addresses PersonY with a report", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-8f2b3b56416f42fc880348bd2c1361fc", "input": "Premise: PersonX measures the ingredients\nHypothesis: PersonX is seen as confident\nUpdate: They look nervous", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-ba38510802c84c06a6fbf264e00f3249", "input": "Premise: PersonX grants PersonY title\nHypothesis: PersonX is seen as proud\nUpdate: PersonX humbles himself to PersonY.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-006f7fee17164bcdb99b31ffa564cfc2", "input": "Premise: PersonX floors it\nHypothesis: PersonX is seen as breathless\nUpdate: PersonX is sprinting as fast as she can.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-3d2c8ef6495b476083c3688d307b49e1", "input": "Premise: PersonX searches for hours\nHypothesis: Before, PersonX needed to decide where to look\nUpdate: He wanted to make sure he does a good job on the project", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-8ce04f61c6454acbb3c0b880dc0b529e", "input": "Premise: PersonX puts the cart before the horse\nHypothesis: As a result, PersonX feels confused\nUpdate: PersonX expected the cart to go forward.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-badbc6086ed04ab2a221bb443197ed36", "input": "Premise: PersonX eats PersonY's plants\nHypothesis: Because PersonX wanted to be healthy\nUpdate: PersonX has been told by their doctor that they're obese.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-c5b60c56941640c796c69034b3baf8c9", "input": "Premise: PersonX plays PersonY's game\nHypothesis: Because PersonX wanted to experience the game\nUpdate: PersonX wanted the game but couldn't afford to buy it.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-4fc8a14e7bcc4df2ab74ac194c42aad4", "input": "Premise: PersonX throws food\nHypothesis: As a result, PersonX wants to go home and get cleaned up\nUpdate: PersonX is in a middle school cafeteria.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-748714ff1eea434497af2a645600fb05", "input": "Premise: PersonX yells for help\nHypothesis: Because PersonX wanted to get someones attention to help them.\nUpdate: PersonX looks at the script again and repeats the line.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-b4323d458c864b24963e7765df52c0f7", "input": "Premise: PersonX finally stopped\nHypothesis: Because PersonX wanted a break\nUpdate: PersonX ran out of spray paint.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-ed883485413147d3b1b3bc29a9f2de14", "input": "Premise: PersonX hears PersonY's cry\nHypothesis: As a result, PersonX feels alarmed\nUpdate: PersonX laughs.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-f37e9bf01fb848b1b59f8427d827da98", "input": "Premise: PersonX eats alone\nHypothesis: Before, PersonX needed to have something to eat\nUpdate: PersonX is in a cafeteria", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-240cac48eabe4a21afde7bd4d16e9216", "input": "Premise: PersonX wants nothing\nHypothesis: PersonX then gets reputation as a simple person\nUpdate: PersonX continues this approach perpetually", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-a36744b790b148d58be9a9845167d60a", "input": "Premise: PersonX calls the school\nHypothesis: PersonX is seen as anxious about  it\nUpdate: PersonX is interested in going back to college.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-cf47b776564c4ece82a47e947bf6bb42", "input": "Premise: PersonX camps with PersonY's family\nHypothesis: Before, PersonX needed get out a sleeping bag\nUpdate: They will be sleeping on the ground in tents.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-7cc36203fbf94ac78fee0b5be49d86a1", "input": "Premise: PersonX stabs PersonY in the back\nHypothesis: PersonX is seen as angry\nUpdate: PersonX is out of control.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-bddc951b1c244b019afe313890d03383", "input": "Premise: PersonX decides to cheat\nHypothesis: As a result, PersonX wants to win\nUpdate: The stakes are high", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-a59b723bc7224583aff2cfea977302e5", "input": "Premise: PersonX applies to many jobs\nHypothesis: PersonX is seen as ready\nUpdate: X has gotten his degree.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-70b940f49f4c41e7b310209878feb238", "input": "Premise: PersonX returns to PersonY room\nHypothesis: Because PersonX wanted to share his room\nUpdate: PersonY invites PersonX inside and PersonX accepts.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-39050c794dd74174a8551664de2572ba", "input": "Premise: PersonX expresses PersonX's belief\nHypothesis: Because PersonX wanted to share what he believes in\nUpdate: PersonX had a speech assigned for class.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-3e5f8069d4304ba3ac84a8a61254dbf9", "input": "Premise: PersonX calls the cable company\nHypothesis: Then, they record details of the conversation on a writing pad\nUpdate: She turns on the recorder on her cell phone.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-9dd6f823c30b4058bb48afa7329f1c06", "input": "Premise: PersonX worships the ground PersonY walks on\nHypothesis: As a result, PersonX wants to give PersonY a gift\nUpdate: PersonX is too afraid to let PersonY know their feelings.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-817d3c58c3d444b7a4c12bb773eb377e", "input": "Premise: PersonX causes PersonY trouble\nHypothesis: PersonX is seen as angry\nUpdate: PersonX just received their refund from the IRS.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-2643d173ba5c44978da64b99f1d55a48", "input": "Premise: PersonX learns everything\nHypothesis: Before, PersonX needed attend class hours\nUpdate: PersonX is a genius", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-c2f67660b0aa40f89d2e8ba72917e4fc", "input": "Premise: PersonX stays longer\nHypothesis: Before, PersonX needed extend his vacation\nUpdate: PersonX  has no more vacation days at work.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-352aab5c38954e7a99a61d487cb70c27", "input": "Premise: PersonX goes blue\nHypothesis: Because PersonX wanted to and cannot hide his embarassment and shock\nUpdate: Person X was dumped by their lover.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-e9c537995afe4f82b5566baf56f348d7", "input": "Premise: PersonX plays so well\nHypothesis: As a result, PersonX wants find more people to play with\nUpdate: PersonX enjoys playing team sports.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-ad698312566e4a83a6bbabf7e4b78ba9", "input": "Premise: PersonX is responsible enough\nHypothesis: As a result, PersonX feels disciplined\nUpdate: They can tie their own shoes with help.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-8ce9dfe974524a92bf61fc2e8acbd800", "input": "Premise: PersonX knows PersonY's names\nHypothesis: As a result, PersonX feels omniscient\nUpdate: X can find out her Social Security number.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-358071a60987456da8787b6b02c94453", "input": "Premise: PersonX takes part in the campaign\nHypothesis: PersonX is seen as satisfied\nUpdate: PersonX is frowning", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-552016ede2804ef390ea2baf4fd9feed", "input": "Premise: PersonX goes home empty handed\nHypothesis: PersonX is seen as feeling very sad\nUpdate: PersonX spends the money on better products.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-3a49c5bd5d03493facd8764f848c7f0b", "input": "Premise: PersonX comes a cropper\nHypothesis: As a result, PersonX feels hands on\nUpdate: X fails the class.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-f83a6d79b5b840cd97085b92c9b4163c", "input": "Premise: PersonX wants to learn how to draw\nHypothesis: PersonX then becomes better at drawing\nUpdate: PersonX cannot afford art supplies.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-be61e7c1a34645099769e330e2a5ff0d", "input": "Premise: PersonX updates PersonX's wardrobe\nHypothesis: As a result, PersonX feels fashionable\nUpdate: PersonX tries out their items like they are in the magazine", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-ba32b96ee32f45279e0bf1910f660eb0", "input": "Premise: PersonX retains PersonX's position\nHypothesis: As a result, PersonX wants to show work ethic\nUpdate: X now has seniority and can't be fired so he slacks off.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-21581108e8d944de9cebd5ccb1b15a45", "input": "Premise: PersonX tells PersonX's landlord\nHypothesis: Before, PersonX needed to know what to do\nUpdate: PersonX identified an issue with the house", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-f46a3136c4dc4ce69c81621a9b32f4d0", "input": "Premise: PersonX lies on the ground\nHypothesis: As a result, PersonX feels relaxed\nUpdate: PersonX is being arrested by the cops.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-7f223494ceea46ceaf88ead0f93480ad", "input": "Premise: PersonX bakes the cookies\nHypothesis: PersonX is seen as generous\nUpdate: A bake sale for charity is happening", "output": ["strengthener"]}, "Prediction": "strengthener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-048b463394704e5e8fc34bf109d00273", "input": "Premise: PersonX takes orders\nHypothesis: PersonX is seen as anxious if he could supply them on time.\nUpdate: The orders are simple and small.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-17412248e8ed4b3ab8829f0823164ef3", "input": "Premise: PersonX realizes it was saturday\nHypothesis: PersonX is seen as surprised\nUpdate: PersonX stayed in bed until 11 AM.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-2799857152404a6686cac02115e2458f", "input": "Premise: PersonX gets a phone call\nHypothesis: As a result, PersonX feels talkative\nUpdate: The phone call is from a debt collector.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-42dd8f204af746848c7ae42799d29165", "input": "Premise: PersonX buries in PersonY's hands\nHypothesis: PersonX is seen as helpless\nUpdate: They are both doing an acrobatic routine.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-f784034c05b947fb9d898e87f5dca934", "input": "Premise: PersonX applies the dye\nHypothesis: PersonX then gets good look\nUpdate: People start buying the dyed products", "output": ["strengthener"]}, "Prediction": "strengthener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-13b9641b65c048e4b9aa20f877ae61dd", "input": "Premise: PersonX cries PersonY's eyes\nHypothesis: PersonX then cries\nUpdate: No one came over to cheer PersonX up.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-11f2678c6c714cd4969bf762e3577cbd", "input": "Premise: PersonX gobbles PersonY up\nHypothesis: PersonX is seen as satisfied\nUpdate: PersonX's stomach is bulging", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-a426da86573b44038d6d92e57f146c6f", "input": "Premise: PersonX keeps an eye peeled\nHypothesis: As a result, PersonX wants find what they were looking for\nUpdate: PersonX has been asked to look out for potential big spenders.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-e1036a41424e417abc759699e8d33e60", "input": "Premise: PersonX minds PersonY business\nHypothesis: PersonX is seen as normal\nUpdate: PersonX is just a stranger ignoring others on a train.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-34b83956d42b48668d63c1bf7f2485dc", "input": "Premise: PersonX sells PersonX's motorcycle\nHypothesis: Before, PersonX needed to put up an add\nUpdate: X was approached as he parked in the lot and asked the price he'd sell at.", "output": ["weakener"]}, "Prediction": "strengthener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-0c761eb9a4694f84891fb44efe44f6ef", "input": "Premise: PersonX reduces PersonX's stress\nHypothesis: As a result, PersonX wants to sleep\nUpdate: PersonX is ready to take on the day.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-e423263700e54d619ef3c5983f1d836e", "input": "Premise: PersonX always ate\nHypothesis: PersonX then gets sick\nUpdate: PersonX ate a lot of meatballs.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-b4a59711fd734d9db6e06703412cbf06", "input": "Premise: PersonX takes matters\nHypothesis: PersonX is seen as contented with himself\nUpdate: Person X is relaxed.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-82b66fc0ac23463783df6398264bb156", "input": "Premise: PersonX wants a new hairstyle\nHypothesis: As a result, PersonX feels openminded\nUpdate: PersonX wants a new look.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-99739d32693a49b89d73aa3d699cbce1", "input": "Premise: PersonX owes PersonY money\nHypothesis: As a result, PersonX feels appreciative\nUpdate: PersonX frowns while paying out.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-18f4d94e57db4304b3b87f1418a0d78e", "input": "Premise: PersonX starts last week\nHypothesis: As a result, PersonX wants to shop for decorations for their desk\nUpdate: PersonX got a job as a bartender at a restaurant.", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-ca71648ac91e4d6887148f74da8afd16", "input": "Premise: PersonX fetches PersonY back\nHypothesis: As a result, PersonX feels attentive\nUpdate: PersonX asks if they can get anything else", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-04c716c6b539415eae7684b6f62660c0", "input": "Premise: PersonX goes free\nHypothesis: PersonX is seen as overjoyed\nUpdate: PersonX is seen crying", "output": ["weakener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-d728bb7b73a04f25b560e95c72e2461f", "input": "Premise: PersonX answers every question\nHypothesis: PersonX is seen as happy\nUpdate: PersonX answers in a friendly manner.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-23c5b385cec64a88b52ceaf28bedaa51", "input": "Premise: PersonX breaks my leg\nHypothesis: PersonX is seen as sorry\nUpdate: PersonX is crying", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-63c624b8a1944f859ab040e5262dfe59", "input": "Premise: PersonX sprains PersonX's wrist\nHypothesis: As a result, PersonX feels unfit\nUpdate: PersonX was trying to lift weights at the gym when they sprained their wrist.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-aa294765b8294401add65f646eefb875", "input": "Premise: PersonX gets my license\nHypothesis: As a result, PersonX feels dependable\nUpdate: PersonX went for a drive.", "output": ["strengthener"]}, "Prediction": "weakener"}
{"Task": "task935_defeasible_nli_atomic_classification_gpt3_0", "Definition": ["In this task, you are given a premise, a hypothesis, and an update. The premise sentence describes a real-world situation and is always assumed to be true. The hypothesis sentence describes an assumption or inference that you might make about that situation having read the premise. The update provides additional information about the situation that might weaken or strengthen the hypothesis. A weakener is a statement that weakens the hypothesis. It makes you much less likely to believe the hypothesis is true. A strengthener is a statement that strengthens the hypothesis. It makes you much more likely to believe the hypothesis is true. Your task is to output 'strengthener' or 'weakener' if the update strengths or weakens the hypothesis, respectively. If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was a good student would be a strengthener. This is because if PersonX was a good student, it is more likely that PersonX would do good activities.  If the premise is that PersonX seems interested, and the hypothesis is that PersonX will then do a good activity, then an update that PersonX was faking to get close to a girl would be a weakener. This is because if PersonX was faking"], "Instance": {"id": "task935-f6effa2f49ed4375a0d218b504c6a82d", "input": "Premise: PersonX is short on money\nHypothesis: As a result, PersonX wants to be better at saving\nUpdate: PersonX spends a lot of money.", "output": ["strengthener"]}, "Prediction": "weakener"}
