{
    "Contributors": [
        "Yeganeh Kordi"
    ],
    "Source": [
        "qasper"
    ],
    "URL": [
        "https://allenai.org/project/qasper/home"
    ],
    "Categories": [
        "Question Understanding"
    ],
    "Reasoning": [],
    "Definition": [
        "In this task, you will read a context from an academic paper and answer a question based on that context. There are three possible types of questions: \"Extractive\", \"Abstractive\", and \"Yes-no\". For an extractive question, the answer is found by taking extracts from the context and putting them together into a summary. For an abstractive question, the answer is found by paraphrasing the context using new sentences. A yes-no question is a question whose expected answer is one of two choices, typically yes or no."
    ],
    "Input_language": [
        "English"
    ],
    "Output_language": [
        "English"
    ],
    "Instruction_language": [
        "English"
    ],
    "Domains": [
        "Scientific Research Papers"
    ],
    "Positive Examples": [
        {
            "input": "We build a dataset of Twitter accounts based on two lists annotated in previous works. For the non-factual accounts, we rely on a list of 180 Twitter accounts from BIBREF1. On the other hand, for the factual accounts, we use a list with another 32 Twitter accounts from BIBREF19 that are considered trustworthy by independent third parties. \n Question: How did they obtain the dataset?",
            "output": "Extractive",
            "explanation": "The answer to this question has been explicitly mentioned in the context, so the question is extractive."
        },
        {
            "input": "We evaluate our pointer-generator performance using BLEU score. The baseline language model is trained using RNNLM BIBREF23 . Perplexity measure is used in the evaluation.\n\n \n Question: Did they use other evaluation metrics?",
            "output": "Yes-no",
            "explanation": "This is a good example, and the given question is a yes-no question."
        },
        {
            "input": "As in the example above, we pre-process documents by removing all numbers and interjections. \n Question: what processing was done on the speeches before being parsed?",
            "output": "Abstractive",
            "explanation": "Answering this question needs paraphrasing the context, so this question is abstractive."
        }
    ],
    "Negative Examples": [
        {
            "input": "For the English version, we performed both a thorough manual analysis and automatic evaluation across three commonly used TS datasets from two different domains  For the English version, we performed both a thorough manual analysis and automatic evaluation across three commonly used TS datasets from two different domains  The evaluation of the German version is in progress. \n Question: What are the corpora used for the task?",
            "output": "Yes-no",
            "explanation": "This question is extractive, and it's not a yes-no question."
        },
        {
            "input": "For Turkish, as the first dataset, we utilised the movie reviews which are collected from a popular website. The number of reviews in this movie corpus is 20,244 and the average number of words in reviews is 39. Each of these reviews has a star-rating score which is indicative of sentiment. These polarity scores are between the values 0.5 and 5, at intervals of 0.5. We consider a review to be negative it the score is equal to or lower than 2.5. On the other hand, if it is equal to or higher than 4, it is assumed to be positive. We have randomly selected 7,020 negative and 7,020 positive reviews and processed only them. \n Question: What details are given about the movie domain dataset?",
            "output": "Extractive",
            "explanation": "This question is Abstractive because we need to paraphrase the context to get to the answer."
        }
    ],
    "Instances": [
        {
            "id": "task462-fac9e58cfea9470da191c7c6aff7a332",
            "input": "We create two models both of which constitutes of three main parts: encoder, interaction and classifier and take two sequences as input. The encoder is shared among the sequences simply uses two stacked GRU layers. The interaction part consists of only attention for one model while for the another one it consists of attention and conflict combined as shown in (eqn.11) . The classifier part is simply stacked fully-connected layers.  \n Question: Which neural architecture do they use as a base for their attention conflict mechanisms?",
            "output": [
                "Abstractive"
            ]
        },
        {
            "id": "task462-8467170af23644d7ae51ac25386c637b",
            "input": "We evaluated our detection models on three benchmarks: the FCE test data (41K tokens) and the two alternative annotations of the CoNLL 2014 Shared Task dataset (30K tokens) BIBREF3 .  \n Question: Which annotated corpus did they use?",
            "output": [
                "Extractive"
            ]
        },
        {
            "id": "task462-2a8b0f16a42c42e0854771b4208462e0",
            "input": "Our novelties include:\n\nUsing self-play learning for the neural response ranker (described in detail below).\n\nOptimizing neural models for specific metrics (e.g. diversity, coherence) in our ensemble setup.\n\nTraining a separate dialog model for each user, personalizing our socialbot and making it more consistent.\n\nUsing a response classification predictor and a response classifier to predict and control aspects of responses such as sentiment, topic, offensiveness, diversity etc.\n\nUsing a model predictor to predict the best responding model, before the response candidates are generated, reducing computational expenses.\n\nUsing our entropy-based filtering technique to filter all dialog datasets, obtaining higher quality training data BIBREF3.\n\nBuilding big, pre-trained, hierarchical BERT and GPT dialog models BIBREF6, BIBREF7, BIBREF8.\n\nConstantly monitoring the user input through our automatic metrics, ensuring that the user stays engaged. \n Question: What is novel in author's approach?",
            "output": [
                "Abstractive"
            ]
        }
    ],
    "Instance License": [
        "CC BY 4.0"
    ]
}