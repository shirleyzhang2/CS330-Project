{
    "Contributors": [
        "Srija Macherla"
    ],
    "Source": [
        "ethos"
    ],
    "URL": [
        "https://huggingface.co/datasets/ethos"
    ],
    "Categories": [
        "Toxic Language Detection"
    ],
    "Reasoning": [
        "Commonsense Reasoning -> Social Situations"
    ],
    "Definition": [
        "In this task, you should read the given text and classify it as 'violence' if it mentions killing people or hurting them in any way. Otherwise, classify it as 'not violence'."
    ],
    "Input_language": [
        "English"
    ],
    "Output_language": [
        "English"
    ],
    "Instruction_language": [
        "English"
    ],
    "Domains": [
        "Social Media"
    ],
    "Positive Examples": [
        {
            "input": "You look like Japanese and speak like Indian. Both are disgusting go kill yourself",
            "output": "violence",
            "explanation": "This is a good example because the words kill and disgusting both relate to violence. Thus it is correctly labelled as 'violence'."
        },
        {
            "input": "who gives shit diamonds from the jews fuck them both",
            "output": "violence",
            "explanation": "This is a good example because the language is related to violence and is hateful. Thus, it is correctly classified."
        },
        {
            "input": "Some people are shit human beings",
            "output": "not violence",
            "explanation": "The words and language are not violence related and hence this is a good example of correctly classified not violence."
        }
    ],
    "Negative Examples": [
        {
            "input": "What about a global massacre of men? Dumb only girls",
            "output": "not violence",
            "explanation": "The word massacre relates to violence and yet it has been mislabelled as non-violent. Therefore, it is a bad example."
        },
        {
            "input": "Watching this kid trying to step up and walk with that crutches is the best thing in the world.",
            "output": "violence",
            "explanation": "There is no violent language involved in this example and it's mislabelled as violent. Thus, it is a bad example."
        }
    ],
    "Instances": [
        {
            "id": "task1605-454d1ccac66740e1b8380cf885c0a0d1",
            "input": "Let's go beat these queers!",
            "output": [
                "violence"
            ]
        },
        {
            "id": "task1605-09302ecfee33446f8857d95000bd5848",
            "input": "She said is christian. Well I now I want to bury her",
            "output": [
                "violence"
            ]
        },
        {
            "id": "task1605-d7a5c6ddb9914cbb89825711ab1b09fc",
            "input": "Anyone who listens to rap and is white is not part of the ethnostate and will be put to death.",
            "output": [
                "violence"
            ]
        }
    ],
    "Instance License": [
        "GPL 3.0"
    ]
}