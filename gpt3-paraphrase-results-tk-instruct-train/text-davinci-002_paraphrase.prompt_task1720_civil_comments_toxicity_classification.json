{
    "orignal_task": "task1720_civil_comments_toxicity_classification.json",
    "engine": "text-davinci-002",
    "template": "paraphrase.prompt",
    "original_prompt": "Categorize the comment on the basis of toxicity. If the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.) output Yes, otherwise output No.",
    "generated_prompts": [
        "Determine if the given comment is toxic or not. If the comment is harmful, malicious, derogatory, threatening, insulting, or an identity attack, output Yes. Otherwise, output No.",
        "Given a comment, categorize it as toxic or not toxic. If the comment is harmful, malicious, derogatory, threatening, insulting, or attacks someone's identity, output 'Yes'. Otherwise, output 'No'.",
        "Given a comment, categorize it as toxic or not toxic. If the comment is harmful, malicious, derogatory, insulting, or an identity attack, output 'Yes'. Otherwise, output 'No'.",
        "For the given comment, output 'Yes' if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.), or output 'No' if the comment is not toxic.",
        "In this task, you will take in a comment and determine if it is toxic or not. A comment is considered toxic if it is harmful, malicious, derogatory, a threat, an insult, or an attack on someone's identity. If the comment is any of these things, output Yes. Otherwise, output No.",
        "For the given comment, output 'Yes' if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.), or 'No' if the comment is not toxic.",
        "Given a comment, categorize it as being toxic or not. If the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.), output 'Yes'. Otherwise, output 'No'.",
        "Given a comment, if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.) output Yes, otherwise output No.",
        "In this task, you are given a comment. You must categorize the comment as being either toxic or not toxic. A toxic comment is harmful, malicious, derogatory, insulting, or an attack on someone's identity. If the comment is toxic, output 'Yes'. If the comment is not toxic, output 'No'.",
        "For the given comment, if it is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.), output Yes, otherwise output No.",
        "For the given comment, output 'Yes' if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.), or 'No' if the comment is not toxic.",
        "You will be given a comment. You need to output 'Yes' if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.), or 'No' if it is not.",
        "The task is to read a comment and decide if it is toxic or not. If the comment is harmful, malicious, derogatory, a threat, an insult, or an identity attack, then it is toxic and you should output Yes. If the comment is not any of those things, then it is not toxic and you should output No.",
        "Determine if the given comment is toxic or not. If the comment is harmful, malicious, derogatory, insulting, or is an identity attack, output 'Yes'. Otherwise, output 'No'.",
        "Given a comment, output 'Yes' if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.), otherwise output 'No'.",
        "Given a comment, if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.), output 'Yes', otherwise output 'No'.",
        "For the given comment, output 'Yes' if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.), and output 'No' if the comment is not toxic.",
        "Given a comment, if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.) output 'Yes', otherwise output 'No'.",
        "Given a comment, if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.), output Yes, otherwise output No.",
        "Determine whether the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.). If the comment is toxic, output 'Yes'. Otherwise, output 'No'.",
        "Given a comment, output 'Yes' if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.), or 'No' if the comment is not toxic.",
        "Given a comment, categorize it as toxic or not toxic. If the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.), output Yes. Otherwise, output No.",
        "For the given comment, output 'Yes' if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.), and output 'No' otherwise.",
        "Determine whether the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.). If the comment is toxic, output 'Yes'. Otherwise, output 'No'.",
        "For the given comment, output Yes if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.), and output No otherwise.",
        "Given a comment, categorize it as being toxic or not. If the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.), output 'Yes'. Otherwise, output 'No'.",
        "Determine whether the given comment is toxic or not. A comment is toxic if it is harmful, malicious, derogatory, threatening, insulting, or an attack on someone's identity. If the comment is any of these things, output Yes. Otherwise, output No.",
        "Given a comment, output 'Yes' if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.), and output 'No' if the comment is not toxic.",
        "For the given comment, output 'Yes' if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.), or output 'No' if the comment is not toxic.",
        "Determine whether the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.). If the comment is toxic, output Yes. Otherwise, output No.",
        "The comment will be categorized as toxic or not toxic. If the comment is toxic, output Yes. If the comment is not toxic, output No.",
        "Given a comment, categorize it as toxic or not toxic. If the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.), output 'Yes'. Otherwise, output 'No'."
    ]
}