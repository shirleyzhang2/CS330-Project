{
    "orignal_task": "task1720_civil_comments_toxicity_classification.json",
    "engine": "text-davinci-003",
    "template": "paraphrase.prompt",
    "original_prompt": "Categorize the comment on the basis of toxicity. If the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.) output Yes, otherwise output No.",
    "generated_prompts": [
        "For a given comment, you need to determine if the comment is toxic. Toxic comments include those that are harmful, malicious, derogatory, threatening, insulting, or involve identity attacks. If the comment is toxic, output 'Yes', otherwise output 'No'.",
        "Given a comment, determine whether it is toxic or not. If it is considered toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.), output Yes, otherwise output No.",
        "Given a comment, determine whether it is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.). Output Yes if the comment is toxic and No otherwise.",
        "Given a comment, you must decide whether it is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.). If the comment is toxic, output 'Yes', and if not, output 'No'.",
        "Given a comment, determine if it is toxic or not. If it is toxic (containing any of the following: harm, malice, derision, threats, insults, or identity attacks), output 'Yes', otherwise output 'No'.",
        "Given a comment, output 'Yes' if it is toxic (such as harmful, malicious, derogatory, threat, insult, identity attack, etc.), and 'No' otherwise. The toxicity of the comment needs to be assessed.",
        "You will be given a comment, and your task is to categorize it according to its toxicity. If the comment contains harmful, malicious, derogatory, threatening, insulting, or identity attacking content, output Yes. Otherwise, output No.",
        "Given a comment, determine if it is considered toxic. If the comment is harmful, malicious, derogatory, threatening, insulting, or an identity attack, output 'Yes', otherwise output 'No'.",
        "Given a comment, your task is to output 'Yes' or 'No' based on the toxicity of the comment. If the comment is toxic (harmful, malicious, derogatory, threatening, insulting, or an identity attack), output 'Yes', otherwise output 'No'.",
        "Given a comment, output 'Yes' if the comment is deemed to be toxic (harmful, malicious, derogatory, threatening, insulting, identity attacking, etc.) or 'No' if it is not.",
        "Given a comment, you must determine if the comment is toxic or not (harmful, malicious, derogatory, threat, insult, identity attck, etc.). If the comment is toxic, output Yes. If the comment is not toxic, output No.",
        "Given a comment, output 'Yes' if it is toxic (e.g. harmful, malicious, derogatory, threat, insult, identity attack, etc.), or 'No' if it is not.",
        "Determine if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.) by categorizing it. Output 'Yes' if the comment is toxic and 'No' if it is not.",
        "You must determine whether the given comment is toxic or not. If the comment is harmful, malicious, derogatory, threatening, insulting, or attacking someone's identity, output Yes. Otherwise, output No.",
        "You will receive a comment and you need to decide whether the comment is toxic or not. Toxic comments include harmful, malicious, derogatory, threatening, insulting, and identity attack content. If the comment is toxic, output 'Yes', otherwise output 'No'.",
        "Given a comment, output 'Yes' if the comment is considered toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.), otherwise output 'No'.",
        "Given a comment, you need to determine if it is toxic. If it is classified as toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.), then output Yes. Otherwise, output No.",
        "Given a comment, determine if it is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.). Output 'Yes' if the comment is toxic, otherwise output 'No'.",
        "Given a comment, you must determine if it is toxic or not. If the comment is harmful, malicious, derogatory, a threat, an insult, an identity attack, or any other type of toxicity, output Yes. If not, output No.",
        "Given a comment, determine if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.) and output Yes or No accordingly.",
        "Given a comment, determine if it is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.) and output 'Yes' if it is, and 'No' if it is not.",
        "Determine if the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.) and output 'Yes' or 'No' accordingly. If the comment is toxic, output 'Yes', otherwise output 'No'.",
        "Determine whether the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.) or not. If the comment is toxic, output 'Yes', otherwise output 'No'.",
        "Given a comment, classify it according to toxicity. If the comment is toxic, meaning it is harmful, malicious, derogatory, a threat, an insult, an identity attack, etc., output 'Yes'. Otherwise, output 'No'.",
        "Given a comment, determine whether it is toxic. Toxic includes harmful, malicious, derogatory, threatening, insulting, or attacking someone's identity. If the comment is toxic, output Yes; otherwise output No.",
        "You will be given a comment. Determine if the comment is toxic by looking for characteristics such as harmful, malicious, derogatory, threatening, insulting, or attacking identity. If it is toxic, output Yes, otherwise output No.",
        "Determine whether the comment is toxic or not. If the comment is malicious, derogatory, threatening, insulting, or attacking someone's identity, output 'Yes'. Otherwise, output 'No'.",
        "Given a comment, your task is to categorize the comment on the basis of toxicity. If the comment is toxic (harmful, malicious, derogatory, threat, insult, identity attack, etc.) then output 'Yes', otherwise output 'No'.",
        "Given a comment, determine whether it is toxic or not. If the comment is harmful, malicious, derogatory, a threat, an insult, or an identity attack, output Yes. Otherwise, output No.",
        "Given a comment, you must determine whether it is toxic (harmful, malicious, derogatory, threat, insult, identity attck, etc.) or not. If it is, output Yes, otherwise output No.",
        "Given a comment, determine if it is toxic. If it is a harmful, malicious, derogatory, threatening, insulting, or identity attacking statement, output 'Yes'. If it is not, output 'No'.",
        "Given a comment, you need to categorize it based on its toxicity. If the comment is malicious, derogatory, threatening, insulting, or attacking someone's identity, output 'Yes'. Otherwise, output 'No'."
    ]
}